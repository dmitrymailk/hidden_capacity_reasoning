{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model = Qwen2ForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A large language model is a type of artificial intelligence (AI) that can generate human-like text, such as written or spoken words, in response to prompts. These models are designed to understand and respond to complex natural language tasks, including generating creative writing, answering questions, and even composing complete sentences. Large language models have become increasingly popular in recent years due to their ability to process vast amounts of data quickly and accurately, making them useful for a wide range of applications, from customer service and education to research and healthcare.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model..1\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 896])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1 = model(\n",
    "    **model_inputs,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_1.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 896])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_2 = model(\n",
    "    inputs_embeds=torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    attention_mask=model_inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_2.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 896])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 896])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].reshape(10, 3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 896])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_2 = model(\n",
    "    inputs_embeds=torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    attention_mask=model_inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_2.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 896])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_3 = model(\n",
    "    inputs_embeds=model_output_1.hidden_states[-1].reshape(10, 3, -1),\n",
    "    # attention_mask=model_inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_3.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3, 896])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].reshape(1, 10, 3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(\n",
    "#     inputs_embeds=model_output_1.hidden_states[-1].reshape(1, 10, 3, -1),\n",
    "#     attention_mask=model_inputs[\"attention_mask\"],\n",
    "#     output_hidden_states=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 896])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Qwen2ModelEmbedPooler(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config).cuda()\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_embeds, attention_mask, window_size=3):\n",
    "        # разбиваем входящие эмбединги на бакеты и усредняем их\n",
    "        sum_mask = attention_mask.reshape(\n",
    "            attention_mask.shape[0],\n",
    "            window_size,\n",
    "            attention_mask.shape[1] // window_size,\n",
    "            -1,\n",
    "        ).sum(1)\n",
    "        embeds_sum = input_embeds.reshape(\n",
    "            attention_mask.shape[0],\n",
    "            window_size,\n",
    "            attention_mask.shape[1] // window_size,\n",
    "            -1,\n",
    "        ).sum(1)\n",
    "        input_embeds = embeds_sum / sum_mask\n",
    "        input_embeds = self.model(\n",
    "            inputs_embeds=input_embeds,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        return input_embeds\n",
    "\n",
    "\n",
    "embed_pooler = Qwen2ModelEmbedPooler.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "result = embed_pooler(\n",
    "    # model_output_1.hidden_states[-1],\n",
    "    torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    torch.cat(\n",
    "        [\n",
    "            model_inputs[\"attention_mask\"],\n",
    "            model_inputs[\"attention_mask\"],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    ")\n",
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 896])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3, 4, 5, 6]).reshape(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from transformers.cache_utils import (\n",
    "    Cache,\n",
    "    DynamicCache,\n",
    "    SlidingWindowCache,\n",
    "    StaticCache,\n",
    ")\n",
    "from transformers.processing_utils import Unpack\n",
    "from transformers.modeling_flash_attention_utils import FlashAttentionKwargs\n",
    "from transformers.utils import LossKwargs\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "\n",
    "\n",
    "class KwargsForCausalLM(FlashAttentionKwargs, LossKwargs): ...\n",
    "\n",
    "\n",
    "class Qwen2ForCausalEmbedModeling(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config)\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.lm_head = torch.nn.Linear(\n",
    "            config.hidden_size,\n",
    "            config.vocab_size,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.embed_pooler = Qwen2ModelEmbedPooler.from_pretrained(\"Qwen/Qwen2.5-1.5B\")\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        logits_to_keep: Union[int, torch.Tensor] = 0,\n",
    "        # pooled_mask: Optional[torch.Tensor] = None,\n",
    "        **kwargs: Unpack[KwargsForCausalLM],\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        output_attentions = (\n",
    "            output_attentions\n",
    "            if output_attentions is not None\n",
    "            else self.config.output_attentions\n",
    "        )\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states\n",
    "            if output_hidden_states is not None\n",
    "            else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        inputs_embeds_tokens = self.model.embed_tokens(input_ids)\n",
    "        # if pixel_values is not None:\n",
    "        #     pixel_values = pixel_values.type(self.visual.get_dtype())\n",
    "        #     image_embeds = self.visual(pixel_values, grid_thw=image_grid_thw)\n",
    "        #     n_image_tokens = (input_ids == self.config.image_token_id).sum().item()\n",
    "        #     n_image_features = image_embeds.shape[0]\n",
    "        #     if n_image_tokens != n_image_features:\n",
    "        #         raise ValueError(\n",
    "        #             f\"Image features and image tokens do not match: tokens: {n_image_tokens}, features {n_image_features}\"\n",
    "        #         )\n",
    "        #     image_mask = (\n",
    "        #         (input_ids == self.config.image_token_id)\n",
    "        #         .unsqueeze(-1)\n",
    "        #         .expand_as(inputs_embeds)\n",
    "        #         .to(inputs_embeds.device)\n",
    "        #     )\n",
    "        #     image_embeds = image_embeds.to(inputs_embeds.device, inputs_embeds.dtype)\n",
    "        #     inputs_embeds = inputs_embeds.masked_scatter(image_mask, image_embeds)\n",
    "        window_size = torch.tensor(\n",
    "            [\n",
    "                [4],\n",
    "                [3],\n",
    "            ]\n",
    "        ).cuda()\n",
    "        tokens_amount = torch.tensor(\n",
    "            [\n",
    "                [2],\n",
    "                [4],\n",
    "            ]\n",
    "        ).cuda()\n",
    "        lengths = window_size * tokens_amount\n",
    "        # max_len = lengths.max()\n",
    "        max_len = inputs_embeds_tokens.shape[1]\n",
    "        batch_size = window_size.shape[0]\n",
    "        pooled_mask = (\n",
    "            torch.arange(max_len, device=device)\n",
    "            .unsqueeze(0)\n",
    "            .expand(batch_size, max_len)\n",
    "        )\n",
    "        pooled_mask = (lengths >= pooled_mask).to(torch.long)\n",
    "        pooled_embeds = inputs_embeds * pooled_mask.to(inputs_embeds.dtype)\n",
    "        pooled_embeds = self.embed_pooler(pooled_embeds, pooled_mask)\n",
    "        embed_mask = (\n",
    "            (input_ids == self.config.image_token_id)\n",
    "            .unsqueeze(-1)\n",
    "            .expand_as(inputs_embeds)\n",
    "            .to(inputs_embeds.device)\n",
    "        )\n",
    "        inputs_embeds = inputs_embeds.masked_scatter(embed_mask, pooled_embeds)\n",
    "\n",
    "        # Из-за смешанной структуры, мы будем всегда подавать только эмбединги\n",
    "        # Идея позаимствована из qwen2vl\n",
    "        outputs = self.model(\n",
    "            input_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            cache_position=cache_position,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        # Only compute necessary logits, and do not upcast them to float if we are not computing the loss\n",
    "        slice_indices = (\n",
    "            slice(-logits_to_keep, None)\n",
    "            if isinstance(logits_to_keep, int)\n",
    "            else logits_to_keep\n",
    "        )\n",
    "        logits = self.lm_head(hidden_states[:, slice_indices, :])\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_function(\n",
    "                logits=logits,\n",
    "                labels=labels,\n",
    "                vocab_size=self.config.vocab_size,\n",
    "                **kwargs,\n",
    "            )\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование концепции qwen2vl для текстовых токенов и эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33464, 6832, 11, 264, 1186, 2566, 315, 5662, 6832, 11]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = \"Deep learning, a subfield of machine learning, has revolutionized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?\"\n",
    "\n",
    "tokenizer.encode(text_example)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151655]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|image_pad|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1318, 39304]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"text_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Случай первый - мы сжимаем только текстовые токены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>ized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 3\n",
    "chunk_size = 4\n",
    "new_tokens = []\n",
    "original_tokens = tokenizer.encode(text_example)\n",
    "new_tokens += tokenizer.encode(\"<|object_ref_start|>\") * chunk_size\n",
    "new_tokens += original_tokens[chunk_size * window_size :]\n",
    "tokenizer.decode(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning, a subfield of machine learning, has revolutionized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(original_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 43, 896])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tokens_torch = torch.tensor(\n",
    "    [\n",
    "        original_tokens,\n",
    "        original_tokens,\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "new_tokens_torch = torch.tensor(\n",
    "    [\n",
    "        new_tokens,\n",
    "        new_tokens,\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "# torch.Size([2, 51, 896])\n",
    "original_embeds = model.get_input_embeddings()(original_tokens_torch)\n",
    "# torch.Size([2, 43, 896]) 51 - 3*4 + 4\n",
    "compressed_embeds_template = model.get_input_embeddings()(new_tokens_torch)\n",
    "compressed_embeds_template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 43, 896])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Qwen2ModelEmbedPoolerV2(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config).cuda()\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_embeds):\n",
    "        input_embeds = self.model(\n",
    "            inputs_embeds=input_embeds,\n",
    "            output_hidden_states=True,\n",
    "        )[0]\n",
    "        input_embeds = input_embeds.sum(1) / torch.tensor(\n",
    "            input_embeds.shape[1],\n",
    "            device=input_embeds.device,\n",
    "        )\n",
    "        input_embeds = input_embeds.unsqueeze(1)\n",
    "        return input_embeds\n",
    "\n",
    "\n",
    "embed_pooler_v2 = Qwen2ModelEmbedPoolerV2.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "\n",
    "# torch.Size([8, 3, 896])\n",
    "compressed_embeds = original_embeds[:, : chunk_size * window_size].reshape(\n",
    "    chunk_size * original_embeds.shape[0],\n",
    "    window_size,\n",
    "    -1,\n",
    ")\n",
    "compressed_embeds.shape\n",
    "# torch.Size([8, 1, 896])\n",
    "pooled_embeds = embed_pooler_v2(compressed_embeds)\n",
    "# torch.Size([2, 4, 896])\n",
    "pooled_embeds = pooled_embeds.reshape(\n",
    "    original_embeds.shape[0],\n",
    "    chunk_size,\n",
    "    -1,\n",
    ")\n",
    "# torch.Size([2, 43, 896])\n",
    "compressed_embeds_template[:, :chunk_size] = pooled_embeds\n",
    "compressed_embeds_template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  1506,   279, 18414,   315, 20443, 11229,\n",
       "           304,  3213,  1635,    13,  5542,   656, 59711,  9331,   311, 34549,\n",
       "         15712,    11,  1181,  8357,   525, 10454, 14756, 70767,    13,  1988,\n",
       "          1128,  6896,   374,  5538,  6832,    30,  1597,  1128,  3643,   432,\n",
       "           773,  7988,    30],\n",
       "        [ -100,  -100,  -100,  -100,  1506,   279, 18414,   315, 20443, 11229,\n",
       "           304,  3213,  1635,    13,  5542,   656, 59711,  9331,   311, 34549,\n",
       "         15712,    11,  1181,  8357,   525, 10454, 14756, 70767,    13,  1988,\n",
       "          1128,  6896,   374,  5538,  6832,    30,  1597,  1128,  3643,   432,\n",
       "           773,  7988,    30]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = new_tokens_torch.clone()\n",
    "text_token_id = tokenizer.encode(\"<|object_ref_start|>\")[0]\n",
    "labels[labels == text_token_id] = -100\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7477, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1 = model(\n",
    "    inputs_embeds=compressed_embeds_template,\n",
    "    labels=labels,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_1.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Смешанный датасет. Совместно сжимаем токены текста и эмбединги "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входная последовательность может быть 5 видов.\n",
    "\n",
    "- когда у нас на входе только текст, который мы просто моделируем \n",
    "- когда на входе текст, но мы хотим сжать его некоторые части\n",
    "- когда на входе текст и эмбединги с последнего слоя, где мы хотим сжать только части текста\n",
    "- когда на входе текст и эмбединги с последнего слоя, где мы хотим сжать, часть текста и эмбедингов, совместно (токены переводим в эмбединги и сжимаем вместе с hidden states)\n",
    "- когда на входе текст и эмбединги с последнего слоя, где мы хотим сжать, только эмбединги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы решаем какие токены хотим сжать?\n",
    "- никак. Просто говорим сожми с такого по такой.\n",
    "- это норм только на этапе обучения, так как мы можем перебрать все комбинации.\n",
    "- не норм на этапе инференса. например мы можем сжимать после каждых сгенеренных 10 токенов или 100, 1000. а какое окно контекста? 3, 10, 100? А что если менять стратегию. Сначала мы сжимали с окном 5 токенов, потом 20?\n",
    "- Кажется что эти гиперпараметры можно найти простым перебором на валидации. Однако перебор стратегии уже не кажется таким очевидным. Напрашивается RL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[33464, 6832, 11, 264, 1186, 2566, 315, 5662, 6832, 11, 702, 13791, 1506, 279, 18414, 315, 20443, 11229, 304, 3213, 1635, 13, 5542, 656, 59711, 9331, 311, 34549, 15712, 11, 1181, 8357, 525, 10454, 14756, 70767, 13, 1988, 1128, 6896, 374, 5538, 6832, 30, 1597, 1128, 3643, 432, 773, 7988, 30], [10227, 42415, 1119, 279, 330, 32880, 1, 949, 11, 1077, 594, 5695, 264, 16266, 448, 279, 31774, 315, 20443, 29728, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 151643, 151643, 151643, 151643, 151643, 151643, 151643]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = [\n",
    "    \"Deep learning, a subfield of machine learning, has revolutionized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?\",\n",
    "    \"\"\"Before diving into the \"deep\" part, let's establish a foundation with the basics of artificial neural networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers. These layers typically include:\"\"\",\n",
    "]\n",
    "\n",
    "tokenizer.batch_encode_plus(\n",
    "    text_example,\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(151643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 43, 896])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_tokens len=51 full_chunks_amount=4\n",
      "chunks_for_tokenization={0, 2}\n",
      "=== replaced_original_tokens\n",
      "<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>ized the landscape of artificial intelligence in recent years. From self<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>. But what exactly is deep learning? And what makes it so powerful?\n",
      "=== new_input_tokens\n",
      "<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>ized the landscape of artificial intelligence in recent years. From self<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>. But what exactly is deep learning? And what makes it so powerful?\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from more_itertools import chunked\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "text_token_id = tokenizer.encode(\"<|object_ref_start|>\")[0]\n",
    "\n",
    "window_size = 3\n",
    "chunk_size = 4\n",
    "new_tokens = []\n",
    "original_tokens = tokenizer.encode(text_example)\n",
    "full_chunks_amount = len(original_tokens) // (window_size * chunk_size)\n",
    "print(\n",
    "    f\"original_tokens len={len(original_tokens)} full_chunks_amount={full_chunks_amount}\"\n",
    ")\n",
    "max_percent = 0.8\n",
    "original_tokens_chunks = list(chunked(original_tokens, window_size * chunk_size))\n",
    "\n",
    "prob = 0.3\n",
    "random_mask = np.random.random(int(full_chunks_amount * max_percent))\n",
    "mask = random_mask < prob\n",
    "chunks_for_tokenization = np.where(mask)[0].tolist()\n",
    "chunks_for_tokenization = set(chunks_for_tokenization)\n",
    "if len(chunks_for_tokenization) == 0:\n",
    "    chunks_for_tokenization = set(\n",
    "        [\n",
    "            random.randint(\n",
    "                0,\n",
    "                int(full_chunks_amount * max_percent),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "# for debug\n",
    "chunks_for_tokenization = set([0, 2])\n",
    "print(f\"chunks_for_tokenization={chunks_for_tokenization}\")\n",
    "replaced_original_tokens = []\n",
    "new_input_tokens = []\n",
    "for i, tokens in enumerate(original_tokens_chunks):\n",
    "    if i in chunks_for_tokenization:\n",
    "        replaced_original_tokens.extend([text_token_id] * len(tokens))\n",
    "        new_input_tokens.extend([text_token_id] * chunk_size)\n",
    "    else:\n",
    "        replaced_original_tokens.extend(tokens)\n",
    "        new_input_tokens.extend(tokens)\n",
    "print(\"=== replaced_original_tokens\")\n",
    "print(tokenizer.decode(replaced_original_tokens))\n",
    "print(\"=== new_input_tokens\")\n",
    "print(tokenizer.decode(new_input_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 35, 896])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tokens_torch = torch.tensor(\n",
    "    [\n",
    "        replaced_original_tokens,\n",
    "        replaced_original_tokens,\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "new_tokens_torch = torch.tensor(\n",
    "    [\n",
    "        new_input_tokens,\n",
    "        new_input_tokens,\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "# torch.Size([2, 51, 896])\n",
    "original_embeds = model.get_input_embeddings()(original_tokens_torch)\n",
    "# torch.Size([2, 35, 896]) 51 - 3*4*2 + 4*2\n",
    "compressed_embeds_template = model.get_input_embeddings()(new_tokens_torch)\n",
    "compressed_embeds_template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False]], device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_for_compression_mask = original_tokens_torch == text_token_id\n",
    "tokens_for_compression_mask"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
