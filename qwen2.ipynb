{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model = Qwen2ForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.bfloat16, torch.bfloat16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_input_embeddings().weight.dtype, model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A large language model is a type of artificial intelligence that can generate human-like text based on input data, such as natural language sentences or questions. These models are designed to mimic the complexity and creativity of human language, allowing them to produce coherent and meaningful responses that can be used in various applications, including speech recognition, chatbots, and virtual assistants. Large language models have been trained on vast amounts of text data, enabling them to understand and respond to complex queries and ideas more accurately than traditional AI systems.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model..1\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 30, 896]), torch.bfloat16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1 = model(\n",
    "    **model_inputs,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_1.hidden_states[-1].shape, model_output_1.hidden_states[-1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 896])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_2 = model(\n",
    "    inputs_embeds=torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    attention_mask=model_inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_2.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 896])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 896])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].reshape(10, 3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 30, 896]), torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_2 = model(\n",
    "    inputs_embeds=torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    attention_mask=model_inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_2.hidden_states[-1].shape, model_output_2.hidden_states[-1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 896])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_3 = model(\n",
    "    inputs_embeds=model_output_1.hidden_states[-1].reshape(10, 3, -1),\n",
    "    # attention_mask=model_inputs[\"attention_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_3.hidden_states[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3, 896])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1.hidden_states[-1].reshape(1, 10, 3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(\n",
    "#     inputs_embeds=model_output_1.hidden_states[-1].reshape(1, 10, 3, -1),\n",
    "#     attention_mask=model_inputs[\"attention_mask\"],\n",
    "#     output_hidden_states=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 896])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Qwen2ModelEmbedPooler(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config).cuda()\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_embeds, attention_mask, window_size=3):\n",
    "        # разбиваем входящие эмбединги на бакеты и усредняем их\n",
    "        sum_mask = attention_mask.reshape(\n",
    "            attention_mask.shape[0],\n",
    "            window_size,\n",
    "            attention_mask.shape[1] // window_size,\n",
    "            -1,\n",
    "        ).sum(1)\n",
    "        embeds_sum = input_embeds.reshape(\n",
    "            attention_mask.shape[0],\n",
    "            window_size,\n",
    "            attention_mask.shape[1] // window_size,\n",
    "            -1,\n",
    "        ).sum(1)\n",
    "        input_embeds = embeds_sum / sum_mask\n",
    "        input_embeds = self.model(\n",
    "            inputs_embeds=input_embeds,\n",
    "            output_hidden_states=True,\n",
    "        )\n",
    "        return input_embeds\n",
    "\n",
    "\n",
    "embed_pooler = Qwen2ModelEmbedPooler.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "result = embed_pooler(\n",
    "    # model_output_1.hidden_states[-1],\n",
    "    torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    torch.cat(\n",
    "        [\n",
    "            model_inputs[\"attention_mask\"],\n",
    "            model_inputs[\"attention_mask\"],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    ")\n",
    "result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 896])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1, 2, 3, 4, 5, 6]).reshape(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from transformers.cache_utils import (\n",
    "    Cache,\n",
    "    DynamicCache,\n",
    "    SlidingWindowCache,\n",
    "    StaticCache,\n",
    ")\n",
    "from transformers.processing_utils import Unpack\n",
    "from transformers.modeling_flash_attention_utils import FlashAttentionKwargs\n",
    "from transformers.utils import LossKwargs\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutputWithPast,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "\n",
    "\n",
    "class KwargsForCausalLM(FlashAttentionKwargs, LossKwargs): ...\n",
    "\n",
    "\n",
    "class Qwen2ForCausalEmbedModeling(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config)\n",
    "        self.vocab_size = config.vocab_size\n",
    "        self.lm_head = torch.nn.Linear(\n",
    "            config.hidden_size,\n",
    "            config.vocab_size,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.embed_pooler = Qwen2ModelEmbedPooler.from_pretrained(\"Qwen/Qwen2.5-1.5B\")\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[Union[Cache, List[torch.FloatTensor]]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        logits_to_keep: Union[int, torch.Tensor] = 0,\n",
    "        # pooled_mask: Optional[torch.Tensor] = None,\n",
    "        **kwargs: Unpack[KwargsForCausalLM],\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        output_attentions = (\n",
    "            output_attentions\n",
    "            if output_attentions is not None\n",
    "            else self.config.output_attentions\n",
    "        )\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states\n",
    "            if output_hidden_states is not None\n",
    "            else self.config.output_hidden_states\n",
    "        )\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        inputs_embeds_tokens = self.model.embed_tokens(input_ids)\n",
    "        # if pixel_values is not None:\n",
    "        #     pixel_values = pixel_values.type(self.visual.get_dtype())\n",
    "        #     image_embeds = self.visual(pixel_values, grid_thw=image_grid_thw)\n",
    "        #     n_image_tokens = (input_ids == self.config.image_token_id).sum().item()\n",
    "        #     n_image_features = image_embeds.shape[0]\n",
    "        #     if n_image_tokens != n_image_features:\n",
    "        #         raise ValueError(\n",
    "        #             f\"Image features and image tokens do not match: tokens: {n_image_tokens}, features {n_image_features}\"\n",
    "        #         )\n",
    "        #     image_mask = (\n",
    "        #         (input_ids == self.config.image_token_id)\n",
    "        #         .unsqueeze(-1)\n",
    "        #         .expand_as(inputs_embeds)\n",
    "        #         .to(inputs_embeds.device)\n",
    "        #     )\n",
    "        #     image_embeds = image_embeds.to(inputs_embeds.device, inputs_embeds.dtype)\n",
    "        #     inputs_embeds = inputs_embeds.masked_scatter(image_mask, image_embeds)\n",
    "        window_size = torch.tensor(\n",
    "            [\n",
    "                [4],\n",
    "                [3],\n",
    "            ]\n",
    "        ).cuda()\n",
    "        tokens_amount = torch.tensor(\n",
    "            [\n",
    "                [2],\n",
    "                [4],\n",
    "            ]\n",
    "        ).cuda()\n",
    "        lengths = window_size * tokens_amount\n",
    "        # max_len = lengths.max()\n",
    "        max_len = inputs_embeds_tokens.shape[1]\n",
    "        batch_size = window_size.shape[0]\n",
    "        pooled_mask = (\n",
    "            torch.arange(max_len, device=device)\n",
    "            .unsqueeze(0)\n",
    "            .expand(batch_size, max_len)\n",
    "        )\n",
    "        pooled_mask = (lengths >= pooled_mask).to(torch.long)\n",
    "        pooled_embeds = inputs_embeds * pooled_mask.to(inputs_embeds.dtype)\n",
    "        pooled_embeds = self.embed_pooler(pooled_embeds, pooled_mask)\n",
    "        embed_mask = (\n",
    "            (input_ids == self.config.image_token_id)\n",
    "            .unsqueeze(-1)\n",
    "            .expand_as(inputs_embeds)\n",
    "            .to(inputs_embeds.device)\n",
    "        )\n",
    "        inputs_embeds = inputs_embeds.masked_scatter(embed_mask, pooled_embeds)\n",
    "\n",
    "        # Из-за смешанной структуры, мы будем всегда подавать только эмбединги\n",
    "        # Идея позаимствована из qwen2vl\n",
    "        outputs = self.model(\n",
    "            input_ids=None,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            cache_position=cache_position,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        hidden_states = outputs[0]\n",
    "        # Only compute necessary logits, and do not upcast them to float if we are not computing the loss\n",
    "        slice_indices = (\n",
    "            slice(-logits_to_keep, None)\n",
    "            if isinstance(logits_to_keep, int)\n",
    "            else logits_to_keep\n",
    "        )\n",
    "        logits = self.lm_head(hidden_states[:, slice_indices, :])\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_function(\n",
    "                logits=logits,\n",
    "                labels=labels,\n",
    "                vocab_size=self.config.vocab_size,\n",
    "                **kwargs,\n",
    "            )\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return (loss,) + output if loss is not None else output\n",
    "\n",
    "        return CausalLMOutputWithPast(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            past_key_values=outputs.past_key_values,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование концепции qwen2vl для текстовых токенов и эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33464, 6832, 11, 264, 1186, 2566, 315, 5662, 6832, 11]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = \"Deep learning, a subfield of machine learning, has revolutionized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?\"\n",
    "\n",
    "tokenizer.encode(text_example)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151655]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|image_pad|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1318, 39304]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"text_example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Случай первый - мы сжимаем только текстовые токены (максимально упрощенный вариант)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>ized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 3\n",
    "chunk_size = 4\n",
    "new_tokens = []\n",
    "original_tokens = tokenizer.encode(text_example)\n",
    "new_tokens += tokenizer.encode(\"<|object_ref_start|>\") * chunk_size\n",
    "new_tokens += original_tokens[chunk_size * window_size :]\n",
    "tokenizer.decode(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning, a subfield of machine learning, has revolutionized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(original_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 43, 896]), torch.bfloat16, torch.bfloat16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tokens_torch = torch.tensor(\n",
    "    [\n",
    "        original_tokens,\n",
    "        original_tokens,\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "new_tokens_torch = torch.tensor(\n",
    "    [\n",
    "        new_tokens,\n",
    "        new_tokens,\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "# torch.Size([2, 51, 896])\n",
    "original_embeds = model.get_input_embeddings()(original_tokens_torch)\n",
    "# torch.Size([2, 43, 896]) 51 - 3*4 + 4\n",
    "compressed_embeds_template = model.get_input_embeddings()(new_tokens_torch)\n",
    "compressed_embeds_template.shape, compressed_embeds_template.dtype, original_embeds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 43, 896]), torch.bfloat16, torch.bfloat16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Qwen2ModelEmbedPoolerV2(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config)\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_embeds):\n",
    "        # print(input_embeds.dtype)\n",
    "        input_embeds = self.model(\n",
    "            inputs_embeds=input_embeds,\n",
    "            output_hidden_states=True,\n",
    "        )[0]\n",
    "        # print(input_embeds.dtype)\n",
    "        input_embeds = input_embeds.sum(1) / torch.tensor(\n",
    "            input_embeds.shape[1],\n",
    "            device=input_embeds.device,\n",
    "        )\n",
    "        # print(input_embeds.dtype)\n",
    "        input_embeds = input_embeds.unsqueeze(1)\n",
    "        return input_embeds\n",
    "\n",
    "\n",
    "embed_pooler_v2 = Qwen2ModelEmbedPoolerV2.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-0.5B\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "\n",
    "# torch.Size([8, 3, 896])\n",
    "compressed_embeds = original_embeds[:, : chunk_size * window_size].reshape(\n",
    "    chunk_size * original_embeds.shape[0],\n",
    "    window_size,\n",
    "    -1,\n",
    ")\n",
    "compressed_embeds.shape\n",
    "# torch.Size([8, 1, 896])\n",
    "pooled_embeds = embed_pooler_v2(compressed_embeds)\n",
    "# torch.Size([2, 4, 896])\n",
    "pooled_embeds = pooled_embeds.reshape(\n",
    "    original_embeds.shape[0],\n",
    "    chunk_size,\n",
    "    -1,\n",
    ")\n",
    "# torch.Size([2, 43, 896])\n",
    "compressed_embeds_template[:, :chunk_size] = pooled_embeds\n",
    "compressed_embeds_template.shape, compressed_embeds_template.dtype, pooled_embeds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_pooler_v2.model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  1506,   279, 18414,   315, 20443, 11229,\n",
       "           304,  3213,  1635,    13,  5542,   656, 59711,  9331,   311, 34549,\n",
       "         15712,    11,  1181,  8357,   525, 10454, 14756, 70767,    13,  1988,\n",
       "          1128,  6896,   374,  5538,  6832,    30,  1597,  1128,  3643,   432,\n",
       "           773,  7988,    30],\n",
       "        [ -100,  -100,  -100,  -100,  1506,   279, 18414,   315, 20443, 11229,\n",
       "           304,  3213,  1635,    13,  5542,   656, 59711,  9331,   311, 34549,\n",
       "         15712,    11,  1181,  8357,   525, 10454, 14756, 70767,    13,  1988,\n",
       "          1128,  6896,   374,  5538,  6832,    30,  1597,  1128,  3643,   432,\n",
       "           773,  7988,    30]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = new_tokens_torch.clone()\n",
    "text_token_id = tokenizer.encode(\"<|object_ref_start|>\")[0]\n",
    "labels[labels == text_token_id] = -100\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7288, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1 = model(\n",
    "    inputs_embeds=compressed_embeds_template,\n",
    "    labels=labels,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_1.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Усложненная версия токенизации текста. Сжатые токены возникают между обычным тектом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входная последовательность может быть 5 видов.\n",
    "\n",
    "- когда у нас на входе только текст, который мы просто моделируем \n",
    "- когда на входе текст, но мы хотим сжать его некоторые части\n",
    "- когда на входе текст и эмбединги с последнего слоя, где мы хотим сжать только части текста\n",
    "- когда на входе текст и эмбединги с последнего слоя, где мы хотим сжать, часть текста и эмбедингов, совместно (токены переводим в эмбединги и сжимаем вместе с hidden states)\n",
    "- когда на входе текст и эмбединги с последнего слоя, где мы хотим сжать, только эмбединги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы решаем какие токены хотим сжать?\n",
    "- никак. Просто говорим сожми с такого по такой.\n",
    "- это норм только на этапе обучения, так как мы можем перебрать все комбинации.\n",
    "- не норм на этапе инференса. например мы можем сжимать после каждых сгенеренных 10 токенов или 100, 1000. а какое окно контекста? 3, 10, 100? А что если менять стратегию. Сначала мы сжимали с окном 5 токенов, потом 20?\n",
    "- Кажется что эти гиперпараметры можно найти простым перебором на валидации. Однако перебор стратегии уже не кажется таким очевидным. Напрашивается RL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[33464, 6832, 11, 264, 1186, 2566, 315, 5662, 6832, 11, 702, 13791, 1506, 279, 18414, 315, 20443, 11229, 304, 3213, 1635, 13, 5542, 656, 59711, 9331, 311, 34549, 15712, 11, 1181, 8357, 525, 10454, 14756, 70767, 13, 1988, 1128, 6896, 374, 5538, 6832, 30, 1597, 1128, 3643, 432, 773, 7988, 30, 220, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], [10227, 42415, 1119, 279, 330, 32880, 1, 949, 11, 1077, 594, 5695, 264, 16266, 448, 279, 31774, 315, 20443, 29728, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_example = [\n",
    "    \"Deep learning, a subfield of machine learning, has revolutionized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful? \",\n",
    "    \"\"\"Before diving into the \"deep\" part, let's establish a foundation with the basics of artificial neural networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers. These layers typically include: These layers typically include: These layers typically include: networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers. These layers typically include: These layers typically include: These layers typically include: networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers. These layers typically include: These layers typically include: These layers typically include:\"\"\",\n",
    "]\n",
    "\n",
    "tokenizer.batch_encode_plus(\n",
    "    text_example,\n",
    "    padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 122])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(\n",
    "    tokenizer.batch_encode_plus(\n",
    "        text_example,\n",
    "        padding=True,\n",
    "    )[\"input_ids\"]\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(151643)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33464, 6832, 11, 264, 1186, 2566, 315, 5662, 6832, 11, 702, 13791, 1506, 279, 18414, 315, 20443, 11229, 304, 3213, 1635, 13, 5542, 656, 59711, 9331, 311, 34549, 15712, 11, 1181, 8357, 525, 10454, 14756, 70767, 13, 1988, 1128, 6896, 374, 5538, 6832, 30, 1597, 1128, 3643, 432, 773, 7988, 30, 220]\n",
      "4\n",
      "[[33464, 6832, 11, 264, 1186, 2566, 315, 5662, 6832, 11, 702, 13791], [1506, 279, 18414, 315, 20443, 11229, 304, 3213, 1635, 13, 5542, 656], [59711, 9331, 311, 34549, 15712, 11, 1181, 8357, 525, 10454, 14756, 70767], [13, 1988, 1128, 6896, 374, 5538, 6832, 30, 1597, 1128, 3643, 432], [773, 7988, 30, 220]]\n",
      "chunks_for_tokenization  {0}\n",
      "=== replaced_original_tokens\n",
      "<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>ized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful? \n",
      "=== new_input_tokens\n",
      "<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>ized the landscape of artificial intelligence in recent years. From self-driving cars to personalized medicine, its applications are becoming increasingly pervasive. But what exactly is deep learning? And what makes it so powerful? \n",
      "44\n",
      "==\n",
      "==\n",
      "==\n",
      "[10227, 42415, 1119, 279, 330, 32880, 1, 949, 11, 1077, 594, 5695, 264, 16266, 448, 279, 31774, 315, 20443, 29728, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 14155, 320, 12003, 82, 568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25]\n",
      "10\n",
      "[[10227, 42415, 1119, 279, 330, 32880, 1, 949, 11, 1077, 594, 5695], [264, 16266, 448, 279, 31774, 315, 20443, 29728, 14155, 320, 12003, 82], [568, 1527, 76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645], [304, 13617, 13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924], [25, 4220, 13617, 11136, 2924, 25, 14155, 320, 12003, 82, 568, 1527], [76406, 17167, 315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617], [13, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220], [13617, 11136, 2924, 25, 14155, 320, 12003, 82, 568, 1527, 76406, 17167], [315, 82316, 7798, 11, 2598, 33213, 11, 16645, 304, 13617, 13, 4220], [13617, 11136, 2924, 25, 4220, 13617, 11136, 2924, 25, 4220, 13617, 11136], [2924, 25]]\n",
      "chunks_for_tokenization  {2, 3, 6}\n",
      "=== replaced_original_tokens\n",
      "Before diving into the \"deep\" part, let's establish a foundation with the basics of artificial neural networks (ANNs<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>: These layers typically include: networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|> layers typically include: networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers. These layers typically include: These layers typically include: These layers typically include:\n",
      "=== new_input_tokens\n",
      "Before diving into the \"deep\" part, let's establish a foundation with the basics of artificial neural networks (ANNs<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|>: These layers typically include: networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers<|object_ref_start|><|object_ref_start|><|object_ref_start|><|object_ref_start|> layers typically include: networks (ANNs). An ANN consists of interconnected nodes, called neurons, organized in layers. These layers typically include: These layers typically include: These layers typically include:\n",
      "98\n",
      "==\n",
      "==\n",
      "==\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2, 98), (2, 122), (2, 122))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from more_itertools import chunked\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "text_token_id = tokenizer.encode(\"<|object_ref_start|>\")[0]\n",
    "eos_token_id = tokenizer.encode(\"<|endoftext|>\")[0]\n",
    "\n",
    "window_size = 3\n",
    "chunk_size = 4\n",
    "new_tokens = []\n",
    "original_tokens = tokenizer.batch_encode_plus(\n",
    "    text_example,\n",
    "    padding=True,\n",
    ")\n",
    "compressed_tokens = []\n",
    "replaced_original_tokens_batch = []\n",
    "# original_tokens\n",
    "for tokens in original_tokens[\"input_ids\"]:\n",
    "    original_lines = np.array(tokens)\n",
    "    pure_tokens = original_lines[original_lines != eos_token_id].tolist()\n",
    "    print(pure_tokens)\n",
    "    full_chunks_amount = len(pure_tokens) // (window_size * chunk_size)\n",
    "    print(full_chunks_amount)\n",
    "    max_percent = 0.8\n",
    "    pure_tokens_chunks = list(chunked(pure_tokens, window_size * chunk_size))\n",
    "    print(pure_tokens_chunks)\n",
    "    prob = 0.3\n",
    "    random_mask = np.random.random(int(full_chunks_amount * max_percent))\n",
    "    mask = random_mask < prob\n",
    "    chunks_for_tokenization = np.where(mask)[0].tolist()\n",
    "    chunks_for_tokenization = set(chunks_for_tokenization)\n",
    "    if len(chunks_for_tokenization) == 0:\n",
    "        chunks_for_tokenization = set(\n",
    "            [\n",
    "                random.randint(\n",
    "                    0,\n",
    "                    int(full_chunks_amount * max_percent),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    print(\"chunks_for_tokenization \", chunks_for_tokenization)\n",
    "    replaced_original_tokens = []\n",
    "    new_input_tokens = []\n",
    "    for i, tokens in enumerate(pure_tokens_chunks):\n",
    "        if i in chunks_for_tokenization:\n",
    "            replaced_original_tokens.extend([text_token_id] * len(tokens))\n",
    "            new_input_tokens.extend([text_token_id] * chunk_size)\n",
    "        else:\n",
    "            replaced_original_tokens.extend(tokens)\n",
    "            new_input_tokens.extend(tokens)\n",
    "    print(\"=== replaced_original_tokens\")\n",
    "    print(tokenizer.decode(replaced_original_tokens))\n",
    "    print(\"=== new_input_tokens\")\n",
    "    print(tokenizer.decode(new_input_tokens))\n",
    "    print(len(new_input_tokens))\n",
    "    compressed_tokens.append(new_input_tokens)\n",
    "    replaced_original_tokens_batch.append(replaced_original_tokens)\n",
    "    print(\"==\")\n",
    "    print(\"==\")\n",
    "    print(\"==\")\n",
    "\n",
    "compressed_tokens_attention = []\n",
    "max_compressed_len = max([len(item) for item in compressed_tokens])\n",
    "max_replaced_len = max([len(item) for item in replaced_original_tokens_batch])\n",
    "\n",
    "for compressed_seq, replaced_seq in zip(\n",
    "    compressed_tokens,\n",
    "    replaced_original_tokens_batch,\n",
    "):\n",
    "    compressed_seq_len = len(compressed_seq)\n",
    "    replaced_seq_len = len(replaced_seq)\n",
    "    attention_mask = [1] * (compressed_seq_len)\n",
    "\n",
    "    if compressed_seq_len < max_compressed_len:\n",
    "        compressed_seq += [eos_token_id] * (max_compressed_len - compressed_seq_len)\n",
    "        attention_mask += [0] * (max_compressed_len - compressed_seq_len)\n",
    "\n",
    "    if compressed_seq_len < max_replaced_len:\n",
    "        replaced_seq += [eos_token_id] * (max_replaced_len - replaced_seq_len)\n",
    "\n",
    "    compressed_tokens_attention.append(attention_mask)\n",
    "# len(compressed_tokens[0]), len(compressed_tokens[1])\n",
    "# compressed_tokens = torch.tensor(compressed_tokens)\n",
    "# compressed_tokens_attention = torch.tensor(compressed_tokens_attention)\n",
    "np.array(compressed_tokens).shape, np.array(\n",
    "    replaced_original_tokens_batch\n",
    ").shape, np.array(original_tokens[\"input_ids\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 98, 896]),\n",
       " torch.Size([2, 122, 896]),\n",
       " torch.Size([2, 122, 896]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tokens_torch = torch.tensor(\n",
    "    original_tokens[\"input_ids\"],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "replaced_tokens_torch = torch.tensor(\n",
    "    replaced_original_tokens_batch,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "compressed_tokens_torch = torch.tensor(\n",
    "    compressed_tokens,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "# torch.Size([2, 51, 896])\n",
    "original_embeds = model.get_input_embeddings()(original_tokens_torch)\n",
    "replaced_embeds = model.get_input_embeddings()(replaced_tokens_torch)\n",
    "# torch.Size([2, 35, 896]) 51 - 3*4*2 + 4*2\n",
    "compressed_embeds_template = model.get_input_embeddings()(compressed_tokens_torch)\n",
    "compressed_embeds_template.shape, original_embeds.shape, replaced_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.bfloat16, torch.bfloat16, torch.bfloat16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_embeds_template.dtype, original_embeds.dtype, replaced_embeds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151646"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 896]), torch.Size([16]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_for_compression_mask = replaced_tokens_torch == text_token_id\n",
    "compressed_tokens_mask = compressed_tokens_torch == text_token_id\n",
    "# original_tokens_torch[tokens_for_compression_mask].shape\n",
    "original_embeds[tokens_for_compression_mask].shape, compressed_tokens_torch[\n",
    "    compressed_tokens_mask\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 896])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds_for_compression = original_embeds[tokens_for_compression_mask].reshape(\n",
    "    -1,\n",
    "    window_size,\n",
    "    original_embeds.shape[-1],\n",
    ")\n",
    "embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 896]), torch.bfloat16)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_embeds = embed_pooler_v2(embeds_for_compression)\n",
    "# pooled_embeds = pooled_embeds.reshape(pooled_embeds.shape[0], -1)\n",
    "pooled_embeds.shape, pooled_embeds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1],\n",
       "        [2, 3, 0, 4, 5]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "self = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0],\n",
    "    ]\n",
    ")\n",
    "mask = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 0, 0, 1],\n",
    "        [1, 1, 0, 1, 1],\n",
    "    ],\n",
    "    dtype=torch.bool,\n",
    ")\n",
    "source = torch.tensor(\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    ")\n",
    "self.masked_scatter_(mask, source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 98, 896])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_embeds_template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 98])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_tokens_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 98, 896])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_embeds_template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 98])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_tokens_mask.shape\n",
    "# .expand_as(compressed_embeds_template).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 98, 896])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_tokens_mask.unsqueeze(-1).expand_as(compressed_embeds_template).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.bfloat16, torch.float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_embeds_template.dtype, pooled_embeds.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 98, 896])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_embeds_template.masked_scatter(\n",
    "    compressed_tokens_mask.unsqueeze(-1).expand_as(compressed_embeds_template),\n",
    "    pooled_embeds,\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_embeds_template = compressed_embeds_template.masked_scatter_(\n",
    "    compressed_tokens_mask.unsqueeze(-1).expand_as(compressed_embeds_template),\n",
    "    pooled_embeds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_embeds_template[compressed_tokens_mask][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_embeds_template[compressed_tokens_mask][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = compressed_tokens_torch.clone()\n",
    "text_token_id = tokenizer.encode(\"<|object_ref_start|>\")[0]\n",
    "labels[labels == text_token_id] = -100\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.9123, device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1 = model(\n",
    "    inputs_embeds=compressed_embeds_template,\n",
    "    labels=labels,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_1.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R1 Chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd9a303631343d885714bbfd24b8c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab84dc315a7d48ebb1e4d541f4fe8bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a433ac65c43645a084cfeb339c7fdf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = Qwen2ForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>You are a helpful assistant.<｜User｜>how many wings has a bird?<｜Assistant｜><think>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, so I need to figure out how many wings a bird has. Hmm, I remember that birds are animals that can fly, but I'm not exactly sure about their wings. Let me think about what I know. I know that birds have wings, but do they have multiple wings? I think some birds have wings that are like flaps or maybe even wings with parts, like flaps and maybe a tail.\\n\\nWait, no, I think most birds have just one pair of wings. That makes sense because having more wings would complicate their flight. So, if I'm not mistaken, every bird has two wings: one upper and one lower. These wings are used for flapping to flap the wings up and down, which allows the bird to fly. \\n\\nLet me try to recall any specific examples. For instance, a bird like a sparrow has a pair of wings that are shaped like a V, one pointing up and one pointing down. Similarly, a crow has a similar structure with a V-shaped wing. I think other birds like eagles have wings that are more streamlined, but they still only have two wings. \\n\\nIs there any bird that has more than two wings? I don't think so. Most birds have two wings, which are usually referred to as the front and back wings. These wings are important for flight because they help the bird generate lift, which is the force that makes the bird fly.\\n\\nWait, but I'm not sure if all birds have wings. Some birds are waterfowl, like ducks or swans. Do they have wings? I think they do, but they have different structures. Ducks have a pair of wings that are more like a V shape, and swans have a different kind of wing shape. But they still have two wings. So, regardless of the bird, whether it's a bird that can fly or not, they have two wings.\\n\\nSo, putting it all together, every bird has two wings. These wings are used to flap and generate lift for flight. Whether it's a sparrow, a crow, an eagle, or any other bird, they all have two wings. I think that's the answer.\\n</think>\\n\\nEvery bird has two wings. These wings are used to flap and generate lift for flight, allowing the bird to fly. The wings are typically V-shaped, with one wing flapping up and the other flapping down. This structure is essential for flight and is present in all species of birds, including those that can fly like ducks, swans, sparrows, crows, eagles, and more.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"how many wings has a bird?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=1024)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>You are a helpful assistant.<｜User｜>how many wings has a bird?<｜Assistant｜><think>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, so I'm trying to figure out how many wings a bird has. I remember that birds are birds, so maybe they have wings. But how many exactly? I know some birds have wings, like the eagle, but I'm not sure about others. Let me think about different types of birds.\n",
      "\n",
      "First, the eagle. I think they have two wings, but I'm not entirely certain. Maybe I should confirm that. Then there's the sparrow. I believe they have two wings too. What about a crow? I'm not sure if they have wings or just airways. Maybe they don't have wings at all.\n",
      "\n",
      "There's also the penguin, but wait, penguins are birds too, right? But they don't have wings, do they? They have beaks. So that's a different category. Then there's the ostrich, I think they have two wings. How about the eagle? Yeah, two wings. So far, all the birds I can think of have two wings.\n",
      "\n",
      "Wait, what about the peacock? I think they have two wings, but I'm not sure. Also, maybe some other birds like the osprey? I'm not sure, but I think they have two wings as well. So, based on what I remember, most birds have two wings.\n",
      "\n",
      "I should also consider if there are any birds that don't have wings. The crow, for example, doesn't have wings but has airways instead. So that's a bird without wings. The penguin doesn't have wings either. So, in general, birds have two wings, but some have different structures like airways or beaks.\n",
      "\n",
      "So, putting it all together, most birds have two wings, but some have different structures like airways or beaks instead. The penguin and crow don't have wings. The eagle, sparrow, and osprey all have two wings each. So, the answer is that most birds have two wings, but some have different structures.\n",
      "</think>\n",
      "\n",
      "Most birds have two wings, but this is not the case for all species. For example:\n",
      "\n",
      "- **Eagle**: Two wings.\n",
      "- **Sparrow**: Two wings.\n",
      "- **Ostrich**: Two wings.\n",
      "- **Eagle (another species)**: Two wings.\n",
      "- **Penguin**: Does not have wings; airways instead.\n",
      "- **Crow**: Does not have wings; airways instead.\n",
      "\n",
      "Thus, while most birds have two wings, some species like the penguin and crow do not. The eagle and other birds like the osprey also have two wings.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(generated_ids, skip_special_tokens=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151662"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|fim_pad|>\", add_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_len 437\n",
      "First, I need to compare the two numbers: 9.11 and 9.9.\n",
      "\n",
      "To make the comparison easier, I'll align their decimal places by writing 9.9 as 9.90.\n",
      "\n",
      "Now, I'll compare each corresponding digit from left to right.\n",
      "\n",
      "Both numbers have 9 in the units place, so they are equal there.\n",
      "\n",
      "Next, I'll look at the tenths place. In 9.11, the tenths digit is 1, while in 9.90, it's 9.\n",
      "\n",
      "Since 9 is greater than 1, 9.90 is larger than 9.11.\n",
      "\n",
      "Therefore, 9.9 is bigger than 9.11.\n",
      "</think>\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "To determine which number is larger between **9.11** and **9.9**, follow these steps:\n",
      "\n",
      "1. **Align the Decimal Places:**\n",
      "   \n",
      "   To make the comparison easier, write both numbers with the same number of decimal places:\n",
      "   \n",
      "   \\[\n",
      "   9.11 \\quad \\text{and} \\quad 9.90\n",
      "   \\]\n",
      "\n",
      "2. **Compare the Numbers Digit by Digit:**\n",
      "   \n",
      "   - **Units Place:**\n",
      "     \n",
      "     Both numbers have **9** in the units place.\n",
      "     \n",
      "     \\[\n",
      "     9 \\quad \\text{vs} \\quad 9\n",
      "     \\]\n",
      "     \n",
      "     They are equal in this place.\n",
      "\n",
      "   - **Tenths Place:**\n",
      "     \n",
      "     In **9.11**, the tenths digit is **1**.\n",
      "     \n",
      "     In **9.90**, the tenths digit is **9**.\n",
      "     \n",
      "     \\[\n",
      "     1 \\quad \\text{vs} \\quad 9\n",
      "     \\]\n",
      "     \n",
      "     Since **9** is greater than **1**, **9.90** is larger than **9.11**.\n",
      "\n",
      "3. **Conclusion:**\n",
      "   \n",
      "   Therefore, **9.9** is bigger than **9.11**.\n",
      "\n",
      "\\[\n",
      "\\boxed{9.9 \\text{ is bigger}}\n",
      "\\]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(f\"http://{open('ip').read()}:1338\")\n",
    "\n",
    "user_prompt = \"9.11 and 9.9 -- which is bigger? Let's think step by step.\"\n",
    "output = client.chat.completions.create(\n",
    "    model=\"tgi\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ],\n",
    "    stream=False,\n",
    "    max_tokens=10000,\n",
    "    temperature=0.0,\n",
    ")\n",
    "result = output.choices[0].message.content\n",
    "print(\"total_len\", len(tokenizer.encode(result)))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'Hello, my name is', Generated text: 'Okay, so I\\'m trying to figure out what the user named is. They just said \"Hello, my name is\" and then stopped. Hmm, that\\'s a bit confusing. Maybe they forgot to finish the sentence. I should probably ask them to complete it so I can help better. I don\\'t want to assume anything about their identity or name. It\\'s better to be safe than sorry. I\\'ll let them know I\\'m here to help once they provide their full name.\\n</think>\\n\\nIt seems like your name is incomplete. Could you please provide your full name so I can assist you better?'\n",
      "Prompt: 'The president of the United States is', Generated text: \"Okay, so I need to figure out what the president of the United States is. Hmm, I'm not exactly sure, but I think the president is the head of the executive branch of the United States. I remember hearing that they're usually named after a person, like George W. Bush or Barack Obama. Maybe I should look up the current president to get the most accurate information.\\n\\nWait, I'm not sure if I can access the internet right now. Maybe I can think of some famous presidents and their names. I know George Washington was the first president, and he's often called the first president. Then there's John Adams, who was the second president. After that, Thomas Jefferson was the third president. I think that's right because he was the first president of the states, not the country.\\n\\nAfter that, James Madison and James Monroe were the fourth and fifth presidents, respectively. Then, after that, Abraham Lincoln was the sixth president. He was the first president of the United States, but he was also the first president of the Confederate States. After him, Andrew Jackson was the seventh president. He was a significant figure in the Civil Rights Movement.\\n\\nThen, after Andrew Jackson, Martin Van Buren was the eighth president. He was a statesman and played a role in the Civil War. After him, James K. Polk was the ninth president. He was known for his policies, like the transcontinental railroad. Following Polk, William Henry Harrison was the tenth president, but he died in office, so he's often excluded from the list.\\n\\nAfter Harrison, John Tyler was the eleventh president, and he was a statesman and military leader. Then, Franklin Pierce was the twelfth president. He was a key figure in the Civil War. After that, James Buchanan was the thirteenth president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the fourteenth president, the first president of the United States. Then, Andrew Johnson was the fifteenth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the sixteenth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the seventeenth president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the eighteenth president again, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler, Franklin Pierce was the twenty-second president. After that, James Buchanan was the twenty-third president, known for his policies and the Civil Rights Movement.\\n\\nAfter Buchanan, Abraham Lincoln was the twenty-fourth president, the first president of the United States. Then, Andrew Johnson was the twenty-fifth president, who was a significant figure in the Civil War. Following Johnson, Ulysses S. Grant was the twenty-sixth president, known for his strategies in the Civil War. After Grant, Rutherford B. Hayes was the twenty-seventh president, who was a statesman and played a role in the Civil Rights Movement.\\n\\nThen, after Hayes, John Tyler was the twenty-eighth president, and he was a statesman and military leader. Following Tyler, James K. Polk was the nineteenth president again, known for the transcontinental railroad. After Polk, William Henry Harrison was the twentieth president, but he died, so he's often excluded.\\n\\nAfter Harrison, John Tyler was the twenty-first president, and he was a statesman and military leader. Following Tyler\"\n",
      "Prompt: 'The capital of France is', Generated text: \"Okay, so I need to figure out the capital of France. I remember that France is a country in Europe, but I'm not exactly sure where its capital is. I think it's somewhere in the north, maybe in the Pyrenees or something. I've heard of Paris before, but I'm not sure if it's the only capital. I should probably start by recalling what I know about capitals.\\n\\nI know that the capital of France is the most populous city, so it's probably a major city. Paris comes to mind because it's the capital of many countries, but I'm not certain if it's the only one. I think there are other capitals, but I'm not sure which ones. Maybe I should think about the countries that are connected to France. France borders several countries, so maybe each of those has their own capital.\\n\\nI remember that the capital of France is also called the capital of the European Union, but I'm not sure if that's correct. I think it's actually the capital of the European Union, but I might be mixing that up with something else. I should double-check that. Oh, right, the European Union's capital is also Paris, so that makes sense.\\n\\nNow, thinking about the geography, France is a large country, so its capital should be in a significant geographical location. The Pyrenees are a mountain range in western Europe, so maybe Paris is near there. I think Paris is in the northern part of France, so it's probably in the Pyrenean region. That would make sense because the Pyrenees are known for their mountains and the surrounding areas.\\n\\nI also recall that Paris is the capital of many European countries, so it's likely the most central and important city in France. It's not just a random city; it's the hub for a lot of activities, trade, and political life. I think it's also the capital of the Seine River, which is a major river in France, so that adds to its importance.\\n\\nWait, I should make sure I'm not confusing it with another city. I think I've heard of other capitals, like Berlin or London, but those are in different countries. So, France's capital is definitely Paris. I can't think of any other cities that are more central or have such a significant role in France as Paris does.\\n\\nTo summarize, I believe the capital of France is Paris. It's the most populous city, the capital of the European Union, and it's located in the Pyrenean region, making it a major hub for various aspects of life in France.\\n</think>\\n\\nThe capital of France is Paris. It is the most populous city in the country, the capital of the European Union, and is located in the Pyrenean region, making it a significant hub for various aspects of life in France.\"\n",
      "Prompt: 'The future of AI is', Generated text: \"Okay, so I'm trying to understand the future of AI. I know a bit about AI from school, but I'm not an expert. Let me start by breaking down what I know and then think about what might happen next.\\n\\nFirst, I remember that AI is about machines learning and doing tasks that usually require human intelligence. So, things like language translation, image recognition, and even playing games at a superhuman level. But I'm not sure how far we've come yet.\\n\\nI think there are different types of AI. There's general AI, which is the broad term, and then there's narrow AI, which is more specific. Narrow AI is good for things like medical diagnosis or stock trading because it's very precise. But I'm not sure if that's the future. Maybe AI will become more like general AI, handling a wider range of tasks.\\n\\nAnother thing I've heard is about the ethical implications. I know that AI can cause problems like job displacement or discrimination if it makes people do tasks that humans do less. There's also the issue of privacy—AI systems can collect and analyze data without consent. So, there's a lot of debate about how to handle AI responsibly.\\n\\nI've also heard about the concept of superintelligent AI. I think that's when AI surpasses human intelligence, but I'm not sure how that's going to happen. Maybe through more efficient algorithms or better understanding of human intelligence. But I'm not certain if that's realistic.\\n\\nThen there's the question of how AI will affect society. I imagine it could lead to more automation in industries, but it might also create new jobs or change how people work. There's also the possibility of AI being used in ways that exacerbate inequality, like in hiring or lending decisions.\\n\\nI'm also thinking about the future of human creativity. I know that AI can generate art, but will it replace human creativity? Or will it complement it? I think it's a mix, but maybe AI will become more of a tool than a creator in the long run.\\n\\nAnother area is the integration of AI with other technologies. I've heard about AI augmenting human capabilities, like in healthcare or education. But there's also the risk of AI becoming too dependent on humans, like in surveillance or control systems.\\n\\nI'm curious about the timeline for AI development. I know that some technologies like self-driving cars are already in the works, but it's still in the early stages. Maybe AI will become more advanced as we develop better algorithms and data.\\n\\nI also wonder about the role of humans in the future. Will AI take over certain jobs, or will humans continue to be essential for things like education, healthcare, and creativity? There's a lot of debate about this.\\n\\nThere's also the issue of job displacement. If AI becomes too powerful, it could replace many jobs, leading to a new kind of labor force. I'm not sure how that will be managed or what the job market will look like.\\n\\nI'm trying to think about the potential for AI to solve problems that are currently unsolvable. For example, climate change or pandemics. AI could help model the spread of diseases or predict environmental changes, which could lead to better policies or solutions.\\n\\nBut I'm also concerned about the limitations of AI. It can't process emotions or learn from scratch data, so it might struggle with complex human-like tasks. There's a need for more human-like AI, like in creative problem-solving or decision-making.\\n\\nI'm also thinking about the ethical guidelines for AI. There's a lot of talk about privacy, bias, and transparency. Ensuring that AI systems are fair and transparent is crucial, but it's a big challenge.\\n\\nIn summary, the future of AI seems to be a mix of advancements, ethical considerations, societal impacts, and the balance between human and AI capabilities. It's a complex and evolving field with many possibilities and challenges. I'm not entirely sure about all these aspects, but I think it's clear that AI will play a significant role in the future, but we'll need to be careful about how it's developed and used.\\n</think>\\n\\nThe future of AI is a multifaceted and evolving field that encompasses several key considerations and possibilities. Here's a structured overview:\\n\\n1. **Types of AI**: \\n   - **General AI**: The broad term representing machines capable of performing tasks that require human intelligence, such as language translation and game playing.\\n   - **Narrow AI**: More specific, like medical diagnosis or stock trading, which excel in precise tasks.\\n\\n2. **Ethical Implications**:\\n   - **Privacy and Bias**: Concerns about data collection and the potential for bias in AI systems.\\n   - ** job displacement**: Risks of automation leading to job loss and the need for job displacement strategies.\\n\\n3. **Superintelligent AI**:\\n   - Theoretical possibility of AI surpassing human intelligence, driven by advancements in algorithms and understanding of human intelligence.\\n\\n4. **Societal Impact**:\\n   - Potential for AI to exacerbate inequality, affecting areas like hiring and lending.\\n   - Integration with other technologies, such as healthcare and education, and risks of dependency on humans.\\n\\n5. **Human Creativity**:\\n   - A blend of AI-generated art and human creativity, with AI potentially becoming more of a tool than a creator.\\n\\n6. **Integration with Other Technologies**:\\n   - AI augmenting human capabilities in healthcare and education, but risks of dependence on humans in surveillance and control systems.\\n\\n7. **Timeline and Development**:\\n   - Early stages of AI development, such as self-driving cars, are in progress, with potential for more advanced technologies.\\n\\n8. **Job Market and Labor Force**:\\n   - Concerns about job displacement and the potential for a new labor force, requiring management strategies.\\n\\n9. **Problem Solving and Complex Tasks**:\\n   - AI's role in solving climate change, pandemics, and other complex problems, leading to new policies and solutions.\\n\\n10. **Ethical Guidelines**:\\n    - Importance of ensuring fairness, transparency, and privacy in AI systems, which requires careful development and regulation.\\n\\nIn conclusion, the future of AI is poised for significant advancements but also requires careful consideration of ethical, societal, and practical implications. Balancing human and AI capabilities, ensuring fairness, and addressing ethical concerns are crucial for the future of AI.\"\n"
     ]
    }
   ],
   "source": [
    "import concurrent\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(f\"http://{open('ip').read()}:1338\")\n",
    "\n",
    "\n",
    "def gen_text(text):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"tgi\",\n",
    "        messages=[{\"role\": \"user\", \"content\": text}],\n",
    "        temperature=0.0,\n",
    "        max_tokens=5_000,\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content\n",
    "\n",
    "\n",
    "batch_size = 4\n",
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "\n",
    "def batch_generation(prompts):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=len(prompts)) as executor:\n",
    "        prompts_results = list(executor.map(gen_text, prompts))\n",
    "    return prompts_results\n",
    "\n",
    "\n",
    "prompts_results = batch_generation(prompts)\n",
    "\n",
    "for prompt, prompts_result in zip(prompts, prompts_results):\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {prompts_result!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'system_prompt', 'question', 'response'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset = dataset.train_test_split(test_size=10_00, seed=42)\n",
    "dataset = dataset[\"test\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c823eb900664b04961ada35f2a779e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from more_itertools import chunked\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "batch_size = 32 * 2 * 2\n",
    "questions = list(\n",
    "    chunked(\n",
    "        dataset[\"question\"],\n",
    "        batch_size,\n",
    "    )\n",
    ")\n",
    "# 5 min 26 sec - 1000\n",
    "correct_qa_pairs = []\n",
    "for question_chunk in tqdm(questions):\n",
    "    answers = batch_generation(question_chunk)\n",
    "    for question, answer in zip(question_chunk, answers):\n",
    "        if answer.count(\"</think>\") == 1:\n",
    "            correct_qa_pairs.append(\n",
    "                [\n",
    "                    question,\n",
    "                    answer,\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(905, 1000)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_qa_pairs), len(dataset[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'NEW: Peterson to media on handcuffs, chains: \"I got the bling. Can\\'t complain\" Drew Peterson arrested in the death of his third wife, Kathleen Savio. Renewed interest in Savio\\'s death came after Peterson\\'s fourth wife disappeared. Peterson, through his attorney, denies any wrongdoing in either case.\\n\\nWrite an article based on these highlights.',\n",
       " 'answer': \"Okay, so I need to write an article based on the highlights provided about Drew Peterson and his fourth wife, Kathleen Savio. The user has given me some specific points to include, so I should make sure to cover all of them.\\n\\nFirst, I should start by introducing Drew Peterson and his fourth wife, Kathleen Savio. I need to mention that he's been arrested in the deaths of his first and fourth wives. That's a significant event because it's the second time he's been involved in such a death, which could be a big deal.\\n\\nI should also note that the renewed interest in Savio's death came after his fourth wife disappeared. That's an important detail because it shows that the case isn't over and that there's still a lot to explore.\\n\\nNext, the user mentioned that Peterson's attorney has denied any wrongdoing in either case. That's crucial because it sets the tone that the case is being handled fairly, and there's no evidence of wrongdoing. I should make sure to highlight that part.\\n\\nI should also touch on the legal implications. Peterson is facing charges related to the deaths, and his attorney's denial is a positive sign. Maybe I can mention that the case is being handled with fairness and transparency.\\n\\nI need to structure the article in a way that flows well. Maybe start with an introduction about Peterson and his fourth wife, then move on to the legal developments, the renewed interest, and the attorney's denial. Finally, conclude with the implications of the case.\\n\\nI should also consider the tone. It should be informative but not too technical, so it's accessible to a general audience. I'll need to make sure the language is clear and concise.\\n\\nI should also think about any potential counterarguments or questions that might arise. For example, why is there renewed interest in Savio's death? It could be because of the fourth wife's disappearance, which is a significant event. Maybe I can mention that as a point of interest.\\n\\nI should also ensure that the article doesn't just list the facts but also provides context and analysis. For example, discussing the legal process, the significance of the deaths, and the impact on the community.\\n\\nI need to make sure that the article is balanced, presenting both the positive developments and any potential challenges. Maybe mention that while the case is being handled fairly, there could be future legal challenges, but for now, it's a positive situation.\\n\\nI should also check for any recent developments or updates. The user didn't provide specific dates, so I'll have to keep it general, mentioning that the case is ongoing and that the attorney's denial is a key point.\\n\\nFinally, I should conclude by summarizing the main points and emphasizing the importance of the case in the community. Maybe suggest that the legal community should support Peterson and his attorney in handling the case.\\n\\nI think that's a good outline. Now, I'll structure the article accordingly, making sure each section flows into the next and covers all the key points the user provided.\\n</think>\\n\\n**Drew Peterson's Fourth Wife: A Legal Journey and Renewed Interest**\\n\\nDrew Peterson, a controversial figure known for his controversial past, has recently come to light as the subject of legal proceedings involving his fourth wife, Kathleen Savio. Peterson, who has been arrested in the deaths of his first and fourth wives, has faced charges related to these tragic incidents. His attorney has denied any wrongdoing in either case, presenting a positive narrative for the legal community.\\n\\n**Introduction to Drew Peterson and His Fourth Wife**\\n\\nDrew Peterson, a controversial figure, has been the subject of legal scrutiny for his past actions, including his controversial death of his first wife, Jane Savio. Now, his fourth wife, Kathleen Savio, has come into the limelight. Peterson, who has been arrested in the deaths of his first and fourth wives, has faced charges of murder and multiple counts of intentional killing. His attorney has denied any wrongdoing in either case, highlighting a positive stance in the legal community.\\n\\n**Legal Developments and Renewed Interest**\\n\\nPeterson's attorney has denied any wrongdoing in either case, emphasizing that the deaths are not isolated incidents. The renewed interest in Savio's death stems from the fact that his fourth wife disappeared, adding another layer of complexity to the case. This disappearance has sparked discussions about the legal process and the potential impact on the community.\\n\\n**The Case's Legal Implications**\\n\\nPeterson is facing charges of murder and multiple counts of intentional killing, with a possible charge of conspiracy. His attorney has denied any wrongdoing, presenting a positive narrative. The case is being handled with fairness and transparency, reflecting the legal community's commitment to resolving the issue without any evidence of wrongdoing.\\n\\n**Conclusion and Implications**\\n\\nWhile the case is being handled fairly, there could be future legal challenges. However, for now, the legal community should support Peterson and his attorney in handling the case. The renewed interest in Savio's death highlights the ongoing legal battle and the importance of addressing the complexities of the case. The legal community should continue to support Peterson and his attorney in resolving the issue, ensuring justice is served.\"}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = []\n",
    "for question, answer in correct_qa_pairs:\n",
    "    new_dataset.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "        }\n",
    "    )\n",
    "new_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "new_dataset = Dataset.from_list(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cc55670f2a40ff960d44683c64d857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74721c2be7a84659949cb2f1410942d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/commit/82cf73531b7b8daaee327e4813aa774abbc0fcc4', commit_message='Upload dataset', commit_description='', oid='82cf73531b7b8daaee327e4813aa774abbc0fcc4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B', endpoint='https://huggingface.co', repo_type='dataset', repo_id='dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.push_to_hub(\"dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 905\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151646"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "think_end_id = tokenizer.encode(\"</think>\")[0]\n",
    "think_end_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>NEW: Peterson to media on handcuffs, chains: \"I got the bling. Can\\'t complain\" Drew Peterson arrested in the death of his third wife, Kathleen Savio. Renewed interest in Savio\\'s death came after Peterson\\'s fourth wife disappeared. Peterson, through his attorney, denies any wrongdoing in either case.\\n\\nWrite an article based on these highlights.<｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": dataset[0][\"question\"]},\n",
    "    # {\"role\": \"assistant\", \"content\": result},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "# print(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>NEW: Peterson to media on handcuffs, chains: \"I got the bling. Can\\'t complain\" Drew Peterson arrested in the death of his third wife, Kathleen Savio. Renewed interest in Savio\\'s death came after Peterson\\'s fourth wife disappeared. Peterson, through his attorney, denies any wrongdoing in either case.\\n\\nWrite an article based on these highlights.<｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text, add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151646, 151644]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<｜begin▁of▁sentence｜><｜User｜>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>NEW: Peterson to media on handcuffs, chains: \"I got the bling. Can't complain\" Drew Peterson arrested in the death of his third wife, Kathleen Savio. Renewed interest in Savio's death came after Peterson's fourth wife disappeared. Peterson, through his attorney, denies any wrongdoing in either case.\n",
      "\n",
      "Write an article based on these highlights.<｜Assistant｜><think>\n",
      "Okay, so I need to write an article based on the highlights provided about Drew Peterson and his fourth wife, Kathleen Savio. The user has given me some specific points to include, so I should make sure to cover all of them.\n",
      "\n",
      "First, I should start by introducing Drew Peterson and his fourth wife, Kathleen Savio. I need to mention that he's been arrested in the deaths of his first and fourth wives. That's a significant event because it's the second time he's been involved in such a death, which could be a big deal.\n",
      "\n",
      "I should also note that the renewed interest in Savio's death came after his fourth wife disappeared. That's an important detail because it shows that the case isn't over and that there's still a lot to explore.\n",
      "\n",
      "Next, the user mentioned that Peterson's attorney has denied any wrongdoing in either case. That's crucial because it sets the tone that the case is being handled fairly, and there's no evidence of wrongdoing. I should make sure to highlight that part.\n",
      "\n",
      "I should also touch on the legal implications. Peterson is facing charges related to the deaths, and his attorney's denial is a positive sign. Maybe I can mention that the case is being handled with fairness and transparency.\n",
      "\n",
      "I need to structure the article in a way that flows well. Maybe start with an introduction about Peterson and his fourth wife, then move on to the legal developments, the renewed interest, and the attorney's denial. Finally, conclude with the implications of the case.\n",
      "\n",
      "I should also consider the tone. It should be informative but not too technical, so it's accessible to a general audience. I'll need to make sure the language is clear and concise.\n",
      "\n",
      "I should also think about any potential counterarguments or questions that might arise. For example, why is there renewed interest in Savio's death? It could be because of the fourth wife's disappearance, which is a significant event. Maybe I can mention that as a point of interest.\n",
      "\n",
      "I should also ensure that the article doesn't just list the facts but also provides context and analysis. For example, discussing the legal process, the significance of the deaths, and the impact on the community.\n",
      "\n",
      "I need to make sure that the article is balanced, presenting both the positive developments and any potential challenges. Maybe mention that while the case is being handled fairly, there could be future legal challenges, but for now, it's a positive situation.\n",
      "\n",
      "I should also check for any recent developments or updates. The user didn't provide specific dates, so I'll have to keep it general, mentioning that the case is ongoing and that the attorney's denial is a key point.\n",
      "\n",
      "Finally, I should conclude by summarizing the main points and emphasizing the importance of the case in the community. Maybe suggest that the legal community should support Peterson and his attorney in handling the case.\n",
      "\n",
      "I think that's a good outline. Now, I'll structure the article accordingly, making sure each section flows into the next and covers all the key points the user provided.\n",
      "</think>\n",
      "\n",
      "**Drew Peterson's Fourth Wife: A Legal Journey and Renewed Interest**\n",
      "\n",
      "Drew Peterson, a controversial figure known for his controversial past, has recently come to light as the subject of legal proceedings involving his fourth wife, Kathleen Savio. Peterson, who has been arrested in the deaths of his first and fourth wives, has faced charges related to these tragic incidents. His attorney has denied any wrongdoing in either case, presenting a positive narrative for the legal community.\n",
      "\n",
      "**Introduction to Drew Peterson and His Fourth Wife**\n",
      "\n",
      "Drew Peterson, a controversial figure, has been the subject of legal scrutiny for his past actions, including his controversial death of his first wife, Jane Savio. Now, his fourth wife, Kathleen Savio, has come into the limelight. Peterson, who has been arrested in the deaths of his first and fourth wives, has faced charges of murder and multiple counts of intentional killing. His attorney has denied any wrongdoing in either case, highlighting a positive stance in the legal community.\n",
      "\n",
      "**Legal Developments and Renewed Interest**\n",
      "\n",
      "Peterson's attorney has denied any wrongdoing in either case, emphasizing that the deaths are not isolated incidents. The renewed interest in Savio's death stems from the fact that his fourth wife disappeared, adding another layer of complexity to the case. This disappearance has sparked discussions about the legal process and the potential impact on the community.\n",
      "\n",
      "**The Case's Legal Implications**\n",
      "\n",
      "Peterson is facing charges of murder and multiple counts of intentional killing, with a possible charge of conspiracy. His attorney has denied any wrongdoing, presenting a positive narrative. The case is being handled with fairness and transparency, reflecting the legal community's commitment to resolving the issue without any evidence of wrongdoing.\n",
      "\n",
      "**Conclusion and Implications**\n",
      "\n",
      "While the case is being handled fairly, there could be future legal challenges. However, for now, the legal community should support Peterson and his attorney in handling the case. The renewed interest in Savio's death highlights the ongoing legal battle and the importance of addressing the complexities of the case. The legal community should continue to support Peterson and his attorney in resolving the issue, ensuring justice is served.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/lm-sys/FastChat/blob/main/fastchat/train/train.py#L150\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": dataset[0][\"question\"]},\n",
    "    # {\"role\": \"assistant\", \"content\": dataset[0][\"answer\"]},\n",
    "]\n",
    "part_1 = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    "    # return_dict=True,\n",
    ")\n",
    "part_2 = tokenizer.encode(\n",
    "    dataset[0][\"answer\"],\n",
    "    add_special_tokens=False,\n",
    ")\n",
    "part_3 = tokenizer.encode(\n",
    "    \"<｜end▁of▁sentence｜>\",\n",
    "    add_special_tokens=False,\n",
    ")\n",
    "print(tokenizer.decode(part_1 + part_2 + part_3))\n",
    "labels = len(part_1) * [-100] + part_2 + [-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>NEW: Peterson to media on handcuffs, chains: \"I got the bling. Can't complain\" Drew Peterson arrested in the death of his third wife, Kathleen Savio. Renewed interest in Savio's death came after Peterson's fourth wife disappeared. Peterson, through his attorney, denies any wrongdoing in either case.\n",
      "\n",
      "Write an article based on these highlights.<｜Assistant｜>\n",
      "\n",
      "**Drew Peterson's Fourth Wife: A Legal Journey and Renewed Interest**\n",
      "\n",
      "Drew Peterson, a controversial figure known for his controversial past, has recently come to light as the subject of legal proceedings involving his fourth wife, Kathleen Savio. Peterson, who has been arrested in the deaths of his first and fourth wives, has faced charges related to these tragic incidents. His attorney has denied any wrongdoing in either case, presenting a positive narrative for the legal community.\n",
      "\n",
      "**Introduction to Drew Peterson and His Fourth Wife**\n",
      "\n",
      "Drew Peterson, a controversial figure, has been the subject of legal scrutiny for his past actions, including his controversial death of his first wife, Jane Savio. Now, his fourth wife, Kathleen Savio, has come into the limelight. Peterson, who has been arrested in the deaths of his first and fourth wives, has faced charges of murder and multiple counts of intentional killing. His attorney has denied any wrongdoing in either case, highlighting a positive stance in the legal community.\n",
      "\n",
      "**Legal Developments and Renewed Interest**\n",
      "\n",
      "Peterson's attorney has denied any wrongdoing in either case, emphasizing that the deaths are not isolated incidents. The renewed interest in Savio's death stems from the fact that his fourth wife disappeared, adding another layer of complexity to the case. This disappearance has sparked discussions about the legal process and the potential impact on the community.\n",
      "\n",
      "**The Case's Legal Implications**\n",
      "\n",
      "Peterson is facing charges of murder and multiple counts of intentional killing, with a possible charge of conspiracy. His attorney has denied any wrongdoing, presenting a positive narrative. The case is being handled with fairness and transparency, reflecting the legal community's commitment to resolving the issue without any evidence of wrongdoing.\n",
      "\n",
      "**Conclusion and Implications**\n",
      "\n",
      "While the case is being handled fairly, there could be future legal challenges. However, for now, the legal community should support Peterson and his attorney in handling the case. The renewed interest in Savio's death highlights the ongoing legal battle and the importance of addressing the complexities of the case. The legal community should continue to support Peterson and his attorney in resolving the issue, ensuring justice is served.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": dataset[0][\"question\"]},\n",
    "    {\"role\": \"assistant\", \"content\": dataset[0][\"answer\"]},\n",
    "]\n",
    "\n",
    "part_3 = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    # add_generation_prompt=False,\n",
    "    # add_generation_prompt=True,\n",
    "    # continue_final_message=True,\n",
    "    # return_dict=True,\n",
    "    # return_assistant_tokens_mask=True\n",
    ")\n",
    "part_3\n",
    "print(tokenizer.decode(part_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual chat templating (single turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>question<｜Assistant｜>answer<｜end▁of▁sentence｜>'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"question\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"answer\"},\n",
    "    ],\n",
    "    tokenize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜><｜User｜>question<｜Assistant｜><think>\\n'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"question\"},\n",
    "    ],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "content_compression_mask = []\n",
    "part_1 = \"\"\"<｜begin▁of▁sentence｜><｜User｜>\"\"\"\n",
    "content_compression_mask += len(\n",
    "    tokenizer.encode(\n",
    "        part_1,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    ") * [0]\n",
    "print(content_compression_mask)\n",
    "part_2 = 'NEW: Peterson to media on handcuffs, chains: \"I got the bling. Can'\n",
    "content_compression_mask += len(\n",
    "    tokenizer.encode(\n",
    "        part_2,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    ") * [1]\n",
    "print(content_compression_mask)\n",
    "part_3 = \"<｜Assistant｜><think>\\n\"\n",
    "content_compression_mask += len(\n",
    "    tokenizer.encode(\n",
    "        part_3,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    ") * [0]\n",
    "print(content_compression_mask)\n",
    "part_4 = \"Peterson attorney that</think>Peterson is facing\"\n",
    "content_compression_mask += len(\n",
    "    tokenizer.encode(\n",
    "        part_4,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    ") * [1]\n",
    "print(content_compression_mask)\n",
    "content_compression_mask += [0]\n",
    "print(content_compression_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
