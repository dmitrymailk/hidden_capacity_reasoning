{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ef7a7bb00246348e4b40a104ceaa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f085db131e654d64964a7040ecfed546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1580\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1580\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _require_custom_configs \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:5475\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5473\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5487\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5491\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1024\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 309\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:420\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    419\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(EntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-68128578-0ea274e125dba3cb1d1ac5b6;c8d72666-fbda-4390-b0c3-c9d217194594)\n\nEntry Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# model = model.to(torch.bfloat16)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2059\u001b[0m )\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1629\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1631\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1019\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1018\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m-> 1019\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m   1026\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1027\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1028\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1030\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m   1031\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m_MODULE_TO_EXTENSIONS[module_name], file_names\u001b[38;5;241m=\u001b[39m_MODULE_TO_METADATA_FILE_NAMES[module_name]\n\u001b[1;32m   1032\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:690\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    685\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    687\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    688\u001b[0m         patterns_for_key\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:583\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 583\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m         )\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:361\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_HUB_VERSION \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# 10 times faster glob with detail=True (ignores costly info like lastCommit)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     glob_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    359\u001b[0m matched_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    360\u001b[0m     filepath \u001b[38;5;28;01mif\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mstartswith(protocol_prefix) \u001b[38;5;28;01melse\u001b[39;00m protocol_prefix \u001b[38;5;241m+\u001b[39m filepath\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filepath, info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mglob_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mislink\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(filepath))))\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (xbasename(filepath) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m files_to_ignore)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_inside_unrequested_special_dir(filepath, fs_pattern)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir(filepath, fs_pattern)\n\u001b[1;32m    366\u001b[0m ]  \u001b[38;5;66;03m# ignore .ipynb and __pycache__, but keep /../\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     out \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    369\u001b[0m         filepath\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m matched_paths\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix \u001b[38;5;129;01min\u001b[39;00m allowed_extensions \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m xbasename(filepath)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    372\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:521\u001b[0m, in \u001b[0;36mHfFileSystem.glob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    520\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:609\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m pattern \u001b[38;5;241m=\u001b[39m glob_translate(path \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    612\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:556\u001b[0m, in \u001b[0;36mHfFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03mList all files below path.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    `Union[List[str], Dict[str, Dict[str, Any]]]`: List of paths or dict of file information.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxdepth:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwithdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    560\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:500\u001b[0m, in \u001b[0;36mAbstractFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Add the root directory if withdirs is requested\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# This is needed for posix glob compliance\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m withdirs \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(path):\n\u001b[0;32m--> 500\u001b[0m     out[path] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk(path, maxdepth, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m withdirs:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:719\u001b[0m, in \u001b[0;36mHfFileSystem.info\u001b[0;34m(self, path, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     out \u001b[38;5;241m=\u001b[39m out1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh \u001b[38;5;129;01mor\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (expand_info \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mand\u001b[39;00m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_commit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 719\u001b[0m     paths_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_paths_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths_info:\n\u001b[1;32m    727\u001b[0m         _raise_file_not_found(path, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3354\u001b[0m, in \u001b[0;36mHfApi.get_paths_info\u001b[0;34m(self, repo_id, paths, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3351\u001b[0m revision \u001b[38;5;241m=\u001b[39m quote(revision, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mDEFAULT_REVISION\n\u001b[1;32m   3352\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m-> 3354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43ms/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/paths-info/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrevision\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m   3363\u001b[0m paths_info \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"hidden_capacity_reasoning\"\n",
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    ScriptArguments,\n",
    "    SFTConfig,\n",
    "    SFTTrainer,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    generate_train_examples,\n",
    "    pad_train_examples,\n",
    "    tokenize_single_turn,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import types\n",
    "\n",
    "# need for auto SFTTrainer patch(possible increase speed)\n",
    "from unsloth import is_bfloat16_supported\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    EOS_TOKEN_ID,\n",
    "    TEXT_TOKEN_ID,\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    find_all_linear_names_v3,\n",
    ")\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    "    Qwen2ForCausalLMCompressionV3,\n",
    "    Qwen2ModelEmbedPoolerV3,\n",
    ")\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"my_r1_model_v3\"\n",
    "model = Qwen2ForCausalLMCompressionV3.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.model.requires_grad_(False)\n",
    "# model = model.to(torch.bfloat16)\n",
    "\n",
    "# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\n",
    "#     model_name,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map={\"\": 0},\n",
    "#     # quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "# )\n",
    "# print(\n",
    "#     model.embed_pooler.load_state_dict(\n",
    "#         temp_model.state_dict(),\n",
    "#         strict=False,\n",
    "#     ),\n",
    "# )\n",
    "# temp_model = temp_model.cpu()\n",
    "# del temp_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset = load_dataset(\"dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "# dataset = dataset[\"train\"]\n",
    "# dataset = dataset.train_test_split(test_size=10, seed=42)\n",
    "\n",
    "# # test pass\n",
    "# tokenize_single_turn(\n",
    "#     question=dataset[\"train\"][0][\"question\"],\n",
    "#     answer=dataset[\"train\"][0][\"answer\"],\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# train_examples = [\n",
    "#     tokenize_single_turn(tokenizer=tokenizer, **item)\n",
    "#     for item in tqdm(dataset[\"train\"].to_list()[:3])\n",
    "# ]\n",
    "\n",
    "# prepared_train_examples = []\n",
    "# for item in tqdm(train_examples):\n",
    "#     for example in generate_train_examples(\n",
    "#         dataset_batch=[item],\n",
    "#         window_size=WINDOW_SIZE,\n",
    "#     ):\n",
    "#         prepared_train_examples.append(example)\n",
    "\n",
    "# print(\n",
    "#     \"max_len\",\n",
    "#     max([len(item[\"original_tokens\"]) for item in prepared_train_examples]),\n",
    "# )\n",
    "\n",
    "# new_dataset = Dataset.from_list(prepared_train_examples)\n",
    "# print(dataset)\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     padded_batch = pad_train_examples(\n",
    "#         train_examples=batch,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )\n",
    "#     padded_batch = {\n",
    "#         \"replaced_original_tokens\": padded_batch[\"replaced_original_tokens\"][\n",
    "#             \"input_ids\"\n",
    "#         ],\n",
    "#         \"compressed_input_ids\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "#         \"original_tokens\": padded_batch[\"original_tokens\"][\"input_ids\"],\n",
    "#         \"attention_mask\": padded_batch[\"compressed_input_ids\"][\"attention_mask\"],\n",
    "#         \"labels\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "#         \"content_compression_mask\": padded_batch[\"content_compression_mask\"][\n",
    "#             \"input_ids\"\n",
    "#         ],\n",
    "#     }\n",
    "#     for key in padded_batch.keys():\n",
    "#         padded_batch[key] = torch.tensor(padded_batch[key])\n",
    "#     skip_ids = [\n",
    "#         TEXT_TOKEN_ID,\n",
    "#         EOS_TOKEN_ID,\n",
    "#         VISION_START,\n",
    "#         VISION_END,\n",
    "#     ]\n",
    "#     for skip_id in skip_ids:\n",
    "#         padded_batch[\"labels\"][padded_batch[\"labels\"] == skip_id] = -100\n",
    "#     #    \n",
    "#     last_index = (padded_batch[\"content_compression_mask\"] == 1).long().nonzero()[-1][1]\n",
    "#     padded_batch[\"labels\"][:, :last_index][\n",
    "#         padded_batch[\"content_compression_mask\"][:, :last_index] == 1\n",
    "#     ] = -100\n",
    "#     # print(padded_batch)\n",
    "#     return padded_batch\n",
    "\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.0,\n",
    "#     bias=\"none\",\n",
    "#     target_modules=find_all_linear_names_v3(model=model),\n",
    "#     modules_to_save=[\n",
    "#         \"embed_pooler.model.embed_tokens\",\n",
    "#         \"embed_pooler.weight_pooler\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# formatted_date = datetime.fromtimestamp(time.time()).strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "# model.embed_pooler = prepare_model_for_kbit_training(model.embed_pooler)\n",
    "# peft_model = get_peft_model(model, peft_config)\n",
    "# peft_model.print_trainable_parameters()\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     train_dataset=new_dataset,\n",
    "#     data_collator=collate_fn,\n",
    "#     peft_config=peft_config,\n",
    "#     args=SFTConfig(\n",
    "#         per_device_train_batch_size=2,\n",
    "#         gradient_accumulation_steps=2,\n",
    "#         warmup_steps=5,\n",
    "#         num_train_epochs=1,  # 90,  # Set this for 1 full training run.\n",
    "#         # num_train_epochs=90,  # Set this for 1 full training run.\n",
    "#         # max_steps=10000,\n",
    "#         learning_rate=1e-4,\n",
    "#         bf16=True,\n",
    "#         # fp16=model.dtype == torch.float16,\n",
    "#         logging_steps=8,\n",
    "#         optim=\"adamw_8bit\",\n",
    "#         weight_decay=0.01,\n",
    "#         lr_scheduler_type=\"linear\",\n",
    "#         seed=3407,\n",
    "#         output_dir=f\"outputs/{formatted_date}\",\n",
    "#         # report_to=\"wandb\",\n",
    "#         report_to=\"none\",\n",
    "#         remove_unused_columns=False,\n",
    "#         dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "#         # gradient_checkpointing=True,\n",
    "#         save_steps=10000,\n",
    "#         run_name=formatted_date,\n",
    "#     ),\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLets denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLets assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLets let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLets denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my_r1_model_v3/tokenizer_config.json',\n",
       " 'my_r1_model_v3/special_tokens_map.json',\n",
       " 'my_r1_model_v3/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.base_model.embed_pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.bfloat16)\n",
    "model.embed_pooler(\n",
    "    torch.randn(\n",
    "        2,\n",
    "        2,\n",
    "        1536,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.bfloat16,\n",
    "    )\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.weight_pooler.modules_to_save.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.model.embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in trainer.model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      " Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b1fbdb17284f328e20769be0db3f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from peft import PeftModel\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    ")\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"r1_compressor_v2\"\n",
    "model = Qwen2ForCausalLMCompressionV2.from_pretrained(\n",
    "    model_name,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    # \"outputs/2025_04_19_17_17_34_493839/checkpoint-210000\",\n",
    "    # \"outputs/2025_04_19_17_17_34_493839/checkpoint-50000\",\n",
    "    # \"outputs/2025_04_21_19_23_11_642509/checkpoint-10000\",\n",
    "    # \"outputs/2025_04_22_01_43_43_347583/checkpoint-90000\",\n",
    "    # \"outputs/2025_04_22_01_43_43_347583/checkpoint-10000\",\n",
    "    # 'outputs/2025_04_23_00_46_10_062896/checkpoint-2794'\n",
    "    # \"outputs/2025_04_29_21_24_17_071961/checkpoint-588\",\n",
    "    # \"outputs/2025_04_30_01_16_22_692562/checkpoint-140000\",\n",
    "    # \"outputs/2025_04_30_01_16_22_692562/checkpoint-10000\",\n",
    "    # \"outputs/2025_05_01_14_33_36_096886/checkpoint-10000\",\n",
    "    \"outputs/2025_05_02_00_34_41_878309/checkpoint-60000\",\n",
    "    # \"outputs/2025_05_02_00_34_41_878309/checkpoint-10000\",\n",
    "    # \"outputs/2025_05_04_22_59_34_768602/checkpoint-160000\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "209 185 0.8851674641148325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    # \"dim/hendrycks_math_train_12k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    \"dim/hendrycks_math_train_1k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(\n",
    "    # test_size=250,\n",
    "    test_size=350,\n",
    "    # test_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dataset = dataset[\"test\"].filter(lambda x: x[\"model_answer\"].count(\"</think>\") == 1)\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "\n",
    "correct_dataset = []\n",
    "\n",
    "for pos, item in enumerate(dataset):\n",
    "    try:\n",
    "        answer = dataset_answer_filter(item[\"answer\"])\n",
    "        model_answer = model_answer_filter(item[\"model_answer\"])\n",
    "        # print(answer, model_answer)\n",
    "        # break\n",
    "        if is_equiv(answer, model_answer):\n",
    "            correct_dataset.append(item)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(dataset), len(correct_dataset), len(correct_dataset) / len(dataset))\n",
    "\n",
    "correct_dataset = correct_dataset[:30]\n",
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<beginofsentence><User>Problem: If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<Assistant><think>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "# prompt = \"how many wings has a bird?\"\n",
    "prompt = correct_dataset[0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    "model_inputs = tokenizer(\n",
    "    [text],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"longest\",\n",
    "    truncation=False,\n",
    "    add_special_tokens=False,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # generated_ids = model.generate(\n",
    "    #     model_inputs.input_ids,\n",
    "    #     max_new_tokens=1,\n",
    "    #     do_sample=False,\n",
    "    # )\n",
    "    generated_ids = model.generate(\n",
    "        # **model_inputs.input_ids,\n",
    "        **model_inputs,\n",
    "        max_new_tokens=4096,\n",
    "        do_sample=False,\n",
    "        # do_sample=not False,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLets denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLets assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLets let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLets denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response == correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<beginofsentence><User>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<Assistant><think>\n",
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<endofsentence><beginofsentence>\n",
      "\n",
      "To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "prompt = correct_dataset[:5][0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "# initial_len = generated_tokens.shape\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    max_steps = 1200\n",
    "    past_key_values = None\n",
    "    for step in range(max_steps):\n",
    "        if step == 0:\n",
    "            logits = model(\n",
    "                inputs_embeds=generated_embeds,\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.arange(generated_embeds.shape[1])\n",
    "                .cuda()\n",
    "                .unsqueeze(0),\n",
    "                use_cache=True,\n",
    "                past_key_values=None,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "        else:\n",
    "            logits = model(\n",
    "                # input_ids=generated_tokens[-1][-1:].unsqueeze(0),\n",
    "                inputs_embeds=generated_embeds[:, -1:, :],\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.tensor(generated_embeds.shape[1] - 1)\n",
    "                .reshape(1, 1)\n",
    "                .cuda(),\n",
    "                use_cache=True,\n",
    "                past_key_values=past_key_values,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "\n",
    "        top_token = logits.argmax(-1)[-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(step, tokenizer.decode(generated_tokens[-1]))\n",
    "    # break\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "# break\n",
    "embeds_generation_tokens = generated_tokens[-1]\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<beginofsentence><User>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.<Assistant><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\\n\\nLet me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\\n\\nSo, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\\n\\nTime = Distance / Speed\\n\\nSo, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\\n\\nLet's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\\n\\nSo, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\\n\\nSo, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\\n\\nAlternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\\n\\nI think that's solid. So, the lion will catch the elephant in 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \\n\\nTo find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\\n\\n\\\\[\\n24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph}\\n\\\\]\\n\\nThe initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\\n\\n\\\\[\\n\\\\text{Time} = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = 0.2 \\\\text{ hours}\\n\\\\]\\n\\nConverting 0.2 hours to minutes:\\n\\n\\\\[\\n0.2 \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes.<endofsentence><beginofsentence>\\n\\nTo determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from transformers.generation import utils\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "dataset_pos = 0\n",
    "prompt = correct_dataset[dataset_pos][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": base_prompt.format(question=prompt),\n",
    "        },\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=4096,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] == correct_dataset[\n",
    "    dataset_pos\n",
    "][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': \"Alicia's average on her five tests is 88 points. The score range for each test is 0 points to 100 points, inclusive. What is the lowest possible score that Alicia could have earned on one of the five tests?\",\n",
       " 'solution': \"If Alicia's average score on her five tests is 88 points, then the sum of her scores must be $88 \\\\times 5 = 440$ points. If she earned   100 points on four of the tests, then she could have earned a score as low as $\\\\boxed{40\\\\text{ points}}$ on the other test.\",\n",
       " 'answer': '40\\\\text{ points}',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 4,\n",
       " 'unique_id': 'test/prealgebra/1697.json',\n",
       " 'model_answer': \"Okay, so I need to figure out the lowest possible score Alicia could have earned on one of her five tests. She has an average of 88 points, and each test is scored between 0 and 100, inclusive. Hmm, let me think about this step by step.\\n\\nFirst, I know that an average is calculated by taking the sum of all the test scores and dividing it by the number of tests. In this case, she has five tests, and her average is 88. So, to find the total points she has across all five tests, I can multiply the average by the number of tests.\\n\\nLet me write that down:\\n\\nTotal points = Average  Number of tests\\nTotal points = 88  5\\n\\nLet me calculate that. 88 times 5 is... 440. So, the total points she has across all five tests is 440.\\n\\nNow, the question is asking for the lowest possible score she could have earned on one of these tests. To minimize one of the test scores, I need to maximize the other scores because the total is fixed at 440.\\n\\nBut there are constraints: each test can only have a score between 0 and 100, inclusive. So, the maximum score on any test is 100. If I try to maximize the other four test scores, each being 100, that would give me the maximum possible sum for four tests.\\n\\nLet me calculate that:\\n\\nMaximizing four tests:\\nMax sum = 100  4 = 400\\n\\nSo, if four tests are 100 each, that's 400 points. Then, the fifth test must make up the remaining points to reach the total of 440.\\n\\nLet me find the score for the fifth test:\\n\\nScore on fifth test = Total points - Max sum of four tests\\nScore = 440 - 400\\nScore = 40\\n\\nWait, so that means if four tests are 100 each, the fifth test must be 40? That seems low, but it's mathematically correct because 100 + 100 + 100 + 100 + 40 = 440.\\n\\nBut hold on, the question is asking for the lowest possible score on one of the tests. So, if I set the other four tests as high as possible (100 each), the fifth test would be 40. But is there a way to get a lower score? Let me think.\\n\\nIf I make one of the other tests lower than 100, does that allow the fifth test to be lower than 40? Wait, no, because if I lower one test, I have to raise the others to compensate, but they can't go above 100. So, actually, to minimize one test, you need to maximize the others as much as possible, which is 100 each. So, 40 is indeed the minimal possible score.\\n\\nBut just to double-check, let's think about it differently. Suppose I try to set four tests to 100, which gives me 400. The fifth test is 40. If I tried to make the fifth test lower, say 30, then the sum of the other four tests would have to be 440 - 30 = 410. But if I have four tests, each can be at most 100, so 100  4 is 400. 410 is more than 400, which isn't possible. So, it's not possible to have a lower score on the fifth test than 40 because the other four tests can't exceed 400.\\n\\nTherefore, 40 is the lowest possible score Alicia could have earned on one of the five tests.\\n\\nWait, but another thought: what if one test is 0? Would that allow the others to be higher? Let me see. If one test is 0, then the total of the other four tests would have to be 440 - 0 = 440. But each of those four tests can only go up to 100, so 100  4 is 400. But 440 is more than 400, which is impossible. Therefore, having a 0 on one test would require the others to sum to 440, which isn't possible since the maximum they can sum to is 400. So, 0 is too low.\\n\\nSo, 40 is indeed the lowest possible score because it's the only score that allows the other four tests to be 100 each without exceeding the maximum.\\n\\nAnother angle: Let's think about the formula for the average. The average is the total divided by the number of tests. So, if I want to minimize one test, I have to maximize the others, but they can't exceed 100. So, the maximum sum of four tests is 400, as we had before. Therefore, the minimal fifth test is 40.\\n\\nWait, let me make sure I'm not missing any other constraints. The problem says each test is between 0 and 100, inclusive. So, 0 is allowed, but in this case, if we tried to set four tests to 100, the fifth must be 40. If we set one test to 100, the others could be higher, but that doesn't help in minimizing a single test. Alternatively, if I set two tests to 100, the others can be higher, but again, that doesn't help.\\n\\nTherefore, the only way to minimize a single test score is to maximize the other four, which is 100 each. So, the minimal possible score is 40.\\n\\nI think that's solid reasoning. I don't see any other way to lower one test score without violating the test score range or the total points.\\n\\n**Final Answer**\\nThe lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\\n</think>\\n\\nAlicia's average score on her five tests is 88 points. To find the total points she has across all five tests, we multiply the average by the number of tests:\\n\\n\\\\[\\n\\\\text{Total points} = 88 \\\\times 5 = 440\\n\\\\]\\n\\nTo find the lowest possible score on one of the tests, we need to maximize the scores of the other four tests. Since each test can score a maximum of 100, the maximum sum of four tests is:\\n\\n\\\\[\\n\\\\text{Max sum of four tests} = 100 \\\\times 4 = 400\\n\\\\]\\n\\nThe score on the fifth test must then be:\\n\\n\\\\[\\n\\\\text{Score on fifth test} = 440 - 400 = 40\\n\\\\]\\n\\nThus, the lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "example_id = correct_dataset[dataset_pos][\"unique_id\"].replace(\"/\", \"_\")\n",
    "with open(f\"./temp/{example_id}\", \"w\") as f:\n",
    "    temp = {\n",
    "        \"generated_ids\": generated_ids.tolist(),\n",
    "        \"input_ids\": generated_tokens.tolist(),\n",
    "    }\n",
    "    json.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\n",
    "    correct_dataset[dataset_pos][\"model_answer\"],\n",
    "    add_special_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<beginofsentence><User>An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?<Assistant><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them will be changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should think of the relative speed as the lion's speed minus the elephant's speed? Wait, no, that might not be right.\\n\\nLet me clarify. If the lion is moving towards the elephant at 24 mph, and the elephant is moving away from the lion at 19 mph, then the lion is effectively closing the gap at a rate of 24 mph minus 19 mph. That makes sense because the lion is moving towards the elephant, but the elephant is moving away. So, the net speed at which the distance between them is decreasing is 24 - 19 = 5 mph.\\n\\nSo, the distance between them is decreasing at 5 miles per hour. They start 1 mile apart, so I can use the formula:\\n\\nTime = Distance / Speed\\n\\nHere, the distance is 1 mile, and the speed is 5 mph. So, time = 1 / 5 hours. But the question asks for the time in minutes, so I need to convert hours to minutes. There are 60 minutes in an hour, so 1/5 hours * 60 minutes/hour = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph towards the elephant, and the elephant is moving away at 19 mph, then the relative speed is indeed 24 - 19 = 5 mph. So, the lion is gaining on the elephant at 5 miles per hour. Since they start 1 mile apart, the time it takes to close that distance is 1 / 5 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure, let me think about it another way. Maybe set up an equation for their positions as functions of time and see when they meet.\\n\\nLet me denote t as the time in hours. The position of the elephant as a function of time would be starting from some point and moving away at 19 mph. Let's say the initial position of the elephant is at position 0, and the lion is at position 1 mile. Then, the position of the elephant at time t is 0 + 19t, and the position of the lion is 1 - 24t. They meet when their positions are equal, so:\\n\\n19t = 1 - 24t\\n\\nAdding 24t to both sides:\\n\\n19t + 24t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours\\n\\nWait, that's different from what I got before. Hmm, so which one is correct? 12 minutes or 1/43 hours?\\n\\nWait, 1/43 hours is approximately 1.395 minutes, which is about 1 minute and 23 seconds. But earlier, I got 12 minutes. That's a big difference. So, I must have made a mistake somewhere.\\n\\nLet me go back. When I thought about the relative speed, I considered the lion moving towards the elephant and the elephant moving away, so the relative speed is 24 - 19 = 5 mph. So, the time should be 1/5 hours, which is 12 minutes. But when I set up the equations, I got t = 1/43 hours, which is about 1.395 minutes. That's conflicting.\\n\\nWait, maybe I messed up the initial positions. Let me define the positions more carefully. Let's say the lion starts at position 0, and the elephant starts at position 1 mile. Then, the lion is moving towards the elephant, so its position as a function of time is 0 + 24t. The elephant is moving away from the lion, so its position is 1 + 19t. They meet when their positions are equal:\\n\\n24t = 1 + 19t\\n\\nSubtracting 19t from both sides:\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. Okay, that makes sense. So, why did I get 1/43 hours earlier?\\n\\nWait, in my second approach, I set the lion's position as 1 - 24t, but that might be incorrect. If the lion starts at position 0, moving towards the elephant, which is at position 1, then the lion's position is 24t. The elephant is moving away from the lion, so its position is 1 + 19t. So, setting them equal:\\n\\n24t = 1 + 19t\\n\\nWhich gives t = 1/5 hours, which is 12 minutes. So, that seems correct.\\n\\nWait, so why did I get 1/43 hours earlier? Maybe I confused the starting positions. Let me re-examine that.\\n\\nIn the second approach, I set the lion's position as 1 - 24t, which would be incorrect because if the lion is moving towards the elephant, starting from position 0, its position should be increasing, not decreasing. So, that was my mistake. I should have set the lion's position as 24t, not 1 - 24t.\\n\\nSo, correcting that, the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes. So, that's consistent with the first method.\\n\\nTherefore, the correct answer is 12 minutes.\\n\\nWait, but just to make sure, let me think about it in another way. Suppose the lion is moving at 24 mph towards the elephant, and the elephant is\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them is changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should consider the relative speed between the lion and the elephant.\\n\\nWait, actually, since the elephant is moving away, the lion has to cover the initial distance plus any additional distance the elephant might cover while the lion is chasing. But since the lion is faster, it should eventually catch up. So, maybe I can model this as a relative speed problem.\\n\\nLet me denote the speed of the lion as \\\\( v_l = 24 \\\\) mph and the speed of the elephant as \\\\( v_e = 19 \\\\) mph. The initial distance between them is \\\\( d = 1 \\\\) mile.\\n\\nSince the lion is moving towards the elephant and the elephant is moving away, the relative speed at which the distance between them is decreasing is the difference between the lion's speed and the elephant's speed. So, the relative speed \\\\( v_{relative} = v_l - v_e = 24 - 19 = 5 \\\\) mph.\\n\\nWait, is that right? If the lion is moving towards the elephant and the elephant is moving away, then the lion is effectively closing the gap at a rate of 5 mph. So, the time it takes to close the 1 mile gap would be the initial distance divided by the relative speed.\\n\\nSo, time \\\\( t = \\\\frac{d}{v_{relative}} = \\\\frac{1}{5} \\\\) hours. But the question asks for the time in minutes, so I need to convert that.\\n\\nSince 1 hour is 60 minutes, \\\\( \\\\frac{1}{5} \\\\) hours is \\\\( \\\\frac{1}{5} \\\\times 60 = 12 \\\\) minutes. So, it should take 12 minutes for the lion to catch the elephant.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, then the lion is gaining on the elephant at a rate of 5 mph. So, to cover the 1 mile gap, it would take \\\\( \\\\frac{1}{5} \\\\) hours, which is indeed 12 minutes. That seems correct.\\n\\nAlternatively, I can model this with equations. Let me set up a coordinate system where at time \\\\( t \\\\) hours, the position of the lion is \\\\( 24t \\\\) miles from its starting point, and the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion. Wait, actually, hold on. If the elephant is moving away from the lion, then the distance between them is increasing. So, the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion, and the position of the lion is \\\\( 24t \\\\) miles from the same starting point.\\n\\nWait, but initially, they are 1 mile apart. So, if the lion starts at position 0 and the elephant starts at position 1 mile, then the distance between them at time \\\\( t \\\\) is \\\\( |24t - (1 + 19t)| \\\\). We want this distance to be 0 when the lion catches the elephant.\\n\\nSo, setting up the equation:\\n\\n\\\\( 24t - (1 + 19t) = 0 \\\\)\\n\\nSimplify:\\n\\n\\\\( 24t - 19t - 1 = 0 \\\\)\\n\\n\\\\( 5t - 1 = 0 \\\\)\\n\\n\\\\( 5t = 1 \\\\)\\n\\n\\\\( t = \\\\frac{1}{5} \\\\) hours, which is 12 minutes. So, that confirms my earlier result.\\n\\nAlternatively, I can think about it in terms of distance covered. The lion needs to cover the initial 1 mile plus whatever distance the elephant covers in that time. But since the lion is faster, the time is determined by the relative speed.\\n\\nWait, another way to think about it is using the concept of relative velocity. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the relative speed is 24 - 19 = 5 mph. So, the lion is closing the gap at 5 mph. Therefore, the time to close 1 mile is 1/5 hours, which is 12 minutes.\\n\\nI think that's solid. I can't see any mistakes in this reasoning. So, I think the answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed.\\n\\nThe relative speed at which the lion is closing the gap is the difference between their speeds:\\n\\\\[ v_{\\\\text{relative}} = v_l - v_e = 24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph} \\\\]\\n\\nThe time it takes to close the 1 mile gap is calculated by dividing the initial distance by the relative speed:\\n\\\\[ t = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours} \\\\]\\n\\nConverting this time into minutes:\\n\\\\[ \\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes} \\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate with compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "===\n",
      "===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPRESSED PART Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\n",
      "\n",
      "First, let me write down each term:\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4\n",
      "\n",
      "P = -i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "And the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\n",
      "\n",
      "Let me start by substituting the values:\n",
      "\n",
      "A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Wait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Okay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\n",
      "\n",
      "First, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\n",
      "\n",
      "(2 + i) - (-4) = (2 + i) + 4\n",
      "\n",
      "So, that simplifies to 2 + 4 + i, which is 6 + i.\n",
      "\n",
      "Alright, so now the expression becomes:\n",
      "\n",
      "6 + i + (-i) + (2 + 4i)\n",
      "\n",
      "Wait, let me write that again:\n",
      "\n",
      "= (6 + i) + (-i) + (2 + 4i)\n",
      "\n",
      "Now,\n",
      "===\n",
      " let's handle the imaginary parts and the real parts separately.\n",
      "\n",
      "Imaginary parts: i + (-i) = i - i = 0i, which is just 0.\n",
      "\n",
      "Real parts: 6 + 2 = 8.\n",
      "\n",
      "So, adding them together: 8 + 0i = 8.\n",
      "\n",
      "Wait, that seems too straightforward. Let me check my steps again to make sure I didn't make a mistake.\n",
      "\n",
      "Starting over:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, handle the subtraction:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P: 6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S: 6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Wait, hold on, that's different from what I had before. Hmm, so I must have made a mistake in my initial breakdown.\n",
      "\n",
      "Let me do it step by step again:\n",
      "\n",
      "Start with A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Wait, so now I get 8 + 4i. But earlier, I thought it was 8. So, which one is correct?\n",
      "\n",
      "Let me count the steps again.\n",
      "\n",
      "1. Compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "2. Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "3. Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "So, that's 8 + 4i. Hmm, so why did I get 8 earlier? Because I thought that adding 6 and 2 gives 8, but actually, 6 is already a real number, and then adding 2 gives 8, but the imaginary parts cancel out, leaving just 8 + 4i.\n",
      "\n",
      "Wait, so perhaps I made a mistake in my initial breakdown when I thought it was 8. So, actually, the correct answer is 8 + 4i.\n",
      "\n",
      "Wait, let me check the arithmetic again.\n",
      "\n",
      "Starting over:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that seems correct. So, the final answer is 8 + 4i.\n",
      "\n",
      "Wait, but in my initial thought process, I thought it was 8, but now I see it's 8 + 4i. So, I need to make sure I don't make that mistake again.\n",
      "\n",
      "Alternatively, maybe I can approach it differently. Let me group the real parts and the imaginary parts separately.\n",
      "\n",
      "So, starting with:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, let's handle the real parts:\n",
      "\n",
      "Real parts: 2 (from A) + 4 (from O) + 2 (from S) = 2 + 4 + 2 = 8\n",
      "\n",
      "Imaginary parts: 1 (from A) + 0 (from O) - 1 (from P) + 4 (from S) = 1 + 0 - 1 + 4 = 4\n",
      "\n",
      "So, combining them: 8 + 4i\n",
      "\n",
      "Yes, that's consistent with the previous result.\n",
      "\n",
      "So, I think I initially made a mistake by not properly grouping the real and imaginary parts, but now that I've broken it down separately, it's clear that the answer is 8 + 4i.\n",
      "\n",
      "Wait, but let me make sure I didn't misplace any signs. Let's go step by step again.\n",
      "\n",
      "Compute A - O + P + S:\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4\n",
      "\n",
      "P = -i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute (2 + i) - (-4):\n",
      "\n",
      "Subtracting a negative is adding a positive, so:\n",
      "\n",
      "2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P: 6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "Then, add S: 6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Alternatively, if I were to write it as:\n",
      "\n",
      "(A - O) + (P + S)\n",
      "\n",
      "Compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 6 + i\n",
      "\n",
      "Compute P + S:\n",
      "\n",
      "(-i) + (2 + 4i) = 2 + 3i\n",
      "\n",
      "Then, add those results: (6 + i) + (2 + 3i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "So, I think I can confidently say that the answer is 8 + 4i.\n",
      "\n",
      "Wait, but just to make sure, let me plug in the values into the original expression and see if it matches.\n",
      "\n",
      "Compute A - O + P + S:\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Compute each operation step by step:\n",
      "\n",
      "First, A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Alternatively, if I were to write it as:\n",
      "\n",
      "(A + P + S) - O\n",
      "\n",
      "Compute A + P + S:\n",
      "\n",
      "(2 + i) + (-i) + (2 + 4i) = 2 + i - i + 2 + 4i = (2 + 2) + (i - i + 4i) = 4 + 4i\n",
      "\n",
      "Then, subtract O: 4 + 4i - (-4) = 4 + 4i + 4 = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "So, regardless of the order in which I group the operations, I still get 8 + 4i.\n",
      "\n",
      "Therefore, I think I can be confident that the correct answer is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another method. Maybe convert all complex numbers to their standard form and then add them.\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4 (which is -4 + 0i)\n",
      "\n",
      "P = -i (which is 0 - i)\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\n",
      "\n",
      "Compute each operation:\n",
      "\n",
      "First, A - O:\n",
      "\n",
      "(2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (0 - i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Alternatively, if I write all the complex numbers in a column:\n",
      "\n",
      "A: 2 + i\n",
      "\n",
      "-O: +4 + 0i\n",
      "\n",
      "P: 0 - i\n",
      "\n",
      "S: 2 + 4i\n",
      "\n",
      "Adding them up:\n",
      "\n",
      "Real parts: 2 + 4 + 0 + 2 = 8\n",
      "\n",
      "Imaginary parts: 1 + 0 - 1 + 4 = 4\n",
      "\n",
      "So, 8 + 4i.\n",
      "\n",
      "Yes, that's consistent.\n",
      "\n",
      "Therefore, I think I can conclude that the value of A - O + P + S is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another approach. Maybe convert all complex numbers to their rectangular form and then add them step by step.\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4 = -4 + 0i\n",
      "\n",
      "P = -i = 0 - i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\n",
      "\n",
      "Compute A - O:\n",
      "\n",
      "(2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + 0 - i = 6 + 0i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Alternatively, if I write all the operations together:\n",
      "\n",
      "A - O + P + S = (2 + i) + 4 + (-i) + 2 + 4i\n",
      "\n",
      "Wait, hold on, that's another way to think about it. Let me see.\n",
      "\n",
      "A - O + P + S = A + (-O) + P + S\n",
      "\n",
      "Since O = -4, -O = 4\n",
      "\n",
      "So, A + 4 + P + S\n",
      "\n",
      "Now, substitute A, P, S:\n",
      "\n",
      "(2 + i) + 4 + (-i) + (2 + 4i)\n",
      "\n",
      "Now, combine like terms:\n",
      "\n",
      "Real parts: 2 + 4 + 2 = 8\n",
      "\n",
      "Imaginary parts: i - i + 4i = 4i\n",
      "\n",
      "So, 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Therefore, I think I can be absolutely sure that the answer is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another method. Maybe using vectors or something.\n",
      "\n",
      "But actually, since all the operations are straightforward addition and subtraction of complex numbers, I think the above methods are sufficient.\n",
      "\n",
      "Therefore, I think the answer is 8 + 4i.\n",
      "\n",
      "**Final Answer**\n",
      "The value of \\( A - O + P + S \\) is \\boxed{8 + 4i}.\n",
      "</think>\n",
      "\n",
      "Given the values \\( A = 2 + i \\), \\( O = -4 \\), \\( P = -i \\), and \\( S = 2 + 4i \\), we need to find the value of \\( A - O + P + S \\).\n",
      "\n",
      "First, substitute the given values into the expression:\n",
      "\n",
      "\\[\n",
      "A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\\]\n",
      "\n",
      "Simplify each term step by step:\n",
      "\n",
      "1. Compute \\( A - O \\):\n",
      "   \\[\n",
      "   (2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "   \\]\n",
      "\n",
      "2. Add \\( P \\) to the result:\n",
      "   \\[\n",
      "   6 + i + (-i) = 6 + 0i = 6\n",
      "   \\]\n",
      "\n",
      "3. Add \\( S \\) to the result:\n",
      "   \\[\n",
      "   6 + (2 + 4i) = 8 + 4i\n",
      "   \\]\n",
      "\n",
      "Thus, the value of \\( A - O + P + S \\) is \\(\\boxed{8 + 4i}\\).<endofsentence>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dataset_pos = 0\n",
    "input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "print(input_ids)\n",
    "print(\"===\")\n",
    "print(\"===\")\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "input_ids = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": base_prompt.format(question=input_ids),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "# input_ids = dataset_item[\"input_ids\"]\n",
    "# generated_ids = dataset_item[\"generated_ids\"]\n",
    "generated_ids = [\n",
    "    tokenizer.encode(\n",
    "        correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "\n",
    "# generated_tokens = tokenizer.apply_chat_template(\n",
    "#     [\n",
    "#         # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "#         {\"role\": \"user\", \"content\": example[\"question\"]},\n",
    "#     ],\n",
    "#     tokenize=True,\n",
    "#     add_generation_prompt=True,\n",
    "# )\n",
    "generated_tokens = input_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # start_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # end_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    input_ids = torch.tensor(input_ids).cuda()\n",
    "    input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "    # input_ids_embeds = model.base_model.embed_pooler.model.get_input_embeddings()(input_ids)\n",
    "    # windows_amount = 100\n",
    "    windows_amount = 200\n",
    "    # windows_amount = 300\n",
    "    # windows_amount = 400\n",
    "    # windows_amount = 500\n",
    "    # windows_amount = 2\n",
    "    next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "        :, : WINDOW_SIZE * windows_amount\n",
    "    ]\n",
    "\n",
    "    # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "    original_embeds = (\n",
    "        model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.base_model.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.get_input_embeddings()(next_true_tokens)\n",
    "    ).to(torch.float32)\n",
    "    # ).to(torch.bfloat16)\n",
    "\n",
    "    # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    new_embeds_for_compression = original_embeds.reshape(\n",
    "        windows_amount, WINDOW_SIZE, -1\n",
    "    )\n",
    "    compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "    # start_embed = torch.rand_like(start_embed)\n",
    "    # compressed_part = torch.rand_like(compressed_part)\n",
    "    # end_embed = torch.rand_like(end_embed)\n",
    "    generated_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds,\n",
    "            start_embed,\n",
    "            compressed_part,\n",
    "            end_embed,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "    print(\"===\")\n",
    "    generated_ids_compressed = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=2800,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        # do_sample=True,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "    # break\n",
    "print(tokenizer.decode(generated_ids_compressed[-1]))\n",
    "# break\n",
    "# embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Below is a magic square, meaning that the sum of the numbers in each row, in each column, and in each of the $2$ main diagonals are equal. What is the value of $n$?\\n\\n[asy]size(125);\\nfor(int i = 0; i<4; ++i)\\n{\\n\\ndraw((0,i)--(3,i),linewidth(1));\\n}\\n\\nfor(int j = 0; j<4; ++j)\\n{\\n\\ndraw((j,0)--(j,3),linewidth(1));\\n}\\n\\nlabel(\"$n-3$\",(.5,.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"$n+1$\",(.5,2.5));\\n\\nlabel(\"$n+2$\",(1.5,.5));\\nlabel(\"$2n-9$\",(1.5,1.5));\\nlabel(\"$1$\",(1.5,2.5));\\n\\nlabel(\"$2$\",(2.5,.5));\\nlabel(\"$n$\",(2.5,1.5));\\nlabel(\"$n-1$\",(2.5,2.5));\\n[/asy]',\n",
       " 'solution': 'First, we can evaluate the sum across the first row, which gives $(n+1)+1+(n-1)=2n+1$.  Evaluate the sum of the entries across the second row, $3+(2n-9)+n=3n-6$. Now, since we have a magic square, these two sums are equal.  So $2n+1=3n-6$. Isolating $n$, we obtain $n = \\\\boxed{7}$.\\n\\nThe square will look like: [asy] size(2cm);\\ndraw((0,0)--(3,0)--(3,3)--(0,3)--cycle,linewidth(1));\\ndraw((1,0)--(1,3),linewidth(1));\\ndraw((2,0)--(2,3),linewidth(1));\\ndraw((0,1)--(3,1),linewidth(1));\\ndraw((0,2)--(3,2),linewidth(1));\\nlabel(\"8\",(.5,2.5));\\nlabel(\"1\",(1.5,2.5));\\nlabel(\"6\",(2.5,2.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"5\",(1.5,1.5));\\nlabel(\"7\",(2.5,1.5));\\nlabel(\"4\",(.5,.5));\\nlabel(\"9\",(1.5,.5));\\nlabel(\"2\",(2.5,.5));\\n[/asy]',\n",
       " 'answer': '7',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1930.json',\n",
       " 'model_answer': \"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). Let me try to figure this out step by step. \\n\\nFirst, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\\\( n \\\\) such that all these sums are equal.\\n\\nLooking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\\n\\n- The top row has three cells: \\\\( n-3 \\\\), \\\\( 3 \\\\), and \\\\( n+1 \\\\).\\n- The middle row has \\\\( n+2 \\\\), \\\\( 2n-9 \\\\), and \\\\( 1 \\\\).\\n- The bottom row has \\\\( 2 \\\\), \\\\( n \\\\), and \\\\( n-1 \\\\).\\n\\nSo, writing this out, the magic square looks like this:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, now I need to find \\\\( n \\\\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\\\( S \\\\).\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That means the magic constant \\\\( S = 2n + 1 \\\\).\\n\\nLet me check the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since this must equal \\\\( S \\\\), we have:\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nLet me solve for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( n = 7 \\\\)\\n\\nWait, hold on. Let me verify this because I might have made a mistake. If \\\\( n = 7 \\\\), let me check the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nBut according to the first row, \\\\( 2n + 1 = 2*7 + 1 = 15 \\\\). So, that's consistent.\\n\\nLet me check the columns as well to make sure.\\n\\nFirst column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nPerfect.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + 1 + (7 - 1) = 8 + 1 + 6 = 15 \\\\)\\n\\nAll columns add up to 15.\\n\\nNow, let me check the diagonals.\\n\\nMain diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (14 - 9) + (7 - 1) = 4 + 5 + 6 = 15 \\\\)\\n\\nGood.\\n\\nOther diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals add up to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\). Therefore, \\\\( n = 7 \\\\) is the solution.\\n\\nBut wait, just to be thorough, let me check if all the individual cells are integers and if there are any constraints on \\\\( n \\\\). The problem doesn't specify that \\\\( n \\\\) has to be an integer, but in magic squares, often the numbers are integers. Let me see if \\\\( n = 7 \\\\) makes all the cells integers.\\n\\nLooking at the cells:\\n\\n- \\\\( n - 3 = 7 - 3 = 4 \\\\)\\n- \\\\( 3 \\\\) is already an integer.\\n- \\\\( n + 1 = 7 + 1 = 8 \\\\)\\n- \\\\( n + 2 = 7 + 2 = 9 \\\\)\\n- \\\\( 2n - 9 = 14 - 9 = 5 \\\\)\\n- \\\\( 1 \\\\) is an integer.\\n- \\\\( 2 \\\\) is an integer.\\n- \\\\( n = 7 \\\\)\\n- \\\\( n - 1 = 6 \\\\)\\n\\nAll of these are integers, so that's good.\\n\\nIs there any other constraint? The problem doesn't specify, so I think \\\\( n = 7 \\\\) is the correct answer.\\n\\nBut just to make sure, let me go back to the second row sum. I had:\\n\\nSecond row sum: \\\\( 3n - 6 \\\\)\\n\\nSet equal to \\\\( S = 2n + 1 \\\\):\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nSubtract \\\\( 2n \\\\):\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6:\\n\\n\\\\( n = 7 \\\\)\\n\\nYes, that's consistent.\\n\\nAlternatively, I could have used another row or column to solve for \\\\( n \\\\), but since all rows, columns, and diagonals give the same equation, it's redundant, but it's a good check.\\n\\nSo, I think I'm confident that \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we need to ensure that the sums of all rows, columns, and diagonals are equal. The magic square is as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nFirst, we calculate the sum of the first row:\\n\\\\[\\n(n - 3) + 3 + (n + 1) = 2n + 1\\n\\\\]\\nThis sum is the magic constant \\\\( S \\\\).\\n\\nNext, we calculate the sum of the second row:\\n\\\\[\\n(n + 2) + (2n - 9) + 1 = 3n - 6\\n\\\\]\\nSince this must equal \\\\( S \\\\), we set up the equation:\\n\\\\[\\n3n - 6 = 2n + 1\\n\\\\]\\nSolving for \\\\( n \\\\):\\n\\\\[\\n3n - 6 = 2n + 1 \\\\\\\\\\nn - 6 = 1 \\\\\\\\\\nn = 7\\n\\\\]\\n\\nWe verify this value by checking the sums of the columns and diagonals with \\\\( n = 7 \\\\):\\n- First column: \\\\( (7 - 3) + (7 + 2) + 2 = 15 \\\\)\\n- Second column: \\\\( 3 + (14 - 9) + 7 = 15 \\\\)\\n- Third column: \\\\( (7 + 1) + 1 + (7 - 1) = 15 \\\\)\\n- Main diagonal: \\\\( (7 - 3) + (14 - 9) + (7 - 1) = 15 \\\\)\\n- Other diagonal: \\\\( (7 + 1) + (14 - 9) + 2 = 15 \\\\)\\n\\nAll sums are equal to 15, confirming that \\\\( n = 7 \\\\) is correct.\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2601, 400, 2801, torch.Size([1, 2356]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids_compressed.shape[1], next_true_tokens.shape[\n",
    "    1\n",
    "], generated_ids_compressed.shape[1] + compressed_part.shape[1], torch.tensor(\n",
    "    generated_ids\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "# \"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\"\n",
    "\n",
    "# compressed\n",
    "# 'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'\n",
    "\n",
    "# generated\n",
    "# \" + i, O is -4, P is -i, and S is 2 + 4i. So, the expression is A - O + P + S, which is (2 + i) - (-4) + (-i) + (2 + 4i). That seems right.\\n\\nNow, let me simplify this step by step. First, I can handle the subtraction of O, which is -(-4). Subtracting a negative is like adding a positive, so -(-4) is +4. So, that part becomes +4.\\n\\nSo, now the expression is:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNext, I can combine the real parts and the imaginary parts separately. Let me rewrite the expression grouping the real numbers and the imaginary numbers together:\\n\\nReal parts: 2 + 4 + 2\\n\\nImaginary parts: i - i + 4i\\n\\nLet me compute the real parts first. 2 + 4 is 6, and then 6 + 2 is 8. So, the real part is 8.\\n\\nNow, the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, the imaginary part is 4i.\\n\\nPutting it all together, the expression simplifies to 8 + 4i.\\n\\nWait, let me double-check that. So, starting from A - O + P + S:\\n\\nA is 2 + i, subtract O which is -4, so that becomes +4. Then add P which is -i, and add S which is 2 + 4i.\\n\\nSo, writing it out:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNow, let's combine the constants first. 2 + 4 is 6, and then 6 + 2 is 8. So, that's the real part.\\n\\nFor the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, that's correct.\\n\\nTherefore, the result is 8 + 4i.\\n\\nWait, but let me think again. Is there another way to approach this? Maybe by distributing the negative sign first.\\n\\nSo, A - O + P + S can be rewritten as A + (-O) + P + S. Since O is -4, -O is +4. So, that's the same as before.\\n\\nAlternatively, maybe I can think of it as A + (-O + P + S). Let me compute -O + P + S first.\\n\\nO is -4, so -O is +4. P is -i, and S is 2 + 4i. So, -O + P + S is 4 + (-i) + (2 + 4i).\\n\\nAgain, combining constants: 4 + 2 is 6, and then 6 + 0 is 6. For the imaginary parts: -i + 4i is 3i. So, that's 6 + 3i.\\n\\nThen, adding A, which is 2 + i, to that: (2 + i) + (6 + 3i) = 8 + 4i. So, same result.\\n\\nAlternatively, maybe I can add A and S first, then subtract O and add P.\\n\\nLet me try that approach.\\n\\nA is 2 + i, S is 2 + 4i. So, A + S is (2 + 2) + (i + 4i) = 4 + 5i.\\n\\nThen, subtract O, which is -4. So, A + S - O is 4 + 5i - (-4) = 4 + 5i + 4 = 8 + 5i.\\n\\nThen, add P, which is -i. So, 8 + 5i + (-i) = 8 + 4i. Again, same result.\\n\\nSo, regardless of the order in which I perform the operations, I end up with 8 + 4i.\\n\\nWait, let me make sure I didn't make any mistakes in my calculations. Sometimes, when dealing with complex numbers, it's easy to mix up the real and imaginary parts.\\n\\nLet me write down each step again:\\n\\n1. Start with A - O + P + S.\\n\\n2. Substitute the values:\\n\\n   (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\n3. Simplify the subtraction of O:\\n\\n   (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n4. Combine constants and imaginary parts:\\n\\n   Real parts: 2 + 4 + 2 = 8\\n\\n   Imaginary parts: i - i + 4i = 4i\\n\\n5. Combine them: 8 + 4i\\n\\nAlternatively, if I group the constants first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine constants: 2 + 4 + 2 = 8\\n\\n4. Combine imaginary parts: i - i + 4i = 4i\\n\\n5. Result: 8 + 4i\\n\\nAlternatively, if I group the imaginary parts first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine imaginary parts: i - i + 4i = 4i\\n\\n4. Combine real parts: 2 + 4 + 2 = 8\\n\\n5. Result: 8 + 4i\\n\\nSo, regardless of the order, I get the same result. Therefore, I think 8 + 4i is the correct answer.\\n\\nWait, just to be absolutely sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA is 2 + i, O is -4. So, A - O is (2 + i) - (-4) = 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i: 6 + i + (-i) = 6 + 0i = 6.\\n\\nThen, add S, which is 2 + 4i: 6 + (2 + 4i) = 8 + 4i.\\n\\nSo, that's another way to compute it step by step:\\n\\nA - O = 6 + i\\n\\nThen, A - O + P = 6 + i - i = 6\\n\\nThen, A - O + P + S = 6 + 2 + 4i = 8 + 4i.\\n\\nSame result.\\n\\nAlternatively, if I compute A - O + P + S step by step without grouping:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation one by one:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the approach, I end up with 8 + 4i.\\n\\nTherefore, I think I can confidently say that the value of A - O + P + S is 8 + 4i.\\n\\nJust to recap, the steps I took were:\\n\\n1. Substitute the given values into the expression.\\n\\n2. Simplify the expression by handling the subtraction of O, which turned into addition of 4.\\n\\n3. Combine the real parts and the imaginary parts separately.\\n\\n4. Verify the result by computing in different orders or by breaking it down into smaller steps.\\n\\n5. Ensure that each step is correct and that I didn't make any arithmetic errors.\\n\\nSo, I think I'm good. The answer is 8 + 4i.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Subtract \\\\( O \\\\) which is \\\\(-4\\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) which is \\\\(-i\\\\):\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) which is \\\\( 2 + 4i \\\\):\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). Let me try to figure this out step by step. \\n\\nFirst, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\\\( n \\\\) such that all these sums are equal.\\n\\nLooking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\\n\\n- The top row has three cells: \\\\( n-3 \\\\), \\\\( 3 \\\\), and \\\\( n+1 \\\\).\\n- The middle row has \\\\( n+2 \\\\), \\\\( 2n-9 \\\\), and \\\\( 1 \\\\).\\n- The bottom row has \\\\( 2 \\\\), \\\\( n \\\\), and \\\\( n-1 \\\\).\\n\\nSo, writing this out, the magic square looks like this:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, now I need to find \\\\( n \\\\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\\\( S \\\\).\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That means the magic constant \\\\( S = 2n + 1 \\\\).\\n\\nLet me check the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since this must equal \\\\( S \\\\), we have:\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nLet me solve for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( n = 7 \\\\)\\n\\nWait, hold on. Let me verify this because I might have made a mistake. If \\\\( n = 7 \\\\), let me check the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nBut according to the first row, \\\\( 2n + 1 = 2*7 + 1 = 15 \\\\). So, that's consistent.\\n\\nLet me check the columns as well to make sure.\\n\\nFirst column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nPerfect.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + 1 + (7 - 1) = 8 + 1 + 6 = 15 \\\\)\\n\\nAll columns add up to 15.\\n\\nNow, let me check the diagonals.\\n\\nMain diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (14 - 9) + (7 - 1) = 4 + 5 + 6 = 15 \\\\)\\n\\nGood.\\n\\nOther diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals add up to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\). Therefore, \\\\( n = 7 \\\\) is the solution.\\n\\nBut wait, just to be thorough, let me check if all the individual cells are integers and if there are any constraints on \\\\( n \\\\). The problem doesn't specify that \\\\( n \\\\) has to be an integer, but in magic squares, often the numbers are integers. Let me see if \\\\( n = 7 \\\\) makes all the cells integers.\\n\\nLooking at the cells:\\n\\n- \\\\( n - 3 = 7 - 3 = 4 \\\\)\\n- \\\\( 3 \\\\) is already an integer.\\n- \\\\( n + 1 = 7 + 1 = 8 \\\\)\\n- \\\\( n + 2 = 7 + 2 = 9 \\\\)\\n- \\\\( 2n - 9 = 14 - 9 = 5 \\\\)\\n- \\\\( 1 \\\\) is an integer.\\n- \\\\( 2 \\\\) is an integer.\\n- \\\\( n = 7 \\\\)\\n- \\\\( n - 1 = 6 \\\\)\\n\\nAll of these are integers, so that's good.\\n\\nIs there any other constraint? The problem doesn't specify, so I think \\\\( n = 7 \\\\) is the correct answer.\\n\\nBut just to make sure, let me go back to the second row sum. I had:\\n\\nSecond row sum: \\\\( 3n - 6 \\\\)\\n\\nSet equal to \\\\( S = 2n + 1 \\\\):\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nSubtract \\\\( 2n \\\\):\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6:\\n\\n\\\\( n = 7 \\\\)\\n\\nYes, that's consistent.\\n\\nAlternatively, I could have used another row or column to solve for \\\\( n \\\\), but since all rows, columns, and diagonals give the same equation, it's redundant, but it's a good check.\\n\\nSo, I think I'm confident that \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we need to ensure that the sums of all rows, columns, and diagonals are equal. The magic square is as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nFirst, we calculate the sum of the first row:\\n\\\\[\\n(n - 3) + 3 + (n + 1) = 2n + 1\\n\\\\]\\nThis sum is the magic constant \\\\( S \\\\).\\n\\nNext, we calculate the sum of the second row:\\n\\\\[\\n(n + 2) + (2n - 9) + 1 = 3n - 6\\n\\\\]\\nSince this must equal \\\\( S \\\\), we set up the equation:\\n\\\\[\\n3n - 6 = 2n + 1\\n\\\\]\\nSolving for \\\\( n \\\\):\\n\\\\[\\n3n - 6 = 2n + 1 \\\\\\\\\\nn - 6 = 1 \\\\\\\\\\nn = 7\\n\\\\]\\n\\nWe verify this value by checking the sums of the columns and diagonals with \\\\( n = 7 \\\\):\\n- First column: \\\\( (7 - 3) + (7 + 2) + 2 = 15 \\\\)\\n- Second column: \\\\( 3 + (14 - 9) + 7 = 15 \\\\)\\n- Third column: \\\\( (7 + 1) + 1 + (7 - 1) = 15 \\\\)\\n- Main diagonal: \\\\( (7 - 3) + (14 - 9) + (7 - 1) = 15 \\\\)\\n- Other diagonal: \\\\( (7 + 1) + (14 - 9) + 2 = 15 \\\\)\\n\\nAll sums are equal to 15, confirming that \\\\( n = 7 \\\\) is correct.\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" + i, O is -4, P is -i, and S is 2 + 4i. So, the expression is A - O + P + S, which is (2 + i) - (-4) + (-i) + (2 + 4i). That seems right.\\n\\nNow, let me simplify this step by step. First, I can handle the subtraction of O, which is -(-4). Subtracting a negative is like adding a positive, so -(-4) is +4. So, that part becomes +4.\\n\\nSo, now the expression is:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNext, I can combine the real parts and the imaginary parts separately. Let me rewrite the expression grouping the real numbers and the imaginary numbers together:\\n\\nReal parts: 2 + 4 + 2\\n\\nImaginary parts: i - i + 4i\\n\\nLet me compute the real parts first. 2 + 4 is 6, and then 6 + 2 is 8. So, the real part is 8.\\n\\nNow, the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, the imaginary part is 4i.\\n\\nPutting it all together, the expression simplifies to 8 + 4i.\\n\\nWait, let me double-check that. So, starting from A - O + P + S:\\n\\nA is 2 + i, subtract O which is -4, so that becomes +4. Then add P which is -i, and add S which is 2 + 4i.\\n\\nSo, writing it out:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNow, let's combine the constants first. 2 + 4 is 6, and then 6 + 2 is 8. So, that's the real part.\\n\\nFor the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, that's correct.\\n\\nTherefore, the result is 8 + 4i.\\n\\nWait, but let me think again. Is there another way to approach this? Maybe by distributing the negative sign first.\\n\\nSo, A - O + P + S can be rewritten as A + (-O) + P + S. Since O is -4, -O is +4. So, that's the same as before.\\n\\nAlternatively, maybe I can think of it as A + (-O + P + S). Let me compute -O + P + S first.\\n\\nO is -4, so -O is +4. P is -i, and S is 2 + 4i. So, -O + P + S is 4 + (-i) + (2 + 4i).\\n\\nAgain, combining constants: 4 + 2 is 6, and then 6 + 0 is 6. For the imaginary parts: -i + 4i is 3i. So, that's 6 + 3i.\\n\\nThen, adding A, which is 2 + i, to that: (2 + i) + (6 + 3i) = 8 + 4i. So, same result.\\n\\nAlternatively, maybe I can add A and S first, then subtract O and add P.\\n\\nLet me try that approach.\\n\\nA is 2 + i, S is 2 + 4i. So, A + S is (2 + 2) + (i + 4i) = 4 + 5i.\\n\\nThen, subtract O, which is -4. So, A + S - O is 4 + 5i - (-4) = 4 + 5i + 4 = 8 + 5i.\\n\\nThen, add P, which is -i. So, 8 + 5i + (-i) = 8 + 4i. Again, same result.\\n\\nSo, regardless of the order in which I perform the operations, I end up with 8 + 4i.\\n\\nWait, let me make sure I didn't make any mistakes in my calculations. Sometimes, when dealing with complex numbers, it's easy to mix up the real and imaginary parts.\\n\\nLet me write down each step again:\\n\\n1. Start with A - O + P + S.\\n\\n2. Substitute the values:\\n\\n   (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\n3. Simplify the subtraction of O:\\n\\n   (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n4. Combine constants and imaginary parts:\\n\\n   Real parts: 2 + 4 + 2 = 8\\n\\n   Imaginary parts: i - i + 4i = 4i\\n\\n5. Combine them: 8 + 4i\\n\\nAlternatively, if I group the constants first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine constants: 2 + 4 + 2 = 8\\n\\n4. Combine imaginary parts: i - i + 4i = 4i\\n\\n5. Result: 8 + 4i\\n\\nAlternatively, if I group the imaginary parts first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine imaginary parts: i - i + 4i = 4i\\n\\n4. Combine real parts: 2 + 4 + 2 = 8\\n\\n5. Result: 8 + 4i\\n\\nSo, regardless of the order, I get the same result. Therefore, I think 8 + 4i is the correct answer.\\n\\nWait, just to be absolutely sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA is 2 + i, O is -4. So, A - O is (2 + i) - (-4) = 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i: 6 + i + (-i) = 6 + 0i = 6.\\n\\nThen, add S, which is 2 + 4i: 6 + (2 + 4i) = 8 + 4i.\\n\\nSo, that's another way to compute it step by step:\\n\\nA - O = 6 + i\\n\\nThen, A - O + P = 6 + i - i = 6\\n\\nThen, A - O + P + S = 6 + 2 + 4i = 8 + 4i.\\n\\nSame result.\\n\\nAlternatively, if I compute A - O + P + S step by step without grouping:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation one by one:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the approach, I end up with 8 + 4i.\\n\\nTherefore, I think I can confidently say that the value of A - O + P + S is 8 + 4i.\\n\\nJust to recap, the steps I took were:\\n\\n1. Substitute the given values into the expression.\\n\\n2. Simplify the expression by handling the subtraction of O, which turned into addition of 4.\\n\\n3. Combine the real parts and the imaginary parts separately.\\n\\n4. Verify the result by computing in different orders or by breaking it down into smaller steps.\\n\\n5. Ensure that each step is correct and that I didn't make any arithmetic errors.\\n\\nSo, I think I'm good. The answer is 8 + 4i.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Subtract \\\\( O \\\\) which is \\\\(-4\\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) which is \\\\(-i\\\\):\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) which is \\\\( 2 + 4i \\\\):\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_think = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "generated_ids[-1].index(end_think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids_compressed[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nNow, let's add the real parts and the imaginary parts separately.\\n\\nReal parts: 2 (from A) + (-4) (from O) + 0 (from P) + 2 (from S) = 0\\n\\nImaginary parts: 1 (from A) + 0 (from O) + (-1) (from P) + 4 (from S) = 4\\n\\nSo, putting it all together, the expression simplifies to 0 + 4i, which is just 4i.\\n\\nWait, hold on, that doesn't seem right. Let me check my steps again.\\n\\nWait, when I separated the real and imaginary parts, I think I might have made a mistake in the signs.\\n\\nLet me try that again.\\n\\nStarting over:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nExpression: A - O + P + S\\n\\nSubstitute the values:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nNow, distribute the negative sign to O:\\n\\n2 + i + 4 - i + (-i) + 2 + 4i\\n\\nWait, hold on, that doesn't seem right. Let me do it step by step.\\n\\nFirst, A - O: (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nWait, that makes more sense. So, the expression simplifies to 8 + 4i.\\n\\nWait, so earlier I messed up the distribution. Let me correct that.\\n\\nSo, starting over:\\n\\nExpression: A - O + P + S\\n\\nSubstitute:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle A - O:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nSo, the final result is 8 + 4i.\\n\\nWait, so earlier I thought it was 4i, but that was incorrect. I must have made a mistake in distributing the negative sign or something.\\n\\nSo, the correct answer is 8 + 4i.\\n\\nBut let me verify once more.\\n\\nCompute A - O + P + S:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation step by step:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems correct. So, the final result is 8 + 4i.\\n\\nI think I initially made a mistake in the distribution step, but upon redoing it, I arrived at the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nStarting with the expression:\\n\\\\[ A - O + P + S \\\\]\\n\\nSubstitute the given values:\\n\\\\[ (2 + i) - (-4) + (-i) + (2 + 4i) \\\\]\\n\\nSimplify each operation step by step:\\n1. Compute \\\\( (2 + i) - (-4) \\\\):\\n   \\\\[ 2 + i + 4 = 6 + i \\\\]\\n2. Add \\\\( P \\\\):\\n   \\\\[ 6 + i + (-i) = 6 + 0i = 6 \\\\]\\n3. Add \\\\( S \\\\):\\n   \\\\[ 6 + (2 + 4i) = 8 + 4i \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 1536])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<endofsentence>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(torch.tensor(generated_ids[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLets denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLets assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLets let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLets denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1536])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 224256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_embeds torch.Size([1, 62, 1536])\n",
      "<beginofsentence><User>Here's a question: What do many people believe happens after you die?  Here are possible answers to this question: - stop moving - nothing - go to heaven - stop living - stop breathing  I believe the correct choice is \"go to heaven\", here's why:\n",
      "Answer:<Assistant><think>\n",
      "Okay, so I'm trying to figure out the answer is correct. Let me think about it again. I think the user is trying to figure out the correct answer to the question they're asking. They provided a list of answers, and I need to heaven, but I'm not sure if I'm sure if I'm on the right track. Let me break it down step by step. The question is about what people believe happens after you die. I know that when someone dies, they believe that people often believe in something called the afterlife, which is the belief that after you die, you don't need to move or anything else. So, the correct answer is \"go to heaven\", which is the correct answer. The other options, like stopping moving, nothing, stop breathing, etc., aren't correct\n"
     ]
    }
   ],
   "source": [
    "from hidden_capacity_reasoning.utils import WINDOW_SIZE, VISION_START, VISION_END\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "\n",
    "def _crop_past_key_values(model, past_key_values, max_length):\n",
    "    \"\"\"Crops the past key values up to a certain maximum length.\"\"\"\n",
    "    new_past = []\n",
    "    if model.config.is_encoder_decoder:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            new_past.append(\n",
    "                (\n",
    "                    past_key_values[idx][0][:, :, :max_length, :],\n",
    "                    past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    past_key_values[idx][2],\n",
    "                    past_key_values[idx][3],\n",
    "                )\n",
    "            )\n",
    "        past_key_values = tuple(new_past)\n",
    "    # gptbigcode is special and stores kv in shape (batch_size, seq_len, dim), if it's a multi_query model\n",
    "    elif \"gptbigcode\" in model.__class__.__name__.lower() or (\n",
    "        model.config.architectures is not None\n",
    "        and \"gptbigcode\" in model.config.architectures[0].lower()\n",
    "    ):\n",
    "        if model.config.multi_query:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :max_length, :]\n",
    "        else:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :, :max_length, :]\n",
    "    elif isinstance(past_key_values, DynamicCache):\n",
    "        past_key_values.crop(max_length)\n",
    "    elif past_key_values is not None:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            if past_key_values[idx] != ([], []):\n",
    "                new_past.append(\n",
    "                    (\n",
    "                        past_key_values[idx][0][:, :, :max_length, :],\n",
    "                        past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                new_past.append((past_key_values[idx][0], past_key_values[idx][1]))\n",
    "        past_key_values = tuple(new_past)\n",
    "    return past_key_values\n",
    "\n",
    "\n",
    "# model = trainer.model\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "        {\"role\": \"user\", \"content\": dataset[\"test\"].to_list()[:5][0][\"question\"]},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "with torch.no_grad(), torch.autocast(device_type=\"cuda\"):\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    temp_gen_size = 0\n",
    "    window_size = WINDOW_SIZE  # + 1\n",
    "    # new_tokens = 4\n",
    "    new_tokens = 1\n",
    "    generation_started = False\n",
    "    max_steps = (new_tokens + window_size) * 15\n",
    "    past_key_values_big = None\n",
    "    print(\"generated_embeds\", generated_embeds.shape)\n",
    "    for step in range(max_steps):\n",
    "        if temp_gen_size == window_size + new_tokens:\n",
    "            # print(\n",
    "            #     \"TOKENS FOR EMDED\",\n",
    "            #     tokenizer.decode(\n",
    "            #         generated_tokens[:, -(window_size + new_tokens) :][:, :WINDOW_SIZE]\n",
    "            #         .cpu()\n",
    "            #         .tolist()[0]\n",
    "            #     ),\n",
    "            # )\n",
    "            # tokenizer.decode(generated_tokens[:, : -window_size ].cpu().tolist()[0])\n",
    "            if hasattr(model.base_model, \"embed_pooler\"):\n",
    "                new_embeds_for_compression = (\n",
    "                    model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "                        generated_tokens[:, -(window_size + new_tokens) :][\n",
    "                            :, :WINDOW_SIZE\n",
    "                        ]\n",
    "                    )\n",
    "                ).to(torch.bfloat16)\n",
    "                compressed_part = model.base_model.embed_pooler(\n",
    "                    new_embeds_for_compression\n",
    "                )\n",
    "            else:\n",
    "                compressed_part = model.embed_pooler(new_embeds_for_compression)\n",
    "            # gen_embeds_prev = generated_tokens.shape[1]\n",
    "            if generation_started:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens + 1)],\n",
    "                        # generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        compressed_part,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            else:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 3,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        start_embed,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        compressed_part,\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "                generation_started = True\n",
    "            past_key_values_big = _crop_past_key_values(\n",
    "                model=model,\n",
    "                past_key_values=past_key_values_big,\n",
    "                max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "            )\n",
    "            temp_gen_size = 1\n",
    "\n",
    "        outputs = model(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            past_key_values=past_key_values_big,\n",
    "            # use_cache=False,\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        past_key_values_big = outputs.past_key_values\n",
    "        top_token = logits.argmax(-1)[-1][-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)], dim=1\n",
    "        )\n",
    "        # print(temp_gen_size, tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "        temp_gen_size += 1\n",
    "\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   ,       KV-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1536])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4, 5, 6, 7, 8][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"test\"][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1536])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   MATH-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777b48e510b2469993b95ae963cc7f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "2024 200 2124 2356\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1100 200 1200 1766\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "833 200 933 825\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1353 200 1453 1781\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "823 200 923 1649\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG (60,-88,25,4)\n",
      " which are (-5)^0, (-5)^1, (-5)^2, (-5)^3. Similarly, the fourth equation has 6, 36, 216, 1296, which are 6^1, 6^2, 6^3, 6^4. The first equation is just 1, 1, 1, 1, which is 1^0, 1^1, 1^2, 1^3. So, it seems like each equation is evaluating a polynomial at a specific point.\n",
      "\n",
      "Let me think. If I let f(k) = a + b*k + c*k^2 + d*k^3, then:\n",
      "\n",
      "- f(0) = a + b*0 + c*0 + d*0 = a = 1\n",
      "- f(1) = a + b*1 + c*1 + d*1 = a + b + c + d = 1\n",
      "- f(-5) = a + b*(-5) + c*(-5)^2 + d*(-5)^3 = a - 5b + 25c - 125d = 625\n",
      "- f(6) = a + b*6 + c*6^2 + d*6^3 = a + 6b + 36c + 216d = 1296\n",
      "\n",
      "Wait, hold on. The first equation is f(0) = 1, the second is f(1) = 1, the third is f(-5) = 625, and the fourth is f(6) = 1296. So, we have four equations:\n",
      "\n",
      "1. f(0) = 1\n",
      "2. f(1) = 1\n",
      "3. f(-5) = 625\n",
      "4. f(6) = 1296\n",
      "\n",
      "So, if I can find a polynomial f(k) = a + b*k + c*k^2 + d*k^3 that passes through these points: (0,1), (1,1), (-5,625), (6,1296). Then, the coefficients a, b, c, d will be the solution.\n",
      "\n",
      "Since it's a cubic polynomial, it's determined uniquely by four points. So, we can set up the system of equations and solve for a, b, c, d.\n",
      "\n",
      "Let me write down the equations:\n",
      "\n",
      "1. f(0) = a = 1\n",
      "2. f(1) = a + b + c + d = 1\n",
      "3. f(-5) = a - 5b + 25c - 125d = 625\n",
      "4. f(6) = a + 6b + 36c + 216d = 1296\n",
      "\n",
      "Wait, but from the first equation, we already know a = 1. So, we can substitute a = 1 into the other equations.\n",
      "\n",
      "So, equation 2 becomes:\n",
      "\n",
      "1 + b + c + d = 1 => b + c + d = 0\n",
      "\n",
      "Equation 3 becomes:\n",
      "\n",
      "1 - 5b + 25c - 125d = 625 => -5b + 25c - 125d = 624\n",
      "\n",
      "Equation 4 becomes:\n",
      "\n",
      "1 + 6b + 36c + 216d = 1296 => 6b + 36c + 216d = 1295\n",
      "\n",
      "So, now we have three equations:\n",
      "\n",
      "1. b + c + d = 0\n",
      "2. -5b + 25c - 125d = 624\n",
      "3. 6b + 36c + 216d = 1295\n",
      "\n",
      "Let me write these equations clearly:\n",
      "\n",
      "Equation A: b + c + d = 0\n",
      "\n",
      "Equation B: -5b + 25c - 125d = 624\n",
      "\n",
      "Equation C: 6b + 36c + 216d = 1295\n",
      "\n",
      "Now, I need to solve for b, c, d.\n",
      "\n",
      "Let me try to solve these equations step by step.\n",
      "\n",
      "First, from Equation A: b + c + d = 0 => d = -b - c\n",
      "\n",
      "So, we can express d in terms of b and c. Let's substitute d into Equations B and C.\n",
      "\n",
      "Substitute d = -b - c into Equation B:\n",
      "\n",
      "-5b + 25c - 125*(-b - c) = 624\n",
      "\n",
      "Simplify:\n",
      "\n",
      "-5b + 25c + 125b + 125c = 624\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "(-5b + 125b) + (25c + 125c) = 624\n",
      "\n",
      "120b + 150c = 624\n",
      "\n",
      "We can simplify this equation by dividing both sides by 30:\n",
      "\n",
      "4b + 5c = 20.68? Wait, 624 divided by 30 is 20.8? Wait, 30*20=600, 30*20.8=624. So, 624/30=20.8. Hmm, but 4b + 5c = 20.8? That's a decimal. Maybe I made a mistake in division.\n",
      "\n",
      "Wait, 624 divided by 30: 30*20=600, 624-600=24, so 24/30=0.8, so 20.8. Yeah, that's correct.\n",
      "\n",
      "But 4b + 5c = 20.8. Hmm, but 20.8 is a decimal. Maybe I should keep it as a fraction. 624/30 simplifies to 104/5, which is 20.8. So, 4b + 5c = 104/5.\n",
      "\n",
      "Similarly, let's substitute d = -b - c into Equation C:\n",
      "\n",
      "6b + 36c + 216*(-b - c) = 1295\n",
      "\n",
      "Simplify:\n",
      "\n",
      "6b + 36c - 216b - 216c = 1295\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "(6b - 216b) + (36c - 216c) = 1295\n",
      "\n",
      "-210b - 180c = 1295\n",
      "\n",
      "We can simplify this equation by dividing both sides by 5:\n",
      "\n",
      "-42b - 36c = 259\n",
      "\n",
      "So, now we have two equations:\n",
      "\n",
      "Equation D: 4b + 5c = 104/5\n",
      "\n",
      "Equation E: -42b - 36c = 259\n",
      "\n",
      "Now, we can solve these two equations for b and c.\n",
      "\n",
      "Let me write them again:\n",
      "\n",
      "4b + 5c = 104/5  --> Let's multiply both sides by 5 to eliminate the fraction:\n",
      "\n",
      "20b + 25c = 104\n",
      "\n",
      "Equation F: 20b + 25c = 104\n",
      "\n",
      "Equation E: -42b - 36c = 259\n",
      "\n",
      "Now, we can use elimination. Let's multiply Equation F by 42 and Equation E by 20 to make the coefficients of b equal.\n",
      "\n",
      "Wait, or maybe find a common multiple. Alternatively, let's use the elimination method.\n",
      "\n",
      "First, let's write Equation F and Equation E:\n",
      "\n",
      "Equation F: 20b + 25c = 104\n",
      "\n",
      "Equation E: -42b - 36c = 259\n",
      "\n",
      "Let me multiply Equation F by 42 and Equation E by 20 to make the coefficients of b equal:\n",
      "\n",
      "Equation F * 42: 840b + 1050c = 4368\n",
      "\n",
      "Equation E * 20: -840b - 720c = 5180\n",
      "\n",
      "Now, add these two equations:\n",
      "\n",
      "(840b - 840b) + (1050c - 720c) = 4368 + 5180\n",
      "\n",
      "0b + 330c = 9548\n",
      "\n",
      "So, 330c = 9548\n",
      "\n",
      "Therefore, c = 9548 / 330\n",
      "\n",
      "Let me simplify this fraction.\n",
      "\n",
      "Divide numerator and denominator by 2: 4774 / 165\n",
      "\n",
      "Check if 4774 and 165 have any common factors. 165 is 5*33=5*3*11. 4774 divided by 2 is 2387, which is odd. 2387 divided by 11 is 217, because 11*217=2387. So, 4774=2*11*217, and 165=5*3*11. So, they have a common factor of 11.\n",
      "\n",
      "So, divide numerator and denominator by 11:\n",
      "\n",
      "4774 / 11 = 434\n",
      "\n",
      "165 / 11 = 15\n",
      "\n",
      "So, c = 434 / 15\n",
      "\n",
      "Hmm, 434 divided by 15 is 28.9333... So, c = 28.9333...\n",
      "\n",
      "Wait, but this is a fraction. Let me check my calculations because this seems a bit messy. Maybe I made a mistake earlier.\n",
      "\n",
      "Let me go back and check.\n",
      "\n",
      "From Equation B: -5b + 25c - 125d = 624\n",
      "\n",
      "We substituted d = -b - c, so:\n",
      "\n",
      "-5b + 25c - 125*(-b - c) = 624\n",
      "\n",
      "Which is -5b + 25c + 125b + 125c = 624\n",
      "\n",
      "So, 120b + 150c = 624\n",
      "\n",
      "Divide by 30: 4b + 5c = 20.8, which is 104/5. That's correct.\n",
      "\n",
      "Equation C: 6b + 36c + 216d = 1295\n",
      "\n",
      "Substituted d = -b - c:\n",
      "\n",
      "6b + 36c + 216*(-b - c) = 1295\n",
      "\n",
      "Which is 6b + 36c - 216b - 216c = 1295\n",
      "\n",
      "So, -210b - 180c = 1295\n",
      "\n",
      "Divide by 5: -42b - 36c = 259. That's correct.\n",
      "\n",
      "Then, Equation F: 20b + 25c = 104\n",
      "\n",
      "Equation E: -42b - 36c = 259\n",
      "\n",
      "Then, multiplied Equation F by 42: 840b + 1050c = 4368\n",
      "\n",
      "Equation E by 20: -840b - 720c = 5180\n",
      "\n",
      "Adding them: 330c = 9548\n",
      "\n",
      "So, c = 9548 / 330\n",
      "\n",
      "Simplify: 9548 divided by 330.\n",
      "\n",
      "Let me do this division:\n",
      "\n",
      "330 * 28 = 9240\n",
      "\n",
      "9548 - 9240 = 308\n",
      "\n",
      "330 * 0.9333... = 308\n",
      "\n",
      "So, c = 28 + 308/330 = 28 + 154/165 = 28 + 14/15 = 28.9333...\n",
      "\n",
      "So, c = 28.9333... which is 28 and 14/15.\n",
      "\n",
      "Wait, but this seems a bit messy. Maybe I made a mistake in setting up the equations.\n",
      "\n",
      "Let me double-check the equations.\n",
      "\n",
      "From the first equation: f(0) = a = 1\n",
      "\n",
      "Second equation: f(1) = a + b + c + d = 1\n",
      "\n",
      "Third equation: f(-5) = a -5b +25c -125d = 625\n",
      "\n",
      "Fourth equation: f(6) = a +6b +36c +216d = 1296\n",
      "\n",
      "So, substituting a=1:\n",
      "\n",
      "1 + b + c + d = 1 => b + c + d = 0\n",
      "\n",
      "1 -5b +25c -125d = 625 => -5b +25c -125d = 624\n",
      "\n",
      "1 +6b +36c +216d = 1296 => 6b +36c +216d = 1295\n",
      "\n",
      "So, that's correct.\n",
      "\n",
      "Then, d = -b -c\n",
      "\n",
      "Substituted into equation B: -5b +25c -125*(-b -c) = 624\n",
      "\n",
      "Which is -5b +25c +125b +125c = 624\n",
      "\n",
      "120b +150c = 624\n",
      "\n",
      "Divide by 30: 4b +5c = 20.8\n",
      "\n",
      "Similarly, equation C: 6b +36c +216*(-b -c) = 1295\n",
      "\n",
      "Which is 6b +36c -216b -216c = 1295\n",
      "\n",
      "-210b -180c = 1295\n",
      "\n",
      "Divide by 5: -42b -36c = 259\n",
      "\n",
      "So, equations F and E are correct.\n",
      "\n",
      "Then, multiplying F by 42 and E by 20:\n",
      "\n",
      "Equation F *42: 840b +1050c = 4368\n",
      "\n",
      "Equation E *20: -840b -720c = 5180\n",
      "\n",
      "Adding them: 330c = 9548\n",
      "\n",
      "So, c = 9548 / 330\n",
      "\n",
      "Let me compute 9548 divided by 330.\n",
      "\n",
      "330 * 28 = 9240\n",
      "\n",
      "9548 - 9240 = 308\n",
      "\n",
      "330 * 0.9333... = 308\n",
      "\n",
      "So, c = 28 + 308/330 = 28 + 154/165 = 28 + 14/15 = 28.9333...\n",
      "\n",
      "So, c = 28.9333...\n",
      "\n",
      "Similarly, from equation F: 4b +5c = 20.8\n",
      "\n",
      "So, 4b = 20.8 -5c\n",
      "\n",
      "So, b = (20.8 -5c)/4\n",
      "\n",
      "Plugging c = 28.9333...:\n",
      "\n",
      "b = (20.8 -5*28.9333...)/4\n",
      "\n",
      "Compute 5*28.9333... = 144.6666...\n",
      "\n",
      "So, 20.8 -144.6666... = -123.8666...\n",
      "\n",
      "Divide by 4: b = -123.8666... /4 = -30.9666...\n",
      "\n",
      "So, b = -30.9666...\n",
      "\n",
      "Similarly, d = -b -c = -(-30.9666...) -28.9333... = 30.9666... -28.9333... = 2.0333...\n",
      "\n",
      "So, d = 2.0333...\n",
      "\n",
      "So, we have a=1, b-30.9666..., c28.9333..., d2.0333...\n",
      "\n",
      "But these are decimal numbers, which seems a bit messy. Maybe I made a mistake in setting up the equations.\n",
      "\n",
      "Alternatively, perhaps there's a better way to approach this problem.\n",
      "\n",
      "Wait, another thought: the equations resemble evaluations of a polynomial at different points. So, if I let f(k) = a + b*k + c*k^2 + d*k^3, then:\n",
      "\n",
      "f(0) = a =1\n",
      "\n",
      "f(1) =1\n",
      "\n",
      "f(-5)=625\n",
      "\n",
      "f(6)=1296\n",
      "\n",
      "So, we have four points: (0,1), (1,1), (-5,625), (6,1296)\n",
      "\n",
      "So, we can set up the system of equations for a, b, c, d.\n",
      "\n",
      "But since it's a cubic polynomial, we can use Lagrange interpolation or set up the equations.\n",
      "\n",
      "Alternatively, since we have four points, we can set up the equations and solve for a, b, c, d.\n",
      "\n",
      "But in this case, we already know a=1, so we can substitute that into the other equations.\n",
      "\n",
      "So, let me write down the equations again:\n",
      "\n",
      "1. a + b + c + d =1\n",
      "\n",
      "2. a -5b +25c -125d =625\n",
      "\n",
      "3. a +6b +36c +216d =1296\n",
      "\n",
      "4. a +11b +121c +1331d = something? Wait, no, we only have four equations.\n",
      "\n",
      "Wait, actually, the first equation is f(0)=1, the second is f(1)=1, the third is f(-5)=625, and the fourth is f(6)=1296.\n",
      "\n",
      "So, we can write the system as:\n",
      "\n",
      "1. a =1\n",
      "\n",
      "2. a + b + c + d =1\n",
      "\n",
      "3. a -5b +25c -125d =625\n",
      "\n",
      "4. a +6b +36c +216d =1296\n",
      "\n",
      "So, substituting a=1 into equations 2,3,4:\n",
      "\n",
      "Equation 2\n",
      "4096 200 4196 3327\n",
      "===\n",
      "===\n",
      "===\n",
      "'NoneType' object has no attribute 'group'\n",
      "WRONG 968\n",
      " the number of ways to answer the test with 0 \"false\"s, 1 \"false\", and 2 \"false\"s, and then subtract that from the total number of combinations.\n",
      "\n",
      "Let me write that down:\n",
      "\n",
      "Total ways without any restriction: 2^10 = 1024\n",
      "\n",
      "Now, let's find the number of ways where fewer than 3 questions are answered with \"false.\" That means:\n",
      "\n",
      "- 0 \"false\"s: All 10 answers are \"true.\" There's only 1 way to do that because every question must be \"true.\"\n",
      "\n",
      "- 1 \"false\": Choose 1 question out of 10 to answer \"false,\" and the rest \"true.\" The number of ways to choose 1 question out of 10 is given by the combination formula C(10,1). C(10,1) is 10.\n",
      "\n",
      "- 2 \"false\"s: Choose 2 questions out of 10 to answer \"false,\" and the rest \"true.\" The number of ways to choose 2 questions out of 10 is C(10,2). Let me calculate that: C(10,2) = 10! / (2! * (10-2)!) = (10*9)/2 = 45.\n",
      "\n",
      "So, adding up these cases:\n",
      "\n",
      "0 \"false\"s: 1\n",
      "\n",
      "1 \"false\": 10\n",
      "\n",
      "2 \"false\"s: 45\n",
      "\n",
      "Total forbidden ways: 1 + 10 + 45 = 56\n",
      "\n",
      "Therefore, the number of valid ways is total ways minus forbidden ways: 1024 - 56 = 968\n",
      "\n",
      "Wait, let me double-check that subtraction. 1024 minus 56 is indeed 968. Hmm, that seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake in calculating the combinations, let me verify C(10,2). Yeah, 10 choose 2 is 45, that's correct. 10*9/2 is 45. So that's good.\n",
      "\n",
      "Another way to think about it is that the number of ways to have at least 3 \"false\"s is the same as the sum from k=3 to k=10 of C(10,k). But since calculating each term individually would take time, and I already subtracted the smaller cases, which is more efficient.\n",
      "\n",
      "Alternatively, I could have used the formula for combinations with restrictions, but in this case, since the forbidden cases are small (less than 3), it's easier to subtract them.\n",
      "\n",
      "Let me also think about whether there's another way to approach this problem. Maybe using the principle of inclusion-exclusion or generating functions? But I think the straightforward subtraction is sufficient here.\n",
      "\n",
      "Wait, just to make sure, let me think about the total number of combinations again. 2^10 is 1024, which is correct because each question has 2 choices, and 2*2*...*2 (10 times) is 1024.\n",
      "\n",
      "Then, the forbidden cases are:\n",
      "\n",
      "- All true: 1 way\n",
      "\n",
      "- Exactly 1 false: 10 ways\n",
      "\n",
      "- Exactly 2 false: 45 ways\n",
      "\n",
      "Adding those up: 1 + 10 + 45 = 56. So, 1024 - 56 = 968.\n",
      "\n",
      "Is there any chance I made a mistake in calculating the combinations? Let me check C(10,2) again. C(10,2) is 45, which is correct because 10*9/2 = 45. So that's right.\n",
      "\n",
      "Another way to think about it is that the number of ways to have at least 3 \"false\"s is the same as the number of ways to have at least 3 \"true\"s, but since the test is about \"false,\" it's symmetric. But in this case, since the test is about \"false,\" it's not symmetric because the number of \"true\"s is 10 - number of \"false\"s. So, maybe that's a different angle.\n",
      "\n",
      "But actually, since the number of \"false\"s is being restricted, it's easier to calculate the forbidden cases directly.\n",
      "\n",
      "Wait, just to make sure, let me think about a smaller example to see if my method works. Suppose instead of 10 questions, there are 3 questions, and I want at least 1 \"false.\" Without any restrictions, there are 8 ways. The forbidden ways are 0 \"false\"s and 1 \"false.\" 0 \"false\"s is 1 way, 1 \"false\" is 3 ways (since C(3,1) = 3). So, forbidden ways are 4, total ways are 8, so valid ways are 4. Let's list them:\n",
      "\n",
      "For 3 questions, the valid ways are those with at least 1 \"false.\" So, the possible combinations are:\n",
      "\n",
      "- F, T, T\n",
      "\n",
      "- T, F, T\n",
      "\n",
      "- T, T, F\n",
      "\n",
      "- F, F, T\n",
      "\n",
      "- F, T, F\n",
      "\n",
      "- T, F, F\n",
      "\n",
      "- F, F, T\n",
      "\n",
      "Wait, hold on, that's 7 ways. But according to my method, total ways without restriction is 8, forbidden ways are 4, so valid ways should be 4. But when I listed them, I got 7. Hmm, that's a discrepancy.\n",
      "\n",
      "Wait, maybe I made a mistake in listing. Let me list all 8 combinations:\n",
      "\n",
      "1. F, F, F\n",
      "\n",
      "2. F, F, T\n",
      "\n",
      "3. F, T, F\n",
      "\n",
      "4. F, T, T\n",
      "\n",
      "5. T, F, F\n",
      "\n",
      "6. T, F, T\n",
      "\n",
      "7. T, T, F\n",
      "\n",
      "8. T, T, T\n",
      "\n",
      "Now, the valid ways are those with at least 1 \"false.\" So, excluding the first combination (F, F, F), which has 3 \"false\"s, the rest are valid. That's 7 ways. But according to my earlier method, total ways are 8, forbidden ways are 4, so valid ways should be 4. Hmm, that's a problem.\n",
      "\n",
      "Wait, so my method gives 4, but actual valid ways are 7. That means my method is incorrect. Hmm, that's a problem.\n",
      "\n",
      "Wait, so where did I go wrong? Let me check my method again.\n",
      "\n",
      "Total ways without restriction: 2^3 = 8.\n",
      "\n",
      "Forbidden ways: 0 \"false\"s and 1 \"false\".\n",
      "\n",
      "0 \"false\"s: 1 way.\n",
      "\n",
      "1 \"false\": C(3,1) = 3 ways.\n",
      "\n",
      "Total forbidden: 4.\n",
      "\n",
      "So, valid ways: 8 - 4 = 4.\n",
      "\n",
      "But when I listed them, I got 7. So, my method is giving an incorrect result here. That means my method is flawed.\n",
      "\n",
      "Wait, so maybe my method is only correct when the forbidden cases are small? Or perhaps I made a mistake in calculating the forbidden cases.\n",
      "\n",
      "Wait, in the smaller example, 3 questions, at least 1 \"false.\" The forbidden cases are 0 \"false\"s and 1 \"false.\" 0 \"false\"s is 1 way, 1 \"false\" is 3 ways, so total forbidden is 4. So, valid ways should be 4.\n",
      "\n",
      "But when I listed all 8 combinations, I got 7 valid ways. That means my method is incorrect.\n",
      "\n",
      "Wait, but in the 3-question case, the valid ways are 7, which is 2^3 - 1 = 7. But that's only because the forbidden case is 0 \"false\"s, which is 1 way. So, in that case, the forbidden ways are only 1, not 4. So, my method was correct in that case.\n",
      "\n",
      "Wait, but in the original problem, the forbidden cases are 0, 1, and 2 \"false\"s, which sum to 56. But in the 3-question example, forbidden cases are only 0 \"false\"s, which is 1 way, so valid ways are 7.\n",
      "\n",
      "So, in the original problem, my method was correct because the forbidden cases are 0, 1, and 2 \"false\"s, which sum to 56. But in the 3-question example, the forbidden cases are only 0 \"false\"s, which is 1 way, so valid ways are 7.\n",
      "\n",
      "So, in the original problem, my method is correct because the forbidden cases are 0, 1, and 2 \"false\"s, which sum to 56. But in the 3-question example, my method would have given 8 - 1 = 7, which is correct.\n",
      "\n",
      "Wait, so in the 3-question example, my method works because the forbidden cases are only 0 \"false\"s. But in the original problem, the forbidden cases are 0, 1, and 2 \"false\"s, which sum to 56. So, my method is correct.\n",
      "\n",
      "Wait, but in the 3-question example, the forbidden cases are only 0 \"false\"s, which is 1 way, so valid ways are 7. But in the original problem, the forbidden cases are 0, 1, and 2 \"false\"s, which sum to 56. So, my method is correct.\n",
      "\n",
      "Wait, so in the 3-question example, my method works because the forbidden cases are only 0 \"false\"s. But in the original problem, the forbidden cases are 0, 1, and 2 \"false\"s, which sum to 56. So, my method is correct.\n",
      "\n",
      "Wait, but in the 3-question example, the valid ways are 7, which is 2^3 - 1 = 7. So, in that case, the forbidden ways are only 0 \"false\"s, which is 1 way.\n",
      "\n",
      "But in the original problem, the forbidden ways are 0, 1, and 2 \"false\"s, which sum to 56. So, my method is correct.\n",
      "\n",
      "Wait, so in the original problem, the total number of ways is 1024, and the forbidden ways are 56, so valid ways are 968.\n",
      "\n",
      "But in the 3-question example, the total number of ways is 8, and the forbidden ways are 1, so valid ways are 7.\n",
      "\n",
      "So, my method works in both cases. So, in the original problem, 10 questions, at least 3 \"false\"s, the total is 1024, forbidden is 56, so valid is 968.\n",
      "\n",
      "But in the 3-question example, 3 questions, at least 1 \"false,\" total is 8, forbidden is 1, so valid is 7.\n",
      "\n",
      "So, my method is correct.\n",
      "\n",
      "Wait, but in the 3-question example, the valid ways are 7, which is 2^3 - 1 = 7. So, in that case, the forbidden ways are only 0 \"false\"s. But in the original problem, the forbidden ways are 0, 1, and 2 \"false\"s, which sum to 56. So, my method is correct.\n",
      "\n",
      "Therefore, in the original problem, the number of valid ways is 1024 - 56 = 968.\n",
      "\n",
      "Wait, but let me think again. In the 3-question example, the valid ways are 7, which is 2^3 - 1. But in the original problem, the valid ways are 1024 - 56 = 968, which is 2^10 - 56.\n",
      "\n",
      "So, that seems correct.\n",
      "\n",
      "Wait, but another way to think about it is that the number of ways to have at least 3 \"false\"s is equal to the sum from k=3 to k=10 of C(10,k). Let me calculate that:\n",
      "\n",
      "C(10,3) + C(10,4) + ... + C(10,10)\n",
      "\n",
      "But calculating each term would take time, but perhaps I can use the fact that the sum from k=0 to k=10 of C(10,k) is 1024, and then subtract the sum from k=0 to k=2 of C(10,k), which is 1 + 10 + 45 = 56. So, 1024 - 56 = 968.\n",
      "\n",
      "Alternatively, I can use the formula for combinations with restrictions. But in this case, since the forbidden cases are small, it's easier to subtract them.\n",
      "\n",
      "So, I think my initial approach is correct.\n",
      "\n",
      "Wait, but just to make sure, let me calculate C(10,3), C(10,4), ..., C(10,10) and see if their sum is 968.\n",
      "\n",
      "C(10,3) = 120\n",
      "\n",
      "C(10,4) = 210\n",
      "\n",
      "C(10,5) = 252\n",
      "\n",
      "C(10,6) = 210\n",
      "\n",
      "C(10,7) = 120\n",
      "\n",
      "C(10,8) = 45\n",
      "\n",
      "C(10,9) = 10\n",
      "\n",
      "C(10,10) = 1\n",
      "\n",
      "Now, let's add them up:\n",
      "\n",
      "120 + 210 = 330\n",
      "\n",
      "330 + 252 = 582\n",
      "\n",
      "582 + 210 = 792\n",
      "\n",
      "792 + 120 = 912\n",
      "\n",
      "912 + 45 = 957\n",
      "\n",
      "957 + 10 = 967\n",
      "\n",
      "967 + 1 = 968\n",
      "\n",
      "Yes, that adds up to 968. So, that confirms that the sum from k=3 to k=10 of C(10,k) is indeed 968.\n",
      "\n",
      "Therefore, the number of ways is 968.\n",
      "\n",
      "Wait, but just to make sure, let me think about another way to calculate it. Maybe using the binomial theorem.\n",
      "\n",
      "The binomial theorem states that (1 + 1)^10 = sum from k=0 to k=10 of C(10,k) = 1024.\n",
      "\n",
      "Similarly, (1 - 1)^10 = sum from k=0 to k=10 of C(10,k) * (-1)^k = 0.\n",
      "\n",
      "So, if we add these two equations:\n",
      "\n",
      "(1 + 1)^10 + (1 - 1)^10 = 2 * sum from k=0 to k=10 of C(10,k) * 1^k = 1024 + 0 = 1024\n",
      "\n",
      "Therefore, sum from k=0 to k=10 of C(10,k) = 1024 / 2 = 512\n",
      "\n",
      "Similarly, if we consider (1 + 1)^10 - (1 - 1)^10 = 2 * sum from k=0 to k=10 of C(10,k) * (-1)^k = 1024 - 0 = 1024\n",
      "\n",
      "Therefore, sum from k=0 to k=10 of C(10,k) * (-1)^k = 512\n",
      "\n",
      "But that's the alternating sum. Hmm, not directly helpful for our problem.\n",
      "\n",
      "But perhaps, if we want to find the sum from k=3 to k=10 of C(10,k), we can subtract the sum from k=0 to k=2 of C(10,k) from the total sum.\n",
      "\n",
      "Which is exactly what I did earlier: 1024 - 56 = 968.\n",
      "\n",
      "So, that confirms it.\n",
      "\n",
      "Therefore, I think my initial approach is correct.\n",
      "\n",
      "So, to summarize:\n",
      "\n",
      "Total number of ways without restriction: 2^10 = 1024\n",
      "\n",
      "Number of ways with fewer than 3 \"false\"s: C(10,0) + C(10,1) + C(10,2) = 1 + 10 + 45 = 56\n",
      "\n",
      "Therefore, valid ways: 1024 - 56 = 968\n",
      "\n",
      "So, the answer is 968.\n",
      "\n",
      "But just to make sure, let me think about another angle. Suppose I fix the number of \"false\"s to be exactly 3, 4, ..., 10, and calculate each case.\n",
      "\n",
      "For exactly 3 \"false\"s: C(10,3) = 120\n",
      "\n",
      "For exactly 4 \"false\"s: C(10,4) = 210\n",
      "\n",
      "For exactly 5 \"false\"s: C(10,5) = 252\n",
      "\n",
      "For exactly 6 \"false\"s: C(10,6) = 210\n",
      "\n",
      "For exactly 7 \"false\"s: C(10,7) = 120\n",
      "\n",
      "For exactly 8 \"false\"s: C(10,8) = 45\n",
      "\n",
      "For exactly 9 \"false\"s: C(10,9) = 10\n",
      "\n",
      "For exactly 10 \"false\"s: C(10,10) = 1\n",
      "\n",
      "Now, adding these up:\n",
      "\n",
      "120 + 210 = 330\n",
      "\n",
      "330 + 252 = 582\n",
      "\n",
      "582 + 210 = 792\n",
      "\n",
      "792 + 120 = 912\n",
      "\n",
      "912 + 45 = 957\n",
      "\n",
      "957 + 10 = 967\n",
      "\n",
      "967 + 1 = 968\n",
      "\n",
      "So, that's another way to confirm that the sum is 968.\n",
      "\n",
      "Therefore, I'm confident that the number of ways is 968.\n",
      "\n",
      "**Final Answer**\n",
      "The number of ways is \\boxed{968}.\n",
      "</think>\n",
      "\n",
      "To determine the number of ways to answer a 10-question true/false test with at least 3 \"false\" answers, we start by calculating the total number of possible combinations without any restrictions. This is given by:\n",
      "\n",
      "\\[ 2^{10} = 1024 \\]\n",
      "\n",
      "Next, we need to subtract the number of combinations where fewer than 3 questions are answered with \"false.\" These cases are:\n",
      "\n",
      "- 0 \"false\"s: \\( \\binom{10}{0} = 1 \\)\n",
      "- 1 \"false\": \\( \\binom{10}{1} = 10 \\)\n",
      "- 2 \"false\"s: \\( \\binom{10}{2} = 45 \\)\n",
      "\n",
      "Adding these cases together:\n",
      "\n",
      "\\[ 1 + 10 + 45 = 56 \\]\n",
      "\n",
      "Subtracting this from the total number of combinations gives us the number of valid ways:\n",
      "\n",
      "\\[ 1024 - 56 = 968 \\]\n",
      "\n",
      "Thus, the number of ways to answer the test with\n",
      "4096 200 4196 1779\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 51\n",
      " 74 is even, so 3774 is even. That means it's divisible by 2. Let me divide 3774 by 2 first.\n",
      "\n",
      "3774  2 = 1887.\n",
      "\n",
      "Okay, so 2 is one of the factors, but 1887 is a three-digit number, which is outside our range of two-digit numbers. So, that means 2 is too small of a factor for our purposes.\n",
      "\n",
      "Next, maybe I can check if 3774 is divisible by 3. To do that, I can add up the digits: 3 + 7 + 7 + 4 = 21. Since 21 is divisible by 3, 3774 is also divisible by 3.\n",
      "\n",
      "Let me divide 3774 by 3:\n",
      "\n",
      "3774  3. Let me do this step by step.\n",
      "\n",
      "3 goes into 3 once, subtract 3, bring down the 7. 3 goes into 7 twice, which is 6, subtract 6, bring down the 7. 3 goes into 17 five times, which is 15, subtract 15, bring down the 4. 3 goes into 24 eight times. So, 3774  3 = 1258.\n",
      "\n",
      "Wait, 1258 is a four-digit number, so that's still too big. So, 3 is also too small a factor.\n",
      "\n",
      "Moving on to the next possible factor. Let me check if 3774 is divisible by 6. Since it's divisible by both 2 and 3, it's divisible by 6.\n",
      "\n",
      "3774  6. Let me do this division.\n",
      "\n",
      "6 into 37 is 6 times 6 is 36, subtract 36, remainder 1. Bring down the 7, making 17. 6 into 17 is 2 times, which is 12, subtract 12, remainder 5. Bring down the 4, making 54. 6 into 54 is 9 times. So, 3774  6 = 629.\n",
      "\n",
      "629 is still a three-digit number, so that's too big. So, 6 is also too small.\n",
      "\n",
      "Next, let me try 9. To check if 3774 is divisible by 9, I can add the digits: 3 + 7 + 7 + 4 = 21. 21 is not divisible by 9, so 3774 is not divisible by 9.\n",
      "\n",
      "How about 11? Let me check the divisibility rule for 11. Subtract the sum of the digits in the odd positions from the sum of the digits in the even positions. For 3774, the digits are 3, 7, 7, 4.\n",
      "\n",
      "Sum of odd positions (1st and 3rd): 3 + 7 = 10.\n",
      "\n",
      "Sum of even positions (2nd and 4th): 7 + 4 = 11.\n",
      "\n",
      "Subtract: 10 - 11 = -1. Since -1 is not divisible by 11, 3774 is not divisible by 11.\n",
      "\n",
      "Moving on to 13. Hmm, 3774 divided by 13. Let me do this division.\n",
      "\n",
      "13 into 37 is 2 times, which is 26. Subtract 26 from 37, remainder 11. Bring down the 7, making 117. 13 into 117 is 9 times, which is 117. Subtract, remainder 0. Bring down the 4. 13 into 4 is 0 times. So, 3774  13 = 290.307... Hmm, that's not an integer, so 13 is not a factor.\n",
      "\n",
      "Wait, actually, 13 into 3774: let me double-check.\n",
      "\n",
      "13 * 290 = 3770, which is 4 less than 3774. So, 13 * 290 + 4 = 3774, so 3774 is not divisible by 13.\n",
      "\n",
      "Next, 17. Let me try 17.\n",
      "\n",
      "3774  17. Let me see, 17 into 37 is 2 times, 2*17=34. Subtract 34 from 37, remainder 3. Bring down the 7, making 37. 17 into 37 is 2 times, 2*17=34. Subtract 34, remainder 3. Bring down the 4, making 34. 17 into 34 is 2 times. So, 3774  17 = 222.058... Hmm, that's not an integer. So, 17 is not a factor.\n",
      "\n",
      "Wait, let me do this division more carefully.\n",
      "\n",
      "17 into 37 is 2, 2*17=34. 37-34=3. Bring down the 7, making 37. 17 into 37 is 2, 2*17=34. 37-34=3. Bring down the 4, making 34. 17 into 34 is 2. So, 3774  17 = 222.058... Wait, that can't be right because 17*222=3774? Let me check: 17*200=3400, 17*22=374, so 3400+374=3774. Yes, actually, 17*222=3774. So, 17 is a factor.\n",
      "\n",
      "Wait, but 222 is a three-digit number, so that's still too big. So, 17 is too small.\n",
      "\n",
      "Next, 19. Let me check if 3774 is divisible by 19.\n",
      "\n",
      "3774  19. Let me do this division.\n",
      "\n",
      "19 into 37 is 1 time, 1*19=19. Subtract 19 from 37, remainder 18. Bring down the 7, making 187. 19 into 187 is 9 times, 9*19=171. Subtract 171 from 187, remainder 16. Bring down the 4, making 164. 19 into 164 is 8 times, 8*19=152. Subtract 152 from 164, remainder 12. So, 3774  19 = 198.631... Not an integer, so 19 is not a factor.\n",
      "\n",
      "Next, 23. Let me check 3774  23.\n",
      "\n",
      "23 into 37 is 1 time, 1*23=23. Subtract 23 from 37, remainder 14. Bring down the 7, making 147. 23 into 147 is 6 times, 6*23=138. Subtract 138 from 147, remainder 9. Bring down the 4, making 94. 23 into 94 is 4 times, 4*23=92. Subtract 92 from 94, remainder 2. So, 3774  23 = 164.087... Not an integer, so 23 is not a factor.\n",
      "\n",
      "Next, 29. Let me check 3774  29.\n",
      "\n",
      "29 into 37 is 1 time, 1*29=29. Subtract 29 from 37, remainder 8. Bring down the 7, making 87. 29 into 87 is 3 times, 3*29=87. Subtract 87 from 87, remainder 0. Bring down the 4, making 04. 29 into 4 is 0 times. So, 3774  29 = 130.482... Not an integer, so 29 is not a factor.\n",
      "\n",
      "Next, 31. Let me check 3774  31.\n",
      "\n",
      "31 into 37 is 1 time, 1*31=31. Subtract 31 from 37, remainder 6. Bring down the 7, making 67. 31 into 67 is 2 times, 2*31=62. Subtract 62 from 67, remainder 5. Bring down the 4, making 54. 31 into 54 is 1 time, 1*31=31. Subtract 31 from 54, remainder 23. So, 3774  31 = 121.741... Not an integer, so 31 is not a factor.\n",
      "\n",
      "Next, 37. Let me check 3774  37.\n",
      "\n",
      "37 into 37 is 1 time, 1*37=37. Subtract 37 from 37, remainder 0. Bring down the 7. 37 into 7 is 0 times. Bring down the 4, making 74. 37 into 74 is 2 times, 2*37=74. Subtract 74 from 74, remainder 0. So, 3774  37 = 102.058... Wait, that can't be right because 37*102=3774. Let me check: 37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 37 is a factor.\n",
      "\n",
      "So, 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that's not an integer. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me check 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=3700, 37*2=74, so 3700+74=3774. Yes, so 3774  37 = 102.058... Wait, that can't be. Wait, 37*102=3774. Let me compute 37*102:\n",
      "\n",
      "37*100=370\n",
      "4096 200 4196 1748\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1398 200 1498 1561\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "853 200 953 925\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "735 200 835 1338\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1154 200 1254 2105\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 990\n",
      "2 to 1000, I need to compute ceil(log2(n)) and floor(log2(n)), add them up for A and B respectively, and then subtract B from A.\n",
      "\n",
      "Let me think about how log2(n) behaves. The logarithm base 2 increases as n increases, but it does so slowly. Specifically, log2(n) increases by 1 every time n doubles. So, between 2^k and 2^(k+1), log2(n) is between k and k+1. That means that for n from 2^k to 2^(k+1) - 1, log2(n) is less than k+1, so the floor of log2(n) would be k, and the ceiling would also be k, right?\n",
      "\n",
      "Wait, no. Let me think again. If n is exactly a power of 2, say n=2^k, then log2(n) is exactly k, so both the floor and ceiling would be k. But if n is just above 2^k, like 2^k + 1, then log2(n) is slightly more than k, so the floor would still be k, and the ceiling would be k+1.\n",
      "\n",
      "So, for each interval from 2^k to 2^(k+1) - 1, the floor of log2(n) is k, and the ceiling is also k, except when n is exactly 2^k, where both are k.\n",
      "\n",
      "Wait, no, actually, for n=2^k, both floor and ceiling are k. For n=2^k + 1, floor is k, ceiling is k+1. Similarly, for n=2^k + 2, floor is k, ceiling is k+1, and so on, until n=2^(k+1) - 1, where floor is still k, and ceiling is k+1.\n",
      "\n",
      "So, for each interval from 2^k to 2^(k+1) - 1, the floor function contributes k for each n, and the ceiling function contributes k+1 for each n.\n",
      "\n",
      "Therefore, for each n in that interval, ceil(log2(n)) - floor(log2(n)) is 1. Because ceil is k+1 and floor is k, so their difference is 1.\n",
      "\n",
      "Therefore, for each n from 2^k to 2^(k+1) - 1, the difference between ceil(log2(n)) and floor(log2(n)) is 1. So, if I sum up all these differences from n=2 to n=1000, the total difference A - B would be equal to the number of terms in the interval where n is from 2^k to 2^(k+1) - 1.\n",
      "\n",
      "Wait, let me clarify. For each n, ceil(log2(n)) - floor(log2(n)) is 1 if n is not a power of 2, and 0 if n is a power of 2. Because if n is a power of 2, then log2(n) is an integer, so both ceiling and floor are equal to that integer, so their difference is 0.\n",
      "\n",
      "Therefore, A - B is equal to the number of integers from 2 to 1000 that are not powers of 2. Because for each such n, the difference is 1, and for n being a power of 2, the difference is 0.\n",
      "\n",
      "So, to compute A - B, I need to find the number of integers from 2 to 1000 that are not powers of 2. Alternatively, I can compute the total number of terms, which is 999 (since it's from 2 to 1000 inclusive), and then subtract the number of powers of 2 in that range.\n",
      "\n",
      "So, let's compute the number of powers of 2 from 2 to 1000. The powers of 2 are 2^1, 2^2, 2^3, ..., up to the largest power less than or equal to 1000.\n",
      "\n",
      "Let me compute 2^10 is 1024, which is greater than 1000, so the largest power of 2 less than or equal to 1000 is 2^9 = 512.\n",
      "\n",
      "So, the powers of 2 from 2^1 to 2^9 are 2, 4, 8, 16, 32, 64, 128, 256, 512. That's 9 numbers.\n",
      "\n",
      "Therefore, there are 9 powers of 2 between 2 and 1000.\n",
      "\n",
      "So, the number of integers from 2 to 1000 is 999 (since 1000 - 2 + 1 = 999). Therefore, the number of non-powers of 2 is 999 - 9 = 990.\n",
      "\n",
      "Therefore, A - B is 990.\n",
      "\n",
      "Wait, let me double-check that. So, from 2 to 1000, that's 999 numbers. The powers of 2 in that range are 2^1 to 2^9, which is 9 numbers. So, 999 - 9 = 990 non-powers of 2. Each of these contributes 1 to the difference A - B, so A - B is 990.\n",
      "\n",
      "But let me think again. Is that correct? Because for each n from 2 to 1000, ceil(log2(n)) - floor(log2(n)) is 1 if n is not a power of 2, and 0 if n is a power of 2. So, the total A - B is equal to the number of non-powers of 2 from 2 to 1000.\n",
      "\n",
      "But wait, let me verify with a smaller example to make sure my reasoning is correct.\n",
      "\n",
      "Suppose I take n from 2 to 8. Let's compute A and B.\n",
      "\n",
      "Compute A: ceil(log2(2)) + ceil(log2(3)) + ceil(log2(4)) + ceil(log2(5)) + ceil(log2(6)) + ceil(log2(7)) + ceil(log2(8))\n",
      "\n",
      "Compute B: floor(log2(2)) + floor(log2(3)) + floor(log2(4)) + floor(log2(5)) + floor(log2(6)) + floor(log2(7)) + floor(log2(8))\n",
      "\n",
      "Compute A - B:\n",
      "\n",
      "For n=2: ceil(1) + floor(1) = 1 + 1 = 2\n",
      "\n",
      "n=3: ceil(1.584) + floor(1.584) = 2 + 1 = 3\n",
      "\n",
      "n=4: ceil(2) + floor(2) = 2 + 2 = 4\n",
      "\n",
      "n=5: ceil(2.3219) + floor(2.3219) = 3 + 2 = 5\n",
      "\n",
      "n=6: ceil(2.58496) + floor(2.58496) = 3 + 2 = 5\n",
      "\n",
      "n=7: ceil(2.807) + floor(2.807) = 3 + 2 = 5\n",
      "\n",
      "n=8: ceil(3) + floor(3) = 3 + 3 = 6\n",
      "\n",
      "So, A = 2 + 3 + 4 + 5 + 5 + 5 + 6 = let's compute that:\n",
      "\n",
      "2 + 3 = 5\n",
      "\n",
      "5 + 4 = 9\n",
      "\n",
      "9 + 5 = 14\n",
      "\n",
      "14 + 5 = 19\n",
      "\n",
      "19 + 5 = 24\n",
      "\n",
      "24 + 6 = 30\n",
      "\n",
      "So, A = 30\n",
      "\n",
      "B: floor(log2(2)) + floor(log2(3)) + floor(log2(4)) + floor(log2(5)) + floor(log2(6)) + floor(log2(7)) + floor(log2(8))\n",
      "\n",
      "floor(1) + floor(1.584) + floor(2) + floor(2.3219) + floor(2.58496) + floor(2.807) + floor(3)\n",
      "\n",
      "Which is 1 + 1 + 2 + 2 + 2 + 2 + 3\n",
      "\n",
      "Compute that:\n",
      "\n",
      "1 + 1 = 2\n",
      "\n",
      "2 + 2 = 4\n",
      "\n",
      "4 + 2 = 6\n",
      "\n",
      "6 + 2 = 8\n",
      "\n",
      "8 + 2 = 10\n",
      "\n",
      "10 + 3 = 13\n",
      "\n",
      "So, B = 13\n",
      "\n",
      "Therefore, A - B = 30 - 13 = 17\n",
      "\n",
      "Now, let's see how many non-powers of 2 are there from 2 to 8. The powers of 2 are 2, 4, 8. So, 3 powers. Total numbers from 2 to 8 is 7. So, non-powers are 4,5,6,7. That's 4 numbers. So, A - B should be 4.\n",
      "\n",
      "But in my calculation above, A - B was 17. Hmm, that's a discrepancy. So, my initial reasoning must be wrong.\n",
      "\n",
      "Wait, what's happening here. In the small example, A - B is 17, but according to my previous reasoning, it should be 4. So, my initial reasoning must be incorrect.\n",
      "\n",
      "Wait, let me recast the problem. In the small example, from 2 to 8, A - B is 17, but according to my previous logic, it should be the number of non-powers of 2, which is 4. But 17 is much larger than 4. So, my initial reasoning must be wrong.\n",
      "\n",
      "So, where did I go wrong? Let me think.\n",
      "\n",
      "Wait, in the small example, for each n from 2 to 8, ceil(log2(n)) - floor(log2(n)) is 1 if n is not a power of 2, and 0 if n is a power of 2. So, for n=2,4,8, the difference is 0, and for the others, it's 1. So, in the small example, there are 7 numbers, 3 of which are powers of 2, so 4 non-powers. So, A - B should be 4.\n",
      "\n",
      "But in my calculation, A - B was 17. So, that's a problem. So, my initial reasoning must be incorrect.\n",
      "\n",
      "Wait, let me recast the small example again.\n",
      "\n",
      "Compute A: sum of ceil(log2(n)) from n=2 to 8.\n",
      "\n",
      "Compute each term:\n",
      "\n",
      "n=2: ceil(log2(2)) = 1\n",
      "\n",
      "n=3: ceil(log2(3))  2\n",
      "\n",
      "n=4: ceil(log2(4)) = 2\n",
      "\n",
      "n=5: ceil(log2(5))  3\n",
      "\n",
      "n=6: ceil(log2(6))  3\n",
      "\n",
      "n=7: ceil(log2(7))  3\n",
      "\n",
      "n=8: ceil(log2(8)) = 3\n",
      "\n",
      "So, A = 1 + 2 + 2 + 3 + 3 + 3 + 3 = let's compute:\n",
      "\n",
      "1 + 2 = 3\n",
      "\n",
      "3 + 2 = 5\n",
      "\n",
      "5 + 3 = 8\n",
      "\n",
      "8 + 3 = 11\n",
      "\n",
      "11 + 3 = 14\n",
      "\n",
      "14 + 3 = 17\n",
      "\n",
      "So, A = 17\n",
      "\n",
      "Compute B: sum of floor(log2(n)) from n=2 to 8.\n",
      "\n",
      "floor(log2(2)) = 1\n",
      "\n",
      "floor(log2(3))  1\n",
      "\n",
      "floor(log2(4)) = 2\n",
      "\n",
      "floor(log2(5))  2\n",
      "\n",
      "floor(log2(6))  2\n",
      "\n",
      "floor(log2(7))  2\n",
      "\n",
      "floor(log2(8)) = 3\n",
      "\n",
      "So, B = 1 + 1 + 2 + 2 + 2 + 2 + 3\n",
      "\n",
      "Compute that:\n",
      "\n",
      "1 + 1 = 2\n",
      "\n",
      "2 + 2 = 4\n",
      "\n",
      "4 + 2 = 6\n",
      "\n",
      "6 + 2 = 8\n",
      "\n",
      "8 + 2 = 10\n",
      "\n",
      "10 + 3 = 13\n",
      "\n",
      "So, B = 13\n",
      "\n",
      "Therefore, A - B = 17 - 13 = 4\n",
      "\n",
      "Wait, so in the small example, A - B is 4, which is equal to the number of non-powers of 2 from 2 to 8, which is 4 (n=5,6,7). So, my initial reasoning was correct. But in my first calculation, I thought A - B was 17, but that was a mistake because I didn't compute A correctly.\n",
      "\n",
      "So, in the small example, A - B is indeed equal to the number of non-powers of 2, which is 4. So, my initial reasoning was correct.\n",
      "\n",
      "Therefore, in the original problem, from 2 to 1000, the number of non-powers of 2 is 999 - 9 = 990, so A - B is 990.\n",
      "\n",
      "But just to be thorough, let me think about another example to make sure.\n",
      "\n",
      "Let me take n from 2 to 16.\n",
      "\n",
      "Compute A and B.\n",
      "\n",
      "First, list the powers of 2: 2,4,8,16.\n",
      "\n",
      "So, from 2 to 16, there are 15 numbers.\n",
      "\n",
      "Non-powers of 2: 15 - 4 = 11 numbers.\n",
      "\n",
      "Compute A - B.\n",
      "\n",
      "For each n from 2 to 16:\n",
      "\n",
      "ceil(log2(n)) - floor(log2(n)) is 1 if n is not a power of 2, 0 if n is a power of 2.\n",
      "\n",
      "So, A - B should be 11.\n",
      "\n",
      "Let me compute A and B.\n",
      "\n",
      "Compute A:\n",
      "\n",
      "ceil(log2(2)) = 1\n",
      "\n",
      "ceil(log2(3))  2\n",
      "\n",
      "ceil(log2(4)) = 2\n",
      "\n",
      "ceil(log2(5))  3\n",
      "\n",
      "ceil(log2(6))  3\n",
      "\n",
      "ceil(log2(7))  3\n",
      "\n",
      "ceil(log2(8)) = 3\n",
      "\n",
      "ceil(log2(9))  4\n",
      "\n",
      "ceil(log2(10))  4\n",
      "\n",
      "ceil(log2(11))  4\n",
      "\n",
      "ceil(log2(12))  4\n",
      "\n",
      "ceil(log2(13))  4\n",
      "\n",
      "ceil(log2(14))  4\n",
      "\n",
      "ceil(log2(15))  4\n",
      "\n",
      "ceil(log2(16)) = 4\n",
      "\n",
      "So, A = 1 + 2 + 2 + 3 + 3 + 3 + 3 + 3 + 4 + 4 + 4 + 4 + 4 + 4 + 4\n",
      "\n",
      "Let me compute that step by step:\n",
      "\n",
      "1 + 2 = 3\n",
      "\n",
      "3 + 2 = 5\n",
      "\n",
      "5 + 3 = 8\n",
      "\n",
      "8 + 3 = 11\n",
      "\n",
      "11 + 3 = 14\n",
      "\n",
      "14 + 3 = 17\n",
      "\n",
      "17 + 3 = 20\n",
      "\n",
      "20 + 3 = 23\n",
      "\n",
      "23 + 4 = 27\n",
      "\n",
      "27 + 4 = 31\n",
      "\n",
      "31 + 4 = 35\n",
      "\n",
      "35 + 4 = 39\n",
      "\n",
      "39 + 4 = 43\n",
      "\n",
      "43 + 4 = 47\n",
      "\n",
      "So, A = 47\n",
      "\n",
      "Compute B:\n",
      "\n",
      "floor(log2(2)) = 1\n",
      "\n",
      "floor(log2(3))  1\n",
      "\n",
      "floor(log2(4)) = 2\n",
      "\n",
      "floor(log2(5))  2\n",
      "\n",
      "floor(log2(6))  2\n",
      "\n",
      "floor(log2(7))  2\n",
      "\n",
      "floor(log2(8)) = 3\n",
      "\n",
      "floor(log2(9))  3\n",
      "\n",
      "floor(log2(10))  3\n",
      "\n",
      "floor(log2(11))  3\n",
      "\n",
      "floor(log2(12))  3\n",
      "\n",
      "floor(log2(13))  3\n",
      "\n",
      "floor(log2(14))  3\n",
      "\n",
      "floor(log2(15))  3\n",
      "\n",
      "floor(log2(16)) = 4\n",
      "\n",
      "So, B = 1 + 1 + 2 + 2 + 2 + 2 + 3 + 3 + 3 + 3 + 3 + 3 + 3 + 3 + 4\n",
      "\n",
      "Compute that:\n",
      "\n",
      "1 + 1 = 2\n",
      "\n",
      "2 + 2 = 4\n",
      "\n",
      "4 + 2 = 6\n",
      "\n",
      "6 + 2 = 8\n",
      "\n",
      "8 + 2 = 10\n",
      "\n",
      "10 + 3 = 13\n",
      "\n",
      "13 + 3 = 16\n",
      "\n",
      "16 + 3 = 19\n",
      "\n",
      "19 + 3 = 22\n",
      "\n",
      "22 + 3 = 25\n",
      "\n",
      "25 + 3 = 28\n",
      "\n",
      "28 + 3 = 31\n",
      "\n",
      "31 + 3 = 34\n",
      "\n",
      "34 + 4 = 38\n",
      "\n",
      "So, B = 38\n",
      "\n",
      "Therefore, A - B = 47 - 38 = 9\n",
      "\n",
      "Which is equal to the number of non-powers of 2 from 2 to 16, which is 15 - 4 = 11. Wait, 11? But 47 - 38 is 9. Hmm, that's a discrepancy.\n",
      "\n",
      "Wait, hold on. From 2 to 16, there are 15 numbers. The powers of 2 are 2,4,8,16, so 4 powers. So, non-powers are 11. But A - B is 9. So, my initial reasoning was incorrect.\n",
      "\n",
      "Wait, so in the small example, from 2 to 8, which is 7 numbers, the number of non-powers is 4, and A - B is 4. But in the example from 2 to 16, which is 15 numbers, the number of non-powers is 11, but A - B is 9. So, my initial reasoning is incorrect.\n",
      "\n",
      "Wait, so what's the issue here? Let me think again.\n",
      "\n",
      "In the first example, from 2 to 8, which is 7 numbers, the number of non-powers is 4, and A - B is 4.\n",
      "\n",
      "In the second example, from 2 to 16, which is 15 numbers, the number of non-powers is 11, and A - B is 9.\n",
      "\n",
      "So, in\n",
      "4096 200 4196 3392\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1025 200 1125 1603\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2267 200 2367 2285\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "655 200 755 1250\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1199 200 1299 1663\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "815 200 915 1093\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1853 200 1953 1386\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1236 200 1336 1421\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "969 200 1069 2533\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "3799 200 3899 3026\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 2\n",
      " but wait, is that the actual value or just an example? The question is asking me to find 'a' for the given graph, so I can't just assume it's 2. I need to figure it out based on the graph.\n",
      "\n",
      "First, let me recall some properties of sine functions. The general form is y = a sin(bx + c) + d. Here, 'a' is the amplitude, which is the maximum value of the function minus the minimum value divided by 2. So, if I can find the maximum and minimum values of the graph, I can compute 'a'.\n",
      "\n",
      "Looking at the Asymptote code, the function is 2*sin(3x + pi) + 1. So, in that case, the amplitude is 2, the vertical shift is 1, the frequency is 3, and the phase shift is -pi/3 (since it's 3x + pi, which is equivalent to 3(x + pi/3)). So, in this example, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. However, the Asymptote code is provided, so maybe I can analyze it. Let me see.\n",
      "\n",
      "The Asymptote code defines f(x) as 2*sin(3x + pi) + 1. So, the graph is a sine wave with amplitude 2, period 2pi/3, phase shift -pi/3, and vertical shift 1. So, in this case, the amplitude is 2.\n",
      "\n",
      "But since the problem is asking me to find 'a' for a different graph, I need to see if I can extract the amplitude from the graph. Let me try to visualize the graph.\n",
      "\n",
      "The graph is a sine wave. The Asymptote code says it's drawn from -3pi to 3pi, so the domain is from -3pi to 3pi. The range is from -4 to 4, so the vertical shift is 1, which means the central line is y=1. The amplitude is 2, so the maximum value is 1 + 2 = 3, and the minimum value is 1 - 2 = -1.\n",
      "\n",
      "So, if I can see the graph, the highest point on the graph should be 3, and the lowest point should be -1. The distance from the central line (y=1) to the highest point is 2, which is the amplitude. So, that should be 'a'.\n",
      "\n",
      "But wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is the coefficient of the sine function. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. However, the Asymptote code is provided, so maybe I can use that to figure out 'a'.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, the period is 2pi/3, the phase shift is -pi/3, and the vertical shift is 1. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. So, maybe I need to think differently. Maybe I can analyze the graph's key features.\n",
      "\n",
      "Let me think about the graph's key points. For a sine wave, the maximum point is at the top, the minimum at the bottom, and the midline is the central line y=d. So, if I can find the maximum and minimum values of the graph, I can compute 'a'.\n",
      "\n",
      "Alternatively, if I can find the distance from the midline to the maximum or minimum, that will be the amplitude, which is 'a'.\n",
      "\n",
      "So, in the given Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, so the maximum is 3, the minimum is -1, and the midline is y=1. So, the distance from midline to max is 2, which is 'a'.\n",
      "\n",
      "But in the problem, since I don't have the graph, maybe I need to think about how to extract 'a' from the graph.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. So, maybe I need to think about how to find 'a' from the graph.\n",
      "\n",
      "Let me try to think step-by-step.\n",
      "\n",
      "1. Identify the midline of the sine wave. The midline is the central line around which the sine wave oscillates. In the Asymptote code, it's y=1. So, in the problem, if I can find the midline, that will be y=d.\n",
      "\n",
      "2. Identify the maximum and minimum points of the sine wave. The maximum point is the highest point on the graph, and the minimum point is the lowest point on the graph.\n",
      "\n",
      "3. Compute the amplitude 'a' as half the distance between the maximum and minimum values. So, if the maximum is y_max and the minimum is y_min, then a = (y_max - y_min)/2.\n",
      "\n",
      "Alternatively, since the amplitude is the distance from the midline to the maximum or minimum, so a = y_max - d or a = d - y_min, but since it's the same, it's just half the total distance.\n",
      "\n",
      "So, in the given Asymptote code, the maximum is 3, the minimum is -1, and the midline is 1. So, the distance from midline to max is 2, which is 'a'.\n",
      "\n",
      "So, in the problem, if I can find the maximum and minimum values of the graph, then 'a' is half the difference between them.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. So, maybe I need to think about how to find 'a' from the graph.\n",
      "\n",
      "Alternatively, maybe I can think about the period of the sine wave. The period is the distance between two consecutive peaks or two consecutive troughs. In the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of x is 3, which is the frequency. The period is 2pi divided by the frequency, so period is 2pi/3.\n",
      "\n",
      "But in the problem, if I can find the period from the graph, then I can compute 'a' if needed, but since 'a' is the amplitude, which is the maximum deviation from the midline, the period doesn't directly give me 'a'. So, maybe the period is useful if I need to find 'b' or 'c' or 'd', but not 'a'.\n",
      "\n",
      "So, maybe the key is to find the amplitude from the graph.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2. So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. So, maybe I need to think about how to find 'a' from the graph.\n",
      "\n",
      "Alternatively, maybe I can think about the phase shift. In the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the phase shift is -pi/3, because it's 3x + pi, which is equivalent to 3(x + pi/3). So, the phase shift is -pi/3.\n",
      "\n",
      "But in the problem, if I can find the phase shift from the graph, that might help, but I don't think it's necessary for finding 'a'.\n",
      "\n",
      "So, going back, the key is to find the amplitude 'a' from the graph. The amplitude is the maximum value minus the minimum value divided by 2.\n",
      "\n",
      "So, if I can find the maximum and minimum values of the graph, then 'a' is (max - min)/2.\n",
      "\n",
      "Alternatively, if I can find the distance from the midline to the maximum or minimum, that is 'a'.\n",
      "\n",
      "So, in the given Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is the coefficient of the sine function.\n",
      "\n",
      "So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. So, maybe I need to think about how to find 'a' from the graph.\n",
      "\n",
      "Alternatively, maybe I can think about the period. The period is the distance between two consecutive peaks or troughs. In the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of x is 3, which is the frequency. The period is 2pi divided by the frequency, so period is 2pi/3.\n",
      "\n",
      "But in the problem, if I can find the period from the graph, then I can compute 'a' if needed, but since 'a' is the amplitude, which is the maximum deviation from the midline, the period doesn't directly give me 'a'. So, maybe the period is useful if I need to find 'b' or 'c' or 'd', but not 'a'.\n",
      "\n",
      "So, maybe the key is to find the amplitude from the graph.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, the graph is given, but I don't have the image. So, maybe I need to think about how to find 'a' from the graph.\n",
      "\n",
      "Alternatively, maybe I can think about the graph's key features. For example, if the graph has a maximum at y=3, a minimum at y=-1, then the amplitude is (3 - (-1))/2 = 2, so 'a' is 2.\n",
      "\n",
      "But in the problem, since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, maybe I can think about the graph's maximum and minimum points.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the maximum is 3, the minimum is -1, so the amplitude is (3 - (-1))/2 = 2.\n",
      "\n",
      "So, in the problem, if I can find the maximum and minimum values of the graph, then 'a' is (max - min)/2.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the coefficient of the sine function from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, if I can find the phase shift, that might help, but I don't think it's necessary for finding 'a'.\n",
      "\n",
      "So, maybe the key is to find the amplitude from the graph.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the coefficient of the sine function from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, if I can find the maximum and minimum values of the graph, then 'a' is (max - min)/2.\n",
      "\n",
      "So, in the Asymptote code, the maximum is 3, the minimum is -1, so 'a' is (3 - (-1))/2 = 2.\n",
      "\n",
      "So, in the problem, if I can find the maximum and minimum values of the graph, then 'a' is (max - min)/2.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, maybe I can think about the graph's key features.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the coefficient of the sine function from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, if I can find the phase shift, that might help, but I don't think it's necessary for finding 'a'.\n",
      "\n",
      "So, maybe the key is to find the amplitude from the graph.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, maybe I can think about the graph's key features.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find 'a' from the Asymptote code.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the coefficient of the sine function is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the coefficient of the sine function from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, if I can find the phase shift, that might help, but I don't think it's necessary for finding 'a'.\n",
      "\n",
      "So, maybe the key is to find the amplitude from the graph.\n",
      "\n",
      "Wait, in the Asymptote code, the function is 2*sin(3x + pi) + 1. So, the amplitude is 2, which is 'a'. So, in this case, 'a' is 2.\n",
      "\n",
      "But in the problem, if I can find the amplitude from the graph, that will be 'a'.\n",
      "\n",
      "Alternatively, maybe I can think about the graph's maximum and minimum points.\n",
      "\n",
      "Wait, in the Asymptote code, the maximum is 3, the minimum is -1, so the amplitude is (3 - (-1))/2 = 2.\n",
      "\n",
      "So, in the problem, if I can find the maximum and minimum values of the graph, then 'a' is (max - min)/2.\n",
      "\n",
      "But since I don't have the graph, maybe I need to think about how to find '\n",
      "4096 200 4196 2318\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2895 200 2995 2645\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2113 200 2213 1949\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2059 200 2159 3533\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG -21\n",
      ". Hmm, 625 is also a perfect square because 25 times 25 is 625. So, the square root of 625 is 25.\n",
      "\n",
      "Now, substituting these back into the original expression, I get \\(4 - 25\\). Wait, 4 minus 25 is negative thirteen. So, is the answer -13? That seems straightforward, but let me double-check to make sure I didn't make any mistakes.\n",
      "\n",
      "Starting again, \\(16^{\\frac{1}{2}}\\) is indeed 4 because \\(4^2 = 16\\). Then, \\(625^{\\frac{1}{2}}\\) is 25 because \\(25^2 = 625\\). Subtracting these, 4 minus 25 is -13. Hmm, that seems correct.\n",
      "\n",
      "But just to be thorough, let me consider if there's another way to approach this problem. Maybe using prime factorization or something? Let's see, 16 is \\(2^4\\) and 625 is \\(5^4\\). So, if I rewrite the original expression using exponents, it becomes \\((2^4)^{\\frac{1}{2}} - (5^4)^{\\frac{1}{2}}\\).\n",
      "\n",
      "When you raise a power to a power, you multiply the exponents. So, \\((2^4)^{\\frac{1}{2}}\\) is \\(2^{4 \\times \\frac{1}{2}} = 2^2 = 4\\). Similarly, \\((5^4)^{\\frac{1}{2}}\\) is \\(5^{4 \\times \\frac{1}{2}} = 5^2 = 25\\). So, subtracting these gives 4 - 25 = -13. Yep, same result.\n",
      "\n",
      "Is there a possibility that I misapplied the exponent rules? Let me recall: when you have a power raised to another power, you multiply the exponents. So, \\( (a^m)^n = a^{m \\times n} \\). In this case, \\(16^{\\frac{1}{2}} = (2^4)^{\\frac{1}{2}} = 2^{4 \\times \\frac{1}{2}} = 2^2 = 4 \\). That seems correct.\n",
      "\n",
      "Similarly, \\(625^{\\frac{1}{2}} = (5^4)^{\\frac{1}{2}} = 5^{4 \\times \\frac{1}{2}} = 5^2 = 25 \\). That also checks out. So, subtracting 25 from 4 gives -13.\n",
      "\n",
      "Wait, another thought: sometimes, when dealing with exponents, especially fractional ones, people might confuse the numerator and denominator. But in this case, the numerator is 1 and 4 is the exponent, so it's definitely the square root. If it were \\(16^{\\frac{4}{2}}\\), that would be different, but that's not the case here.\n",
      "\n",
      "Also, I should make sure that I didn't mix up the order of operations or misapply the subtraction. The expression is \\(16^{\\frac{1}{2}} - 625^{\\frac{1}{2}}\\), so it's the square root of 16 minus the square root of 625. That's 4 - 25, which is -13.\n",
      "\n",
      "Is there a way this could be interpreted differently? Maybe if the exponents were applied differently, but I don't think so. The problem is written clearly as \\(16^{\\frac{1}{2}} - 625^{\\frac{1}{2}}\\), so I don't think there's any ambiguity there.\n",
      "\n",
      "Let me also consider if the negative sign is part of the subtraction or if it's a separate term. In the original problem, it's written as \\(16^{\\frac{1}{2}} - 625^{\\frac{1}{2}}\\), so the negative sign is attached to the entire second term. So, it's not like \\(16^{\\frac{1}{2}} - 625^{\\frac{1}{2}}\\) is subtracting just the square root of 625, but rather subtracting the square root of 625 from the square root of 16. So, that's 4 - 25, which is -13.\n",
      "\n",
      "I think I've covered all the bases here. I've converted the exponents to roots, verified the calculations, double-checked the prime factorization, and considered potential misunderstandings. So, I'm confident that the answer is -13.\n",
      "\n",
      "**Final Answer**\n",
      "The simplified form is \\boxed{-13}.\n",
      "</think>\n",
      "\n",
      "To simplify \\(16^{\\frac{1}{2}} - 625^{\\frac{1}{2}}\\), we start by recognizing that the exponents represent square roots.\n",
      "\n",
      "First, we calculate the square root of 16:\n",
      "\\[\n",
      "16^{\\frac{1}{2}} = \\sqrt{16} = 4\n",
      "\\]\n",
      "\n",
      "Next, we calculate the square root of 625:\n",
      "\\[\n",
      "625^{\\frac{1}{2}} = \\sqrt{625} = 25\n",
      "\\]\n",
      "\n",
      "Subtracting these results, we get:\n",
      "\\[\n",
      "4 - 25 = -13\n",
      "\\]\n",
      "\n",
      "Thus, the simplified form is \\(\\boxed{-13}\\).<endofsentence>\n",
      "1182 200 1282 1301\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1562 200 1662 1895\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1465 200 1565 1765\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "736 200 836 826\n",
      "===\n",
      "===\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct_items = 0\n",
    "torch.manual_seed(0)\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "evaluation_dataset = []\n",
    "\n",
    "for dataset_pos in tqdm(range(len(correct_dataset))):\n",
    "    # dataset_pos = 11\n",
    "    input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "    # print(input_ids)\n",
    "    # print(\"===\")\n",
    "    # print(\"===\")\n",
    "\n",
    "    input_ids = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": base_prompt.format(question=input_ids),\n",
    "                },\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # input_ids = dataset_item[\"input_ids\"]\n",
    "    # generated_ids = dataset_item[\"generated_ids\"]\n",
    "    generated_ids = [\n",
    "        tokenizer.encode(\n",
    "            correct_dataset[dataset_pos][\"model_answer\"],\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "        )\n",
    "        end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "        )\n",
    "        input_ids = torch.tensor(input_ids).cuda()\n",
    "        input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "        windows_amount = 100\n",
    "        # windows_amount = 200\n",
    "        # windows_amount = 300\n",
    "        # windows_amount = 400\n",
    "        # windows_amount = 500\n",
    "        # windows_amount = 2\n",
    "        generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "        original_total_len = torch.tensor(generated_ids).shape[1]\n",
    "        if generated_tokens_amount > original_total_len:\n",
    "            windows_amount = original_total_len // WINDOW_SIZE\n",
    "            generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "\n",
    "        next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "            :, :generated_tokens_amount\n",
    "        ]\n",
    "\n",
    "        # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "        # original_embeds = (model.get_input_embeddings()(next_true_tokens)).to(\n",
    "        original_embeds = (model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)).to(\n",
    "            torch.float32\n",
    "        )\n",
    "\n",
    "        # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        new_embeds_for_compression = original_embeds.reshape(\n",
    "            windows_amount, WINDOW_SIZE, -1\n",
    "        )\n",
    "        compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "        # start_embed = torch.rand_like(start_embed)\n",
    "        # compressed_part = torch.rand_like(compressed_part)\n",
    "        # end_embed = torch.rand_like(end_embed)\n",
    "        generated_embeds = torch.cat(\n",
    "            [\n",
    "                input_ids_embeds,\n",
    "                start_embed,\n",
    "                compressed_part,\n",
    "                end_embed,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "        # print(\"===\")\n",
    "        generated_ids_compressed = model.generate(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            # attention_mask=torch.ones_like(generated_embeds),\n",
    "            attention_mask=torch.ones(\n",
    "                generated_embeds.shape[:2],\n",
    "                device=\"cuda\",\n",
    "            ).long(),\n",
    "            max_new_tokens=4096,\n",
    "            # max_new_tokens=5,\n",
    "            do_sample=False,\n",
    "            # do_sample=True,\n",
    "            # temperature=0.6,\n",
    "            # top_p=0.95,\n",
    "        )\n",
    "        # break\n",
    "    generated_result = tokenizer.decode(generated_ids_compressed[-1])\n",
    "    # print()\n",
    "    gold_answer = correct_dataset[dataset_pos][\"answer\"]\n",
    "    answer = dataset_answer_filter(gold_answer)\n",
    "    model_answer = model_answer_filter(generated_result)\n",
    "    if is_equiv(answer, model_answer):\n",
    "        correct_items += 1\n",
    "        print(\"CORRECT\")\n",
    "    else:\n",
    "        print(\"WRONG\", gold_answer)\n",
    "        print(generated_result)\n",
    "    compressed_total_len = generated_ids_compressed.shape[1] + compressed_part.shape[1]\n",
    "    print(\n",
    "        generated_ids_compressed.shape[1],\n",
    "        next_true_tokens.shape[1],\n",
    "        compressed_total_len,\n",
    "        torch.tensor(generated_ids).shape[1],\n",
    "    )\n",
    "    evaluation_dataset.append(\n",
    "        {\n",
    "            **correct_dataset[dataset_pos],\n",
    "            \"compressed_input_part\": tokenizer.decode(next_true_tokens[-1]),\n",
    "            \"compressed_output_generation\": generated_result,\n",
    "            \"compressed_compression_size\": generated_tokens_amount,\n",
    "            \"original_total_len\": torch.tensor(generated_ids).shape[1],\n",
    "            \"compressed_total_len\": compressed_total_len,\n",
    "        }\n",
    "    )\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    # break\n",
    "    # embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 656])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 719, 1536])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(next_true_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14354066985645933, 0.11961722488038277, 0.8333333333333334)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset) / len(dataset), correct_items / len(dataset), correct_items / len(\n",
    "    correct_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(correct_dataset) / len(dataset), correct_items / len(dataset), (\n",
    "#     correct_items + 1\n",
    "# ) / len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.base_model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57044, 67466, 1.182701072856041)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_total_len = 0\n",
    "compressed_total_len = 0\n",
    "for item in evaluation_dataset:\n",
    "    original_total_len += item[\"original_total_len\"]\n",
    "    compressed_total_len += item[\"compressed_total_len\"]\n",
    "original_total_len, compressed_total_len, compressed_total_len / original_total_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
