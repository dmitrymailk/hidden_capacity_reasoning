{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ef7a7bb00246348e4b40a104ceaa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f085db131e654d64964a7040ecfed546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1580\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1580\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _require_custom_configs \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:5475\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5473\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5487\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5491\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1024\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 309\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:420\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    419\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(EntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-68128578-0ea274e125dba3cb1d1ac5b6;c8d72666-fbda-4390-b0c3-c9d217194594)\n\nEntry Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# model = model.to(torch.bfloat16)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2059\u001b[0m )\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1629\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1631\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1019\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1018\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m-> 1019\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m   1026\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1027\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1028\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1030\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m   1031\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m_MODULE_TO_EXTENSIONS[module_name], file_names\u001b[38;5;241m=\u001b[39m_MODULE_TO_METADATA_FILE_NAMES[module_name]\n\u001b[1;32m   1032\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:690\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    685\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    687\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    688\u001b[0m         patterns_for_key\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:583\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 583\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m         )\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:361\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_HUB_VERSION \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# 10 times faster glob with detail=True (ignores costly info like lastCommit)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     glob_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    359\u001b[0m matched_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    360\u001b[0m     filepath \u001b[38;5;28;01mif\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mstartswith(protocol_prefix) \u001b[38;5;28;01melse\u001b[39;00m protocol_prefix \u001b[38;5;241m+\u001b[39m filepath\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filepath, info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mglob_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mislink\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(filepath))))\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (xbasename(filepath) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m files_to_ignore)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_inside_unrequested_special_dir(filepath, fs_pattern)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir(filepath, fs_pattern)\n\u001b[1;32m    366\u001b[0m ]  \u001b[38;5;66;03m# ignore .ipynb and __pycache__, but keep /../\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     out \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    369\u001b[0m         filepath\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m matched_paths\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix \u001b[38;5;129;01min\u001b[39;00m allowed_extensions \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m xbasename(filepath)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    372\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:521\u001b[0m, in \u001b[0;36mHfFileSystem.glob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    520\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:609\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m pattern \u001b[38;5;241m=\u001b[39m glob_translate(path \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    612\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:556\u001b[0m, in \u001b[0;36mHfFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03mList all files below path.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    `Union[List[str], Dict[str, Dict[str, Any]]]`: List of paths or dict of file information.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxdepth:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwithdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    560\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:500\u001b[0m, in \u001b[0;36mAbstractFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Add the root directory if withdirs is requested\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# This is needed for posix glob compliance\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m withdirs \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(path):\n\u001b[0;32m--> 500\u001b[0m     out[path] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk(path, maxdepth, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m withdirs:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:719\u001b[0m, in \u001b[0;36mHfFileSystem.info\u001b[0;34m(self, path, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     out \u001b[38;5;241m=\u001b[39m out1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh \u001b[38;5;129;01mor\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (expand_info \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mand\u001b[39;00m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_commit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 719\u001b[0m     paths_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_paths_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths_info:\n\u001b[1;32m    727\u001b[0m         _raise_file_not_found(path, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3354\u001b[0m, in \u001b[0;36mHfApi.get_paths_info\u001b[0;34m(self, repo_id, paths, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3351\u001b[0m revision \u001b[38;5;241m=\u001b[39m quote(revision, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mDEFAULT_REVISION\n\u001b[1;32m   3352\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m-> 3354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43ms/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/paths-info/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrevision\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m   3363\u001b[0m paths_info \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"hidden_capacity_reasoning\"\n",
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    ScriptArguments,\n",
    "    SFTConfig,\n",
    "    SFTTrainer,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    generate_train_examples,\n",
    "    pad_train_examples,\n",
    "    tokenize_single_turn,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import types\n",
    "\n",
    "# need for auto SFTTrainer patch(possible increase speed)\n",
    "from unsloth import is_bfloat16_supported\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    EOS_TOKEN_ID,\n",
    "    TEXT_TOKEN_ID,\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    find_all_linear_names_v3,\n",
    ")\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    "    Qwen2ForCausalLMCompressionV3,\n",
    "    Qwen2ModelEmbedPoolerV3,\n",
    ")\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"my_r1_model_v3\"\n",
    "model = Qwen2ForCausalLMCompressionV3.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.model.requires_grad_(False)\n",
    "# model = model.to(torch.bfloat16)\n",
    "\n",
    "# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\n",
    "#     model_name,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map={\"\": 0},\n",
    "#     # quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "# )\n",
    "# print(\n",
    "#     model.embed_pooler.load_state_dict(\n",
    "#         temp_model.state_dict(),\n",
    "#         strict=False,\n",
    "#     ),\n",
    "# )\n",
    "# temp_model = temp_model.cpu()\n",
    "# del temp_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset = load_dataset(\"dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "# dataset = dataset[\"train\"]\n",
    "# dataset = dataset.train_test_split(test_size=10, seed=42)\n",
    "\n",
    "# # test pass\n",
    "# tokenize_single_turn(\n",
    "#     question=dataset[\"train\"][0][\"question\"],\n",
    "#     answer=dataset[\"train\"][0][\"answer\"],\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# train_examples = [\n",
    "#     tokenize_single_turn(tokenizer=tokenizer, **item)\n",
    "#     for item in tqdm(dataset[\"train\"].to_list()[:3])\n",
    "# ]\n",
    "\n",
    "# prepared_train_examples = []\n",
    "# for item in tqdm(train_examples):\n",
    "#     for example in generate_train_examples(\n",
    "#         dataset_batch=[item],\n",
    "#         window_size=WINDOW_SIZE,\n",
    "#     ):\n",
    "#         prepared_train_examples.append(example)\n",
    "\n",
    "# print(\n",
    "#     \"max_len\",\n",
    "#     max([len(item[\"original_tokens\"]) for item in prepared_train_examples]),\n",
    "# )\n",
    "\n",
    "# new_dataset = Dataset.from_list(prepared_train_examples)\n",
    "# print(dataset)\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     padded_batch = pad_train_examples(\n",
    "#         train_examples=batch,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )\n",
    "#     padded_batch = {\n",
    "#         \"replaced_original_tokens\": padded_batch[\"replaced_original_tokens\"][\n",
    "#             \"input_ids\"\n",
    "#         ],\n",
    "#         \"compressed_input_ids\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "#         \"original_tokens\": padded_batch[\"original_tokens\"][\"input_ids\"],\n",
    "#         \"attention_mask\": padded_batch[\"compressed_input_ids\"][\"attention_mask\"],\n",
    "#         \"labels\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "#         \"content_compression_mask\": padded_batch[\"content_compression_mask\"][\n",
    "#             \"input_ids\"\n",
    "#         ],\n",
    "#     }\n",
    "#     for key in padded_batch.keys():\n",
    "#         padded_batch[key] = torch.tensor(padded_batch[key])\n",
    "#     skip_ids = [\n",
    "#         TEXT_TOKEN_ID,\n",
    "#         EOS_TOKEN_ID,\n",
    "#         VISION_START,\n",
    "#         VISION_END,\n",
    "#     ]\n",
    "#     for skip_id in skip_ids:\n",
    "#         padded_batch[\"labels\"][padded_batch[\"labels\"] == skip_id] = -100\n",
    "#     # часть инпута от пользователя\n",
    "#     last_index = (padded_batch[\"content_compression_mask\"] == 1).long().nonzero()[-1][1]\n",
    "#     padded_batch[\"labels\"][:, :last_index][\n",
    "#         padded_batch[\"content_compression_mask\"][:, :last_index] == 1\n",
    "#     ] = -100\n",
    "#     # print(padded_batch)\n",
    "#     return padded_batch\n",
    "\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.0,\n",
    "#     bias=\"none\",\n",
    "#     target_modules=find_all_linear_names_v3(model=model),\n",
    "#     modules_to_save=[\n",
    "#         \"embed_pooler.model.embed_tokens\",\n",
    "#         \"embed_pooler.weight_pooler\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# formatted_date = datetime.fromtimestamp(time.time()).strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "# model.embed_pooler = prepare_model_for_kbit_training(model.embed_pooler)\n",
    "# peft_model = get_peft_model(model, peft_config)\n",
    "# peft_model.print_trainable_parameters()\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     train_dataset=new_dataset,\n",
    "#     data_collator=collate_fn,\n",
    "#     peft_config=peft_config,\n",
    "#     args=SFTConfig(\n",
    "#         per_device_train_batch_size=2,\n",
    "#         gradient_accumulation_steps=2,\n",
    "#         warmup_steps=5,\n",
    "#         num_train_epochs=1,  # 90,  # Set this for 1 full training run.\n",
    "#         # num_train_epochs=90,  # Set this for 1 full training run.\n",
    "#         # max_steps=10000,\n",
    "#         learning_rate=1e-4,\n",
    "#         bf16=True,\n",
    "#         # fp16=model.dtype == torch.float16,\n",
    "#         logging_steps=8,\n",
    "#         optim=\"adamw_8bit\",\n",
    "#         weight_decay=0.01,\n",
    "#         lr_scheduler_type=\"linear\",\n",
    "#         seed=3407,\n",
    "#         output_dir=f\"outputs/{formatted_date}\",\n",
    "#         # report_to=\"wandb\",\n",
    "#         report_to=\"none\",\n",
    "#         remove_unused_columns=False,\n",
    "#         dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "#         # gradient_checkpointing=True,\n",
    "#         save_steps=10000,\n",
    "#         run_name=formatted_date,\n",
    "#     ),\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLet’s denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLet’s assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLet’s let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLet’s denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my_r1_model_v3/tokenizer_config.json',\n",
       " 'my_r1_model_v3/special_tokens_map.json',\n",
       " 'my_r1_model_v3/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.base_model.embed_pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.bfloat16)\n",
    "model.embed_pooler(\n",
    "    torch.randn(\n",
    "        2,\n",
    "        2,\n",
    "        1536,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.bfloat16,\n",
    "    )\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.weight_pooler.modules_to_save.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.model.embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in trainer.model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from peft import PeftModel\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ForCausalLMCompressionV5,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    ")\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# model_name = \"r1_compressor_v2\"\n",
    "# model = Qwen2ForCausalLMCompressionV2.from_pretrained(\n",
    "#     model_name,\n",
    "#     # torch_dtype=torch.bfloat16,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     device_map={\"\": 0},\n",
    "#     # attn_implementation=\"flash_attention_2\",\n",
    "#     attn_implementation=\"sdpa\",\n",
    "# )\n",
    "# model = PeftModel.from_pretrained(\n",
    "#     model,\n",
    "#     # \"outputs/2025_04_19_17_17_34_493839/checkpoint-210000\",\n",
    "#     # \"outputs/2025_04_19_17_17_34_493839/checkpoint-50000\",\n",
    "#     # \"outputs/2025_04_21_19_23_11_642509/checkpoint-10000\",\n",
    "#     # \"outputs/2025_04_22_01_43_43_347583/checkpoint-90000\",\n",
    "#     # \"outputs/2025_04_22_01_43_43_347583/checkpoint-10000\",\n",
    "#     # 'outputs/2025_04_23_00_46_10_062896/checkpoint-2794'\n",
    "#     # \"outputs/2025_04_29_21_24_17_071961/checkpoint-588\",\n",
    "#     # \"outputs/2025_04_30_01_16_22_692562/checkpoint-140000\",\n",
    "#     # \"outputs/2025_04_30_01_16_22_692562/checkpoint-10000\",\n",
    "#     # \"outputs/2025_05_01_14_33_36_096886/checkpoint-10000\",\n",
    "#     \"outputs/2025_05_02_00_34_41_878309/checkpoint-60000\",\n",
    "#     # \"outputs/2025_05_02_00_34_41_878309/checkpoint-10000\",\n",
    "#     # \"outputs/2025_05_04_22_59_34_768602/checkpoint-160000\",\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "###\n",
    "\n",
    "# model_name = \"outputs/2025_05_06_01_19_17_860068/checkpoint-300000\"\n",
    "# model_name = \"outputs/2025_05_06_01_19_17_860068/checkpoint-100000\"\n",
    "# model_name = \"outputs/2025_05_07_00_29_16_600547/checkpoint-448762\"\n",
    "# model_name = \"outputs/2025_05_08_13_26_40_258983/checkpoint-7010\"\n",
    "model_name = \"outputs/2025_05_09_23_58_07_868327/checkpoint-10000\"\n",
    "model = Qwen2ForCausalLMCompressionV5.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "224 202 0.9017857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    # \"dim/hendrycks_math_train_12k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    # \"dim/hendrycks_math_train_1k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(\n",
    "    # test_size=250,\n",
    "    test_size=350,\n",
    "    # test_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dataset = dataset[\"test\"].filter(lambda x: x[\"model_answer\"].count(\"</think>\") == 1)\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "\n",
    "correct_dataset = []\n",
    "\n",
    "for pos, item in enumerate(dataset):\n",
    "    try:\n",
    "        answer = dataset_answer_filter(item[\"answer\"])\n",
    "        model_answer = model_answer_filter(item[\"model_answer\"])\n",
    "        # print(answer, model_answer)\n",
    "        # break\n",
    "        if is_equiv(answer, model_answer):\n",
    "            correct_dataset.append(item)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(dataset), len(correct_dataset), len(correct_dataset) / len(dataset))\n",
    "\n",
    "correct_dataset = correct_dataset[:30]\n",
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>Problem: If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<｜Assistant｜><think>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "# prompt = \"how many wings has a bird?\"\n",
    "prompt = correct_dataset[0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    "model_inputs = tokenizer(\n",
    "    [text],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"longest\",\n",
    "    truncation=False,\n",
    "    add_special_tokens=False,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # generated_ids = model.generate(\n",
    "    #     model_inputs.input_ids,\n",
    "    #     max_new_tokens=1,\n",
    "    #     do_sample=False,\n",
    "    # )\n",
    "    generated_ids = model.generate(\n",
    "        # **model_inputs.input_ids,\n",
    "        **model_inputs,\n",
    "        max_new_tokens=4096,\n",
    "        do_sample=False,\n",
    "        # do_sample=not False,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLet’s denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLet’s assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLet’s let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLet’s denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response == correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<｜Assistant｜><think>\n",
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<｜end▁of▁sentence｜><｜begin▁of▁sentence｜>\n",
      "\n",
      "To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "prompt = correct_dataset[:5][0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "# initial_len = generated_tokens.shape\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    max_steps = 1200\n",
    "    past_key_values = None\n",
    "    for step in range(max_steps):\n",
    "        if step == 0:\n",
    "            logits = model(\n",
    "                inputs_embeds=generated_embeds,\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.arange(generated_embeds.shape[1])\n",
    "                .cuda()\n",
    "                .unsqueeze(0),\n",
    "                use_cache=True,\n",
    "                past_key_values=None,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "        else:\n",
    "            logits = model(\n",
    "                # input_ids=generated_tokens[-1][-1:].unsqueeze(0),\n",
    "                inputs_embeds=generated_embeds[:, -1:, :],\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.tensor(generated_embeds.shape[1] - 1)\n",
    "                .reshape(1, 1)\n",
    "                .cuda(),\n",
    "                use_cache=True,\n",
    "                past_key_values=past_key_values,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "\n",
    "        top_token = logits.argmax(-1)[-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(step, tokenizer.decode(generated_tokens[-1]))\n",
    "    # break\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "# break\n",
    "embeds_generation_tokens = generated_tokens[-1]\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜User｜>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.<｜Assistant｜><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\\n\\nLet me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\\n\\nSo, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\\n\\nTime = Distance / Speed\\n\\nSo, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\\n\\nLet's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\\n\\nSo, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\\n\\nSo, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\\n\\nAlternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\\n\\nI think that's solid. So, the lion will catch the elephant in 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \\n\\nTo find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\\n\\n\\\\[\\n24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph}\\n\\\\]\\n\\nThe initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\\n\\n\\\\[\\n\\\\text{Time} = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = 0.2 \\\\text{ hours}\\n\\\\]\\n\\nConverting 0.2 hours to minutes:\\n\\n\\\\[\\n0.2 \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes.<｜end▁of▁sentence｜><｜begin▁of▁sentence｜>\\n\\nTo determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from transformers.generation import utils\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "dataset_pos = 0\n",
    "prompt = correct_dataset[dataset_pos][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": base_prompt.format(question=prompt),\n",
    "        },\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=4096,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] == correct_dataset[\n",
    "    dataset_pos\n",
    "][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': \"Alicia's average on her five tests is 88 points. The score range for each test is 0 points to 100 points, inclusive. What is the lowest possible score that Alicia could have earned on one of the five tests?\",\n",
       " 'solution': \"If Alicia's average score on her five tests is 88 points, then the sum of her scores must be $88 \\\\times 5 = 440$ points. If she earned   100 points on four of the tests, then she could have earned a score as low as $\\\\boxed{40\\\\text{ points}}$ on the other test.\",\n",
       " 'answer': '40\\\\text{ points}',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 4,\n",
       " 'unique_id': 'test/prealgebra/1697.json',\n",
       " 'model_answer': \"Okay, so I need to figure out the lowest possible score Alicia could have earned on one of her five tests. She has an average of 88 points, and each test is scored between 0 and 100, inclusive. Hmm, let me think about this step by step.\\n\\nFirst, I know that an average is calculated by taking the sum of all the test scores and dividing it by the number of tests. In this case, she has five tests, and her average is 88. So, to find the total points she has across all five tests, I can multiply the average by the number of tests.\\n\\nLet me write that down:\\n\\nTotal points = Average × Number of tests\\nTotal points = 88 × 5\\n\\nLet me calculate that. 88 times 5 is... 440. So, the total points she has across all five tests is 440.\\n\\nNow, the question is asking for the lowest possible score she could have earned on one of these tests. To minimize one of the test scores, I need to maximize the other scores because the total is fixed at 440.\\n\\nBut there are constraints: each test can only have a score between 0 and 100, inclusive. So, the maximum score on any test is 100. If I try to maximize the other four test scores, each being 100, that would give me the maximum possible sum for four tests.\\n\\nLet me calculate that:\\n\\nMaximizing four tests:\\nMax sum = 100 × 4 = 400\\n\\nSo, if four tests are 100 each, that's 400 points. Then, the fifth test must make up the remaining points to reach the total of 440.\\n\\nLet me find the score for the fifth test:\\n\\nScore on fifth test = Total points - Max sum of four tests\\nScore = 440 - 400\\nScore = 40\\n\\nWait, so that means if four tests are 100 each, the fifth test must be 40? That seems low, but it's mathematically correct because 100 + 100 + 100 + 100 + 40 = 440.\\n\\nBut hold on, the question is asking for the lowest possible score on one of the tests. So, if I set the other four tests as high as possible (100 each), the fifth test would be 40. But is there a way to get a lower score? Let me think.\\n\\nIf I make one of the other tests lower than 100, does that allow the fifth test to be lower than 40? Wait, no, because if I lower one test, I have to raise the others to compensate, but they can't go above 100. So, actually, to minimize one test, you need to maximize the others as much as possible, which is 100 each. So, 40 is indeed the minimal possible score.\\n\\nBut just to double-check, let's think about it differently. Suppose I try to set four tests to 100, which gives me 400. The fifth test is 40. If I tried to make the fifth test lower, say 30, then the sum of the other four tests would have to be 440 - 30 = 410. But if I have four tests, each can be at most 100, so 100 × 4 is 400. 410 is more than 400, which isn't possible. So, it's not possible to have a lower score on the fifth test than 40 because the other four tests can't exceed 400.\\n\\nTherefore, 40 is the lowest possible score Alicia could have earned on one of the five tests.\\n\\nWait, but another thought: what if one test is 0? Would that allow the others to be higher? Let me see. If one test is 0, then the total of the other four tests would have to be 440 - 0 = 440. But each of those four tests can only go up to 100, so 100 × 4 is 400. But 440 is more than 400, which is impossible. Therefore, having a 0 on one test would require the others to sum to 440, which isn't possible since the maximum they can sum to is 400. So, 0 is too low.\\n\\nSo, 40 is indeed the lowest possible score because it's the only score that allows the other four tests to be 100 each without exceeding the maximum.\\n\\nAnother angle: Let's think about the formula for the average. The average is the total divided by the number of tests. So, if I want to minimize one test, I have to maximize the others, but they can't exceed 100. So, the maximum sum of four tests is 400, as we had before. Therefore, the minimal fifth test is 40.\\n\\nWait, let me make sure I'm not missing any other constraints. The problem says each test is between 0 and 100, inclusive. So, 0 is allowed, but in this case, if we tried to set four tests to 100, the fifth must be 40. If we set one test to 100, the others could be higher, but that doesn't help in minimizing a single test. Alternatively, if I set two tests to 100, the others can be higher, but again, that doesn't help.\\n\\nTherefore, the only way to minimize a single test score is to maximize the other four, which is 100 each. So, the minimal possible score is 40.\\n\\nI think that's solid reasoning. I don't see any other way to lower one test score without violating the test score range or the total points.\\n\\n**Final Answer**\\nThe lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\\n</think>\\n\\nAlicia's average score on her five tests is 88 points. To find the total points she has across all five tests, we multiply the average by the number of tests:\\n\\n\\\\[\\n\\\\text{Total points} = 88 \\\\times 5 = 440\\n\\\\]\\n\\nTo find the lowest possible score on one of the tests, we need to maximize the scores of the other four tests. Since each test can score a maximum of 100, the maximum sum of four tests is:\\n\\n\\\\[\\n\\\\text{Max sum of four tests} = 100 \\\\times 4 = 400\\n\\\\]\\n\\nThe score on the fifth test must then be:\\n\\n\\\\[\\n\\\\text{Score on fifth test} = 440 - 400 = 40\\n\\\\]\\n\\nThus, the lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "example_id = correct_dataset[dataset_pos][\"unique_id\"].replace(\"/\", \"_\")\n",
    "with open(f\"./temp/{example_id}\", \"w\") as f:\n",
    "    temp = {\n",
    "        \"generated_ids\": generated_ids.tolist(),\n",
    "        \"input_ids\": generated_tokens.tolist(),\n",
    "    }\n",
    "    json.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\n",
    "    correct_dataset[dataset_pos][\"model_answer\"],\n",
    "    add_special_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜User｜>An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?<｜Assistant｜><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them will be changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should think of the relative speed as the lion's speed minus the elephant's speed? Wait, no, that might not be right.\\n\\nLet me clarify. If the lion is moving towards the elephant at 24 mph, and the elephant is moving away from the lion at 19 mph, then the lion is effectively closing the gap at a rate of 24 mph minus 19 mph. That makes sense because the lion is moving towards the elephant, but the elephant is moving away. So, the net speed at which the distance between them is decreasing is 24 - 19 = 5 mph.\\n\\nSo, the distance between them is decreasing at 5 miles per hour. They start 1 mile apart, so I can use the formula:\\n\\nTime = Distance / Speed\\n\\nHere, the distance is 1 mile, and the speed is 5 mph. So, time = 1 / 5 hours. But the question asks for the time in minutes, so I need to convert hours to minutes. There are 60 minutes in an hour, so 1/5 hours * 60 minutes/hour = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph towards the elephant, and the elephant is moving away at 19 mph, then the relative speed is indeed 24 - 19 = 5 mph. So, the lion is gaining on the elephant at 5 miles per hour. Since they start 1 mile apart, the time it takes to close that distance is 1 / 5 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure, let me think about it another way. Maybe set up an equation for their positions as functions of time and see when they meet.\\n\\nLet me denote t as the time in hours. The position of the elephant as a function of time would be starting from some point and moving away at 19 mph. Let's say the initial position of the elephant is at position 0, and the lion is at position 1 mile. Then, the position of the elephant at time t is 0 + 19t, and the position of the lion is 1 - 24t. They meet when their positions are equal, so:\\n\\n19t = 1 - 24t\\n\\nAdding 24t to both sides:\\n\\n19t + 24t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours\\n\\nWait, that's different from what I got before. Hmm, so which one is correct? 12 minutes or 1/43 hours?\\n\\nWait, 1/43 hours is approximately 1.395 minutes, which is about 1 minute and 23 seconds. But earlier, I got 12 minutes. That's a big difference. So, I must have made a mistake somewhere.\\n\\nLet me go back. When I thought about the relative speed, I considered the lion moving towards the elephant and the elephant moving away, so the relative speed is 24 - 19 = 5 mph. So, the time should be 1/5 hours, which is 12 minutes. But when I set up the equations, I got t = 1/43 hours, which is about 1.395 minutes. That's conflicting.\\n\\nWait, maybe I messed up the initial positions. Let me define the positions more carefully. Let's say the lion starts at position 0, and the elephant starts at position 1 mile. Then, the lion is moving towards the elephant, so its position as a function of time is 0 + 24t. The elephant is moving away from the lion, so its position is 1 + 19t. They meet when their positions are equal:\\n\\n24t = 1 + 19t\\n\\nSubtracting 19t from both sides:\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. Okay, that makes sense. So, why did I get 1/43 hours earlier?\\n\\nWait, in my second approach, I set the lion's position as 1 - 24t, but that might be incorrect. If the lion starts at position 0, moving towards the elephant, which is at position 1, then the lion's position is 24t. The elephant is moving away from the lion, so its position is 1 + 19t. So, setting them equal:\\n\\n24t = 1 + 19t\\n\\nWhich gives t = 1/5 hours, which is 12 minutes. So, that seems correct.\\n\\nWait, so why did I get 1/43 hours earlier? Maybe I confused the starting positions. Let me re-examine that.\\n\\nIn the second approach, I set the lion's position as 1 - 24t, which would be incorrect because if the lion is moving towards the elephant, starting from position 0, its position should be increasing, not decreasing. So, that was my mistake. I should have set the lion's position as 24t, not 1 - 24t.\\n\\nSo, correcting that, the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes. So, that's consistent with the first method.\\n\\nTherefore, the correct answer is 12 minutes.\\n\\nWait, but just to make sure, let me think about it in another way. Suppose the lion is moving at 24 mph towards the elephant, and the elephant is\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them is changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should consider the relative speed between the lion and the elephant.\\n\\nWait, actually, since the elephant is moving away, the lion has to cover the initial distance plus any additional distance the elephant might cover while the lion is chasing. But since the lion is faster, it should eventually catch up. So, maybe I can model this as a relative speed problem.\\n\\nLet me denote the speed of the lion as \\\\( v_l = 24 \\\\) mph and the speed of the elephant as \\\\( v_e = 19 \\\\) mph. The initial distance between them is \\\\( d = 1 \\\\) mile.\\n\\nSince the lion is moving towards the elephant and the elephant is moving away, the relative speed at which the distance between them is decreasing is the difference between the lion's speed and the elephant's speed. So, the relative speed \\\\( v_{relative} = v_l - v_e = 24 - 19 = 5 \\\\) mph.\\n\\nWait, is that right? If the lion is moving towards the elephant and the elephant is moving away, then the lion is effectively closing the gap at a rate of 5 mph. So, the time it takes to close the 1 mile gap would be the initial distance divided by the relative speed.\\n\\nSo, time \\\\( t = \\\\frac{d}{v_{relative}} = \\\\frac{1}{5} \\\\) hours. But the question asks for the time in minutes, so I need to convert that.\\n\\nSince 1 hour is 60 minutes, \\\\( \\\\frac{1}{5} \\\\) hours is \\\\( \\\\frac{1}{5} \\\\times 60 = 12 \\\\) minutes. So, it should take 12 minutes for the lion to catch the elephant.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, then the lion is gaining on the elephant at a rate of 5 mph. So, to cover the 1 mile gap, it would take \\\\( \\\\frac{1}{5} \\\\) hours, which is indeed 12 minutes. That seems correct.\\n\\nAlternatively, I can model this with equations. Let me set up a coordinate system where at time \\\\( t \\\\) hours, the position of the lion is \\\\( 24t \\\\) miles from its starting point, and the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion. Wait, actually, hold on. If the elephant is moving away from the lion, then the distance between them is increasing. So, the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion, and the position of the lion is \\\\( 24t \\\\) miles from the same starting point.\\n\\nWait, but initially, they are 1 mile apart. So, if the lion starts at position 0 and the elephant starts at position 1 mile, then the distance between them at time \\\\( t \\\\) is \\\\( |24t - (1 + 19t)| \\\\). We want this distance to be 0 when the lion catches the elephant.\\n\\nSo, setting up the equation:\\n\\n\\\\( 24t - (1 + 19t) = 0 \\\\)\\n\\nSimplify:\\n\\n\\\\( 24t - 19t - 1 = 0 \\\\)\\n\\n\\\\( 5t - 1 = 0 \\\\)\\n\\n\\\\( 5t = 1 \\\\)\\n\\n\\\\( t = \\\\frac{1}{5} \\\\) hours, which is 12 minutes. So, that confirms my earlier result.\\n\\nAlternatively, I can think about it in terms of distance covered. The lion needs to cover the initial 1 mile plus whatever distance the elephant covers in that time. But since the lion is faster, the time is determined by the relative speed.\\n\\nWait, another way to think about it is using the concept of relative velocity. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the relative speed is 24 - 19 = 5 mph. So, the lion is closing the gap at 5 mph. Therefore, the time to close 1 mile is 1/5 hours, which is 12 minutes.\\n\\nI think that's solid. I can't see any mistakes in this reasoning. So, I think the answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed.\\n\\nThe relative speed at which the lion is closing the gap is the difference between their speeds:\\n\\\\[ v_{\\\\text{relative}} = v_l - v_e = 24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph} \\\\]\\n\\nThe time it takes to close the 1 mile gap is calculated by dividing the initial distance by the relative speed:\\n\\\\[ t = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours} \\\\]\\n\\nConverting this time into minutes:\\n\\\\[ \\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes} \\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate with compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "===\n",
      "===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPRESSED PART Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\n",
      "\n",
      "First, let me write down each term:\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4\n",
      "\n",
      "P = -i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "And the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\n",
      "\n",
      "Let me start by substituting the values:\n",
      "\n",
      "A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Wait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Okay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\n",
      "\n",
      "First, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\n",
      "\n",
      "(2 + i) - (-4) = (2 + i) + 4\n",
      "\n",
      "So, that simplifies to 2 + 4 + i, which is 6 + i.\n",
      "\n",
      "Alright, so now the expression becomes:\n",
      "\n",
      "6 + i + (-i) + (2 + 4i)\n",
      "\n",
      "Wait, let me write that again:\n",
      "\n",
      "= (6 + i) + (-i) + (2 + 4i)\n",
      "\n",
      "Now,\n",
      "===\n",
      " let's handle the imaginary parts and the real parts separately.\n",
      "\n",
      "Imaginary parts: i + (-i) = i - i = 0i, which is just 0.\n",
      "\n",
      "Real parts: 6 + 2 = 8.\n",
      "\n",
      "So, adding them together: 8 + 0i = 8.\n",
      "\n",
      "Wait, that seems too straightforward. Let me check my steps again to make sure I didn't make a mistake.\n",
      "\n",
      "Starting over:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, handle the subtraction:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P: 6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S: 6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Wait, hold on, that's different from what I had before. Hmm, so I must have made a mistake in my initial breakdown.\n",
      "\n",
      "Let me do it step by step again:\n",
      "\n",
      "Start with A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Wait, so now I get 8 + 4i. But earlier, I thought it was 8. So, which one is correct?\n",
      "\n",
      "Let me count the steps again.\n",
      "\n",
      "1. Compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "2. Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "3. Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "So, that's 8 + 4i. Hmm, so why did I get 8 earlier? Because I thought that adding 6 and 2 gives 8, but actually, 6 is already a real number, and then adding 2 gives 8, but the imaginary parts cancel out, leaving just 8 + 4i.\n",
      "\n",
      "Wait, so perhaps I made a mistake in my initial breakdown when I thought it was 8. So, actually, the correct answer is 8 + 4i.\n",
      "\n",
      "Wait, let me check the arithmetic again.\n",
      "\n",
      "Starting over:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that seems correct. So, the final answer is 8 + 4i.\n",
      "\n",
      "Wait, but in my initial thought process, I thought it was 8, but now I see it's 8 + 4i. So, I need to make sure I don't make that mistake again.\n",
      "\n",
      "Alternatively, maybe I can approach it differently. Let me group the real parts and the imaginary parts separately.\n",
      "\n",
      "So, starting with:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, let's handle the real parts:\n",
      "\n",
      "Real parts: 2 (from A) + 4 (from O) + 2 (from S) = 2 + 4 + 2 = 8\n",
      "\n",
      "Imaginary parts: 1 (from A) + 0 (from O) - 1 (from P) + 4 (from S) = 1 + 0 - 1 + 4 = 4\n",
      "\n",
      "So, combining them: 8 + 4i\n",
      "\n",
      "Yes, that's consistent with the previous result.\n",
      "\n",
      "So, I think I initially made a mistake by not properly grouping the real and imaginary parts, but now that I've broken it down separately, it's clear that the answer is 8 + 4i.\n",
      "\n",
      "Wait, but let me make sure I didn't misplace any signs. Let's go step by step again.\n",
      "\n",
      "Compute A - O + P + S:\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4\n",
      "\n",
      "P = -i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute (2 + i) - (-4):\n",
      "\n",
      "Subtracting a negative is adding a positive, so:\n",
      "\n",
      "2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P: 6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "Then, add S: 6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Alternatively, if I were to write it as:\n",
      "\n",
      "(A - O) + (P + S)\n",
      "\n",
      "Compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 6 + i\n",
      "\n",
      "Compute P + S:\n",
      "\n",
      "(-i) + (2 + 4i) = 2 + 3i\n",
      "\n",
      "Then, add those results: (6 + i) + (2 + 3i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "So, I think I can confidently say that the answer is 8 + 4i.\n",
      "\n",
      "Wait, but just to make sure, let me plug in the values into the original expression and see if it matches.\n",
      "\n",
      "Compute A - O + P + S:\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Compute each operation step by step:\n",
      "\n",
      "First, A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Alternatively, if I were to write it as:\n",
      "\n",
      "(A + P + S) - O\n",
      "\n",
      "Compute A + P + S:\n",
      "\n",
      "(2 + i) + (-i) + (2 + 4i) = 2 + i - i + 2 + 4i = (2 + 2) + (i - i + 4i) = 4 + 4i\n",
      "\n",
      "Then, subtract O: 4 + 4i - (-4) = 4 + 4i + 4 = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "So, regardless of the order in which I group the operations, I still get 8 + 4i.\n",
      "\n",
      "Therefore, I think I can be confident that the correct answer is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another method. Maybe convert all complex numbers to their standard form and then add them.\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4 (which is -4 + 0i)\n",
      "\n",
      "P = -i (which is 0 - i)\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\n",
      "\n",
      "Compute each operation:\n",
      "\n",
      "First, A - O:\n",
      "\n",
      "(2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (0 - i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Alternatively, if I write all the complex numbers in a column:\n",
      "\n",
      "A: 2 + i\n",
      "\n",
      "-O: +4 + 0i\n",
      "\n",
      "P: 0 - i\n",
      "\n",
      "S: 2 + 4i\n",
      "\n",
      "Adding them up:\n",
      "\n",
      "Real parts: 2 + 4 + 0 + 2 = 8\n",
      "\n",
      "Imaginary parts: 1 + 0 - 1 + 4 = 4\n",
      "\n",
      "So, 8 + 4i.\n",
      "\n",
      "Yes, that's consistent.\n",
      "\n",
      "Therefore, I think I can conclude that the value of A - O + P + S is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another approach. Maybe convert all complex numbers to their rectangular form and then add them step by step.\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4 = -4 + 0i\n",
      "\n",
      "P = -i = 0 - i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\n",
      "\n",
      "Compute A - O:\n",
      "\n",
      "(2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + 0 - i = 6 + 0i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Alternatively, if I write all the operations together:\n",
      "\n",
      "A - O + P + S = (2 + i) + 4 + (-i) + 2 + 4i\n",
      "\n",
      "Wait, hold on, that's another way to think about it. Let me see.\n",
      "\n",
      "A - O + P + S = A + (-O) + P + S\n",
      "\n",
      "Since O = -4, -O = 4\n",
      "\n",
      "So, A + 4 + P + S\n",
      "\n",
      "Now, substitute A, P, S:\n",
      "\n",
      "(2 + i) + 4 + (-i) + (2 + 4i)\n",
      "\n",
      "Now, combine like terms:\n",
      "\n",
      "Real parts: 2 + 4 + 2 = 8\n",
      "\n",
      "Imaginary parts: i - i + 4i = 4i\n",
      "\n",
      "So, 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Therefore, I think I can be absolutely sure that the answer is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another method. Maybe using vectors or something.\n",
      "\n",
      "But actually, since all the operations are straightforward addition and subtraction of complex numbers, I think the above methods are sufficient.\n",
      "\n",
      "Therefore, I think the answer is 8 + 4i.\n",
      "\n",
      "**Final Answer**\n",
      "The value of \\( A - O + P + S \\) is \\boxed{8 + 4i}.\n",
      "</think>\n",
      "\n",
      "Given the values \\( A = 2 + i \\), \\( O = -4 \\), \\( P = -i \\), and \\( S = 2 + 4i \\), we need to find the value of \\( A - O + P + S \\).\n",
      "\n",
      "First, substitute the given values into the expression:\n",
      "\n",
      "\\[\n",
      "A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\\]\n",
      "\n",
      "Simplify each term step by step:\n",
      "\n",
      "1. Compute \\( A - O \\):\n",
      "   \\[\n",
      "   (2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "   \\]\n",
      "\n",
      "2. Add \\( P \\) to the result:\n",
      "   \\[\n",
      "   6 + i + (-i) = 6 + 0i = 6\n",
      "   \\]\n",
      "\n",
      "3. Add \\( S \\) to the result:\n",
      "   \\[\n",
      "   6 + (2 + 4i) = 8 + 4i\n",
      "   \\]\n",
      "\n",
      "Thus, the value of \\( A - O + P + S \\) is \\(\\boxed{8 + 4i}\\).<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dataset_pos = 0\n",
    "input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "print(input_ids)\n",
    "print(\"===\")\n",
    "print(\"===\")\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "input_ids = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": base_prompt.format(question=input_ids),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "# input_ids = dataset_item[\"input_ids\"]\n",
    "# generated_ids = dataset_item[\"generated_ids\"]\n",
    "generated_ids = [\n",
    "    tokenizer.encode(\n",
    "        correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "\n",
    "# generated_tokens = tokenizer.apply_chat_template(\n",
    "#     [\n",
    "#         # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "#         {\"role\": \"user\", \"content\": example[\"question\"]},\n",
    "#     ],\n",
    "#     tokenize=True,\n",
    "#     add_generation_prompt=True,\n",
    "# )\n",
    "generated_tokens = input_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # start_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # end_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    input_ids = torch.tensor(input_ids).cuda()\n",
    "    input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "    # input_ids_embeds = model.base_model.embed_pooler.model.get_input_embeddings()(input_ids)\n",
    "    # windows_amount = 100\n",
    "    windows_amount = 200\n",
    "    # windows_amount = 300\n",
    "    # windows_amount = 400\n",
    "    # windows_amount = 500\n",
    "    # windows_amount = 2\n",
    "    next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "        :, : WINDOW_SIZE * windows_amount\n",
    "    ]\n",
    "\n",
    "    # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "    original_embeds = (\n",
    "        model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.base_model.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.get_input_embeddings()(next_true_tokens)\n",
    "    ).to(torch.float32)\n",
    "    # ).to(torch.bfloat16)\n",
    "\n",
    "    # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    new_embeds_for_compression = original_embeds.reshape(\n",
    "        windows_amount, WINDOW_SIZE, -1\n",
    "    )\n",
    "    compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "    # start_embed = torch.rand_like(start_embed)\n",
    "    # compressed_part = torch.rand_like(compressed_part)\n",
    "    # end_embed = torch.rand_like(end_embed)\n",
    "    generated_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds,\n",
    "            start_embed,\n",
    "            compressed_part,\n",
    "            end_embed,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "    print(\"===\")\n",
    "    generated_ids_compressed = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=2800,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        # do_sample=True,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "    # break\n",
    "print(tokenizer.decode(generated_ids_compressed[-1]))\n",
    "# break\n",
    "# embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Below is a magic square, meaning that the sum of the numbers in each row, in each column, and in each of the $2$ main diagonals are equal. What is the value of $n$?\\n\\n[asy]size(125);\\nfor(int i = 0; i<4; ++i)\\n{\\n\\ndraw((0,i)--(3,i),linewidth(1));\\n}\\n\\nfor(int j = 0; j<4; ++j)\\n{\\n\\ndraw((j,0)--(j,3),linewidth(1));\\n}\\n\\nlabel(\"$n-3$\",(.5,.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"$n+1$\",(.5,2.5));\\n\\nlabel(\"$n+2$\",(1.5,.5));\\nlabel(\"$2n-9$\",(1.5,1.5));\\nlabel(\"$1$\",(1.5,2.5));\\n\\nlabel(\"$2$\",(2.5,.5));\\nlabel(\"$n$\",(2.5,1.5));\\nlabel(\"$n-1$\",(2.5,2.5));\\n[/asy]',\n",
       " 'solution': 'First, we can evaluate the sum across the first row, which gives $(n+1)+1+(n-1)=2n+1$.  Evaluate the sum of the entries across the second row, $3+(2n-9)+n=3n-6$. Now, since we have a magic square, these two sums are equal.  So $2n+1=3n-6$. Isolating $n$, we obtain $n = \\\\boxed{7}$.\\n\\nThe square will look like: [asy] size(2cm);\\ndraw((0,0)--(3,0)--(3,3)--(0,3)--cycle,linewidth(1));\\ndraw((1,0)--(1,3),linewidth(1));\\ndraw((2,0)--(2,3),linewidth(1));\\ndraw((0,1)--(3,1),linewidth(1));\\ndraw((0,2)--(3,2),linewidth(1));\\nlabel(\"8\",(.5,2.5));\\nlabel(\"1\",(1.5,2.5));\\nlabel(\"6\",(2.5,2.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"5\",(1.5,1.5));\\nlabel(\"7\",(2.5,1.5));\\nlabel(\"4\",(.5,.5));\\nlabel(\"9\",(1.5,.5));\\nlabel(\"2\",(2.5,.5));\\n[/asy]',\n",
       " 'answer': '7',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1930.json',\n",
       " 'model_answer': \"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). Let me try to figure this out step by step. \\n\\nFirst, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\\\( n \\\\) such that all these sums are equal.\\n\\nLooking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\\n\\n- The top row has three cells: \\\\( n-3 \\\\), \\\\( 3 \\\\), and \\\\( n+1 \\\\).\\n- The middle row has \\\\( n+2 \\\\), \\\\( 2n-9 \\\\), and \\\\( 1 \\\\).\\n- The bottom row has \\\\( 2 \\\\), \\\\( n \\\\), and \\\\( n-1 \\\\).\\n\\nSo, writing this out, the magic square looks like this:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, now I need to find \\\\( n \\\\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\\\( S \\\\).\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That means the magic constant \\\\( S = 2n + 1 \\\\).\\n\\nLet me check the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since this must equal \\\\( S \\\\), we have:\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nLet me solve for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( n = 7 \\\\)\\n\\nWait, hold on. Let me verify this because I might have made a mistake. If \\\\( n = 7 \\\\), let me check the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nBut according to the first row, \\\\( 2n + 1 = 2*7 + 1 = 15 \\\\). So, that's consistent.\\n\\nLet me check the columns as well to make sure.\\n\\nFirst column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nPerfect.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + 1 + (7 - 1) = 8 + 1 + 6 = 15 \\\\)\\n\\nAll columns add up to 15.\\n\\nNow, let me check the diagonals.\\n\\nMain diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (14 - 9) + (7 - 1) = 4 + 5 + 6 = 15 \\\\)\\n\\nGood.\\n\\nOther diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals add up to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\). Therefore, \\\\( n = 7 \\\\) is the solution.\\n\\nBut wait, just to be thorough, let me check if all the individual cells are integers and if there are any constraints on \\\\( n \\\\). The problem doesn't specify that \\\\( n \\\\) has to be an integer, but in magic squares, often the numbers are integers. Let me see if \\\\( n = 7 \\\\) makes all the cells integers.\\n\\nLooking at the cells:\\n\\n- \\\\( n - 3 = 7 - 3 = 4 \\\\)\\n- \\\\( 3 \\\\) is already an integer.\\n- \\\\( n + 1 = 7 + 1 = 8 \\\\)\\n- \\\\( n + 2 = 7 + 2 = 9 \\\\)\\n- \\\\( 2n - 9 = 14 - 9 = 5 \\\\)\\n- \\\\( 1 \\\\) is an integer.\\n- \\\\( 2 \\\\) is an integer.\\n- \\\\( n = 7 \\\\)\\n- \\\\( n - 1 = 6 \\\\)\\n\\nAll of these are integers, so that's good.\\n\\nIs there any other constraint? The problem doesn't specify, so I think \\\\( n = 7 \\\\) is the correct answer.\\n\\nBut just to make sure, let me go back to the second row sum. I had:\\n\\nSecond row sum: \\\\( 3n - 6 \\\\)\\n\\nSet equal to \\\\( S = 2n + 1 \\\\):\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nSubtract \\\\( 2n \\\\):\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6:\\n\\n\\\\( n = 7 \\\\)\\n\\nYes, that's consistent.\\n\\nAlternatively, I could have used another row or column to solve for \\\\( n \\\\), but since all rows, columns, and diagonals give the same equation, it's redundant, but it's a good check.\\n\\nSo, I think I'm confident that \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we need to ensure that the sums of all rows, columns, and diagonals are equal. The magic square is as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nFirst, we calculate the sum of the first row:\\n\\\\[\\n(n - 3) + 3 + (n + 1) = 2n + 1\\n\\\\]\\nThis sum is the magic constant \\\\( S \\\\).\\n\\nNext, we calculate the sum of the second row:\\n\\\\[\\n(n + 2) + (2n - 9) + 1 = 3n - 6\\n\\\\]\\nSince this must equal \\\\( S \\\\), we set up the equation:\\n\\\\[\\n3n - 6 = 2n + 1\\n\\\\]\\nSolving for \\\\( n \\\\):\\n\\\\[\\n3n - 6 = 2n + 1 \\\\\\\\\\nn - 6 = 1 \\\\\\\\\\nn = 7\\n\\\\]\\n\\nWe verify this value by checking the sums of the columns and diagonals with \\\\( n = 7 \\\\):\\n- First column: \\\\( (7 - 3) + (7 + 2) + 2 = 15 \\\\)\\n- Second column: \\\\( 3 + (14 - 9) + 7 = 15 \\\\)\\n- Third column: \\\\( (7 + 1) + 1 + (7 - 1) = 15 \\\\)\\n- Main diagonal: \\\\( (7 - 3) + (14 - 9) + (7 - 1) = 15 \\\\)\\n- Other diagonal: \\\\( (7 + 1) + (14 - 9) + 2 = 15 \\\\)\\n\\nAll sums are equal to 15, confirming that \\\\( n = 7 \\\\) is correct.\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2601, 400, 2801, torch.Size([1, 2356]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids_compressed.shape[1], next_true_tokens.shape[\n",
    "    1\n",
    "], generated_ids_compressed.shape[1] + compressed_part.shape[1], torch.tensor(\n",
    "    generated_ids\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "# \"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\"\n",
    "\n",
    "# compressed\n",
    "# 'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'\n",
    "\n",
    "# generated\n",
    "# \" + i, O is -4, P is -i, and S is 2 + 4i. So, the expression is A - O + P + S, which is (2 + i) - (-4) + (-i) + (2 + 4i). That seems right.\\n\\nNow, let me simplify this step by step. First, I can handle the subtraction of O, which is -(-4). Subtracting a negative is like adding a positive, so -(-4) is +4. So, that part becomes +4.\\n\\nSo, now the expression is:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNext, I can combine the real parts and the imaginary parts separately. Let me rewrite the expression grouping the real numbers and the imaginary numbers together:\\n\\nReal parts: 2 + 4 + 2\\n\\nImaginary parts: i - i + 4i\\n\\nLet me compute the real parts first. 2 + 4 is 6, and then 6 + 2 is 8. So, the real part is 8.\\n\\nNow, the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, the imaginary part is 4i.\\n\\nPutting it all together, the expression simplifies to 8 + 4i.\\n\\nWait, let me double-check that. So, starting from A - O + P + S:\\n\\nA is 2 + i, subtract O which is -4, so that becomes +4. Then add P which is -i, and add S which is 2 + 4i.\\n\\nSo, writing it out:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNow, let's combine the constants first. 2 + 4 is 6, and then 6 + 2 is 8. So, that's the real part.\\n\\nFor the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, that's correct.\\n\\nTherefore, the result is 8 + 4i.\\n\\nWait, but let me think again. Is there another way to approach this? Maybe by distributing the negative sign first.\\n\\nSo, A - O + P + S can be rewritten as A + (-O) + P + S. Since O is -4, -O is +4. So, that's the same as before.\\n\\nAlternatively, maybe I can think of it as A + (-O + P + S). Let me compute -O + P + S first.\\n\\nO is -4, so -O is +4. P is -i, and S is 2 + 4i. So, -O + P + S is 4 + (-i) + (2 + 4i).\\n\\nAgain, combining constants: 4 + 2 is 6, and then 6 + 0 is 6. For the imaginary parts: -i + 4i is 3i. So, that's 6 + 3i.\\n\\nThen, adding A, which is 2 + i, to that: (2 + i) + (6 + 3i) = 8 + 4i. So, same result.\\n\\nAlternatively, maybe I can add A and S first, then subtract O and add P.\\n\\nLet me try that approach.\\n\\nA is 2 + i, S is 2 + 4i. So, A + S is (2 + 2) + (i + 4i) = 4 + 5i.\\n\\nThen, subtract O, which is -4. So, A + S - O is 4 + 5i - (-4) = 4 + 5i + 4 = 8 + 5i.\\n\\nThen, add P, which is -i. So, 8 + 5i + (-i) = 8 + 4i. Again, same result.\\n\\nSo, regardless of the order in which I perform the operations, I end up with 8 + 4i.\\n\\nWait, let me make sure I didn't make any mistakes in my calculations. Sometimes, when dealing with complex numbers, it's easy to mix up the real and imaginary parts.\\n\\nLet me write down each step again:\\n\\n1. Start with A - O + P + S.\\n\\n2. Substitute the values:\\n\\n   (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\n3. Simplify the subtraction of O:\\n\\n   (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n4. Combine constants and imaginary parts:\\n\\n   Real parts: 2 + 4 + 2 = 8\\n\\n   Imaginary parts: i - i + 4i = 4i\\n\\n5. Combine them: 8 + 4i\\n\\nAlternatively, if I group the constants first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine constants: 2 + 4 + 2 = 8\\n\\n4. Combine imaginary parts: i - i + 4i = 4i\\n\\n5. Result: 8 + 4i\\n\\nAlternatively, if I group the imaginary parts first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine imaginary parts: i - i + 4i = 4i\\n\\n4. Combine real parts: 2 + 4 + 2 = 8\\n\\n5. Result: 8 + 4i\\n\\nSo, regardless of the order, I get the same result. Therefore, I think 8 + 4i is the correct answer.\\n\\nWait, just to be absolutely sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA is 2 + i, O is -4. So, A - O is (2 + i) - (-4) = 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i: 6 + i + (-i) = 6 + 0i = 6.\\n\\nThen, add S, which is 2 + 4i: 6 + (2 + 4i) = 8 + 4i.\\n\\nSo, that's another way to compute it step by step:\\n\\nA - O = 6 + i\\n\\nThen, A - O + P = 6 + i - i = 6\\n\\nThen, A - O + P + S = 6 + 2 + 4i = 8 + 4i.\\n\\nSame result.\\n\\nAlternatively, if I compute A - O + P + S step by step without grouping:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation one by one:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the approach, I end up with 8 + 4i.\\n\\nTherefore, I think I can confidently say that the value of A - O + P + S is 8 + 4i.\\n\\nJust to recap, the steps I took were:\\n\\n1. Substitute the given values into the expression.\\n\\n2. Simplify the expression by handling the subtraction of O, which turned into addition of 4.\\n\\n3. Combine the real parts and the imaginary parts separately.\\n\\n4. Verify the result by computing in different orders or by breaking it down into smaller steps.\\n\\n5. Ensure that each step is correct and that I didn't make any arithmetic errors.\\n\\nSo, I think I'm good. The answer is 8 + 4i.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Subtract \\\\( O \\\\) which is \\\\(-4\\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) which is \\\\(-i\\\\):\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) which is \\\\( 2 + 4i \\\\):\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). Let me try to figure this out step by step. \\n\\nFirst, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\\\( n \\\\) such that all these sums are equal.\\n\\nLooking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\\n\\n- The top row has three cells: \\\\( n-3 \\\\), \\\\( 3 \\\\), and \\\\( n+1 \\\\).\\n- The middle row has \\\\( n+2 \\\\), \\\\( 2n-9 \\\\), and \\\\( 1 \\\\).\\n- The bottom row has \\\\( 2 \\\\), \\\\( n \\\\), and \\\\( n-1 \\\\).\\n\\nSo, writing this out, the magic square looks like this:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, now I need to find \\\\( n \\\\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\\\( S \\\\).\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That means the magic constant \\\\( S = 2n + 1 \\\\).\\n\\nLet me check the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since this must equal \\\\( S \\\\), we have:\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nLet me solve for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( n = 7 \\\\)\\n\\nWait, hold on. Let me verify this because I might have made a mistake. If \\\\( n = 7 \\\\), let me check the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nBut according to the first row, \\\\( 2n + 1 = 2*7 + 1 = 15 \\\\). So, that's consistent.\\n\\nLet me check the columns as well to make sure.\\n\\nFirst column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nPerfect.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + 1 + (7 - 1) = 8 + 1 + 6 = 15 \\\\)\\n\\nAll columns add up to 15.\\n\\nNow, let me check the diagonals.\\n\\nMain diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (14 - 9) + (7 - 1) = 4 + 5 + 6 = 15 \\\\)\\n\\nGood.\\n\\nOther diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals add up to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\). Therefore, \\\\( n = 7 \\\\) is the solution.\\n\\nBut wait, just to be thorough, let me check if all the individual cells are integers and if there are any constraints on \\\\( n \\\\). The problem doesn't specify that \\\\( n \\\\) has to be an integer, but in magic squares, often the numbers are integers. Let me see if \\\\( n = 7 \\\\) makes all the cells integers.\\n\\nLooking at the cells:\\n\\n- \\\\( n - 3 = 7 - 3 = 4 \\\\)\\n- \\\\( 3 \\\\) is already an integer.\\n- \\\\( n + 1 = 7 + 1 = 8 \\\\)\\n- \\\\( n + 2 = 7 + 2 = 9 \\\\)\\n- \\\\( 2n - 9 = 14 - 9 = 5 \\\\)\\n- \\\\( 1 \\\\) is an integer.\\n- \\\\( 2 \\\\) is an integer.\\n- \\\\( n = 7 \\\\)\\n- \\\\( n - 1 = 6 \\\\)\\n\\nAll of these are integers, so that's good.\\n\\nIs there any other constraint? The problem doesn't specify, so I think \\\\( n = 7 \\\\) is the correct answer.\\n\\nBut just to make sure, let me go back to the second row sum. I had:\\n\\nSecond row sum: \\\\( 3n - 6 \\\\)\\n\\nSet equal to \\\\( S = 2n + 1 \\\\):\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nSubtract \\\\( 2n \\\\):\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6:\\n\\n\\\\( n = 7 \\\\)\\n\\nYes, that's consistent.\\n\\nAlternatively, I could have used another row or column to solve for \\\\( n \\\\), but since all rows, columns, and diagonals give the same equation, it's redundant, but it's a good check.\\n\\nSo, I think I'm confident that \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we need to ensure that the sums of all rows, columns, and diagonals are equal. The magic square is as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nFirst, we calculate the sum of the first row:\\n\\\\[\\n(n - 3) + 3 + (n + 1) = 2n + 1\\n\\\\]\\nThis sum is the magic constant \\\\( S \\\\).\\n\\nNext, we calculate the sum of the second row:\\n\\\\[\\n(n + 2) + (2n - 9) + 1 = 3n - 6\\n\\\\]\\nSince this must equal \\\\( S \\\\), we set up the equation:\\n\\\\[\\n3n - 6 = 2n + 1\\n\\\\]\\nSolving for \\\\( n \\\\):\\n\\\\[\\n3n - 6 = 2n + 1 \\\\\\\\\\nn - 6 = 1 \\\\\\\\\\nn = 7\\n\\\\]\\n\\nWe verify this value by checking the sums of the columns and diagonals with \\\\( n = 7 \\\\):\\n- First column: \\\\( (7 - 3) + (7 + 2) + 2 = 15 \\\\)\\n- Second column: \\\\( 3 + (14 - 9) + 7 = 15 \\\\)\\n- Third column: \\\\( (7 + 1) + 1 + (7 - 1) = 15 \\\\)\\n- Main diagonal: \\\\( (7 - 3) + (14 - 9) + (7 - 1) = 15 \\\\)\\n- Other diagonal: \\\\( (7 + 1) + (14 - 9) + 2 = 15 \\\\)\\n\\nAll sums are equal to 15, confirming that \\\\( n = 7 \\\\) is correct.\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" + i, O is -4, P is -i, and S is 2 + 4i. So, the expression is A - O + P + S, which is (2 + i) - (-4) + (-i) + (2 + 4i). That seems right.\\n\\nNow, let me simplify this step by step. First, I can handle the subtraction of O, which is -(-4). Subtracting a negative is like adding a positive, so -(-4) is +4. So, that part becomes +4.\\n\\nSo, now the expression is:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNext, I can combine the real parts and the imaginary parts separately. Let me rewrite the expression grouping the real numbers and the imaginary numbers together:\\n\\nReal parts: 2 + 4 + 2\\n\\nImaginary parts: i - i + 4i\\n\\nLet me compute the real parts first. 2 + 4 is 6, and then 6 + 2 is 8. So, the real part is 8.\\n\\nNow, the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, the imaginary part is 4i.\\n\\nPutting it all together, the expression simplifies to 8 + 4i.\\n\\nWait, let me double-check that. So, starting from A - O + P + S:\\n\\nA is 2 + i, subtract O which is -4, so that becomes +4. Then add P which is -i, and add S which is 2 + 4i.\\n\\nSo, writing it out:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNow, let's combine the constants first. 2 + 4 is 6, and then 6 + 2 is 8. So, that's the real part.\\n\\nFor the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, that's correct.\\n\\nTherefore, the result is 8 + 4i.\\n\\nWait, but let me think again. Is there another way to approach this? Maybe by distributing the negative sign first.\\n\\nSo, A - O + P + S can be rewritten as A + (-O) + P + S. Since O is -4, -O is +4. So, that's the same as before.\\n\\nAlternatively, maybe I can think of it as A + (-O + P + S). Let me compute -O + P + S first.\\n\\nO is -4, so -O is +4. P is -i, and S is 2 + 4i. So, -O + P + S is 4 + (-i) + (2 + 4i).\\n\\nAgain, combining constants: 4 + 2 is 6, and then 6 + 0 is 6. For the imaginary parts: -i + 4i is 3i. So, that's 6 + 3i.\\n\\nThen, adding A, which is 2 + i, to that: (2 + i) + (6 + 3i) = 8 + 4i. So, same result.\\n\\nAlternatively, maybe I can add A and S first, then subtract O and add P.\\n\\nLet me try that approach.\\n\\nA is 2 + i, S is 2 + 4i. So, A + S is (2 + 2) + (i + 4i) = 4 + 5i.\\n\\nThen, subtract O, which is -4. So, A + S - O is 4 + 5i - (-4) = 4 + 5i + 4 = 8 + 5i.\\n\\nThen, add P, which is -i. So, 8 + 5i + (-i) = 8 + 4i. Again, same result.\\n\\nSo, regardless of the order in which I perform the operations, I end up with 8 + 4i.\\n\\nWait, let me make sure I didn't make any mistakes in my calculations. Sometimes, when dealing with complex numbers, it's easy to mix up the real and imaginary parts.\\n\\nLet me write down each step again:\\n\\n1. Start with A - O + P + S.\\n\\n2. Substitute the values:\\n\\n   (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\n3. Simplify the subtraction of O:\\n\\n   (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n4. Combine constants and imaginary parts:\\n\\n   Real parts: 2 + 4 + 2 = 8\\n\\n   Imaginary parts: i - i + 4i = 4i\\n\\n5. Combine them: 8 + 4i\\n\\nAlternatively, if I group the constants first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine constants: 2 + 4 + 2 = 8\\n\\n4. Combine imaginary parts: i - i + 4i = 4i\\n\\n5. Result: 8 + 4i\\n\\nAlternatively, if I group the imaginary parts first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine imaginary parts: i - i + 4i = 4i\\n\\n4. Combine real parts: 2 + 4 + 2 = 8\\n\\n5. Result: 8 + 4i\\n\\nSo, regardless of the order, I get the same result. Therefore, I think 8 + 4i is the correct answer.\\n\\nWait, just to be absolutely sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA is 2 + i, O is -4. So, A - O is (2 + i) - (-4) = 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i: 6 + i + (-i) = 6 + 0i = 6.\\n\\nThen, add S, which is 2 + 4i: 6 + (2 + 4i) = 8 + 4i.\\n\\nSo, that's another way to compute it step by step:\\n\\nA - O = 6 + i\\n\\nThen, A - O + P = 6 + i - i = 6\\n\\nThen, A - O + P + S = 6 + 2 + 4i = 8 + 4i.\\n\\nSame result.\\n\\nAlternatively, if I compute A - O + P + S step by step without grouping:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation one by one:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the approach, I end up with 8 + 4i.\\n\\nTherefore, I think I can confidently say that the value of A - O + P + S is 8 + 4i.\\n\\nJust to recap, the steps I took were:\\n\\n1. Substitute the given values into the expression.\\n\\n2. Simplify the expression by handling the subtraction of O, which turned into addition of 4.\\n\\n3. Combine the real parts and the imaginary parts separately.\\n\\n4. Verify the result by computing in different orders or by breaking it down into smaller steps.\\n\\n5. Ensure that each step is correct and that I didn't make any arithmetic errors.\\n\\nSo, I think I'm good. The answer is 8 + 4i.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Subtract \\\\( O \\\\) which is \\\\(-4\\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) which is \\\\(-i\\\\):\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) which is \\\\( 2 + 4i \\\\):\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_think = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "generated_ids[-1].index(end_think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids_compressed[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nNow, let's add the real parts and the imaginary parts separately.\\n\\nReal parts: 2 (from A) + (-4) (from O) + 0 (from P) + 2 (from S) = 0\\n\\nImaginary parts: 1 (from A) + 0 (from O) + (-1) (from P) + 4 (from S) = 4\\n\\nSo, putting it all together, the expression simplifies to 0 + 4i, which is just 4i.\\n\\nWait, hold on, that doesn't seem right. Let me check my steps again.\\n\\nWait, when I separated the real and imaginary parts, I think I might have made a mistake in the signs.\\n\\nLet me try that again.\\n\\nStarting over:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nExpression: A - O + P + S\\n\\nSubstitute the values:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nNow, distribute the negative sign to O:\\n\\n2 + i + 4 - i + (-i) + 2 + 4i\\n\\nWait, hold on, that doesn't seem right. Let me do it step by step.\\n\\nFirst, A - O: (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nWait, that makes more sense. So, the expression simplifies to 8 + 4i.\\n\\nWait, so earlier I messed up the distribution. Let me correct that.\\n\\nSo, starting over:\\n\\nExpression: A - O + P + S\\n\\nSubstitute:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle A - O:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nSo, the final result is 8 + 4i.\\n\\nWait, so earlier I thought it was 4i, but that was incorrect. I must have made a mistake in distributing the negative sign or something.\\n\\nSo, the correct answer is 8 + 4i.\\n\\nBut let me verify once more.\\n\\nCompute A - O + P + S:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation step by step:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems correct. So, the final result is 8 + 4i.\\n\\nI think I initially made a mistake in the distribution step, but upon redoing it, I arrived at the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nStarting with the expression:\\n\\\\[ A - O + P + S \\\\]\\n\\nSubstitute the given values:\\n\\\\[ (2 + i) - (-4) + (-i) + (2 + 4i) \\\\]\\n\\nSimplify each operation step by step:\\n1. Compute \\\\( (2 + i) - (-4) \\\\):\\n   \\\\[ 2 + i + 4 = 6 + i \\\\]\\n2. Add \\\\( P \\\\):\\n   \\\\[ 6 + i + (-i) = 6 + 0i = 6 \\\\]\\n3. Add \\\\( S \\\\):\\n   \\\\[ 6 + (2 + 4i) = 8 + 4i \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 1536])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(torch.tensor(generated_ids[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLet’s denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLet’s assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLet’s let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLet’s denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1536])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 224256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_embeds torch.Size([1, 62, 1536])\n",
      "<｜begin▁of▁sentence｜><｜User｜>Here's a question: What do many people believe happens after you die?  Here are possible answers to this question: - stop moving - nothing - go to heaven - stop living - stop breathing  I believe the correct choice is \"go to heaven\", here's why:\n",
      "Answer:<｜Assistant｜><think>\n",
      "Okay, so I'm trying to figure out the answer is correct. Let me think about it again. I think the user is trying to figure out the correct answer to the question they're asking. They provided a list of answers, and I need to heaven, but I'm not sure if I'm sure if I'm on the right track. Let me break it down step by step. The question is about what people believe happens after you die. I know that when someone dies, they believe that people often believe in something called the afterlife, which is the belief that after you die, you don't need to move or anything else. So, the correct answer is \"go to heaven\", which is the correct answer. The other options, like stopping moving, nothing, stop breathing, etc., aren't correct\n"
     ]
    }
   ],
   "source": [
    "from hidden_capacity_reasoning.utils import WINDOW_SIZE, VISION_START, VISION_END\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "\n",
    "def _crop_past_key_values(model, past_key_values, max_length):\n",
    "    \"\"\"Crops the past key values up to a certain maximum length.\"\"\"\n",
    "    new_past = []\n",
    "    if model.config.is_encoder_decoder:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            new_past.append(\n",
    "                (\n",
    "                    past_key_values[idx][0][:, :, :max_length, :],\n",
    "                    past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    past_key_values[idx][2],\n",
    "                    past_key_values[idx][3],\n",
    "                )\n",
    "            )\n",
    "        past_key_values = tuple(new_past)\n",
    "    # gptbigcode is special and stores kv in shape (batch_size, seq_len, dim), if it's a multi_query model\n",
    "    elif \"gptbigcode\" in model.__class__.__name__.lower() or (\n",
    "        model.config.architectures is not None\n",
    "        and \"gptbigcode\" in model.config.architectures[0].lower()\n",
    "    ):\n",
    "        if model.config.multi_query:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :max_length, :]\n",
    "        else:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :, :max_length, :]\n",
    "    elif isinstance(past_key_values, DynamicCache):\n",
    "        past_key_values.crop(max_length)\n",
    "    elif past_key_values is not None:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            if past_key_values[idx] != ([], []):\n",
    "                new_past.append(\n",
    "                    (\n",
    "                        past_key_values[idx][0][:, :, :max_length, :],\n",
    "                        past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                new_past.append((past_key_values[idx][0], past_key_values[idx][1]))\n",
    "        past_key_values = tuple(new_past)\n",
    "    return past_key_values\n",
    "\n",
    "\n",
    "# model = trainer.model\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "        {\"role\": \"user\", \"content\": dataset[\"test\"].to_list()[:5][0][\"question\"]},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "with torch.no_grad(), torch.autocast(device_type=\"cuda\"):\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    temp_gen_size = 0\n",
    "    window_size = WINDOW_SIZE  # + 1\n",
    "    # new_tokens = 4\n",
    "    new_tokens = 1\n",
    "    generation_started = False\n",
    "    max_steps = (new_tokens + window_size) * 15\n",
    "    past_key_values_big = None\n",
    "    print(\"generated_embeds\", generated_embeds.shape)\n",
    "    for step in range(max_steps):\n",
    "        if temp_gen_size == window_size + new_tokens:\n",
    "            # print(\n",
    "            #     \"TOKENS FOR EMDED\",\n",
    "            #     tokenizer.decode(\n",
    "            #         generated_tokens[:, -(window_size + new_tokens) :][:, :WINDOW_SIZE]\n",
    "            #         .cpu()\n",
    "            #         .tolist()[0]\n",
    "            #     ),\n",
    "            # )\n",
    "            # tokenizer.decode(generated_tokens[:, : -window_size ].cpu().tolist()[0])\n",
    "            if hasattr(model.base_model, \"embed_pooler\"):\n",
    "                new_embeds_for_compression = (\n",
    "                    model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "                        generated_tokens[:, -(window_size + new_tokens) :][\n",
    "                            :, :WINDOW_SIZE\n",
    "                        ]\n",
    "                    )\n",
    "                ).to(torch.bfloat16)\n",
    "                compressed_part = model.base_model.embed_pooler(\n",
    "                    new_embeds_for_compression\n",
    "                )\n",
    "            else:\n",
    "                compressed_part = model.embed_pooler(new_embeds_for_compression)\n",
    "            # gen_embeds_prev = generated_tokens.shape[1]\n",
    "            if generation_started:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens + 1)],\n",
    "                        # generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        compressed_part,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            else:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 3,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        start_embed,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        compressed_part,\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "                generation_started = True\n",
    "            past_key_values_big = _crop_past_key_values(\n",
    "                model=model,\n",
    "                past_key_values=past_key_values_big,\n",
    "                max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "            )\n",
    "            temp_gen_size = 1\n",
    "\n",
    "        outputs = model(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            past_key_values=past_key_values_big,\n",
    "            # use_cache=False,\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        past_key_values_big = outputs.past_key_values\n",
    "        top_token = logits.argmax(-1)[-1][-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)], dim=1\n",
    "        )\n",
    "        # print(temp_gen_size, tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "        temp_gen_size += 1\n",
    "\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# я не знаю, может быть я неправильно управляюсь с KV-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1536])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4, 5, 6, 7, 8][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"test\"][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1536])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем на MATH-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858387ce1a124a3cac7d2220dbfa51f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 7\n",
      "-2n - 9 \\) is in the center bottom right, and \\( n - 1 \\) is at the bottom left.\n",
      "\n",
      "Wait, maybe I should draw a table to visualize this better. Let me set up a 3x3 grid where each cell corresponds to a position in the Asymptote code.\n",
      "\n",
      "So, the grid looks like this:\n",
      "\n",
      "\\[\n",
      "\\begin{array}{|c|c|c|}\n",
      "\\hline\n",
      "n - 3 & 3 & n + 1 \\\\\n",
      "\\hline\n",
      "n + 2 & 2n - 9 & 1 \\\\\n",
      "\\hline\n",
      "2 & n & n - 1 \\\\\n",
      "\\hline\n",
      "\\end{array}\n",
      "\\]\n",
      "\n",
      "Yes, that's correct. So, now, I can label each cell with the given expressions.\n",
      "\n",
      "Now, the goal is to find the value of \\( n \\) such that the sum of each row, each column, and the two main diagonals are equal. Let's denote this common sum as \\( S \\).\n",
      "\n",
      "So, I can write equations for each row, column, and diagonal that equal \\( S \\).\n",
      "\n",
      "Let's start with the first row: \\( (n - 3) + 3 + (n + 1) = S \\). Let me compute that:\n",
      "\n",
      "\\( n - 3 + 3 + n + 1 = 2n + 0 = 2n \\). So, \\( 2n = S \\). That's equation one.\n",
      "\n",
      "Next, the second row: \\( (n + 2) + (2n - 9) + 1 = S \\). Let's compute that:\n",
      "\n",
      "\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\). So, \\( 3n - 6 = S \\). That's equation two.\n",
      "\n",
      "Now, the third row: \\( 2 + n + (n - 1) = S \\). Let's compute:\n",
      "\n",
      "\\( 2 + n + n - 1 = 2n + 1 \\). So, \\( 2n + 1 = S \\). That's equation three.\n",
      "\n",
      "So, now I have three equations:\n",
      "\n",
      "1. \\( 2n = S \\)\n",
      "2. \\( 3n - 6 = S \\)\n",
      "3. \\( 2n + 1 = S \\)\n",
      "\n",
      "Since all of these are equal to \\( S \\), I can set them equal to each other.\n",
      "\n",
      "First, set equation 1 equal to equation 2:\n",
      "\n",
      "\\( 2n = 3n - 6 \\)\n",
      "\n",
      "Let me solve for \\( n \\):\n",
      "\n",
      "Subtract \\( 2n \\) from both sides:\n",
      "\n",
      "\\( 0 = n - 6 \\)\n",
      "\n",
      "Add 6 to both sides:\n",
      "\n",
      "\\( n = 6 \\)\n",
      "\n",
      "Wait, let me check if this works with equation 3 as well.\n",
      "\n",
      "Plug \\( n = 6 \\) into equation 3:\n",
      "\n",
      "\\( 2(6) + 1 = 12 + 1 = 13 \\). So, \\( S = 13 \\).\n",
      "\n",
      "Let me verify with equation 1: \\( 2n = 2*6 = 12 \\). But wait, that's not equal to 13. Hmm, that's a problem.\n",
      "\n",
      "Wait, maybe I made a mistake in setting up the equations. Let me double-check.\n",
      "\n",
      "First, the first row: \\( (n - 3) + 3 + (n + 1) = 2n + 0 = 2n \\). That seems correct.\n",
      "\n",
      "Second row: \\( (n + 2) + (2n - 9) + 1 = n + 2 + 2n - 9 + 1 = 3n - 6 \\). That seems correct.\n",
      "\n",
      "Third row: \\( 2 + n + (n - 1) = 2 + n + n - 1 = 2n + 1 \\). That seems correct.\n",
      "\n",
      "So, equations are correct. Then, setting equation 1 equal to equation 2 gives \\( 2n = 3n - 6 \\) leading to \\( n = 6 \\). But then equation 3 gives \\( S = 13 \\), but equation 1 gives \\( S = 12 \\). That's a contradiction.\n",
      "\n",
      "Wait, that can't be. So, maybe I made a mistake in setting up the equations. Let me double-check the grid.\n",
      "\n",
      "Looking back at the grid:\n",
      "\n",
      "Top row: \\( n - 3, 3, n + 1 \\)\n",
      "\n",
      "Middle row: \\( n + 2, 2n - 9, 1 \\)\n",
      "\n",
      "Bottom row: \\( 2, n, n - 1 \\)\n",
      "\n",
      "So, maybe I misread the positions. Let me confirm.\n",
      "\n",
      "Wait, in the Asymptote code, the labels are placed at (0.5, 0.5), which is the center of the top-left cell. Similarly, (1.5, 0.5) is the center of the top-middle, etc. So, the grid is:\n",
      "\n",
      "Top row: left, center, right: \\( n - 3, 3, n + 1 \\)\n",
      "\n",
      "Middle row: left, center, right: \\( n + 2, 2n - 9, 1 \\)\n",
      "\n",
      "Bottom row: left, center, right: \\( 2, n, n - 1 \\)\n",
      "\n",
      "So, that's correct. So, the grid is:\n",
      "\n",
      "\\[\n",
      "\\begin{array}{|c|c|c|}\n",
      "\\hline\n",
      "n - 3 & 3 & n + 1 \\\\\n",
      "\\hline\n",
      "n + 2 & 2n - 9 & 1 \\\\\n",
      "\\hline\n",
      "2 & n & n - 1 \\\\\n",
      "\\hline\n",
      "\\end{array}\n",
      "\\]\n",
      "\n",
      "So, the sums are correct. So, perhaps the issue is that I set all three equations equal to each other, but actually, the common sum \\( S \\) should be the same for all rows, columns, and diagonals. So, maybe I need to set all rows, columns, and diagonals equal to each other.\n",
      "\n",
      "Wait, but I only have three equations so far. Maybe I need to set the rows equal to each other and also set the columns and diagonals equal to the rows.\n",
      "\n",
      "Let me try that.\n",
      "\n",
      "First, let's compute the sums of the rows:\n",
      "\n",
      "Row 1: \\( 2n \\)\n",
      "\n",
      "Row 2: \\( 3n - 6 \\)\n",
      "\n",
      "Row 3: \\( 2n + 1 \\)\n",
      "\n",
      "So, for all rows to be equal, we need:\n",
      "\n",
      "\\( 2n = 3n - 6 \\) (from Row1 = Row2)\n",
      "\n",
      "and\n",
      "\n",
      "\\( 2n = 2n + 1 \\) (from Row1 = Row3)\n",
      "\n",
      "Wait, the last one, \\( 2n = 2n + 1 \\), subtracting \\( 2n \\) from both sides gives \\( 0 = 1 \\), which is impossible. That can't be. So, that means my initial assumption is wrong. Maybe not all rows are equal? Wait, no, in a magic square, all rows, columns, and diagonals sum to the same value. So, if I get a contradiction here, that means something is wrong.\n",
      "\n",
      "Wait, perhaps I made a mistake in computing the sums. Let me double-check.\n",
      "\n",
      "Row 1: \\( (n - 3) + 3 + (n + 1) = n - 3 + 3 + n + 1 = 2n + 0 = 2n \\). That seems correct.\n",
      "\n",
      "Row 2: \\( (n + 2) + (2n - 9) + 1 = n + 2 + 2n - 9 + 1 = 3n - 6 \\). That seems correct.\n",
      "\n",
      "Row 3: \\( 2 + n + (n - 1) = 2 + n + n - 1 = 2n + 1 \\). That seems correct.\n",
      "\n",
      "So, the sums are 2n, 3n - 6, and 2n + 1. So, for these to be equal, we need:\n",
      "\n",
      "2n = 3n - 6 and 2n = 2n + 1\n",
      "\n",
      "But the second equation, 2n = 2n + 1, is impossible. So, that suggests that either the grid is not a magic square, or I made a mistake in interpreting the grid.\n",
      "\n",
      "Wait, maybe I misread the grid. Let me double-check the Asymptote code.\n",
      "\n",
      "The Asymptote code labels:\n",
      "\n",
      "- \\( n - 3 \\) at (0.5, 0.5)\n",
      "- \\( 3 \\) at (1.5, 0.5)\n",
      "- \\( n + 1 \\) at (2.5, 0.5)\n",
      "\n",
      "So, that's the top row.\n",
      "\n",
      "Then, middle row:\n",
      "\n",
      "- \\( n + 2 \\) at (0.5, 1.5)\n",
      "- \\( 2n - 9 \\) at (1.5, 1.5)\n",
      "- \\( 1 \\) at (2.5, 1.5)\n",
      "\n",
      "Bottom row:\n",
      "\n",
      "- \\( 2 \\) at (0.5, 2.5)\n",
      "- \\( n \\) at (1.5, 2.5)\n",
      "- \\( n - 1 \\) at (2.5, 2.5)\n",
      "\n",
      "So, the grid is:\n",
      "\n",
      "Top row: \\( n - 3, 3, n + 1 \\)\n",
      "\n",
      "Middle row: \\( n + 2, 2n - 9, 1 \\)\n",
      "\n",
      "Bottom row: \\( 2, n, n - 1 \\)\n",
      "\n",
      "So, that's correct. So, the sums are as I computed.\n",
      "\n",
      "But then, the problem is that the rows don't all equal each other. So, perhaps the grid is not a magic square? But the problem says it is a magic square. So, maybe I made a mistake in computing the sums.\n",
      "\n",
      "Wait, let's double-check the sums again.\n",
      "\n",
      "Top row: \\( (n - 3) + 3 + (n + 1) = n - 3 + 3 + n + 1 = 2n + 0 = 2n \\). That's correct.\n",
      "\n",
      "Middle row: \\( (n + 2) + (2n - 9) + 1 = n + 2 + 2n - 9 + 1 = 3n - 6 \\). That's correct.\n",
      "\n",
      "Bottom row: \\( 2 + n + (n - 1) = 2 + n + n - 1 = 2n + 1 \\). That's correct.\n",
      "\n",
      "So, the sums are 2n, 3n - 6, and 2n + 1. So, for the grid to be a magic square, all these sums must be equal. But as I saw, 2n = 3n - 6 leads to n = 6, but then 2n = 12, which is not equal to 3n - 6 = 12 - 6 = 6. Wait, no, 3n - 6 with n=6 is 18 - 6 = 12. So, 2n = 12, 3n - 6 = 12, and 2n + 1 = 13. So, 12, 12, 13. That's not equal. So, that's a problem.\n",
      "\n",
      "Wait, maybe I need to consider the columns as well. Let's compute the sums of the columns.\n",
      "\n",
      "First column: \\( n - 3 + n + 2 + 2 \\)\n",
      "\n",
      "Compute that: \\( n - 3 + n + 2 + 2 = 2n + 1 \\)\n",
      "\n",
      "Second column: \\( 3 + 2n - 9 + n \\)\n",
      "\n",
      "Compute that: \\( 3 + 2n - 9 + n = 3n - 6 \\)\n",
      "\n",
      "Third column: \\( n + 1 + 1 + n - 1 \\)\n",
      "\n",
      "Compute that: \\( n + 1 + 1 + n - 1 = 2n + 1 \\)\n",
      "\n",
      "So, the column sums are 2n + 1, 3n - 6, and 2n + 1. So, similar to the rows, the columns are 2n + 1, 3n - 6, 2n + 1. So, for the columns to be equal, we need 2n + 1 = 3n - 6.\n",
      "\n",
      "Setting them equal: 2n + 1 = 3n - 6\n",
      "\n",
      "Subtract 2n: 1 = n - 6\n",
      "\n",
      "Add 6: n = 7\n",
      "\n",
      "Wait, so n = 7. Let's check if this works.\n",
      "\n",
      "If n = 7, then let's compute all the cells:\n",
      "\n",
      "Top row: \\( 7 - 3 = 4, 3, 7 + 1 = 8 \\). So, 4, 3, 8. Sum: 4 + 3 + 8 = 15.\n",
      "\n",
      "Middle row: \\( 7 + 2 = 9, 2*7 - 9 = 14 - 9 = 5, 1 \\). So, 9, 5, 1. Sum: 9 + 5 + 1 = 15.\n",
      "\n",
      "Bottom row: \\( 2, 7, 7 - 1 = 6 \\). So, 2, 7, 6. Sum: 2 + 7 + 6 = 15.\n",
      "\n",
      "So, all rows sum to 15.\n",
      "\n",
      "Now, let's check the columns:\n",
      "\n",
      "First column: \\( 4 + 9 + 2 = 15 \\)\n",
      "\n",
      "Second column: \\( 3 + 5 + 7 = 15 \\)\n",
      "\n",
      "Third column: \\( 8 + 1 + 6 = 15 \\)\n",
      "\n",
      "Diagonals:\n",
      "\n",
      "Main diagonal: \\( 4 + 5 + 6 = 15 \\)\n",
      "\n",
      "Other diagonal: \\( 8 + 5 + 2 = 15 \\)\n",
      "\n",
      "So, all rows, columns, and diagonals sum to 15. That works!\n",
      "\n",
      "Wait, but earlier, when I set the rows equal to each other, I got n = 6, but that didn't work because the columns didn't match. So, perhaps I need to set both the rows and columns equal to each other.\n",
      "\n",
      "So, let's try that.\n",
      "\n",
      "From the rows, we have:\n",
      "\n",
      "Row1: 2n\n",
      "\n",
      "Row2: 3n - 6\n",
      "\n",
      "Row3: 2n + 1\n",
      "\n",
      "So, for all rows to be equal, we need:\n",
      "\n",
      "2n = 3n - 6 and 2n = 2n + 1\n",
      "\n",
      "But the second equation, 2n = 2n + 1, is impossible. So, that suggests that the grid cannot be a magic square with the given labels unless we allow for some inconsistency.\n",
      "\n",
      "But the problem states that it is a magic square, so perhaps I made a mistake in computing the sums.\n",
      "\n",
      "Wait, let me double-check the sums again.\n",
      "\n",
      "Top row: \\( (n - 3) + 3 + (n + 1) = 2n \\). Correct.\n",
      "\n",
      "Middle row: \\( (n + 2) + (2n - 9) + 1 = 3n - 6 \\). Correct.\n",
      "\n",
      "Bottom row: \\( 2 + n + (n - 1) = 2n + 1 \\). Correct.\n",
      "\n",
      "Columns:\n",
      "\n",
      "First column: \\( (n - 3) + (n + 2) + 2 = 2n + 1 \\). Correct.\n",
      "\n",
      "Second column: \\( 3 + (2n - 9) + n = 3n - 6 \\). Correct.\n",
      "\n",
      "Third column: \\( (n + 1) + 1 + (n - 1) = 2n + 1 \\). Correct.\n",
      "\n",
      "Diagonals:\n",
      "\n",
      "Main diagonal: \\( (n - 3) + (2n - 9) + (n - 1) = 4n - 13 \\). Wait, is that correct?\n",
      "\n",
      "Wait, no, the main diagonal is top-left to bottom-right: \\( (n - 3) \\), \\( (2n - 9) \\), \\( (n - 1) \\). So, sum is \\( (n - 3) + (2n - 9) + (n - 1) = 4n - 13 \\).\n",
      "\n",
      "Other diagonal: \\( (n + 1) \\), \\( (2n - 9) \\), \\( (2) \\). Sum is \\( (n + 1) + (2n - 9) + 2 = 3n - 6 \\).\n",
      "\n",
      "So, the diagonals are \\( 4n - 13 \\) and \\( 3n - 6 \\). For it to be a magic square, these must also equal the row sums.\n",
      "\n",
      "So, we have:\n",
      "\n",
      "From rows: 2n, 3n - 6, 2n + 1\n",
      "\n",
      "From columns: 2n + 1, 3n - 6, 2n + 1\n",
      "\n",
      "From diagonals: 4n - 13, 3n - 6, 3n - 6\n",
      "\n",
      "So, for all these to be equal, we need:\n",
      "\n",
      "2n = 3n - 6 = 4n - 13 = 3n - 6\n",
      "\n",
      "Wait, that's a lot of equations. Let's see.\n",
      "\n",
      "First, set 2n = 3n - 6:\n",
      "\n",
      "2n = 3n - 6 => -n = -6 => n = 6\n",
      "\n",
      "Then, set 2n = 4n - 13:\n",
      "\n",
      "2n = 4n - 13 => -2n = -13 => n = 6.5\n",
      "\n",
      "Wait, that's inconsistent. So, n can't be both 6 and 6.5.\n",
      "\n",
      "Similarly, set 3n - 6 = 4n - 13:\n",
      "\n",
      "3n - 6 = 4n - 13 => -n = -7 => n = 7\n",
      "\n",
      "But n can't be both 6 and 7.\n",
      "\n",
      "This is confusing. Maybe I need to find n such that all the sums are equal.\n",
      "\n",
      "Let me denote the common sum as S.\n",
      "\n",
      "From the rows:\n",
      "\n",
      "Row1: 2n = S\n",
      "\n",
      "Row2: 3n - 6 = S\n",
      "\n",
      "Row3: 2n + 1 = S\n",
      "\n",
      "From columns:\n",
      "\n",
      "Column1: 2n + 1 = S\n",
      "\n",
      "Column2: 3n - 6 = S\n",
      "\n",
      "Column3: 2n + 1 = S\n",
      "\n",
      "From diagonals:\n",
      "\n",
      "Diagonal1: 4n - 13 = S\n",
      "\n",
      "Diagonal2: 3n - 6 = S\n",
      "\n",
      "So, now, we have multiple equations:\n",
      "\n",
      "1. 2n = S\n",
      "\n",
      "2. 3n - 6 = S\n",
      "\n",
      "3. 2n + 1 = S\n",
      "\n",
      "4. 4n - 1\n",
      "4096 200 4196 1959\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1326 200 1426 1125\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2007 200 2107 1548\n",
      "===\n",
      "===\n",
      "===\n",
      "'NoneType' object has no attribute 'group'\n",
      "WRONG 6\n",
      " = 0 \\). Let me see... Maybe I can factor this polynomial or relate it to some known roots of unity.\n",
      "\n",
      "I recall that \\( z^4 + z^2 + 1 \\) can be factored. Let me try factoring it. Hmm, maybe I can factor it as a quadratic in terms of \\( z^2 \\). Let me set \\( w = z^2 \\), then the equation becomes \\( w^2 + w + 1 = 0 \\). That's a quadratic equation, so I can solve for \\( w \\) using the quadratic formula.\n",
      "\n",
      "So, \\( w = \\frac{-1 \\pm \\sqrt{1 - 4}}{2} = \\frac{-1 \\pm \\sqrt{-3}}{2} = \\frac{-1 \\pm i\\sqrt{3}}{2} \\). Therefore, \\( z^2 = \\frac{-1 \\pm i\\sqrt{3}}{2} \\). Now, I need to find the square roots of these complex numbers to get back to \\( z \\).\n",
      "\n",
      "Let me denote \\( \\omega = \\frac{-1 + i\\sqrt{3}}{2} \\) and \\( \\omega' = \\frac{-1 - i\\sqrt{3}}{2} \\). These are complex numbers with magnitude 1, since \\( |\\omega| = \\sqrt{ \\left( \\frac{-1}{2} \\right)^2 + \\left( \\frac{\\sqrt{3}}{2} \\right)^2 } = \\sqrt{ \\frac{1}{4} + \\frac{3}{4} } = \\sqrt{1} = 1 \\). So, both \\( \\omega \\) and \\( \\omega' \\) are on the unit circle.\n",
      "\n",
      "Moreover, \\( \\omega \\) and \\( \\omega' \\) are the primitive 3rd roots of unity because \\( \\omega^3 = 1 \\) and similarly for \\( \\omega' \\). Let me verify that:\n",
      "\n",
      "Compute \\( \\omega^3 \\): Since \\( \\omega = e^{2\\pi i / 3} \\), then \\( \\omega^3 = e^{2\\pi i} = 1 \\). Similarly, \\( \\omega'^3 = 1 \\). So, yes, they are 3rd roots of unity.\n",
      "\n",
      "Therefore, \\( z^2 = \\omega \\) or \\( z^2 = \\omega' \\). So, to find \\( z \\), I need to take the square roots of \\( \\omega \\) and \\( \\omega' \\).\n",
      "\n",
      "Since \\( \\omega \\) is a 3rd root of unity, its square roots will be 6th roots of unity. Similarly, \\( \\omega' \\) is also a 3rd root of unity, so its square roots will also be 6th roots of unity. Therefore, all the roots of \\( z^4 + z^2 + 1 = 0 \\) are 6th roots of unity.\n",
      "\n",
      "Wait, let me make sure. Let me compute the roots explicitly.\n",
      "\n",
      "Given \\( z^2 = \\omega \\) and \\( z^2 = \\omega' \\), where \\( \\omega = e^{2\\pi i / 3} \\) and \\( \\omega' = e^{-2\\pi i / 3} \\).\n",
      "\n",
      "So, to find \\( z \\), we take the square roots of \\( \\omega \\) and \\( \\omega' \\). The square roots of \\( \\omega \\) are \\( e^{\\pi i / 3} \\) and \\( e^{5\\pi i / 3} \\), which are \\( e^{2\\pi i / 6} \\) and \\( e^{10\\pi i / 6} \\). Similarly, the square roots of \\( \\omega' \\) are \\( e^{-\\pi i / 3} \\) and \\( e^{-5\\pi i / 3} \\), which are \\( e^{4\\pi i / 6} \\) and \\( e^{8\\pi i / 6} \\).\n",
      "\n",
      "So, all the roots are \\( e^{2\\pi i / 6} \\), \\( e^{4\\pi i / 6} \\), \\( e^{8\\pi i / 6} \\), and \\( e^{10\\pi i / 6} \\). Simplifying these exponents:\n",
      "\n",
      "- \\( 2\\pi / 6 = \\pi / 3 \\)\n",
      "- \\( 4\\pi / 6 = 2\\pi / 3 \\)\n",
      "- \\( 8\\pi / 6 = 4\\pi / 3 \\)\n",
      "- \\( 10\\pi / 6 = 5\\pi / 3 \\)\n",
      "\n",
      "So, the roots are \\( e^{\\pi i / 3} \\), \\( e^{2\\pi i / 3} \\), \\( e^{4\\pi i / 3} \\), and \\( e^{5\\pi i / 3} \\). These are the 6th roots of unity, specifically the primitive 6th roots of unity. Because the 6th roots of unity are \\( e^{2\\pi i k / 6} \\) for \\( k = 0, 1, 2, 3, 4, 5 \\). The primitive ones are those where \\( k \\) and 6 are coprime, which are \\( k = 1, 5 \\). Wait, but in this case, the roots are \\( e^{\\pi i / 3} = e^{2\\pi i / 6} \\), \\( e^{2\\pi i / 3} = e^{4\\pi i / 6} \\), \\( e^{4\\pi i / 3} = e^{8\\pi i / 6} \\), and \\( e^{5\\pi i / 3} = e^{10\\pi i / 6} \\). So, these correspond to \\( k = 1, 2, 4, 5 \\) modulo 6. Wait, but 1, 2, 4, 5 are all coprime to 6 except for 2 and 4? No, 2 and 6 are not coprime, neither are 4 and 6. Wait, 1, 5 are coprime to 6. So, actually, only two of them are primitive 6th roots of unity. But wait, the polynomial \\( z^4 + z^2 + 1 \\) has 4 roots, which are half of the 6th roots of unity. So, perhaps these are the primitive 3rd roots of unity squared?\n",
      "\n",
      "Wait, let me think differently. Maybe I should check if these roots are actually 3rd or 6th roots of unity.\n",
      "\n",
      "Compute \\( z^3 \\) for one of the roots, say \\( z = e^{\\pi i / 3} \\). Then \\( z^3 = e^{\\pi i} = -1 \\neq 1 \\). So, \\( z \\) is not a 3rd root of unity. Similarly, \\( z^6 = (z^3)^2 = (-1)^2 = 1 \\), so \\( z \\) is a 6th root of unity. Therefore, all the roots are 6th roots of unity.\n",
      "\n",
      "But wait, the polynomial \\( z^4 + z^2 + 1 \\) is degree 4, so it has 4 roots, which are half of the 6th roots of unity. So, the 6th roots of unity are \\( 1, e^{2\\pi i / 6}, e^{4\\pi i / 6}, e^{6\\pi i / 6}, e^{8\\pi i / 6}, e^{10\\pi i / 6} \\). So, the 4 roots of the polynomial are \\( e^{\\pi i / 3}, e^{2\\pi i / 3}, e^{4\\pi i / 3}, e^{5\\pi i / 3} \\), which are \\( e^{2\\pi i / 6}, e^{4\\pi i / 6}, e^{8\\pi i / 6}, e^{10\\pi i / 6} \\). So, these are the even multiples of \\( \\pi / 3 \\). So, they are the primitive 6th roots of unity.\n",
      "\n",
      "Therefore, all the roots are 6th roots of unity. So, the smallest positive integer \\( n \\) such that all roots are \\( n \\)th roots of unity is 6.\n",
      "\n",
      "But wait, let me make sure there isn't a smaller \\( n \\). Suppose \\( n = 3 \\). Then, the 3rd roots of unity are \\( 1, e^{2\\pi i / 3}, e^{4\\pi i / 3} \\). But our polynomial has roots \\( e^{\\pi i / 3}, e^{2\\pi i / 3}, e^{4\\pi i / 3}, e^{5\\pi i / 3} \\). So, the roots are not all 3rd roots of unity because we have \\( e^{\\pi i / 3} \\) which is not a 3rd root. Similarly, if \\( n = 2 \\), the roots would only be \\( 1 \\) and \\( -1 \\), but our polynomial has roots that are complex numbers on the unit circle, not just 1 and -1. So, \\( n = 2 \\) is out.\n",
      "\n",
      "Therefore, the smallest \\( n \\) is 6.\n",
      "\n",
      "Wait, but let me double-check. Maybe these roots are actually 12th roots of unity? Let me see. The 12th roots of unity are \\( e^{2\\pi i k / 12} \\) for \\( k = 0, 1, ..., 11 \\). But our roots are \\( e^{\\pi i / 3} = e^{4\\pi i / 12} \\), \\( e^{2\\pi i / 3} = e^{8\\pi i / 12} \\), \\( e^{4\\pi i / 3} = e^{16\\pi i / 12} \\), and \\( e^{5\\pi i / 3} = e^{20\\pi i / 12} \\). So, these are \\( e^{4\\pi i / 12}, e^{8\\pi i / 12}, e^{16\\pi i / 12}, e^{20\\pi i / 12} \\). Simplifying, these are \\( e^{\\pi i / 3}, e^{2\\pi i / 3}, e^{4\\pi i / 3}, e^{5\\pi i / 3} \\). So, these are actually the same as the 12th roots of unity, but only every third root. So, they are not all 12th roots of unity because, for example, \\( e^{\\pi i / 3} \\) is not a 12th root of unity because \\( (e^{\\pi i / 3})^{12} = e^{4\\pi i} = 1 \\), which is true, but wait, \\( e^{\\pi i / 3} \\) is actually a 12th root of unity because \\( (e^{\\pi i / 3})^{12} = e^{4\\pi i} = 1 \\). Similarly, \\( e^{2\\pi i / 3} \\) is a 6th root of unity, which is also a 12th root of unity. So, actually, all the roots are 12th roots of unity. But wait, is that true?\n",
      "\n",
      "Wait, let me compute \\( (e^{\\pi i / 3})^{12} = e^{4\\pi i} = 1 \\), so yes, it is a 12th root of unity. Similarly, \\( (e^{2\\pi i / 3})^{6} = e^{4\\pi i} = 1 \\), so it is a 6th root of unity, which is also a 12th root of unity. So, actually, all the roots are both 6th and 12th roots of unity. But the question is asking for the smallest \\( n \\) such that all roots are \\( n \\)th roots of unity. So, if they are both 6th and 12th roots, then the smallest \\( n \\) is 6.\n",
      "\n",
      "But wait, let me think again. If all the roots are 6th roots of unity, then they are also 12th roots of unity, but the question is about the smallest \\( n \\). So, since 6 is smaller than 12, and all roots are 6th roots of unity, then 6 is the answer.\n",
      "\n",
      "But just to be thorough, let me check if these roots are indeed 6th roots of unity. So, \\( z^6 = 1 \\) for these roots. Let's take \\( z = e^{\\pi i / 3} \\). Then, \\( z^6 = e^{2\\pi i} = 1 \\). Similarly, \\( z = e^{2\\pi i / 3} \\), \\( z^6 = e^{4\\pi i} = 1 \\). Same for the others. So, yes, they are 6th roots of unity.\n",
      "\n",
      "Therefore, the smallest positive integer \\( n \\) is 6.\n",
      "\n",
      "Wait, but just to make sure, let me think if there is a smaller \\( n \\). Suppose \\( n = 4 \\). Then, the 4th roots of unity are \\( 1, -1, i, -i \\). But our polynomial has roots that are \\( e^{\\pi i / 3}, e^{2\\pi i / 3}, e^{4\\pi i / 3}, e^{5\\pi i / 3} \\). These are not among the 4th roots of unity because \\( e^{\\pi i / 3} \\) is not equal to 1, -1, \\( i \\), or \\( -i \\). So, \\( n = 4 \\) is out.\n",
      "\n",
      "What about \\( n = 3 \\)? The 3rd roots of unity are \\( 1, e^{2\\pi i / 3}, e^{4\\pi i / 3} \\). But our polynomial has roots \\( e^{\\pi i / 3}, e^{2\\pi i / 3}, e^{4\\pi i / 3}, e^{5\\pi i / 3} \\). So, we are missing \\( e^{\\pi i / 3} \\) and \\( e^{5\\pi i / 3} \\) which are not 3rd roots of unity. Therefore, \\( n = 3 \\) is out.\n",
      "\n",
      "What about \\( n = 1 \\)? Well, the only 1st root of unity is 1, but our polynomial has roots that are not 1, so \\( n = 1 \\) is out.\n",
      "\n",
      "What about \\( n = 2 \\)? The 2nd roots of unity are \\( 1 \\) and \\( -1 \\). Our polynomial has roots that are complex numbers on the unit circle, not just 1 and -1. So, \\( n = 2 \\) is out.\n",
      "\n",
      "Therefore, the smallest \\( n \\) is 6.\n",
      "\n",
      "Wait, just to make sure, let me think if these roots are actually primitive 6th roots of unity. So, a primitive 6th root of unity is a root of \\( z^6 - 1 = 0 \\) but not a root of \\( z^k - 1 = 0 \\) for any \\( k < 6 \\). Let's check if \\( z = e^{\\pi i / 3} \\) is a primitive 6th root of unity.\n",
      "\n",
      "Compute \\( z^6 = e^{2\\pi i} = 1 \\). Now, is \\( z^k = 1 \\) for any \\( k < 6 \\)? Let's see:\n",
      "\n",
      "- \\( z^1 = e^{\\pi i / 3} \\neq 1 \\)\n",
      "- \\( z^2 = e^{2\\pi i / 3} \\neq 1 \\)\n",
      "- \\( z^3 = e^{\\pi i} = -1 \\neq 1 \\)\n",
      "- \\( z^4 = e^{4\\pi i / 3} \\neq 1 \\)\n",
      "- \\( z^5 = e^{5\\pi i / 3} \\neq 1 \\)\n",
      "\n",
      "So, none of the powers \\( k = 1, 2, 3, 4, 5 \\) give 1. Therefore, \\( z \\) is a primitive 6th root of unity. Similarly, the other roots are also primitive 6th roots of unity. Therefore, all roots are 6th roots of unity, and 6 is the smallest such \\( n \\).\n",
      "\n",
      "Therefore, the answer is \\( \\boxed{6} \\).\n",
      "\n",
      "**Final Answer**\n",
      "The smallest positive integer \\( n \\) is \\boxed{6}.\n",
      "</think>\n",
      "\n",
      "To find the smallest positive integer \\( n \\) such that all the roots of the polynomial \\( z^4 + z^2 + 1 = 0 \\) are \\( n \\)th roots of unity, we start by rewriting the polynomial. Let \\( w = z^2 \\), then the equation becomes \\( w^2 + w + 1 = 0 \\). Solving this quadratic equation using the quadratic formula, we get:\n",
      "\n",
      "\\[\n",
      "w = \\frac{-1 \\pm \\sqrt{-3}}{2} = \\frac{-1 \\pm i\\sqrt{3}}{2}\n",
      "\\]\n",
      "\n",
      "These solutions are the primitive 3rd roots of unity, denoted as \\( \\omega = \\frac{-1 + i\\sqrt{3}}{2} \\) and \\( \\omega' = \\frac{-1 - i\\sqrt{3}}{2} \\). Therefore, \\( z^2 = \\omega \\) or \\( z^2 = \\omega' \\).\n",
      "\n",
      "Next, we find the square roots of \\( \\omega \\) and \\( \\omega' \\). The square roots of \\( \\omega \\) are \\( e^{\\pi i / 3} \\) and \\( e^{5\\pi i / 3} \\), and the square roots of \\( \\omega' \\) are \\( e^{-\\pi i / 3} \\) and \\( e^{-5\\pi i / 3} \\). These roots are:\n",
      "\n",
      "\\[\n",
      "e^{\\pi i / 3}, e^{2\\pi i / 3}, e^{4\\pi i / 3}, e^{5\\pi i / 3}\n",
      "\\]\n",
      "\n",
      "These are the 6th roots of unity, specifically the primitive 6th roots of unity. Therefore, all the roots of the polynomial \\( z^4 + z^2 + 1 = 0 \\\n",
      "4096 200 4196 3960\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1138 200 1238 748\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "967 200 1067 1080\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1443 200 1543 1639\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1962 200 2062 1732\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1958 200 2058 1198\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1935 200 2035 2314\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2629 200 2729 1262\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 1260\n",
      " 1/2, since there are two Ls. So, the total number of ways to arrange the letters is 7! divided by 2!, which is 5040 / 2 = 2520. So, there are 2520 different arrangements.\n",
      "\n",
      "Wait, but hold on a second. The word ELLIPSE has repeating letters, specifically two Ls. So, when I calculate the total number of arrangements, I need to account for that repetition. That's why I divided by 2! earlier. So, 7! / 2! gives me the total number of distinct arrangements.\n",
      "\n",
      "But the question is about whether the arrangement is possible on a number line. Hmm, the word ELLIPSE has 7 letters, so if I were to place them on a number line from 1 to 7, each letter would occupy a unique position. But since some letters are repeated, some positions will have the same letter. So, the arrangement is possible, but it's not unique because of the repeated letters.\n",
      "\n",
      "Wait, but the question is just asking for the number of ways to arrange the letters, not whether it's possible or not. So, I think I was correct earlier. The number of distinct arrangements is 7! / 2! = 2520.\n",
      "\n",
      "Let me double-check my reasoning. The word ELLIPSE has 7 letters: E, L, L, I, P, S, E. So, that's 7 letters in total. The formula for permutations of multiset is n! divided by the product of the factorials of the counts of each distinct element. Here, n is 7, and the counts are: E appears 2 times, L appears 2 times, and the others (I, P, S) appear once each.\n",
      "\n",
      "So, the formula would be 7! / (2! * 2!) = 5040 / (2 * 2) = 5040 / 4 = 1260. Wait, hold on, that's different from what I got earlier. Hmm, so now I'm confused.\n",
      "\n",
      "Wait, where did I go wrong? Let me see. The word ELLIPSE has 7 letters: E, L, L, I, P, S, E. So, E appears 3 times? Wait, no, let me count again. E, L, L, I, P, S, E. So, E is first, then L, L, I, P, S, E. So, E appears at positions 1, 7, and also... Wait, no, position 1 is E, then position 2 is L, position 3 is L, position 4 is I, position 5 is P, position 6 is S, position 7 is E. So, E appears at positions 1, 3, and 7. So, that's three E's? Wait, no, position 1 is E, position 3 is L, position 7 is E. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. Wait, no, position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I, position 5 is P, position 6 is S. So, E appears twice? Wait, no, position 1 is E, position 7 is E, and position 4 is I\n",
      "4096 200 4196 1176\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1434 200 1534 1482\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1153 200 1253 814\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1700 200 1800 2318\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG (8,-2)\n",
      " line. The formula for the midpoint of a segment between two points \\( (x_1, y_1) \\) and \\( (x_2, y_2) \\) is \\( \\left( \\frac{x_1 + x_2}{2}, \\frac{y_1 + y_2}{2} \\right) \\). So, applying that here, the midpoint \\( M \\) would be \\( \\left( \\frac{10 + 0}{2}, \\frac{-10 + 0}{2} \\right) = (5, -5) \\). That seems correct.\n",
      "\n",
      "Next, I need to find the equation of the perpendicular bisector of segment \\( AO \\). Since the slope of \\( AO \\) is -1, the slope of the perpendicular bisector should be the negative reciprocal, which is 1. So, the perpendicular bisector has a slope of 1 and passes through the midpoint \\( (5, -5) \\). Using the point-slope form, the equation is \\( y - (-5) = 1(x - 5) \\), which simplifies to \\( y + 5 = x - 5 \\), or \\( y = x - 10 \\).\n",
      "\n",
      "Wait, hold on. If I set \\( y = x - 10 \\) and \\( y = -x + 6 \\), solving these two equations should give me the point \\( P \\). Let me write that down:\n",
      "\n",
      "1. \\( y = x - 10 \\)\n",
      "2. \\( y = -x + 6 \\)\n",
      "\n",
      "Setting them equal: \\( x - 10 = -x + 6 \\). Adding \\( x \\) to both sides: \\( 2x - 10 = 6 \\). Adding 10 to both sides: \\( 2x = 16 \\). Dividing by 2: \\( x = 8 \\). Then, plugging back into either equation, let's use the second one: \\( y = -8 + 6 = -2 \\). So, the point \\( P \\) is \\( (8, -2) \\).\n",
      "\n",
      "But wait, the problem mentions that \\( P \\) is equidistant from \\( A \\) and \\( O \\). So, I should verify that \\( PA = PO \\). Let me compute the distances.\n",
      "\n",
      "First, \\( PO \\): distance from \\( P(8, -2) \\) to \\( O(0,0) \\). Using the distance formula: \\( \\sqrt{(8 - 0)^2 + (-2 - 0)^2} = \\sqrt{64 + 4} = \\sqrt{68} \\).\n",
      "\n",
      "Next, \\( PA \\): distance from \\( P(8, -2) \\) to \\( A(10, -10) \\). Using the distance formula: \\( \\sqrt{(10 - 8)^2 + (-10 - (-2))^2} = \\sqrt{4 + 64} = \\sqrt{68} \\).\n",
      "\n",
      "Yep, both distances are \\( \\sqrt{68} \\), so that checks out. So, \\( P(8, -2) \\) is indeed equidistant from \\( A \\) and \\( O \\).\n",
      "\n",
      "But wait, the problem also mentions that \\( P \\) is on the line \\( y = -x + 6 \\). Let me plug \\( x = 8 \\) into that equation: \\( y = -8 + 6 = -2 \\). So, yes, \\( P(8, -2) \\) is on that line. Great, so that seems to fit.\n",
      "\n",
      "However, earlier I thought maybe there could be another point, but since the perpendicular bisector intersects the line \\( y = -x + 6 \\) at only one point, which is the midpoint, I think that's the only point. So, \\( P \\) is uniquely determined.\n",
      "\n",
      "Wait, but just to be thorough, let me think if there could be another point. The perpendicular bisector of \\( AO \\) is \\( y = x - 10 \\), which intersects \\( y = -x + 6 \\) at \\( x = 8 \\), \\( y = -2 \\). Since these are two lines intersecting at only one point, there is only one such point \\( P \\). So, that's the only solution.\n",
      "\n",
      "Alternatively, I could have approached this problem using coordinate geometry. Let me try another method to verify.\n",
      "\n",
      "Let me denote \\( P \\) as \\( (x, y) \\). Since \\( P \\) is on the line \\( y = -x + 6 \\), we have \\( y = -x + 6 \\). Also, since \\( P \\) is equidistant from \\( A(10, -10) \\) and \\( O(0,0) \\), the distance from \\( P \\) to \\( A \\) equals the distance from \\( P \\) to \\( O \\).\n",
      "\n",
      "So, writing the distance equations:\n",
      "\n",
      "1. \\( \\sqrt{(x - 10)^2 + (y + 10)^2} = \\sqrt{(x - 0)^2 + (y - 0)^2} \\)\n",
      "\n",
      "Squaring both sides to eliminate the square roots:\n",
      "\n",
      "\\( (x - 10)^2 + (y + 10)^2 = x^2 + y^2 \\)\n",
      "\n",
      "Expanding both sides:\n",
      "\n",
      "Left side: \\( x^2 - 20x + 100 + y^2 + 20y + 100 \\)\n",
      "\n",
      "Right side: \\( x^2 + y^2 \\)\n",
      "\n",
      "Simplifying:\n",
      "\n",
      "\\( x^2 - 20x + 100 + y^2 + 20y + 100 = x^2 + y^2 \\)\n",
      "\n",
      "Subtract \\( x^2 + y^2 \\) from both sides:\n",
      "\n",
      "\\( -20x + 100 + 20y + 100 = 0 \\)\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "\\( -20x + 20y + 200 = 0 \\)\n",
      "\n",
      "Divide both sides by 20:\n",
      "\n",
      "\\( -x + y + 10 = 0 \\)\n",
      "\n",
      "So, \\( y = x - 10 \\)\n",
      "\n",
      "Wait, that's the same as the perpendicular bisector I found earlier. So, substituting \\( y = x - 10 \\) into \\( y = -x + 6 \\):\n",
      "\n",
      "\\( x - 10 = -x + 6 \\)\n",
      "\n",
      "Adding \\( x \\) to both sides:\n",
      "\n",
      "\\( 2x - 10 = 6 \\)\n",
      "\n",
      "Adding 10:\n",
      "\n",
      "\\( 2x = 16 \\)\n",
      "\n",
      "Dividing by 2:\n",
      "\n",
      "\\( x = 8 \\)\n",
      "\n",
      "Then, \\( y = -8 + 6 = -2 \\)\n",
      "\n",
      "So, again, \\( P(8, -2) \\). So, this method also leads me to the same point.\n",
      "\n",
      "Wait, but just to make sure, let me think if there's another way to approach this problem. Maybe using vectors or something else. But I think the two methods I used are solid.\n",
      "\n",
      "Alternatively, I could have used the midpoint and the perpendicular bisector method, which is what I did initially. So, that's consistent.\n",
      "\n",
      "Wait, another thought: since \\( P \\) is on the line \\( y = -x + 6 \\), and it's equidistant from \\( A \\) and \\( O \\), it must lie on the perpendicular bisector of \\( AO \\). So, the intersection of these two lines is the only point \\( P \\). Therefore, there is only one such point, which is \\( (8, -2) \\).\n",
      "\n",
      "So, I think I'm confident that \\( P(8, -2) \\) is the correct answer.\n",
      "\n",
      "But just to double-check, let me compute the distances again.\n",
      "\n",
      "From \\( P(8, -2) \\) to \\( O(0,0) \\): \\( \\sqrt{(8-0)^2 + (-2-0)^2} = \\sqrt{64 + 4} = \\sqrt{68} \\).\n",
      "\n",
      "From \\( P(8, -2) \\) to \\( A(10, -10) \\): \\( \\sqrt{(10-8)^2 + (-10 - (-2))^2} = \\sqrt{4 + 64} = \\sqrt{68} \\).\n",
      "\n",
      "Yep, both distances are equal, so \\( P \\) is indeed equidistant from \\( A \\) and \\( O \\).\n",
      "\n",
      "Wait, just to make sure, let me think if there's any other point on the line \\( y = -x + 6 \\) that could be equidistant from \\( A \\) and \\( O \\). Since the perpendicular bisector intersects the line at only one point, which is the midpoint, there should only be one such point. So, that's \\( P(8, -2) \\).\n",
      "\n",
      "Alternatively, if I consider the reflection of \\( O \\) over the line \\( y = -x + 6 \\), that point should lie on the perpendicular bisector, which is \\( y = x - 10 \\). Let me compute the reflection of \\( O(0,0) \\) over the line \\( y = -x + 6 \\).\n",
      "\n",
      "The formula for reflection over a line \\( ax + by + c = 0 \\) is a bit complicated, but maybe I can use it here.\n",
      "\n",
      "First, write the line \\( y = -x + 6 \\) in standard form: \\( x + y - 6 = 0 \\). So, \\( a = 1 \\), \\( b = 1 \\), \\( c = -6 \\).\n",
      "\n",
      "The formula for reflection of a point \\( (x_0, y_0) \\) over the line \\( ax + by + c = 0 \\) is:\n",
      "\n",
      "\\[ x' = x_0 - \\frac{2a(ax_0 + by_0 + c)}{a^2 + b^2} \\]\n",
      "\\[ y' = y_0 - \\frac{2b(ax_0 + by_0 + c)}{a^2 + b^2} \\]\n",
      "\n",
      "So, plugging in \\( x_0 = 0 \\), \\( y_0 = 0 \\):\n",
      "\n",
      "First, compute \\( ax_0 + by_0 + c = 0 + 0 - 6 = -6 \\).\n",
      "\n",
      "Then,\n",
      "\n",
      "\\[ x' = 0 - \\frac{2 \\cdot 1 \\cdot (-6)}{1 + 1} = 0 - \\frac{-12}{2} = 0 + 6 = 6 \\]\n",
      "\\[ y' = 0 - \\frac{2 \\cdot 1 \\cdot (-6)}{1 + 1} = 0 - \\frac{-12}{2} = 0 + 6 = 6 \\]\n",
      "\n",
      "So, the reflection of \\( O(0,0) \\) over the line \\( y = -x + 6 \\) is \\( (6,6) \\). Now, if \\( P \\) is the midpoint of \\( O \\) and its reflection, then \\( P \\) should be \\( \\left( \\frac{0 + 6}{2}, \\frac{0 + 6}{2} \\right) = (3, 3) \\). Wait, that's different from what I got earlier. Hmm, that's confusing.\n",
      "\n",
      "Wait, no, actually, the reflection of \\( O \\) over the line \\( y = -x + 6 \\) is \\( (6,6) \\), but the point \\( P \\) is the midpoint of \\( O \\) and its reflection, which would be \\( (3,3) \\). However, \\( (3,3) \\) is not on the line \\( y = -x + 6 \\). Let me check: \\( y = -3 + 6 = 3 \\). So, \\( (3,3) \\) is on the line. Wait, so that's another point on the line \\( y = -x + 6 \\) that is equidistant from \\( O \\) and its reflection, which is \\( (6,6) \\).\n",
      "\n",
      "But wait, is \\( (3,3) \\) equidistant from \\( A(10,-10) \\) and \\( O(0,0) \\)? Let me compute the distances.\n",
      "\n",
      "From \\( (3,3) \\) to \\( O(0,0) \\): \\( \\sqrt{9 + 9} = \\sqrt{18} \\).\n",
      "\n",
      "From \\( (3,3) \\) to \\( A(10,-10) \\): \\( \\sqrt{(10 - 3)^2 + (-10 - 3)^2} = \\sqrt{49 + 169} = \\sqrt{218} \\).\n",
      "\n",
      "Which are not equal. So, \\( (3,3) \\) is not equidistant from \\( A \\) and \\( O \\). So, that's confusing. Why is that?\n",
      "\n",
      "Wait, perhaps I made a mistake in the reflection process. Let me double-check the reflection formula.\n",
      "\n",
      "The formula for reflection over the line \\( ax + by + c = 0 \\) is:\n",
      "\n",
      "\\[ x' = x - \\frac{2a(ax + by + c)}{a^2 + b^2} \\]\n",
      "\\[ y' = y - \\frac{2b(ax + by + c)}{a^2 + b^2} \\]\n",
      "\n",
      "So, for the line \\( x + y - 6 = 0 \\), \\( a = 1 \\), \\( b = 1 \\), \\( c = -6 \\).\n",
      "\n",
      "So, for \\( O(0,0) \\):\n",
      "\n",
      "\\( ax + by + c = 0 + 0 - 6 = -6 \\).\n",
      "\n",
      "Then,\n",
      "\n",
      "\\[ x' = 0 - \\frac{2 \\cdot 1 \\cdot (-6)}{1 + 1} = 0 + 6 = 6 \\]\n",
      "\\[ y' = 0 - \\frac{2 \\cdot 1 \\cdot (-6)}{1 + 1} = 0 + 6 = 6 \\]\n",
      "\n",
      "So, the reflection is \\( (6,6) \\). That seems correct.\n",
      "\n",
      "Then, the midpoint of \\( O(0,0) \\) and \\( (6,6) \\) is \\( (3,3) \\). But \\( (3,3) \\) is on the line \\( y = -x + 6 \\), as \\( 3 = -3 + 6 \\). However, as we saw, \\( (3,3) \\) is not equidistant from \\( A(10,-10) \\) and \\( O(0,0) \\). So, that's a problem.\n",
      "\n",
      "Wait, perhaps the reflection method is not applicable here? Or maybe I misunderstood the method.\n",
      "\n",
      "Wait, the reflection of \\( O \\) over the line \\( y = -x + 6 \\) is \\( (6,6) \\). The point \\( P \\) is the midpoint of \\( O \\) and its reflection, which is \\( (3,3) \\). However, \\( (3,3) \\) is on the line \\( y = -x + 6 \\), but it's not equidistant from \\( A \\) and \\( O \\). So, that suggests that the reflection method might not be directly applicable here.\n",
      "\n",
      "Alternatively, perhaps I should have used the midpoint of \\( O \\) and \\( P \\) instead of the reflection. Wait, no, the reflection method is used to find the image of a point over a line, which is used in some reflection problems, but in this case, I think it's not directly helpful.\n",
      "\n",
      "Alternatively, perhaps I should have used the midpoint of \\( O \\) and \\( P \\) as the point on the line \\( y = -x + 6 \\) that is equidistant from \\( A \\) and \\( O \\). But that seems like what I did earlier.\n",
      "\n",
      "Wait, but in that case, \\( P \\) is the midpoint of \\( O \\) and its reflection, which is \\( (6,6) \\), but \\( (6,6) \\) is not on the line \\( y = -x + 6 \\). Wait, no, \\( (6,6) \\) is on the line \\( y = -x + 6 \\) because \\( 6 = -6 + 12 \\). Wait, no, \\( y = -x + 6 \\), so \\( x = 6 \\) gives \\( y = -6 + 6 = 0 \\). Wait, that's not correct. Wait, \\( x = 6 \\), \\( y = -6 + 6 = 0 \\). So, \\( (6,0) \\) is on the line. Wait, no, \\( (6,6) \\) would be \\( y = -6 + 6 = 0 \\). So, actually, \\( (6,6) \\) is not on the line \\( y = -x + 6 \\). Wait, that's confusing.\n",
      "\n",
      "Wait, let me compute \\( y \\) when \\( x = 6 \\) on the line \\( y = -x + 6 \\): \\( y = -6 + 6 = 0 \\). So, \\( (6,0) \\) is on the line. So, the reflection of \\( O(0,0) \\) over the line \\( y = -x + 6 \\) is \\( (6,0) \\). Wait, that's different from what I got earlier.\n",
      "\n",
      "Wait, maybe I made a mistake in the reflection formula. Let me recalculate.\n",
      "\n",
      "The formula is:\n",
      "\n",
      "\\[ x' = x - \\frac{2a(ax + by + c)}{a^2 + b^2} \\]\n",
      "\\[ y' = y - \\frac{2b(ax + by + c)}{a^2 + b^2} \\]\n",
      "\n",
      "For the line \\( x + y - 6 = 0 \\), \\( a = 1 \\), \\( b = 1 \\), \\( c = -6 \\).\n",
      "\n",
      "For \\( O(0,0) \\):\n",
      "\n",
      "\\( ax + by + c = 0 + 0 - 6 = -6 \\).\n",
      "\n",
      "Then,\n",
      "\n",
      "\\[ x' = 0 - \\frac{2 \\cdot 1 \\cdot (-6)}{1 + 1} = 0 + 6 = 6 \\]\n",
      "\\[ y' = 0 - \\frac{2 \\cdot 1 \\cdot (-6)}{1 + 1} = 0 + 6 = 6 \\]\n",
      "\n",
      "Wait, so the reflection is \\( (6,6) \\). But when I plug \\( x = 6 \\) into \\( y = -x + 6 \\), I get \\( y = -6 + 6 = 0 \\). So, \\( (6,6) \\) is not on the line. That's a problem.\n",
      "\n",
      "Wait, perhaps I messed up the reflection formula. Let me check the formula again.\n",
      "\n",
      "The formula for reflection over the line \\( ax + by + c = 0 \\) is:\n",
      "\n",
      "\\[ x' = x - \\frac{2a(ax + by + c)}{a^2 + b\n",
      "4096 200 4196 2469\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2354 200 2454 1907\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2418 200 2518 2678\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2017 200 2117 2664\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "907 200 1007 1143\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 17\n",
      ":\n",
      "\n",
      "t + 2 ≡ 1/t mod 23.\n",
      "\n",
      "Hmm, so if I can find an integer t between 1 and 22 (since 0 < t < 23) such that when I add 2 to it, it's congruent to its multiplicative inverse modulo 23.\n",
      "\n",
      "Another way to write this is:\n",
      "\n",
      "t + 2 ≡ t^{-1} mod 23.\n",
      "\n",
      "Which implies that:\n",
      "\n",
      "t * (t + 2) ≡ 1 mod 23.\n",
      "\n",
      "So, multiplying both sides by t, we get:\n",
      "\n",
      "t^2 + 2t ≡ 1 mod 23.\n",
      "\n",
      "Rewriting this, we have:\n",
      "\n",
      "t^2 + 2t - 1 ≡ 0 mod 23.\n",
      "\n",
      "So, this is a quadratic congruence: t^2 + 2t - 1 ≡ 0 mod 23.\n",
      "\n",
      "I need to solve this quadratic congruence for t modulo 23. Since 23 is a prime number, the congruence should have solutions if the discriminant is a quadratic residue modulo 23.\n",
      "\n",
      "The general form of a quadratic congruence is at^2 + bt + c ≡ 0 mod p, where p is prime. Here, a = 1, b = 2, c = -1.\n",
      "\n",
      "The discriminant D = b^2 - 4ac = 4 - 4*1*(-1) = 4 + 4 = 8.\n",
      "\n",
      "So, D = 8. We need to check if 8 is a quadratic residue modulo 23.\n",
      "\n",
      "To check if 8 is a quadratic residue modulo 23, we can use the Legendre symbol (8/23). If it's 1, then 8 is a quadratic residue; if it's -1, then it's not.\n",
      "\n",
      "Recall that (a/b) = (a^{(b-1)/2}/b) mod b, by Euler's criterion.\n",
      "\n",
      "So, (8/23) = (8^{11} mod 23).\n",
      "\n",
      "Let me compute 8^11 mod 23.\n",
      "\n",
      "First, compute 8^2 = 64 ≡ 64 - 2*23 = 64 - 46 = 18 mod 23.\n",
      "\n",
      "8^4 = (8^2)^2 = 18^2 = 324 ≡ 324 - 14*23 = 324 - 322 = 2 mod 23.\n",
      "\n",
      "8^8 = (8^4)^2 = 2^2 = 4 mod 23.\n",
      "\n",
      "Now, 8^11 = 8^8 * 8^2 * 8^1 ≡ 4 * 18 * 8 mod 23.\n",
      "\n",
      "Compute 4 * 18 = 72 ≡ 72 - 3*23 = 72 - 69 = 3 mod 23.\n",
      "\n",
      "Then, 3 * 8 = 24 ≡ 24 - 23 = 1 mod 23.\n",
      "\n",
      "So, (8/23) = 1, which means 8 is a quadratic residue modulo 23. Therefore, the congruence t^2 + 2t - 1 ≡ 0 mod 23 has two solutions.\n",
      "\n",
      "So, we can solve for t using the quadratic formula modulo 23.\n",
      "\n",
      "The quadratic formula in modular arithmetic is a bit different, but we can use the fact that if D is a quadratic residue, then the solutions are:\n",
      "\n",
      "t ≡ (-b ± sqrt(D)) / (2a) mod p.\n",
      "\n",
      "Here, a = 1, b = 2, D = 8.\n",
      "\n",
      "So, t ≡ (-2 ± sqrt(8)) / 2 mod 23.\n",
      "\n",
      "We already computed sqrt(8) ≡ 8^11 ≡ 1 mod 23, wait, no, that was the Legendre symbol. Wait, actually, sqrt(8) is a number x such that x^2 ≡ 8 mod 23.\n",
      "\n",
      "We need to find x such that x^2 ≡ 8 mod 23.\n",
      "\n",
      "Let me try to find such x.\n",
      "\n",
      "Compute x^2 mod 23 for x from 1 to 11 (since 23 is prime, quadratic residues are symmetric).\n",
      "\n",
      "1^2 = 1 ≡ 1\n",
      "\n",
      "2^2 = 4 ≡ 4\n",
      "\n",
      "3^2 = 9 ≡ 9\n",
      "\n",
      "4^2 = 16 ≡ 16\n",
      "\n",
      "5^2 = 25 ≡ 2\n",
      "\n",
      "6^2 = 36 ≡ 13\n",
      "\n",
      "7^2 = 49 ≡ 3\n",
      "\n",
      "8^2 = 64 ≡ 64 - 2*23=18\n",
      "\n",
      "9^2 = 81 ≡ 81 - 3*23=81-69=12\n",
      "\n",
      "10^2=100 ≡ 100 - 4*23=100-92=8\n",
      "\n",
      "Ah, so 10^2 ≡ 8 mod 23. So, sqrt(8) ≡ 10 mod 23.\n",
      "\n",
      "Similarly, since 23 is prime, -10 ≡ 13 mod 23 is also a square root of 8, because (-10)^2 = 100 ≡ 8 mod 23.\n",
      "\n",
      "So, sqrt(8) ≡ 10 or 13 mod 23.\n",
      "\n",
      "Therefore, the solutions for t are:\n",
      "\n",
      "t ≡ (-2 ± 10) / 2 mod 23\n",
      "\n",
      "and\n",
      "\n",
      "t ≡ (-2 ± 13) / 2 mod 23.\n",
      "\n",
      "Let's compute both possibilities.\n",
      "\n",
      "First, with sqrt(8) ≡ 10:\n",
      "\n",
      "t ≡ (-2 + 10) / 2 ≡ 8 / 2 ≡ 4 mod 23.\n",
      "\n",
      "t ≡ (-2 - 10) / 2 ≡ (-12) / 2 ≡ -6 ≡ 17 mod 23.\n",
      "\n",
      "Second, with sqrt(8) ≡ 13:\n",
      "\n",
      "t ≡ (-2 + 13) / 2 ≡ 11 / 2 mod 23.\n",
      "\n",
      "t ≡ (-2 - 13) / 2 ≡ (-15) / 2 ≡ (-15 + 23) / 2 ≡ 8 / 2 ≡ 4 mod 23.\n",
      "\n",
      "Wait, hold on, that can't be. Let me double-check.\n",
      "\n",
      "Wait, when sqrt(8) ≡ 13, then:\n",
      "\n",
      "t ≡ (-2 + 13) / 2 ≡ 11 / 2 mod 23.\n",
      "\n",
      "Similarly, t ≡ (-2 - 13) / 2 ≡ (-15) / 2 mod 23.\n",
      "\n",
      "But 11 / 2 mod 23 is equivalent to 11 * 12 mod 23, since 2 * 12 ≡ 24 ≡ 1 mod 23.\n",
      "\n",
      "Similarly, -15 / 2 mod 23 is equivalent to (-15) * 12 mod 23.\n",
      "\n",
      "Let me compute these.\n",
      "\n",
      "First, 11 * 12 mod 23:\n",
      "\n",
      "11 * 12 = 132.\n",
      "\n",
      "132 divided by 23: 23*5=115, 132-115=17. So, 132 ≡ 17 mod 23.\n",
      "\n",
      "Second, -15 * 12 mod 23:\n",
      "\n",
      "-15 * 12 = -180.\n",
      "\n",
      "-180 mod 23: 180 divided by 23: 23*7=161, 180-161=19, so -180 ≡ -19 ≡ 4 mod 23.\n",
      "\n",
      "So, the solutions are t ≡ 4, 17, 4, 17 mod 23.\n",
      "\n",
      "Wait, that's only two distinct solutions: 4 and 17.\n",
      "\n",
      "So, the solutions are t ≡ 4 and t ≡ 17 mod 23.\n",
      "\n",
      "But the problem states that t is an odd integer between 1 and 22. So, let's check which of these solutions are odd.\n",
      "\n",
      "4 is even, 17 is odd. So, t ≡ 17 mod 23.\n",
      "\n",
      "Hence, the unique odd integer t between 1 and 22 such that t + 2 is the inverse of t modulo 23 is 17.\n",
      "\n",
      "Wait, let me verify this.\n",
      "\n",
      "Compute t + 2 = 17 + 2 = 19.\n",
      "\n",
      "Compute t^{-1} mod 23, which is 17^{-1} mod 23.\n",
      "\n",
      "We need to find x such that 17x ≡ 1 mod 23.\n",
      "\n",
      "Let me compute 17 * x ≡ 1 mod 23.\n",
      "\n",
      "Try x=1: 17\n",
      "\n",
      "x=2: 34 ≡ 11\n",
      "\n",
      "x=3: 51 ≡ 51 - 2*23=51-46=5\n",
      "\n",
      "x=4: 68 ≡ 68 - 2*23=68-46=22\n",
      "\n",
      "x=5: 85 ≡ 85 - 3*23=85-69=16\n",
      "\n",
      "x=6: 102 ≡ 102 - 4*23=102-92=10\n",
      "\n",
      "x=7: 119 ≡ 119 - 5*23=119-115=4\n",
      "\n",
      "x=8: 136 ≡ 136 - 5*23=136-115=21\n",
      "\n",
      "x=9: 153 ≡ 153 - 6*23=153-138=15\n",
      "\n",
      "x=10: 170 ≡ 170 - 7*23=170-161=9\n",
      "\n",
      "x=11: 187 ≡ 187 - 8*23=187-184=3\n",
      "\n",
      "x=12: 204 ≡ 204 - 8*23=204-184=20\n",
      "\n",
      "x=13: 221 ≡ 221 - 9*23=221-207=14\n",
      "\n",
      "x=14: 238 ≡ 238 - 10*23=238-230=8\n",
      "\n",
      "x=15: 255 ≡ 255 - 11*23=255-253=2\n",
      "\n",
      "x=16: 272 ≡ 272 - 11*23=272-253=19\n",
      "\n",
      "x=17: 289 ≡ 289 - 12*23=289-276=13\n",
      "\n",
      "x=18: 306 ≡ 306 - 13*23=306-299=7\n",
      "\n",
      "x=19: 323 ≡ 323 - 14*23=323-322=1\n",
      "\n",
      "Ah, finally, x=19: 17*19=323 ≡ 1 mod 23.\n",
      "\n",
      "So, 17^{-1} ≡ 19 mod 23.\n",
      "\n",
      "But s/t + 2 ≡ 19 mod 23, which is t + 2 ≡ 19 mod 23.\n",
      "\n",
      "So, t ≡ 19 - 2 ≡ 17 mod 23.\n",
      "\n",
      "Hence, t ≡ 17 mod 23, which is the solution we found earlier.\n",
      "\n",
      "So, 17 is the unique odd integer between 1 and 22 such that t + 2 is the inverse of t modulo 23.\n",
      "\n",
      "Wait, just to make sure, let's check another odd number, say 3.\n",
      "\n",
      "Compute t + 2 = 5.\n",
      "\n",
      "Compute 3^{-1} mod 23: find x such that 3x ≡ 1 mod 23.\n",
      "\n",
      "3*8=24≡1 mod23, so 3^{-1}≡8 mod23.\n",
      "\n",
      "But t + 2 =5≠8, so 3 doesn't work.\n",
      "\n",
      "Similarly, let's check t=5.\n",
      "\n",
      "t + 2=7.\n",
      "\n",
      "5^{-1} mod23: find x such that 5x≡1 mod23.\n",
      "\n",
      "5*14=70≡70-3*23=70-69=1 mod23. So, 5^{-1}≡14 mod23.\n",
      "\n",
      "But t +2=7≠14, so 5 doesn't work.\n",
      "\n",
      "Similarly, t=7.\n",
      "\n",
      "t +2=9.\n",
      "\n",
      "7^{-1} mod23: find x such that 7x≡1 mod23.\n",
      "\n",
      "7*10=70≡1 mod23. So, 7^{-1}≡10 mod23.\n",
      "\n",
      "But t +2=9≠10, so 7 doesn't work.\n",
      "\n",
      "t=9.\n",
      "\n",
      "t +2=11.\n",
      "\n",
      "9^{-1} mod23: find x such that 9x≡1 mod23.\n",
      "\n",
      "9*5=45≡45-1*23=22≡-1 mod23.\n",
      "\n",
      "9*10=90≡90-3*23=90-69=21≡-2 mod23.\n",
      "\n",
      "9*11=99≡99-4*23=99-92=7≡7 mod23.\n",
      "\n",
      "9*12=108≡108-4*23=108-92=16≡16 mod23.\n",
      "\n",
      "9*13=117≡117-5*23=117-115=2≡2 mod23.\n",
      "\n",
      "9*14=126≡126-5*23=126-115=11≡11 mod23.\n",
      "\n",
      "9*15=135≡135-5*23=135-115=20≡20 mod23.\n",
      "\n",
      "9*16=144≡144-6*23=144-138=6≡6 mod23.\n",
      "\n",
      "9*17=153≡153-6*23=153-138=15≡15 mod23.\n",
      "\n",
      "9*18=162≡162-7*23=162-161=1≡1 mod23.\n",
      "\n",
      "So, 9^{-1}≡18 mod23.\n",
      "\n",
      "But t +2=11≠18, so 9 doesn't work.\n",
      "\n",
      "Similarly, t=11.\n",
      "\n",
      "t +2=13.\n",
      "\n",
      "11^{-1} mod23: find x such that 11x≡1 mod23.\n",
      "\n",
      "11*2=22≡-1 mod23.\n",
      "\n",
      "11*3=33≡10 mod23.\n",
      "\n",
      "11*4=44≡44-1*23=21≡-2 mod23.\n",
      "\n",
      "11*5=55≡55-2*23=55-46=9≡9 mod23.\n",
      "\n",
      "11*6=66≡66-2*23=66-46=20≡20 mod23.\n",
      "\n",
      "11*7=77≡77-3*23=77-69=8≡8 mod23.\n",
      "\n",
      "11*8=88≡88-3*23=88-69=19≡19 mod23.\n",
      "\n",
      "11*9=99≡99-4*23=99-92=7≡7 mod23.\n",
      "\n",
      "11*10=110≡110-4*23=110-92=18≡18 mod23.\n",
      "\n",
      "11*11=121≡121-5*23=121-115=6≡6 mod23.\n",
      "\n",
      "11*12=132≡132-5*23=132-115=17≡17 mod23.\n",
      "\n",
      "11*13=143≡143-6*23=143-138=5≡5 mod23.\n",
      "\n",
      "11*14=154≡154-6*23=154-138=16≡16 mod23.\n",
      "\n",
      "11*15=165≡165-7*23=165-161=4≡4 mod23.\n",
      "\n",
      "11*16=176≡176-7*23=176-161=15≡15 mod23.\n",
      "\n",
      "11*17=187≡187-8*23=187-184=3≡3 mod23.\n",
      "\n",
      "11*18=198≡198-8*23=198-184=14≡14 mod23.\n",
      "\n",
      "11*19=209≡209-9*23=209-207=2≡2 mod23.\n",
      "\n",
      "11*20=220≡220-9*23=220-207=13≡13 mod23.\n",
      "\n",
      "11*21=231≡231-10*23=231-230=1≡1 mod23.\n",
      "\n",
      "So, 11^{-1}≡21 mod23.\n",
      "\n",
      "But t +2=13≠21, so 11 doesn't work.\n",
      "\n",
      "Similarly, t=13.\n",
      "\n",
      "t +2=15.\n",
      "\n",
      "13^{-1} mod23: find x such that 13x≡1 mod23.\n",
      "\n",
      "13*10=130≡1\n",
      "4096 200 4196 1759\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2814 200 2914 3001\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1159 200 1259 1554\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2519 200 2619 2260\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1425 200 1525 1478\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1728 200 1828 3321\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1238 200 1338 1269\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 3\n",
      " 2, 3, 5, 7. So, the possible values for n are 2, 3, 5, 7.\n",
      "\n",
      "Let me start with n = 2. If n = 2, then the number is 10a + b = 2b. Since 2b must be a two-digit number, a must be 1 because 10*1 + b = 10 + b. So, 2b must be equal to 10 + b. Let me write that equation:\n",
      "\n",
      "2b = 10 + b\n",
      "\n",
      "Subtract b from both sides:\n",
      "\n",
      "b = 10\n",
      "\n",
      "Wait, that can't be right because b is a single digit, so b can only be from 0 to 9. 10 is not a valid digit. Hmm, so maybe n = 2 doesn't work? Or perhaps I made a mistake in my reasoning.\n",
      "\n",
      "Let me double-check. If n = 2, then the number is 10a + b = 2b. Since it's a two-digit number, a must be 1. So, 10 + b = 2b. Subtract b from both sides: 10 = b. But b can't be 10, so indeed, n = 2 doesn't work. So, maybe n = 2 is not a valid number of digits.\n",
      "\n",
      "Wait, but 10a + b = 2b implies that 10a = b. But since a is a single digit (1-9) and b is a single digit (0-9), 10a = b would require b to be at least 10, which is impossible. So, n = 2 doesn't yield a valid two-digit prime. So, n = 2 is out.\n",
      "\n",
      "Alright, moving on to n = 3. So, the number is 10a + b = 3b. Similarly, since it's a two-digit number, a must be 1. So, 10 + b = 3b. Let me solve for b:\n",
      "\n",
      "10 + b = 3b\n",
      "\n",
      "Subtract b from both sides:\n",
      "\n",
      "10 = 2b\n",
      "\n",
      "So, b = 5. So, b is 5. Therefore, the number is 15. Wait, but 15 is not a prime number because it's divisible by 3 and 5. So, even though n = 3 and b = 5 satisfy the equation, the resulting number 15 is not prime. So, n = 3 doesn't work either.\n",
      "\n",
      "Wait, but hold on. Maybe I should check if 15 is a prime. No, 15 is 3*5, so it's not prime. So, n = 3 doesn't give a valid prime.\n",
      "\n",
      "Let me try n = 5. So, the number is 10a + b = 5b. Again, a must be 1 because it's a two-digit number. So, 10 + b = 5b. Let me solve for b:\n",
      "\n",
      "10 + b = 5b\n",
      "\n",
      "Subtract b from both sides:\n",
      "\n",
      "10 = 4b\n",
      "\n",
      "So, b = 10/4 = 2.5. Hmm, but b has to be an integer digit, so 2.5 isn't valid. Therefore, n = 5 doesn't work either.\n",
      "\n",
      "Wait, but 2.5 isn't an integer, so b can't be 2.5. So, n = 5 doesn't yield a valid two-digit prime.\n",
      "\n",
      "Finally, let me try n = 7. So, the number is 10a + b = 7b. Again, a must be 1. So, 10 + b = 7b. Let me solve for b:\n",
      "\n",
      "10 + b = 7b\n",
      "\n",
      "Subtract b from both sides:\n",
      "\n",
      "10 = 6b\n",
      "\n",
      "So, b = 10/6 = 1.666... Hmm, that's approximately 1.666, which is not an integer. So, b isn't an integer here, which means n = 7 doesn't work either.\n",
      "\n",
      "Wait, but 1.666... is 1 and 2/3, which isn't an integer. So, b isn't an integer, so n = 7 doesn't work.\n",
      "\n",
      "Wait, but hold on. Maybe I made a mistake in my approach. Let me think again. Maybe n isn't necessarily the number of digits? Wait, no, n is the number of digits. So, for a two-digit number, n must be 2. So, n can only be 2, 3, 5, or 7. So, I think I covered all possible cases.\n",
      "\n",
      "But wait, maybe I should check if there are any other possible values of n. But no, for a two-digit number, the number of digits n can only be 2, 3, 5, or 7 because those are the only single-digit numbers that are primes. So, n can only be 2, 3, 5, or 7.\n",
      "\n",
      "Wait, but in my earlier calculations, none of these values of n resulted in a valid two-digit prime number. So, is it possible that there are no such two-digit primes where the sum of the digits is 8?\n",
      "\n",
      "Wait, that can't be. Let me think again. Maybe I made a mistake in my calculations.\n",
      "\n",
      "Let me try n = 2 again. So, the number is 10a + b = 2b. Since it's a two-digit number, a must be 1. So, 10 + b = 2b. Subtract b: 10 = b. But b can only be 0-9, so 10 isn't valid. So, n = 2 doesn't work.\n",
      "\n",
      "n = 3: 10a + b = 3b. a = 1, so 10 + b = 3b. 10 = 2b, so b = 5. So, the number is 15. But 15 is not prime. So, n = 3 doesn't work.\n",
      "\n",
      "n = 5: 10a + b = 5b. a = 1, so 10 + b = 5b. 10 = 4b, so b = 2.5. Not an integer. So, n = 5 doesn't work.\n",
      "\n",
      "n = 7: 10a + b = 7b. a = 1, so 10 + b = 7b. 10 = 6b, so b = 1.666... Not an integer. So, n = 7 doesn't work.\n",
      "\n",
      "Wait, so none of these values of n give a valid two-digit prime. So, is the answer zero? But that seems odd. Maybe I made a mistake in my approach.\n",
      "\n",
      "Wait, perhaps I should consider that n isn't necessarily the number of digits. Wait, no, for a two-digit number, n must be 2. So, that's correct.\n",
      "\n",
      "Alternatively, maybe I should think about the digits themselves. Let me list all two-digit primes and check their digit sums.\n",
      "\n",
      "Two-digit primes are: 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97.\n",
      "\n",
      "Now, let me compute the sum of the digits for each:\n",
      "\n",
      "- 11: 1 + 1 = 2\n",
      "- 13: 1 + 3 = 4\n",
      "- 17: 1 + 7 = 8\n",
      "- 19: 1 + 9 = 10\n",
      "- 23: 2 + 3 = 5\n",
      "- 29: 2 + 9 = 11\n",
      "- 31: 3 + 1 = 4\n",
      "- 37: 3 + 7 = 10\n",
      "- 41: 4 + 1 = 5\n",
      "- 43: 4 + 3 = 7\n",
      "- 47: 4 + 7 = 11\n",
      "- 53: 5 + 3 = 8\n",
      "- 59: 5 + 9 = 14\n",
      "- 61: 6 + 1 = 7\n",
      "- 67: 6 + 7 = 13\n",
      "- 71: 7 + 1 = 8\n",
      "- 73: 7 + 3 = 10\n",
      "- 79: 7 + 9 = 16\n",
      "- 83: 8 + 3 = 11\n",
      "- 89: 8 + 9 = 17\n",
      "- 97: 9 + 7 = 16\n",
      "\n",
      "Now, let me see which of these have a digit sum of 8:\n",
      "\n",
      "- 17: 1 + 7 = 8\n",
      "- 53: 5 + 3 = 8\n",
      "- 71: 7 + 1 = 8\n",
      "\n",
      "So, that's three numbers: 17, 53, and 71. So, there are three two-digit primes where the sum of the digits is 8.\n",
      "\n",
      "Wait, but in my earlier approach, when I tried n = 2, 3, 5, 7, none of them gave me a valid prime. But when I listed all two-digit primes, I found three. So, perhaps my initial approach was flawed because I was assuming that the number must be a multiple of n, but that's not necessarily the case.\n",
      "\n",
      "Wait, let me think again. When I said that the number is equal to n*b, where n is the number of digits and b is the digit, that's only true if the number is a multiple of n. But actually, that's not correct. For example, 17 is a two-digit number, but 17 is not a multiple of 2. So, that approach was incorrect.\n",
      "\n",
      "So, perhaps my initial method was wrong because I assumed that the number is a multiple of n, but that's not true. So, that's why I got zero, but when I listed all two-digit primes, I found three. So, perhaps I need to approach this differently.\n",
      "\n",
      "Wait, maybe I should consider that the number is equal to 10*a + b, where a is the tens digit and b is the units digit. So, the sum of the digits is a + b = 8. So, a + b = 8, and the number is 10a + b, which is a two-digit prime.\n",
      "\n",
      "So, perhaps I can list all two-digit primes where the sum of the digits is 8. From the list above, that's 17, 53, and 71. So, three primes.\n",
      "\n",
      "But wait, in my initial approach, when I tried n = 2, 3, 5, 7, I didn't get any valid primes. So, perhaps I need to consider that the number isn't necessarily a multiple of n. So, my initial method was incorrect because I assumed that the number is a multiple of n, but that's not true.\n",
      "\n",
      "So, perhaps I should approach this problem differently. Let me try to think of it as a digit sum problem. So, I need to find all two-digit primes where the sum of the digits is 8.\n",
      "\n",
      "Alternatively, I can think of it as finding all two-digit primes where the units digit plus the tens digit equals 8. So, for example, 17: 1 + 7 = 8, 53: 5 + 3 = 8, 71: 7 + 1 = 8.\n",
      "\n",
      "So, perhaps I can list all two-digit primes and check their digit sums. But that might be time-consuming. Alternatively, I can think of all possible two-digit numbers where the sum of the digits is 8 and check if they're prime.\n",
      "\n",
      "So, let's list all two-digit numbers where the sum of the digits is 8:\n",
      "\n",
      "- 17: 1 + 7 = 8\n",
      "- 26: 2 + 6 = 8\n",
      "- 35: 3 + 5 = 8\n",
      "- 44: 4 + 4 = 8\n",
      "- 53: 5 + 3 = 8\n",
      "- 62: 6 + 2 = 8\n",
      "- 71: 7 + 1 = 8\n",
      "- 80: 8 + 0 = 8\n",
      "\n",
      "Wait, but 80 is not a prime number. So, 80 is out. So, the valid numbers are 17, 26, 35, 44, 53, 62, 71.\n",
      "\n",
      "Now, let's check which of these are prime:\n",
      "\n",
      "- 17: Prime\n",
      "- 26: Not prime (26 = 2*13)\n",
      "- 35: Not prime (35 = 5*7)\n",
      "- 44: Not prime (44 = 2*2*11)\n",
      "- 53: Prime\n",
      "- 62: Not prime (62 = 2*31)\n",
      "- 71: Prime\n",
      "\n",
      "So, the primes are 17, 53, and 71. So, that's three primes.\n",
      "\n",
      "Wait, but in my initial approach, when I tried n = 2, 3, 5, 7, I didn't get any valid primes. So, perhaps my initial method was incorrect because I assumed that the number is a multiple of n, but that's not true. So, perhaps I should not have restricted myself to numbers where the number is a multiple of n, but rather, consider all two-digit primes and check their digit sums.\n",
      "\n",
      "So, perhaps the correct approach is to list all two-digit primes and check their digit sums. But that might be time-consuming, but since there are only 9 two-digit primes, it's manageable.\n",
      "\n",
      "Alternatively, I can think of all two-digit primes where the sum of the digits is 8. So, as I listed above, 17, 53, and 71 are the only ones.\n",
      "\n",
      "Wait, but in my initial approach, when I tried n = 2, 3, 5, 7, I didn't get any valid primes. So, perhaps I should have considered that the number isn't necessarily a multiple of n. So, my initial method was flawed because I assumed that the number is a multiple of n, but that's not true.\n",
      "\n",
      "So, perhaps the correct answer is three two-digit primes: 17, 53, and 71.\n",
      "\n",
      "Wait, but let me double-check. Let me list all two-digit primes and check their digit sums:\n",
      "\n",
      "- 11: 1 + 1 = 2\n",
      "- 13: 1 + 3 = 4\n",
      "- 17: 1 + 7 = 8\n",
      "- 19: 1 + 9 = 10\n",
      "- 23: 2 + 3 = 5\n",
      "- 29: 2 + 9 = 11\n",
      "- 31: 3 + 1 = 4\n",
      "- 37: 3 + 7 = 10\n",
      "- 41: 4 + 1 = 5\n",
      "- 43: 4 + 3 = 7\n",
      "- 47: 4 + 7 = 11\n",
      "- 53: 5 + 3 = 8\n",
      "- 59: 5 + 9 = 14\n",
      "- 61: 6 + 1 = 7\n",
      "- 67: 6 + 7 = 13\n",
      "- 71: 7 + 1 = 8\n",
      "- 73: 7 + 3 = 10\n",
      "- 79: 7 + 9 = 16\n",
      "- 83: 8 + 3 = 11\n",
      "- 89: 8 + 9 = 17\n",
      "- 97: 9 + 7 = 16\n",
      "\n",
      "From this list, the primes with digit sums of 8 are 17, 53, and 71. So, that's three primes.\n",
      "\n",
      "Wait, but in my initial approach, when I tried n = 2, 3, 5, 7, I didn't get any valid primes. So, perhaps my initial method was incorrect because I assumed that the number is a multiple of n, but that's not true. So, perhaps I should not have restricted myself to numbers where the number is a multiple of n, but rather, consider all two-digit primes and check their digit sums.\n",
      "\n",
      "So, perhaps the correct answer is three two-digit primes: 17, 53, and 71.\n",
      "\n",
      "Wait, but let me think again. Maybe I should consider that the number is a multiple of n, where n is the number of digits. So, for a two-digit number, n = 2. So, the number is 10a + b = 2b. So, 10a + b = 2b. So, 10a = b. But b is a single digit, so b can only be 0-9. So, 10a = b. But a is a single digit, so a can be 1-9. So, 10a = b implies that b is 10, 20, ..., 90, which are not single digits. So, no solution for n = 2.\n",
      "\n",
      "Similarly, for n = 3, the number is 100a + 10b + c = 3c. So, 100a + 10b + c = 3c. So, 100a + 10b = 2c. But 100a + 10b is at least 100 (if a=1, b=0) and at most 990 (if a=9, b=9). So, 2c must be in that range. So, c can be from 50 to 99, but c is a single digit, so c can only be 50-99, which is impossible. So, no solution for n = 3.\n",
      "\n",
      "Similarly, for n = 5, the number is 10000a + 1000b + 100c + 10d + e = 5e. So, 10000a + 1000b + 100c + 10d + e = 5\n",
      "4096 200 4196 2693\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1600 200 1700 1346\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "874 200 974 2159\n",
      "===\n",
      "===\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct_items = 0\n",
    "torch.manual_seed(0)\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "evaluation_dataset = []\n",
    "\n",
    "for dataset_pos in tqdm(range(len(correct_dataset))):\n",
    "    # dataset_pos = 11\n",
    "    input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "    # print(input_ids)\n",
    "    # print(\"===\")\n",
    "    # print(\"===\")\n",
    "\n",
    "    input_ids = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": base_prompt.format(question=input_ids),\n",
    "                },\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # input_ids = dataset_item[\"input_ids\"]\n",
    "    # generated_ids = dataset_item[\"generated_ids\"]\n",
    "    generated_ids = [\n",
    "        tokenizer.encode(\n",
    "            correct_dataset[dataset_pos][\"model_answer\"],\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        start_embed = model.embed_pooler.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "        )\n",
    "        # end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        end_embed = model.embed_pooler.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "        )\n",
    "        input_ids = torch.tensor(input_ids).cuda()\n",
    "        input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "        windows_amount = 100\n",
    "        # windows_amount = 200\n",
    "        # windows_amount = 300\n",
    "        # windows_amount = 400\n",
    "        # windows_amount = 500\n",
    "        # windows_amount = 2\n",
    "        generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "        original_total_len = torch.tensor(generated_ids).shape[1]\n",
    "        if generated_tokens_amount > original_total_len:\n",
    "            windows_amount = original_total_len // WINDOW_SIZE\n",
    "            generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "\n",
    "        next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "            :, :generated_tokens_amount\n",
    "        ]\n",
    "\n",
    "        # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "        # original_embeds = (model.get_input_embeddings()(next_true_tokens)).to(\n",
    "        original_embeds = (\n",
    "            # model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)\n",
    "            model.embed_pooler.get_input_embeddings()(next_true_tokens)\n",
    "        ).to(torch.float32)\n",
    "\n",
    "        # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        new_embeds_for_compression = original_embeds.reshape(\n",
    "            windows_amount, WINDOW_SIZE, -1\n",
    "        )\n",
    "        # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        compressed_part = model.embed_pooler(new_embeds_for_compression)\n",
    "        compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "        # start_embed = torch.rand_like(start_embed)\n",
    "        # compressed_part = torch.rand_like(compressed_part)\n",
    "        # end_embed = torch.rand_like(end_embed)\n",
    "        generated_embeds = torch.cat(\n",
    "            [\n",
    "                input_ids_embeds,\n",
    "                start_embed,\n",
    "                compressed_part,\n",
    "                end_embed,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "        # print(\"===\")\n",
    "        generated_ids_compressed = model.generate(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            # attention_mask=torch.ones_like(generated_embeds),\n",
    "            attention_mask=torch.ones(\n",
    "                generated_embeds.shape[:2],\n",
    "                device=\"cuda\",\n",
    "            ).long(),\n",
    "            max_new_tokens=4096,\n",
    "            # max_new_tokens=5,\n",
    "            do_sample=False,\n",
    "            # do_sample=True,\n",
    "            # temperature=0.6,\n",
    "            # top_p=0.95,\n",
    "        )\n",
    "        # break\n",
    "    generated_result = tokenizer.decode(generated_ids_compressed[-1])\n",
    "    # print()\n",
    "    gold_answer = correct_dataset[dataset_pos][\"answer\"]\n",
    "    answer = dataset_answer_filter(gold_answer)\n",
    "    model_answer = model_answer_filter(generated_result)\n",
    "    if is_equiv(answer, model_answer):\n",
    "        correct_items += 1\n",
    "        print(\"CORRECT\")\n",
    "    else:\n",
    "        print(\"WRONG\", gold_answer)\n",
    "        print(generated_result)\n",
    "    compressed_total_len = generated_ids_compressed.shape[1] + compressed_part.shape[1]\n",
    "    print(\n",
    "        generated_ids_compressed.shape[1],\n",
    "        next_true_tokens.shape[1],\n",
    "        compressed_total_len,\n",
    "        torch.tensor(generated_ids).shape[1],\n",
    "    )\n",
    "    evaluation_dataset.append(\n",
    "        {\n",
    "            **correct_dataset[dataset_pos],\n",
    "            \"compressed_input_part\": tokenizer.decode(next_true_tokens[-1]),\n",
    "            \"compressed_output_generation\": generated_result,\n",
    "            \"compressed_compression_size\": generated_tokens_amount,\n",
    "            \"original_total_len\": torch.tensor(generated_ids).shape[1],\n",
    "            \"compressed_total_len\": compressed_total_len,\n",
    "        }\n",
    "    )\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    # break\n",
    "    # embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 656])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 719, 1536])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(next_true_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13392857142857142, 0.10714285714285714, 0.8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset) / len(dataset), correct_items / len(dataset), correct_items / len(\n",
    "    correct_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(correct_dataset) / len(dataset), correct_items / len(dataset), (\n",
    "#     correct_items + 1\n",
    "# ) / len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.base_model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57044, 55461, 0.9722494916205034)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_total_len = 0\n",
    "compressed_total_len = 0\n",
    "for item in evaluation_dataset:\n",
    "    original_total_len += item[\"original_total_len\"]\n",
    "    compressed_total_len += item[\"compressed_total_len\"]\n",
    "original_total_len, compressed_total_len, compressed_total_len / original_total_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
