{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ef7a7bb00246348e4b40a104ceaa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f085db131e654d64964a7040ecfed546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1580\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1580\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _require_custom_configs \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:5475\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5473\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5487\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5491\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1024\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 309\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:420\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    419\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(EntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-68128578-0ea274e125dba3cb1d1ac5b6;c8d72666-fbda-4390-b0c3-c9d217194594)\n\nEntry Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# model = model.to(torch.bfloat16)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2059\u001b[0m )\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1629\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1631\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1019\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1018\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m-> 1019\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m   1026\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1027\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1028\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1030\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m   1031\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m_MODULE_TO_EXTENSIONS[module_name], file_names\u001b[38;5;241m=\u001b[39m_MODULE_TO_METADATA_FILE_NAMES[module_name]\n\u001b[1;32m   1032\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:690\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    685\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    687\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    688\u001b[0m         patterns_for_key\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:583\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 583\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m         )\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:361\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_HUB_VERSION \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# 10 times faster glob with detail=True (ignores costly info like lastCommit)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     glob_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    359\u001b[0m matched_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    360\u001b[0m     filepath \u001b[38;5;28;01mif\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mstartswith(protocol_prefix) \u001b[38;5;28;01melse\u001b[39;00m protocol_prefix \u001b[38;5;241m+\u001b[39m filepath\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filepath, info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mglob_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mislink\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(filepath))))\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (xbasename(filepath) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m files_to_ignore)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_inside_unrequested_special_dir(filepath, fs_pattern)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir(filepath, fs_pattern)\n\u001b[1;32m    366\u001b[0m ]  \u001b[38;5;66;03m# ignore .ipynb and __pycache__, but keep /../\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     out \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    369\u001b[0m         filepath\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m matched_paths\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix \u001b[38;5;129;01min\u001b[39;00m allowed_extensions \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m xbasename(filepath)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    372\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:521\u001b[0m, in \u001b[0;36mHfFileSystem.glob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    520\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:609\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m pattern \u001b[38;5;241m=\u001b[39m glob_translate(path \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    612\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:556\u001b[0m, in \u001b[0;36mHfFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03mList all files below path.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    `Union[List[str], Dict[str, Dict[str, Any]]]`: List of paths or dict of file information.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxdepth:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwithdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    560\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:500\u001b[0m, in \u001b[0;36mAbstractFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Add the root directory if withdirs is requested\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# This is needed for posix glob compliance\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m withdirs \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(path):\n\u001b[0;32m--> 500\u001b[0m     out[path] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk(path, maxdepth, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m withdirs:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:719\u001b[0m, in \u001b[0;36mHfFileSystem.info\u001b[0;34m(self, path, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     out \u001b[38;5;241m=\u001b[39m out1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh \u001b[38;5;129;01mor\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (expand_info \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mand\u001b[39;00m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_commit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 719\u001b[0m     paths_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_paths_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths_info:\n\u001b[1;32m    727\u001b[0m         _raise_file_not_found(path, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3354\u001b[0m, in \u001b[0;36mHfApi.get_paths_info\u001b[0;34m(self, repo_id, paths, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3351\u001b[0m revision \u001b[38;5;241m=\u001b[39m quote(revision, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mDEFAULT_REVISION\n\u001b[1;32m   3352\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m-> 3354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43ms/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/paths-info/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrevision\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m   3363\u001b[0m paths_info \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"hidden_capacity_reasoning\"\n",
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    ScriptArguments,\n",
    "    SFTConfig,\n",
    "    SFTTrainer,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    generate_train_examples,\n",
    "    pad_train_examples,\n",
    "    tokenize_single_turn,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import types\n",
    "\n",
    "# need for auto SFTTrainer patch(possible increase speed)\n",
    "from unsloth import is_bfloat16_supported\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    EOS_TOKEN_ID,\n",
    "    TEXT_TOKEN_ID,\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    find_all_linear_names_v3,\n",
    ")\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    "    Qwen2ForCausalLMCompressionV3,\n",
    "    Qwen2ModelEmbedPoolerV3,\n",
    ")\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"my_r1_model_v3\"\n",
    "model = Qwen2ForCausalLMCompressionV3.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.model.requires_grad_(False)\n",
    "# model = model.to(torch.bfloat16)\n",
    "\n",
    "# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\n",
    "#     model_name,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map={\"\": 0},\n",
    "#     # quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "# )\n",
    "# print(\n",
    "#     model.embed_pooler.load_state_dict(\n",
    "#         temp_model.state_dict(),\n",
    "#         strict=False,\n",
    "#     ),\n",
    "# )\n",
    "# temp_model = temp_model.cpu()\n",
    "# del temp_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "dataset = load_dataset(\"dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset = dataset.train_test_split(test_size=10, seed=42)\n",
    "\n",
    "# test pass\n",
    "tokenize_single_turn(\n",
    "    question=dataset[\"train\"][0][\"question\"],\n",
    "    answer=dataset[\"train\"][0][\"answer\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "train_examples = [\n",
    "    tokenize_single_turn(tokenizer=tokenizer, **item)\n",
    "    for item in tqdm(dataset[\"train\"].to_list()[:3])\n",
    "]\n",
    "\n",
    "prepared_train_examples = []\n",
    "for item in tqdm(train_examples):\n",
    "    for example in generate_train_examples(\n",
    "        dataset_batch=[item],\n",
    "        window_size=WINDOW_SIZE,\n",
    "    ):\n",
    "        prepared_train_examples.append(example)\n",
    "\n",
    "print(\n",
    "    \"max_len\",\n",
    "    max([len(item[\"original_tokens\"]) for item in prepared_train_examples]),\n",
    ")\n",
    "\n",
    "new_dataset = Dataset.from_list(prepared_train_examples)\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    padded_batch = pad_train_examples(\n",
    "        train_examples=batch,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    padded_batch = {\n",
    "        \"replaced_original_tokens\": padded_batch[\"replaced_original_tokens\"][\n",
    "            \"input_ids\"\n",
    "        ],\n",
    "        \"compressed_input_ids\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "        \"original_tokens\": padded_batch[\"original_tokens\"][\"input_ids\"],\n",
    "        \"attention_mask\": padded_batch[\"compressed_input_ids\"][\"attention_mask\"],\n",
    "        \"labels\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "        \"content_compression_mask\": padded_batch[\"content_compression_mask\"][\n",
    "            \"input_ids\"\n",
    "        ],\n",
    "    }\n",
    "    for key in padded_batch.keys():\n",
    "        padded_batch[key] = torch.tensor(padded_batch[key])\n",
    "    skip_ids = [\n",
    "        TEXT_TOKEN_ID,\n",
    "        EOS_TOKEN_ID,\n",
    "        VISION_START,\n",
    "        VISION_END,\n",
    "    ]\n",
    "    for skip_id in skip_ids:\n",
    "        padded_batch[\"labels\"][padded_batch[\"labels\"] == skip_id] = -100\n",
    "    # часть инпута от пользователя\n",
    "    last_index = (padded_batch[\"content_compression_mask\"] == 1).long().nonzero()[-1][1]\n",
    "    padded_batch[\"labels\"][:, :last_index][\n",
    "        padded_batch[\"content_compression_mask\"][:, :last_index] == 1\n",
    "    ] = -100\n",
    "    # print(padded_batch)\n",
    "    return padded_batch\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\",\n",
    "    target_modules=find_all_linear_names_v3(model=model),\n",
    "    modules_to_save=[\n",
    "        \"embed_pooler.model.embed_tokens\",\n",
    "        \"embed_pooler.weight_pooler\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "formatted_date = datetime.fromtimestamp(time.time()).strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "model.embed_pooler = prepare_model_for_kbit_training(model.embed_pooler)\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=new_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=1,  # 90,  # Set this for 1 full training run.\n",
    "        # num_train_epochs=90,  # Set this for 1 full training run.\n",
    "        # max_steps=10000,\n",
    "        learning_rate=1e-4,\n",
    "        bf16=True,\n",
    "        # fp16=model.dtype == torch.float16,\n",
    "        logging_steps=8,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=f\"outputs/{formatted_date}\",\n",
    "        # report_to=\"wandb\",\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,\n",
    "        dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "        # gradient_checkpointing=True,\n",
    "        save_steps=10000,\n",
    "        run_name=formatted_date,\n",
    "    ),\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLet’s denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLet’s assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLet’s let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLet’s denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my_r1_model_v3/tokenizer_config.json',\n",
       " 'my_r1_model_v3/special_tokens_map.json',\n",
       " 'my_r1_model_v3/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.base_model.embed_pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.bfloat16)\n",
    "model.embed_pooler(\n",
    "    torch.randn(\n",
    "        2,\n",
    "        2,\n",
    "        1536,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.bfloat16,\n",
    "    )\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.weight_pooler.modules_to_save.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.model.embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in trainer.model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09588f9a8f65410ea8177fb66720c433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from peft import PeftModel\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    ")\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"r1_compressor_v2\"\n",
    "model = Qwen2ForCausalLMCompressionV2.from_pretrained(\n",
    "    model_name,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    # \"outputs/2025_04_19_17_17_34_493839/checkpoint-210000\",\n",
    "    # \"outputs/2025_04_19_17_17_34_493839/checkpoint-50000\",\n",
    "    # \"outputs/2025_04_21_19_23_11_642509/checkpoint-10000\",\n",
    "    # \"outputs/2025_04_22_01_43_43_347583/checkpoint-90000\",\n",
    "    # \"outputs/2025_04_22_01_43_43_347583/checkpoint-10000\",\n",
    "    # 'outputs/2025_04_23_00_46_10_062896/checkpoint-2794'\n",
    "    # \"outputs/2025_04_29_21_24_17_071961/checkpoint-588\",\n",
    "    # \"outputs/2025_04_30_01_16_22_692562/checkpoint-140000\",\n",
    "    \"outputs/2025_04_30_01_16_22_692562/checkpoint-10000\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "163 148 0.9079754601226994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    # \"dim/hendrycks_math_train_12k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    # \"dim/hendrycks_math_train_1k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(\n",
    "    test_size=250,\n",
    "    # test_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dataset = dataset[\"test\"].filter(lambda x: x[\"model_answer\"].count(\"</think>\") == 1)\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "\n",
    "correct_dataset = []\n",
    "\n",
    "for pos, item in enumerate(dataset):\n",
    "    try:\n",
    "        answer = dataset_answer_filter(item[\"answer\"])\n",
    "        model_answer = model_answer_filter(item[\"model_answer\"])\n",
    "        # print(answer, model_answer)\n",
    "        # break\n",
    "        if is_equiv(answer, model_answer):\n",
    "            correct_dataset.append(item)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(dataset), len(correct_dataset), len(correct_dataset) / len(dataset))\n",
    "\n",
    "correct_dataset = correct_dataset[:30]\n",
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>Problem: If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<｜Assistant｜><think>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "# prompt = \"how many wings has a bird?\"\n",
    "prompt = correct_dataset[0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    "model_inputs = tokenizer(\n",
    "    [text],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"longest\",\n",
    "    truncation=False,\n",
    "    add_special_tokens=False,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # generated_ids = model.generate(\n",
    "    #     model_inputs.input_ids,\n",
    "    #     max_new_tokens=1,\n",
    "    #     do_sample=False,\n",
    "    # )\n",
    "    generated_ids = model.generate(\n",
    "        # **model_inputs.input_ids,\n",
    "        **model_inputs,\n",
    "        max_new_tokens=4096,\n",
    "        do_sample=False,\n",
    "        # do_sample=not False,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLet’s denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLet’s assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLet’s let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLet’s denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response  # == dataset[0]['model_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<｜Assistant｜><think>\n",
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<｜end▁of▁sentence｜><｜begin▁of▁sentence｜>\n",
      "\n",
      "To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "prompt = correct_dataset[:5][0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "# initial_len = generated_tokens.shape\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    max_steps = 1200\n",
    "    past_key_values = None\n",
    "    for step in range(max_steps):\n",
    "        if step == 0:\n",
    "            logits = model(\n",
    "                inputs_embeds=generated_embeds,\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.arange(generated_embeds.shape[1])\n",
    "                .cuda()\n",
    "                .unsqueeze(0),\n",
    "                use_cache=True,\n",
    "                past_key_values=None,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "        else:\n",
    "            logits = model(\n",
    "                # input_ids=generated_tokens[-1][-1:].unsqueeze(0),\n",
    "                inputs_embeds=generated_embeds[:, -1:, :],\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.tensor(generated_embeds.shape[1] - 1)\n",
    "                .reshape(1, 1)\n",
    "                .cuda(),\n",
    "                use_cache=True,\n",
    "                past_key_values=past_key_values,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "\n",
    "        top_token = logits.argmax(-1)[-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(step, tokenizer.decode(generated_tokens[-1]))\n",
    "    # break\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "# break\n",
    "embeds_generation_tokens = generated_tokens[-1]\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜User｜>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.<｜Assistant｜><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\\n\\nLet me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\\n\\nSo, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\\n\\nTime = Distance / Speed\\n\\nSo, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\\n\\nLet's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\\n\\nSo, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\\n\\nSo, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\\n\\nAlternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\\n\\nI think that's solid. So, the lion will catch the elephant in 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \\n\\nTo find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\\n\\n\\\\[\\n24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph}\\n\\\\]\\n\\nThe initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\\n\\n\\\\[\\n\\\\text{Time} = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = 0.2 \\\\text{ hours}\\n\\\\]\\n\\nConverting 0.2 hours to minutes:\\n\\n\\\\[\\n0.2 \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes.<｜end▁of▁sentence｜><｜begin▁of▁sentence｜>\\n\\nTo determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from transformers.generation import utils\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "dataset_pos = 10\n",
    "prompt = correct_dataset[dataset_pos][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": base_prompt.format(question=prompt),\n",
    "        },\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    inputs_embeds=generated_embeds,\n",
    "    max_new_tokens=1800,\n",
    "    # max_new_tokens=5,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': \"Alicia's average on her five tests is 88 points. The score range for each test is 0 points to 100 points, inclusive. What is the lowest possible score that Alicia could have earned on one of the five tests?\",\n",
       " 'solution': \"If Alicia's average score on her five tests is 88 points, then the sum of her scores must be $88 \\\\times 5 = 440$ points. If she earned   100 points on four of the tests, then she could have earned a score as low as $\\\\boxed{40\\\\text{ points}}$ on the other test.\",\n",
       " 'answer': '40\\\\text{ points}',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 4,\n",
       " 'unique_id': 'test/prealgebra/1697.json',\n",
       " 'model_answer': \"Okay, so I need to figure out the lowest possible score Alicia could have earned on one of her five tests. She has an average of 88 points, and each test is scored between 0 and 100, inclusive. Hmm, let me think about this step by step.\\n\\nFirst, I know that an average is calculated by taking the sum of all the test scores and dividing it by the number of tests. In this case, she has five tests, and her average is 88. So, to find the total points she has across all five tests, I can multiply the average by the number of tests.\\n\\nLet me write that down:\\n\\nTotal points = Average × Number of tests\\nTotal points = 88 × 5\\n\\nLet me calculate that. 88 times 5 is... 440. So, the total points she has across all five tests is 440.\\n\\nNow, the question is asking for the lowest possible score she could have earned on one of these tests. To minimize one of the test scores, I need to maximize the other scores because the total is fixed at 440.\\n\\nBut there are constraints: each test can only have a score between 0 and 100, inclusive. So, the maximum score on any test is 100. If I try to maximize the other four test scores, each being 100, that would give me the maximum possible sum for four tests.\\n\\nLet me calculate that:\\n\\nMaximizing four tests:\\nMax sum = 100 × 4 = 400\\n\\nSo, if four tests are 100 each, that's 400 points. Then, the fifth test must make up the remaining points to reach the total of 440.\\n\\nLet me find the score for the fifth test:\\n\\nScore on fifth test = Total points - Max sum of four tests\\nScore = 440 - 400\\nScore = 40\\n\\nWait, so that means if four tests are 100 each, the fifth test must be 40? That seems low, but it's mathematically correct because 100 + 100 + 100 + 100 + 40 = 440.\\n\\nBut hold on, the question is asking for the lowest possible score on one of the tests. So, if I set the other four tests as high as possible (100 each), the fifth test would be 40. But is there a way to get a lower score? Let me think.\\n\\nIf I make one of the other tests lower than 100, does that allow the fifth test to be lower than 40? Wait, no, because if I lower one test, I have to raise the others to compensate, but they can't go above 100. So, actually, to minimize one test, you need to maximize the others as much as possible, which is 100 each. So, 40 is indeed the minimal possible score.\\n\\nBut just to double-check, let's think about it differently. Suppose I try to set four tests to 100, which gives me 400. The fifth test is 40. If I tried to make the fifth test lower, say 30, then the sum of the other four tests would have to be 440 - 30 = 410. But if I have four tests, each can be at most 100, so 100 × 4 is 400. 410 is more than 400, which isn't possible. So, it's not possible to have a lower score on the fifth test than 40 because the other four tests can't exceed 400.\\n\\nTherefore, 40 is the lowest possible score Alicia could have earned on one of the five tests.\\n\\nWait, but another thought: what if one test is 0? Would that allow the others to be higher? Let me see. If one test is 0, then the total of the other four tests would have to be 440 - 0 = 440. But each of those four tests can only go up to 100, so 100 × 4 is 400. But 440 is more than 400, which is impossible. Therefore, having a 0 on one test would require the others to sum to 440, which isn't possible since the maximum they can sum to is 400. So, 0 is too low.\\n\\nSo, 40 is indeed the lowest possible score because it's the only score that allows the other four tests to be 100 each without exceeding the maximum.\\n\\nAnother angle: Let's think about the formula for the average. The average is the total divided by the number of tests. So, if I want to minimize one test, I have to maximize the others, but they can't exceed 100. So, the maximum sum of four tests is 400, as we had before. Therefore, the minimal fifth test is 40.\\n\\nWait, let me make sure I'm not missing any other constraints. The problem says each test is between 0 and 100, inclusive. So, 0 is allowed, but in this case, if we tried to set four tests to 100, the fifth must be 40. If we set one test to 100, the others could be higher, but that doesn't help in minimizing a single test. Alternatively, if I set two tests to 100, the others can be higher, but again, that doesn't help.\\n\\nTherefore, the only way to minimize a single test score is to maximize the other four, which is 100 each. So, the minimal possible score is 40.\\n\\nI think that's solid reasoning. I don't see any other way to lower one test score without violating the test score range or the total points.\\n\\n**Final Answer**\\nThe lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\\n</think>\\n\\nAlicia's average score on her five tests is 88 points. To find the total points she has across all five tests, we multiply the average by the number of tests:\\n\\n\\\\[\\n\\\\text{Total points} = 88 \\\\times 5 = 440\\n\\\\]\\n\\nTo find the lowest possible score on one of the tests, we need to maximize the scores of the other four tests. Since each test can score a maximum of 100, the maximum sum of four tests is:\\n\\n\\\\[\\n\\\\text{Max sum of four tests} = 100 \\\\times 4 = 400\\n\\\\]\\n\\nThe score on the fifth test must then be:\\n\\n\\\\[\\n\\\\text{Score on fifth test} = 440 - 400 = 40\\n\\\\]\\n\\nThus, the lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "example_id = correct_dataset[dataset_pos][\"unique_id\"].replace(\"/\", \"_\")\n",
    "with open(f\"./temp/{example_id}\", \"w\") as f:\n",
    "    temp = {\n",
    "        \"generated_ids\": generated_ids.tolist(),\n",
    "        \"input_ids\": generated_tokens.tolist(),\n",
    "    }\n",
    "    json.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\n",
    "    correct_dataset[dataset_pos][\"model_answer\"],\n",
    "    add_special_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜><｜User｜>An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?<｜Assistant｜><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them will be changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should think of the relative speed as the lion's speed minus the elephant's speed? Wait, no, that might not be right.\\n\\nLet me clarify. If the lion is moving towards the elephant at 24 mph, and the elephant is moving away from the lion at 19 mph, then the lion is effectively closing the gap at a rate of 24 mph minus 19 mph. That makes sense because the lion is moving towards the elephant, but the elephant is moving away. So, the net speed at which the distance between them is decreasing is 24 - 19 = 5 mph.\\n\\nSo, the distance between them is decreasing at 5 miles per hour. They start 1 mile apart, so I can use the formula:\\n\\nTime = Distance / Speed\\n\\nHere, the distance is 1 mile, and the speed is 5 mph. So, time = 1 / 5 hours. But the question asks for the time in minutes, so I need to convert hours to minutes. There are 60 minutes in an hour, so 1/5 hours * 60 minutes/hour = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph towards the elephant, and the elephant is moving away at 19 mph, then the relative speed is indeed 24 - 19 = 5 mph. So, the lion is gaining on the elephant at 5 miles per hour. Since they start 1 mile apart, the time it takes to close that distance is 1 / 5 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure, let me think about it another way. Maybe set up an equation for their positions as functions of time and see when they meet.\\n\\nLet me denote t as the time in hours. The position of the elephant as a function of time would be starting from some point and moving away at 19 mph. Let's say the initial position of the elephant is at position 0, and the lion is at position 1 mile. Then, the position of the elephant at time t is 0 + 19t, and the position of the lion is 1 - 24t. They meet when their positions are equal, so:\\n\\n19t = 1 - 24t\\n\\nAdding 24t to both sides:\\n\\n19t + 24t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours\\n\\nWait, that's different from what I got before. Hmm, so which one is correct? 12 minutes or 1/43 hours?\\n\\nWait, 1/43 hours is approximately 1.395 minutes, which is about 1 minute and 23 seconds. But earlier, I got 12 minutes. That's a big difference. So, I must have made a mistake somewhere.\\n\\nLet me go back. When I thought about the relative speed, I considered the lion moving towards the elephant and the elephant moving away, so the relative speed is 24 - 19 = 5 mph. So, the time should be 1/5 hours, which is 12 minutes. But when I set up the equations, I got t = 1/43 hours, which is about 1.395 minutes. That's conflicting.\\n\\nWait, maybe I messed up the initial positions. Let me define the positions more carefully. Let's say the lion starts at position 0, and the elephant starts at position 1 mile. Then, the lion is moving towards the elephant, so its position as a function of time is 0 + 24t. The elephant is moving away from the lion, so its position is 1 + 19t. They meet when their positions are equal:\\n\\n24t = 1 + 19t\\n\\nSubtracting 19t from both sides:\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. Okay, that makes sense. So, why did I get 1/43 hours earlier?\\n\\nWait, in my second approach, I set the lion's position as 1 - 24t, but that might be incorrect. If the lion starts at position 0, moving towards the elephant, which is at position 1, then the lion's position is 24t. The elephant is moving away from the lion, so its position is 1 + 19t. So, setting them equal:\\n\\n24t = 1 + 19t\\n\\nWhich gives t = 1/5 hours, which is 12 minutes. So, that seems correct.\\n\\nWait, so why did I get 1/43 hours earlier? Maybe I confused the starting positions. Let me re-examine that.\\n\\nIn the second approach, I set the lion's position as 1 - 24t, which would be incorrect because if the lion is moving towards the elephant, starting from position 0, its position should be increasing, not decreasing. So, that was my mistake. I should have set the lion's position as 24t, not 1 - 24t.\\n\\nSo, correcting that, the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes. So, that's consistent with the first method.\\n\\nTherefore, the correct answer is 12 minutes.\\n\\nWait, but just to make sure, let me think about it in another way. Suppose the lion is moving at 24 mph towards the elephant, and the elephant is\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them is changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should consider the relative speed between the lion and the elephant.\\n\\nWait, actually, since the elephant is moving away, the lion has to cover the initial distance plus any additional distance the elephant might cover while the lion is chasing. But since the lion is faster, it should eventually catch up. So, maybe I can model this as a relative speed problem.\\n\\nLet me denote the speed of the lion as \\\\( v_l = 24 \\\\) mph and the speed of the elephant as \\\\( v_e = 19 \\\\) mph. The initial distance between them is \\\\( d = 1 \\\\) mile.\\n\\nSince the lion is moving towards the elephant and the elephant is moving away, the relative speed at which the distance between them is decreasing is the difference between the lion's speed and the elephant's speed. So, the relative speed \\\\( v_{relative} = v_l - v_e = 24 - 19 = 5 \\\\) mph.\\n\\nWait, is that right? If the lion is moving towards the elephant and the elephant is moving away, then the lion is effectively closing the gap at a rate of 5 mph. So, the time it takes to close the 1 mile gap would be the initial distance divided by the relative speed.\\n\\nSo, time \\\\( t = \\\\frac{d}{v_{relative}} = \\\\frac{1}{5} \\\\) hours. But the question asks for the time in minutes, so I need to convert that.\\n\\nSince 1 hour is 60 minutes, \\\\( \\\\frac{1}{5} \\\\) hours is \\\\( \\\\frac{1}{5} \\\\times 60 = 12 \\\\) minutes. So, it should take 12 minutes for the lion to catch the elephant.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, then the lion is gaining on the elephant at a rate of 5 mph. So, to cover the 1 mile gap, it would take \\\\( \\\\frac{1}{5} \\\\) hours, which is indeed 12 minutes. That seems correct.\\n\\nAlternatively, I can model this with equations. Let me set up a coordinate system where at time \\\\( t \\\\) hours, the position of the lion is \\\\( 24t \\\\) miles from its starting point, and the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion. Wait, actually, hold on. If the elephant is moving away from the lion, then the distance between them is increasing. So, the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion, and the position of the lion is \\\\( 24t \\\\) miles from the same starting point.\\n\\nWait, but initially, they are 1 mile apart. So, if the lion starts at position 0 and the elephant starts at position 1 mile, then the distance between them at time \\\\( t \\\\) is \\\\( |24t - (1 + 19t)| \\\\). We want this distance to be 0 when the lion catches the elephant.\\n\\nSo, setting up the equation:\\n\\n\\\\( 24t - (1 + 19t) = 0 \\\\)\\n\\nSimplify:\\n\\n\\\\( 24t - 19t - 1 = 0 \\\\)\\n\\n\\\\( 5t - 1 = 0 \\\\)\\n\\n\\\\( 5t = 1 \\\\)\\n\\n\\\\( t = \\\\frac{1}{5} \\\\) hours, which is 12 minutes. So, that confirms my earlier result.\\n\\nAlternatively, I can think about it in terms of distance covered. The lion needs to cover the initial 1 mile plus whatever distance the elephant covers in that time. But since the lion is faster, the time is determined by the relative speed.\\n\\nWait, another way to think about it is using the concept of relative velocity. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the relative speed is 24 - 19 = 5 mph. So, the lion is closing the gap at 5 mph. Therefore, the time to close 1 mile is 1/5 hours, which is 12 minutes.\\n\\nI think that's solid. I can't see any mistakes in this reasoning. So, I think the answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed.\\n\\nThe relative speed at which the lion is closing the gap is the difference between their speeds:\\n\\\\[ v_{\\\\text{relative}} = v_l - v_e = 24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph} \\\\]\\n\\nThe time it takes to close the 1 mile gap is calculated by dividing the initial distance by the relative speed:\\n\\\\[ t = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours} \\\\]\\n\\nConverting this time into minutes:\\n\\\\[ \\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes} \\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate with compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a magic square, meaning that the sum of the numbers in each row, in each column, and in each of the $2$ main diagonals are equal. What is the value of $n$?\n",
      "\n",
      "[asy]size(125);\n",
      "for(int i = 0; i<4; ++i)\n",
      "{\n",
      "\n",
      "draw((0,i)--(3,i),linewidth(1));\n",
      "}\n",
      "\n",
      "for(int j = 0; j<4; ++j)\n",
      "{\n",
      "\n",
      "draw((j,0)--(j,3),linewidth(1));\n",
      "}\n",
      "\n",
      "label(\"$n-3$\",(.5,.5));\n",
      "label(\"3\",(.5,1.5));\n",
      "label(\"$n+1$\",(.5,2.5));\n",
      "\n",
      "label(\"$n+2$\",(1.5,.5));\n",
      "label(\"$2n-9$\",(1.5,1.5));\n",
      "label(\"$1$\",(1.5,2.5));\n",
      "\n",
      "label(\"$2$\",(2.5,.5));\n",
      "label(\"$n$\",(2.5,1.5));\n",
      "label(\"$n-1$\",(2.5,2.5));\n",
      "[/asy]\n",
      "===\n",
      "===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPRESSED PART Okay, so I have this magic square problem here, and I need to find the value of \\( n \\). Let me try to figure this out step by step. \n",
      "\n",
      "First, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\( n \\) such that all these sums are equal.\n",
      "\n",
      "Looking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\n",
      "\n",
      "- The top row has three cells: \\( n-3 \\), \\( 3 \\), and \\( n+1 \\).\n",
      "- The middle row has \\( n+2 \\), \\( 2n-9 \\), and \\( 1 \\).\n",
      "- The bottom row has \\( 2 \\), \\( n \\), and \\( n-1 \\).\n",
      "\n",
      "So, writing this out, the magic square looks like this:\n",
      "\n",
      "\\[\n",
      "\\begin{array}{|c|c|c|}\n",
      "\\hline\n",
      "n - 3 & 3 & n + 1 \\\\\n",
      "\\hline\n",
      "n + 2 & 2n - 9 & 1 \\\\\n",
      "\\hline\n",
      "2 & n & n - 1 \\\\\n",
      "\\hline\n",
      "\\end{array}\n",
      "\\]\n",
      "\n",
      "Alright, now I need to find \\( n \\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\( S \\).\n",
      "\n",
      "First, let me compute the sum of the first row:\n",
      "\n",
      "\\( (n - 3) + 3 + (n + 1) \\)\n",
      "\n",
      "Simplify that:\n",
      "\n",
      "\\( n - 3 + 3 + n + 1 = 2n + 1 \\)\n",
      "\n",
      "So, the sum of the first row is \\( 2n + 1 \\). That means the magic constant \\( S = 2n + 1 \\).\n",
      "\n",
      "Let me check the second row:\n",
      "\n",
      "\\( (n + 2) + (2n - 9) + 1 \\)\n",
      "\n",
      "Simplify:\n",
      "\n",
      "\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\)\n",
      "\n",
      "So, the sum of the second row is \\( 3n - 6 \\). Since this must equal \\( S \\), we have:\n",
      "\n",
      "\\( 3n - 6 = 2n + 1 \\)\n",
      "\n",
      "Let me solve for \\( n \\):\n",
      "\n",
      "Subtract \\( 2n \\) from both sides:\n",
      "\n",
      "\\( n - 6 = 1 \\)\n",
      "\n",
      "Add 6 to both sides:\n",
      "\n",
      "\\( n = 7 \\)\n",
      "\n",
      "Wait, hold on. Let me verify this because I might have made a mistake. If \\( n = 7 \\), let me check the third row:\n",
      "\n",
      "\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\)\n",
      "\n",
      "But according to the first row, \\( 2n + 1 = 2*7 + 1 = 15 \\). So, that's consistent.\n",
      "\n",
      "Let me check the columns as well to make sure.\n",
      "\n",
      "First column:\n",
      "\n",
      "\\( (n - 3) + (n + 2) + 2 \\)\n",
      "\n",
      "Substitute \\( n = 7 \\):\n",
      "\n",
      "\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\)\n",
      "\n",
      "Good, that's 15.\n",
      "\n",
      "Second column:\n",
      "\n",
      "\\( 3 + (2n - 9) + n \\)\n",
      "\n",
      "Substitute \\( n = 7 \\):\n",
      "\n",
      "\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\)\n",
      "\n",
      "Perfect.\n",
      "\n",
      "Third column:\n",
      "\n",
      "\\( (n\n",
      "===\n",
      " - 1) + (n - 1) \\)\n",
      "\n",
      "Wait, hold on, the third column is \\( n - 1 \\) and \\( n - 1 \\). So, substituting \\( n = 7 \\):\n",
      "\n",
      "\\( 7 - 1 + 7 - 1 = 6 + 6 = 12 \\)\n",
      "\n",
      "Wait, that's 12. Hmm, that's different from the other columns. That can't be right. So, something's wrong here.\n",
      "\n",
      "Wait, let me recount the third column. Looking back at the Asymptote code, the bottom row is \\( 2 \\), \\( n \\), \\( n - 1 \\). So, yes, that's correct. So, \\( 2 + n + (n - 1) = 2 + 7 + 6 = 15 \\). Wait, no, 2 + 7 + 6 is 15? 2 + 7 is 9, plus 6 is 15. Yes, that's correct.\n",
      "\n",
      "Wait, but the second column was \\( 3 + (2n - 9) + n \\). Substituting \\( n = 7 \\):\n",
      "\n",
      "\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\). That's correct.\n",
      "\n",
      "Third column: \\( (n - 1) + (n - 1) \\). Wait, no, the third column is \\( n - 1 \\) and \\( n - 1 \\). So, \\( 7 - 1 + 7 - 1 = 6 + 6 = 12 \\). Hmm, that's 12, which is different from the other columns.\n",
      "\n",
      "Wait, that can't be. So, that means my initial assumption that \\( S = 2n + 1 \\) is incorrect? Or maybe I made a mistake in calculating the sum of the first row.\n",
      "\n",
      "Let me recalculate the sum of the first row:\n",
      "\n",
      "Top row: \\( n - 3 \\), \\( 3 \\), \\( n + 1 \\)\n",
      "\n",
      "Sum: \\( (n - 3) + 3 + (n + 1) = n - 3 + 3 + n + 1 = 2n + 1 \\). That seems correct.\n",
      "\n",
      "But then, the second row sums to \\( 3 + (2n - 9) + 1 = 3 + 2n - 9 + 1 = 2n - 5 \\). Wait, hold on, earlier I thought it was \\( 3 + (2n - 9) + 1 = 3 + 2n - 9 + 1 = 2n - 5 \\). Wait, that's different from what I thought before.\n",
      "\n",
      "Wait, let me recalculate the second row:\n",
      "\n",
      "Top row: \\( n - 3 \\), \\( 3 \\), \\( n + 1 \\)\n",
      "\n",
      "Middle row: \\( n + 2 \\), \\( 2n - 9 \\), \\( 1 \\)\n",
      "\n",
      "Bottom row: \\( 2 \\), \\( n \\), \\( n - 1 \\)\n",
      "\n",
      "So, second row: \\( n + 2 + 2n - 9 + 1 \\)\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "\\( n + 2n = 3n \\)\n",
      "\n",
      "\\( 2 - 9 + 1 = -6 \\)\n",
      "\n",
      "So, sum is \\( 3n - 6 \\). So, that's correct.\n",
      "\n",
      "Similarly, first row sum is \\( 2n + 1 \\), second row is \\( 3n - 6 \\), third row is \\( 2 + n + (n - 1) = 2 + n + n - 1 = 2n + 1 \\). So, third row sum is also \\( 2n + 1 \\).\n",
      "\n",
      "So, the three row sums are:\n",
      "\n",
      "1. \\( 2n + 1 \\)\n",
      "2. \\( 3n - 6 \\)\n",
      "3. \\( 2n + 1 \\)\n",
      "\n",
      "Similarly, let's check the columns.\n",
      "\n",
      "First column: \\( n - 3 \\), \\( n + 2 \\), \\( 2 \\)\n",
      "\n",
      "Sum: \\( (n - 3) + (n + 2) + 2 = n - 3 + n + 2 + 2 = 2n + 1 \\)\n",
      "\n",
      "Second column: \\( 3 \\), \\( 2n - 9 \\), \\( n \\)\n",
      "\n",
      "Sum: \\( 3 + (2n - 9) + n = 3 + 2n - 9 + n = 3n - 6 \\)\n",
      "\n",
      "Third column: \\( n + 1 \\), \\( 1 \\), \\( n - 1 \\)\n",
      "\n",
      "Sum: \\( (n + 1) + 1 + (n - 1) = n + 1 + 1 + n - 1 = 2n + 1 \\)\n",
      "\n",
      "So, columns sum to \\( 2n + 1 \\), \\( 3n - 6 \\), \\( 2n + 1 \\). So, same as rows.\n",
      "\n",
      "Now, the diagonals. Let's compute them.\n",
      "\n",
      "Main diagonal (top-left to bottom-right): \\( n - 3 \\), \\( 2n - 9 \\), \\( n - 1 \\)\n",
      "\n",
      "Sum: \\( (n - 3) + (2n - 9) + (n - 1) = n - 3 + 2n - 9 + n - 1 = 4n - 13 \\)\n",
      "\n",
      "Other diagonal (top-right to bottom-left): \\( n + 1 \\), \\( 2n - 9 \\), \\( 2 \\)\n",
      "\n",
      "Sum: \\( (n + 1) + (2n - 9) + 2 = n + 1 + 2n - 9 + 2 = 3n - 6 \\)\n",
      "\n",
      "So, the two diagonals sum to \\( 4n - 13 \\) and \\( 3n - 6 \\). For it to be a magic square, these must be equal to the magic sum \\( S = 2n + 1 \\).\n",
      "\n",
      "So, set \\( 4n - 13 = 2n + 1 \\)\n",
      "\n",
      "Subtract \\( 2n \\) from both sides:\n",
      "\n",
      "\\( 2n - 13 = 1 \\)\n",
      "\n",
      "Add 13 to both sides:\n",
      "\n",
      "\\( 2n = 14 \\)\n",
      "\n",
      "Divide by 2:\n",
      "\n",
      "\\( n = 7 \\)\n",
      "\n",
      "Wait, but earlier, when I checked the columns, the second column summed to \\( 3n - 6 \\), which with \\( n = 7 \\) is \\( 21 - 6 = 15 \\), same as the other columns and rows. But the third column summed to \\( 2n + 1 = 15 \\), which is consistent. The diagonals summed to \\( 4n - 13 = 28 - 13 = 15 \\) and \\( 3n - 6 = 21 - 6 = 15 \\). So, all sums are 15 when \\( n = 7 \\).\n",
      "\n",
      "Wait, but earlier, I thought the third column summed to 12, which was a mistake. Let me recalculate the third column:\n",
      "\n",
      "Third column: \\( n + 1 \\), \\( 1 \\), \\( n - 1 \\)\n",
      "\n",
      "Substitute \\( n = 7 \\):\n",
      "\n",
      "\\( 7 + 1 = 8 \\), \\( 1 \\), \\( 7 - 1 = 6 \\)\n",
      "\n",
      "Sum: \\( 8 + 1 + 6 = 15 \\). Yes, that's correct. So, all columns sum to 15.\n",
      "\n",
      "Wait, so why did I think it summed to 12 before? Maybe I miscounted. Let me recount:\n",
      "\n",
      "Third column: \\( n + 1 \\), \\( 1 \\), \\( n - 1 \\)\n",
      "\n",
      "With \\( n = 7 \\):\n",
      "\n",
      "\\( 7 + 1 = 8 \\), \\( 1 \\), \\( 7 - 1 = 6 \\)\n",
      "\n",
      "8 + 1 + 6 = 15. Yes, that's correct.\n",
      "\n",
      "So, all columns sum to 15, and all rows and diagonals sum to 15. So, that's consistent.\n",
      "\n",
      "Wait, but in the initial problem, the third row was labeled as \\( 2 \\), \\( n \\), \\( n - 1 \\). So, with \\( n = 7 \\), that's 2, 7, 6. Which sums to 15. So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row was labeled as \\( 2 \\), \\( n \\), \\( n - 1 \\). So, with \\( n = 7 \\), that's 2, 7, 6. Which is correct.\n",
      "\n",
      "Wait, but in the Asymptote code, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, with \\( n = 7 \\), that's 2, 7, 6. Which is correct.\n",
      "\n",
      "So, all sums are 15. So, that's consistent.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the Asymptote code, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the Asymptote code, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So, that's correct.\n",
      "\n",
      "Wait, but in the initial problem, the third row is labeled as \"2\", \"n\", \"n-1\". So,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dataset_pos = 0\n",
    "input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "print(input_ids)\n",
    "print(\"===\")\n",
    "print(\"===\")\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "input_ids = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": base_prompt.format(question=input_ids),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "# input_ids = dataset_item[\"input_ids\"]\n",
    "# generated_ids = dataset_item[\"generated_ids\"]\n",
    "generated_ids = [\n",
    "    tokenizer.encode(\n",
    "        correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "\n",
    "# generated_tokens = tokenizer.apply_chat_template(\n",
    "#     [\n",
    "#         # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "#         {\"role\": \"user\", \"content\": example[\"question\"]},\n",
    "#     ],\n",
    "#     tokenize=True,\n",
    "#     add_generation_prompt=True,\n",
    "# )\n",
    "generated_tokens = input_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # start_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # end_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    input_ids = torch.tensor(input_ids).cuda()\n",
    "    input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "    # windows_amount = 100\n",
    "    # windows_amount = 200\n",
    "    # windows_amount = 300\n",
    "    windows_amount = 400\n",
    "    # windows_amount = 500\n",
    "    # windows_amount = 2\n",
    "    next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "        :, : WINDOW_SIZE * windows_amount\n",
    "    ]\n",
    "\n",
    "    # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "    original_embeds = (\n",
    "        # model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.base_model.model.get_input_embeddings()(next_true_tokens)\n",
    "        model.get_input_embeddings()(next_true_tokens)\n",
    "    ).to(torch.float32)\n",
    "    # ).to(torch.bfloat16)\n",
    "\n",
    "    # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    new_embeds_for_compression = original_embeds.reshape(\n",
    "        windows_amount, WINDOW_SIZE, -1\n",
    "    )\n",
    "    compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "    # start_embed = torch.rand_like(start_embed)\n",
    "    # compressed_part = torch.rand_like(compressed_part)\n",
    "    # end_embed = torch.rand_like(end_embed)\n",
    "    generated_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds,\n",
    "            start_embed,\n",
    "            compressed_part,\n",
    "            end_embed,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "    print(\"===\")\n",
    "    generated_ids_compressed = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=2800,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        # do_sample=True,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "    # break\n",
    "print(tokenizer.decode(generated_ids_compressed[-1]))\n",
    "# break\n",
    "# embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.',\n",
       " 'solution': 'Adding real parts and imaginary parts separately, we have $(2-(-4)+0+2)+(1+0-1+4)i=\\\\boxed{8+4i}$.',\n",
       " 'answer': '8+4i',\n",
       " 'subject': 'Algebra',\n",
       " 'level': 3,\n",
       " 'unique_id': 'train/algebra/3.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1621, 200, 1721, torch.Size([1, 2356]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids_compressed.shape[1], next_true_tokens.shape[\n",
    "    1\n",
    "], generated_ids_compressed.shape[1] + compressed_part.shape[1], torch.tensor(\n",
    "    generated_ids\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "# \"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\"\n",
    "\n",
    "# compressed\n",
    "# 'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2' \"\n",
    "# generated\n",
    "# \" + i, O is -4, P is -i, and S is 2 + 4i. So, substituting, it's (2 + i) - (-4) + (-i) + (2 + 4i).\\n\\nNow, let's simplify this step by step. I think the first thing I should do is handle the subtraction of a negative number, which is essentially addition. So, (2 + i) - (-4) is the same as (2 + i) + 4.\\n\\nSo, let's compute that:\\n\\n(2 + i) + 4 = 2 + 4 + i = 6 + i\\n\\nOkay, so that simplifies the first part to 6 + i.\\n\\nNow, let's move on to the next term, which is + (-i). So, we have 6 + i + (-i). Hmm, that's the same as 6 + i - i.\\n\\nWait, so i - i is zero, right? So, that simplifies to 6 + 0i, which is just 6.\\n\\nAlright, so after handling the first two terms, we're left with 6.\\n\\nNow, we need to add the last term, which is + (2 + 4i). So, 6 + (2 + 4i).\\n\\nLet's compute that:\\n\\n6 + 2 + 4i = 8 + 4i\\n\\nSo, putting it all together, A - O + P + S simplifies to 8 + 4i.\\n\\nWait a minute, let me double-check my steps to make sure I didn't make any mistakes.\\n\\nStarting with A - O + P + S:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nWait, hold on, I think I might have made a mistake there. Let me re-examine that step.\\n\\nSo, (2 + i) - (-4) is indeed 2 + i + 4, which is 6 + i. That part seems correct.\\n\\nThen, adding (-i) to that: 6 + i - i. Yep, that cancels out the i terms, leaving 6.\\n\\nThen, adding (2 + 4i) to 6: 6 + 2 + 4i = 8 + 4i. That seems correct.\\n\\nAlternatively, maybe I can approach this differently to verify. Let's group the real parts and the imaginary parts separately.\\n\\nSo, let's rewrite the expression A - O + P + S as:\\n\\n(A + P + S) - O\\n\\nGiven that, let's compute A + P + S first.\\n\\nA is 2 + i, P is -i, and S is 2 + 4i.\\n\\nSo, A + P + S = (2 + i) + (-i) + (2 + 4i)\\n\\nLet's compute the real parts and the imaginary parts separately.\\n\\nReal parts: 2 + 0 + 2 = 4\\n\\nImaginary parts: i - i + 4i = (1 - 1 + 4)i = 4i\\n\\nSo, A + P + S = 4 + 4i\\n\\nNow, subtract O, which is -4. So, (4 + 4i) - (-4) = 4 + 4i + 4 = 8 + 4i\\n\\nSame result as before. So, that seems consistent.\\n\\nAlternatively, another way to approach this could be to write all the terms in standard form (a + bi) and then combine them.\\n\\nSo, A = 2 + i\\n\\nO = -4 + 0i\\n\\nP = 0 - i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\\n\\nLet's compute each operation step by step.\\n\\nFirst, (2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = (2 + 4) + (i - 0i) = 6 + i\\n\\nThen, adding P: 6 + i + (0 - i) = 6 + i + 0 - i = 6 + (i - i) = 6 + 0i = 6\\n\\nThen, adding S: 6 + (2 + 4i) = 8 + 4i\\n\\nAgain, same result. So, regardless of the method, I end up with 8 + 4i.\\n\\nI think that's correct. Let me just quickly recap the steps to ensure I didn't skip anything or make any errors in arithmetic.\\n\\n1. Substitute each term into the expression: A - O + P + S becomes (2 + i) - (-4) + (-i) + (2 + 4i).\\n\\n2. Simplify the expression by handling the subtraction of a negative: (2 + i) + 4 + (-i) + (2 + 4i).\\n\\n3. Combine like terms: real parts (2 + 4 + 2) and imaginary parts (i - i + 4i).\\n\\n4. Compute real parts: 2 + 4 + 2 = 8\\n\\n5. Compute imaginary parts: i - i + 4i = 4i\\n\\n6. Combine: 8 + 4i\\n\\nAlternatively, grouping real and imaginary parts separately:\\n\\n1. Compute A + P + S: (2 + i) + (-i) + (2 + 4i) = (2 + 2) + (i - i + 4i) = 4 + 4i\\n\\n2. Subtract O: 4 + 4i - (-4) = 4 + 4i + 4 = 8 + 4i\\n\\nBoth methods lead to the same result, so I'm confident that 8 + 4i is the correct answer.\\n\\nI don't think I made any mistakes here. The key steps were substituting the values correctly and then simplifying step by step, handling the negative signs appropriately. Also, grouping real and imaginary parts separately helped me verify my result.\\n\\nSo, final answer: 8 + 4i\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Handle the subtraction of a negative number:\\n   \\\\[\\n   (2 + i) - (-4) = (2 + i) + 4 = 6 + i\\n   \\\\]\\n\\n2. Add the next term:\\n   \\\\[\\n   6 + i + (-i) = 6 + i - i = 6\\n   \\\\]\\n\\n3. Add the last term:\\n   \\\\[\\n   6 + (2 + 4i) = 6 + 2 + 4i = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" + i, O is -4, P is -i, and S is 2 + 4i. So, substituting, it's (2 + i) - (-4) + (-i) + (2 + 4i).\\n\\nNow, let's simplify this step by step. I think the first thing I should do is handle the subtraction of a negative number, which is essentially addition. So, (2 + i) - (-4) is the same as (2 + i) + 4.\\n\\nSo, let's compute that:\\n\\n(2 + i) + 4 = 2 + 4 + i = 6 + i\\n\\nOkay, so that simplifies the first part to 6 + i.\\n\\nNow, let's move on to the next term, which is + (-i). So, we have 6 + i + (-i). Hmm, that's the same as 6 + i - i.\\n\\nWait, so i - i is zero, right? So, that simplifies to 6 + 0i, which is just 6.\\n\\nAlright, so after handling the first two terms, we're left with 6.\\n\\nNow, we need to add the last term, which is + (2 + 4i). So, 6 + (2 + 4i).\\n\\nLet's compute that:\\n\\n6 + 2 + 4i = 8 + 4i\\n\\nSo, putting it all together, A - O + P + S simplifies to 8 + 4i.\\n\\nWait a minute, let me double-check my steps to make sure I didn't make any mistakes.\\n\\nStarting with A - O + P + S:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nWait, hold on, I think I might have made a mistake there. Let me re-examine that step.\\n\\nSo, (2 + i) - (-4) is indeed 2 + i + 4, which is 6 + i. That part seems correct.\\n\\nThen, adding (-i) to that: 6 + i - i. Yep, that cancels out the i terms, leaving 6.\\n\\nThen, adding (2 + 4i) to 6: 6 + 2 + 4i = 8 + 4i. That seems correct.\\n\\nAlternatively, maybe I can approach this differently to verify. Let's group the real parts and the imaginary parts separately.\\n\\nSo, let's rewrite the expression A - O + P + S as:\\n\\n(A + P + S) - O\\n\\nGiven that, let's compute A + P + S first.\\n\\nA is 2 + i, P is -i, and S is 2 + 4i.\\n\\nSo, A + P + S = (2 + i) + (-i) + (2 + 4i)\\n\\nLet's compute the real parts and the imaginary parts separately.\\n\\nReal parts: 2 + 0 + 2 = 4\\n\\nImaginary parts: i - i + 4i = (1 - 1 + 4)i = 4i\\n\\nSo, A + P + S = 4 + 4i\\n\\nNow, subtract O, which is -4. So, (4 + 4i) - (-4) = 4 + 4i + 4 = 8 + 4i\\n\\nSame result as before. So, that seems consistent.\\n\\nAlternatively, another way to approach this could be to write all the terms in standard form (a + bi) and then combine them.\\n\\nSo, A = 2 + i\\n\\nO = -4 + 0i\\n\\nP = 0 - i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\\n\\nLet's compute each operation step by step.\\n\\nFirst, (2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = (2 + 4) + (i - 0i) = 6 + i\\n\\nThen, adding P: 6 + i + (0 - i) = 6 + i + 0 - i = 6 + (i - i) = 6 + 0i = 6\\n\\nThen, adding S: 6 + (2 + 4i) = 8 + 4i\\n\\nAgain, same result. So, regardless of the method, I end up with 8 + 4i.\\n\\nI think that's correct. Let me just quickly recap the steps to ensure I didn't skip anything or make any errors in arithmetic.\\n\\n1. Substitute each term into the expression: A - O + P + S becomes (2 + i) - (-4) + (-i) + (2 + 4i).\\n\\n2. Simplify the expression by handling the subtraction of a negative: (2 + i) + 4 + (-i) + (2 + 4i).\\n\\n3. Combine like terms: real parts (2 + 4 + 2) and imaginary parts (i - i + 4i).\\n\\n4. Compute real parts: 2 + 4 + 2 = 8\\n\\n5. Compute imaginary parts: i - i + 4i = 4i\\n\\n6. Combine: 8 + 4i\\n\\nAlternatively, grouping real and imaginary parts separately:\\n\\n1. Compute A + P + S: (2 + i) + (-i) + (2 + 4i) = (2 + 2) + (i - i + 4i) = 4 + 4i\\n\\n2. Subtract O: 4 + 4i - (-4) = 4 + 4i + 4 = 8 + 4i\\n\\nBoth methods lead to the same result, so I'm confident that 8 + 4i is the correct answer.\\n\\nI don't think I made any mistakes here. The key steps were substituting the values correctly and then simplifying step by step, handling the negative signs appropriately. Also, grouping real and imaginary parts separately helped me verify my result.\\n\\nSo, final answer: 8 + 4i\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Handle the subtraction of a negative number:\\n   \\\\[\\n   (2 + i) - (-4) = (2 + i) + 4 = 6 + i\\n   \\\\]\\n\\n2. Add the next term:\\n   \\\\[\\n   6 + i + (-i) = 6 + i - i = 6\\n   \\\\]\\n\\n3. Add the last term:\\n   \\\\[\\n   6 + (2 + 4i) = 6 + 2 + 4i = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_think = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "generated_ids[-1].index(end_think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids_compressed[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nNow, let's add the real parts and the imaginary parts separately.\\n\\nReal parts: 2 (from A) + (-4) (from O) + 0 (from P) + 2 (from S) = 0\\n\\nImaginary parts: 1 (from A) + 0 (from O) + (-1) (from P) + 4 (from S) = 4\\n\\nSo, putting it all together, the expression simplifies to 0 + 4i, which is just 4i.\\n\\nWait, hold on, that doesn't seem right. Let me check my steps again.\\n\\nWait, when I separated the real and imaginary parts, I think I might have made a mistake in the signs.\\n\\nLet me try that again.\\n\\nStarting over:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nExpression: A - O + P + S\\n\\nSubstitute the values:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nNow, distribute the negative sign to O:\\n\\n2 + i + 4 - i + (-i) + 2 + 4i\\n\\nWait, hold on, that doesn't seem right. Let me do it step by step.\\n\\nFirst, A - O: (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nWait, that makes more sense. So, the expression simplifies to 8 + 4i.\\n\\nWait, so earlier I messed up the distribution. Let me correct that.\\n\\nSo, starting over:\\n\\nExpression: A - O + P + S\\n\\nSubstitute:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle A - O:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nSo, the final result is 8 + 4i.\\n\\nWait, so earlier I thought it was 4i, but that was incorrect. I must have made a mistake in distributing the negative sign or something.\\n\\nSo, the correct answer is 8 + 4i.\\n\\nBut let me verify once more.\\n\\nCompute A - O + P + S:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation step by step:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems correct. So, the final result is 8 + 4i.\\n\\nI think I initially made a mistake in the distribution step, but upon redoing it, I arrived at the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nStarting with the expression:\\n\\\\[ A - O + P + S \\\\]\\n\\nSubstitute the given values:\\n\\\\[ (2 + i) - (-4) + (-i) + (2 + 4i) \\\\]\\n\\nSimplify each operation step by step:\\n1. Compute \\\\( (2 + i) - (-4) \\\\):\\n   \\\\[ 2 + i + 4 = 6 + i \\\\]\\n2. Add \\\\( P \\\\):\\n   \\\\[ 6 + i + (-i) = 6 + 0i = 6 \\\\]\\n3. Add \\\\( S \\\\):\\n   \\\\[ 6 + (2 + 4i) = 8 + 4i \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<｜end▁of▁sentence｜>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 1536])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(torch.tensor(generated_ids[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLet’s denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLet’s assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLet’s let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLet’s denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1536])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 224256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_embeds torch.Size([1, 62, 1536])\n",
      "<｜begin▁of▁sentence｜><｜User｜>Here's a question: What do many people believe happens after you die?  Here are possible answers to this question: - stop moving - nothing - go to heaven - stop living - stop breathing  I believe the correct choice is \"go to heaven\", here's why:\n",
      "Answer:<｜Assistant｜><think>\n",
      "Okay, so I'm trying to figure out the answer is correct. Let me think about it again. I think the user is trying to figure out the correct answer to the question they're asking. They provided a list of answers, and I need to heaven, but I'm not sure if I'm sure if I'm on the right track. Let me break it down step by step. The question is about what people believe happens after you die. I know that when someone dies, they believe that people often believe in something called the afterlife, which is the belief that after you die, you don't need to move or anything else. So, the correct answer is \"go to heaven\", which is the correct answer. The other options, like stopping moving, nothing, stop breathing, etc., aren't correct\n"
     ]
    }
   ],
   "source": [
    "from hidden_capacity_reasoning.utils import WINDOW_SIZE, VISION_START, VISION_END\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "\n",
    "def _crop_past_key_values(model, past_key_values, max_length):\n",
    "    \"\"\"Crops the past key values up to a certain maximum length.\"\"\"\n",
    "    new_past = []\n",
    "    if model.config.is_encoder_decoder:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            new_past.append(\n",
    "                (\n",
    "                    past_key_values[idx][0][:, :, :max_length, :],\n",
    "                    past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    past_key_values[idx][2],\n",
    "                    past_key_values[idx][3],\n",
    "                )\n",
    "            )\n",
    "        past_key_values = tuple(new_past)\n",
    "    # gptbigcode is special and stores kv in shape (batch_size, seq_len, dim), if it's a multi_query model\n",
    "    elif \"gptbigcode\" in model.__class__.__name__.lower() or (\n",
    "        model.config.architectures is not None\n",
    "        and \"gptbigcode\" in model.config.architectures[0].lower()\n",
    "    ):\n",
    "        if model.config.multi_query:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :max_length, :]\n",
    "        else:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :, :max_length, :]\n",
    "    elif isinstance(past_key_values, DynamicCache):\n",
    "        past_key_values.crop(max_length)\n",
    "    elif past_key_values is not None:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            if past_key_values[idx] != ([], []):\n",
    "                new_past.append(\n",
    "                    (\n",
    "                        past_key_values[idx][0][:, :, :max_length, :],\n",
    "                        past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                new_past.append((past_key_values[idx][0], past_key_values[idx][1]))\n",
    "        past_key_values = tuple(new_past)\n",
    "    return past_key_values\n",
    "\n",
    "\n",
    "# model = trainer.model\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "        {\"role\": \"user\", \"content\": dataset[\"test\"].to_list()[:5][0][\"question\"]},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "with torch.no_grad(), torch.autocast(device_type=\"cuda\"):\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    temp_gen_size = 0\n",
    "    window_size = WINDOW_SIZE  # + 1\n",
    "    # new_tokens = 4\n",
    "    new_tokens = 1\n",
    "    generation_started = False\n",
    "    max_steps = (new_tokens + window_size) * 15\n",
    "    past_key_values_big = None\n",
    "    print(\"generated_embeds\", generated_embeds.shape)\n",
    "    for step in range(max_steps):\n",
    "        if temp_gen_size == window_size + new_tokens:\n",
    "            # print(\n",
    "            #     \"TOKENS FOR EMDED\",\n",
    "            #     tokenizer.decode(\n",
    "            #         generated_tokens[:, -(window_size + new_tokens) :][:, :WINDOW_SIZE]\n",
    "            #         .cpu()\n",
    "            #         .tolist()[0]\n",
    "            #     ),\n",
    "            # )\n",
    "            # tokenizer.decode(generated_tokens[:, : -window_size ].cpu().tolist()[0])\n",
    "            if hasattr(model.base_model, \"embed_pooler\"):\n",
    "                new_embeds_for_compression = (\n",
    "                    model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "                        generated_tokens[:, -(window_size + new_tokens) :][\n",
    "                            :, :WINDOW_SIZE\n",
    "                        ]\n",
    "                    )\n",
    "                ).to(torch.bfloat16)\n",
    "                compressed_part = model.base_model.embed_pooler(\n",
    "                    new_embeds_for_compression\n",
    "                )\n",
    "            else:\n",
    "                compressed_part = model.embed_pooler(new_embeds_for_compression)\n",
    "            # gen_embeds_prev = generated_tokens.shape[1]\n",
    "            if generation_started:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens + 1)],\n",
    "                        # generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        compressed_part,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            else:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 3,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        start_embed,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        compressed_part,\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "                generation_started = True\n",
    "            past_key_values_big = _crop_past_key_values(\n",
    "                model=model,\n",
    "                past_key_values=past_key_values_big,\n",
    "                max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "            )\n",
    "            temp_gen_size = 1\n",
    "\n",
    "        outputs = model(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            past_key_values=past_key_values_big,\n",
    "            # use_cache=False,\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        past_key_values_big = outputs.past_key_values\n",
    "        top_token = logits.argmax(-1)[-1][-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)], dim=1\n",
    "        )\n",
    "        # print(temp_gen_size, tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "        temp_gen_size += 1\n",
    "\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# я не знаю, может быть я неправильно управляюсь с KV-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1536])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4, 5, 6, 7, 8][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"test\"][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1536])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестируем на MATH-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c7030d672440a4a354c626420b4939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "1014 800 1414 1959\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "272 800 672 1125\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "905 800 1305 1548\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "3013 800 3413 3960\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "165 748 539 748\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "630 800 1030 1080\n",
      "===\n",
      "===\n",
      "===\n",
      "'NoneType' object has no attribute 'group'\n",
      "WRONG 3.21\n",
      " 1)\n",
      "0.3 x 0.3 = 0.09 (the second decimal place)\n",
      "So, adding them up: 0.39 + 0.09 = 0.39 + 0.09 = 0.48\n",
      "\n",
      "Wait, no, that's not right. Wait, 1.3 squared is actually 1.69, right? Because 1.3 times 1.3 is 1.69. Let me verify that:\n",
      "\n",
      "1.3\n",
      "x1.3\n",
      "--------\n",
      "0.39 (1.3 x 0.3)\n",
      "13.00 (1.3 x 1.0, shifted one position)\n",
      "--------\n",
      "1.69\n",
      "\n",
      "Yes, that's correct. So, \\( b^2 = 1.69 \\).\n",
      "\n",
      "Now, plug that into the equation \\( b^2 + c = 36 \\):\n",
      "\n",
      "\\( 1.69 + c = 36 \\)\n",
      "\n",
      "Subtract 1.69 from both sides to solve for c:\n",
      "\n",
      "\\( c = 36 - 1.69 \\)\n",
      "\n",
      "Calculating that, 36 minus 1.69 is:\n",
      "\n",
      "36.00\n",
      "-1.69\n",
      "--------\n",
      "34.31\n",
      "\n",
      "So, \\( c = 34.31 \\).\n",
      "\n",
      "Now, the problem asks for \\( b + c \\). We have \\( b = 1.3 \\) and \\( c = 34.31 \\).\n",
      "\n",
      "Adding them together:\n",
      "\n",
      "1.3 + 34.31\n",
      "\n",
      "Let me add those:\n",
      "\n",
      "1.3 is the same as 1.30\n",
      "\n",
      "So, 1.30 + 34.31 = 35.61\n",
      "\n",
      "Therefore, \\( b + c = 35.61 \\).\n",
      "\n",
      "Wait, let me double-check my calculations to make sure I didn't make a mistake.\n",
      "\n",
      "First, I found \\( b = 1.3 \\) because \\( 2b = 2.6 \\), so \\( b = 1.3 \\). That seems correct.\n",
      "\n",
      "Then, \\( b^2 = 1.3^2 = 1.69 \\). That's correct.\n",
      "\n",
      "Then, \\( 1.69 + c = 36 \\), so \\( c = 36 - 1.69 = 34.31 \\). That seems right.\n",
      "\n",
      "Adding \\( b + c = 1.3 + 34.31 = 35.61 \\). That seems correct.\n",
      "\n",
      "Wait, but let me make sure that when I completed the square, I didn't make any mistakes.\n",
      "\n",
      "Starting with \\( x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "To complete the square, I take the coefficient of x, which is 2.6, divide by 2 to get 1.3, square it to get 1.69, and then add and subtract that inside the equation.\n",
      "\n",
      "So, \\( x^2 + 2.6x + 1.69 - 1.69 + 3.6 \\).\n",
      "\n",
      "Wait, hold on, that's not exactly how I did it before. Let me write it step by step.\n",
      "\n",
      "The original quadratic is \\( x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "To complete the square, I take the coefficient of x, which is 2.6, divide by 2 to get 1.3, square it to get 1.69. Then, I add and subtract 1.69 inside the equation.\n",
      "\n",
      "So, \\( x^2 + 2.6x + 1.69 - 1.69 + 3.6 \\).\n",
      "\n",
      "This can be rewritten as \\( (x + 1.3)^2 - 1.69 + 3.6 \\).\n",
      "\n",
      "Simplifying the constants: \\( -1.69 + 3.6 \\).\n",
      "\n",
      "Calculating that: 3.6 - 1.69 = 1.91.\n",
      "\n",
      "Wait, hold on, that's different from what I got before. Earlier, I got \\( c = 34.31 \\), but now, according to this, it's 1.91.\n",
      "\n",
      "Wait, that's a discrepancy. So, which one is correct?\n",
      "\n",
      "Let me check my earlier steps.\n",
      "\n",
      "Wait, in the first method, I set \\( (x + b)^2 + c = x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "Expanding \\( (x + b)^2 + c \\) gives \\( x^2 + 2bx + b^2 + c \\).\n",
      "\n",
      "Setting coefficients equal:\n",
      "\n",
      "- Coefficient of x: 2b = 2.6 => b = 1.3\n",
      "- Constant term: b^2 + c = 3.6 => 1.69 + c = 3.6 => c = 3.6 - 1.69 = 1.91\n",
      "\n",
      "So, according to this, \\( c = 1.91 \\), not 34.31.\n",
      "\n",
      "Wait, so where did I go wrong earlier?\n",
      "\n",
      "Oh, I think I made a mistake in the second method. Let me re-examine that.\n",
      "\n",
      "I wrote \\( (x + b)^2 + c = x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "Expanding \\( (x + b)^2 + c \\) gives \\( x^2 + 2bx + b^2 + c \\).\n",
      "\n",
      "So, equating coefficients:\n",
      "\n",
      "- Coefficient of x: 2b = 2.6 => b = 1.3\n",
      "- Constant term: b^2 + c = 3.6 => 1.69 + c = 3.6 => c = 3.6 - 1.69 = 1.91\n",
      "\n",
      "So, that's correct. So, in my first method, I must have made a mistake.\n",
      "\n",
      "Wait, in my first method, I thought that \\( b^2 + c = 36 \\), but that's not correct. Wait, no, in the original problem, the constant term is 3.6, not 36.\n",
      "\n",
      "Wait, hold on, let me go back.\n",
      "\n",
      "Wait, in the first method, I set \\( (x + b)^2 + c = x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "Expanding \\( (x + b)^2 + c \\) gives \\( x^2 + 2bx + b^2 + c \\).\n",
      "\n",
      "So, equating coefficients:\n",
      "\n",
      "- Coefficient of x: 2b = 2.6 => b = 1.3\n",
      "- Constant term: b^2 + c = 3.6 => 1.69 + c = 3.6 => c = 3.6 - 1.69 = 1.91\n",
      "\n",
      "So, that's correct. So, in my first method, I must have confused the constant term with something else.\n",
      "\n",
      "Wait, in my first method, I thought that \\( b^2 + c = 36 \\), but that's not correct. The constant term is 3.6, not 36.\n",
      "\n",
      "So, that was my mistake. I think I added 36 instead of 3.6 somewhere.\n",
      "\n",
      "So, in the first method, I incorrectly set \\( b^2 + c = 36 \\), but it should be \\( b^2 + c = 3.6 \\). So, that's where I went wrong.\n",
      "\n",
      "So, correcting that, \\( c = 3.6 - 1.69 = 1.91 \\).\n",
      "\n",
      "Therefore, \\( b = 1.3 \\) and \\( c = 1.91 \\).\n",
      "\n",
      "So, \\( b + c = 1.3 + 1.91 = 3.21 \\).\n",
      "\n",
      "Wait, that's different from my earlier result. So, now, I have two different answers: 35.61 and 3.21.\n",
      "\n",
      "Wait, that can't be. So, I must have made a mistake in one of the methods.\n",
      "\n",
      "Let me double-check both methods.\n",
      "\n",
      "First method:\n",
      "\n",
      "Starting with \\( x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "Completing the square:\n",
      "\n",
      "Take half of 2.6, which is 1.3, square it to get 1.69.\n",
      "\n",
      "So, \\( x^2 + 2.6x + 1.69 - 1.69 + 3.6 \\).\n",
      "\n",
      "This can be written as \\( (x + 1.3)^2 - 1.69 + 3.6 \\).\n",
      "\n",
      "Simplifying the constants: \\( -1.69 + 3.6 = 1.91 \\).\n",
      "\n",
      "So, the quadratic can be written as \\( (x + 1.3)^2 + 1.91 \\).\n",
      "\n",
      "Therefore, \\( b = 1.3 \\) and \\( c = 1.91 \\).\n",
      "\n",
      "So, \\( b + c = 1.3 + 1.91 = 3.21 \\).\n",
      "\n",
      "Second method:\n",
      "\n",
      "Expanding \\( (x + b)^2 + c \\):\n",
      "\n",
      "\\( x^2 + 2bx + b^2 + c \\).\n",
      "\n",
      "Setting equal to \\( x^2 + 2.6x + 3.6 \\):\n",
      "\n",
      "- Coefficient of x: 2b = 2.6 => b = 1.3\n",
      "- Constant term: b^2 + c = 3.6 => 1.69 + c = 3.6 => c = 1.91\n",
      "\n",
      "So, same result: \\( b = 1.3 \\), \\( c = 1.91 \\), so \\( b + c = 3.21 \\).\n",
      "\n",
      "Wait, so why did I get 35.61 earlier? That must have been a mistake.\n",
      "\n",
      "Wait, in my first method, I thought that \\( b^2 + c = 36 \\), but that's incorrect. It should be \\( b^2 + c = 3.6 \\). So, that was my mistake.\n",
      "\n",
      "So, correcting that, both methods give the same result: \\( b = 1.3 \\), \\( c = 1.91 \\), so \\( b + c = 3.21 \\).\n",
      "\n",
      "Wait, but in my first attempt, I thought \\( b^2 + c = 36 \\), which is incorrect. So, that was my error.\n",
      "\n",
      "So, the correct answer is 3.21.\n",
      "\n",
      "Wait, but let me double-check by expanding \\( (x + 1.3)^2 + 1.91 \\) to see if it equals the original quadratic.\n",
      "\n",
      "Expanding \\( (x + 1.3)^2 \\):\n",
      "\n",
      "\\( x^2 + 2.6x + 1.69 \\).\n",
      "\n",
      "Adding 1.91:\n",
      "\n",
      "\\( x^2 + 2.6x + 1.69 + 1.91 = x^2 + 2.6x + 3.6 \\).\n",
      "\n",
      "Yes, that's correct. So, the quadratic is indeed \\( (x + 1.3)^2 + 1.91 \\).\n",
      "\n",
      "Therefore, \\( b = 1.3 \\), \\( c = 1.91 \\), so \\( b + c = 1.3 + 1.91 = 3.21 \\).\n",
      "\n",
      "So, the answer is 3.21.\n",
      "\n",
      "Wait, but in my first attempt, I thought \\( b^2 + c = 36 \\), which was incorrect. So, that was my mistake. So, the correct answer is 3.21.\n",
      "\n",
      "Wait, but let me think again. Maybe I should use another method to verify.\n",
      "\n",
      "Another method is to use the formula for completing the square.\n",
      "\n",
      "Given \\( ax^2 + bx + c \\), the vertex form is \\( a(x - h)^2 + k \\), where \\( h = -b/(2a) \\) and \\( k = c - b^2/(4a) \\).\n",
      "\n",
      "In this case, \\( a = 1 \\), \\( b = 2.6 \\), \\( c = 3.6 \\).\n",
      "\n",
      "So, \\( h = -2.6 / (2*1) = -1.3 \\).\n",
      "\n",
      "So, the vertex form is \\( (x - (-1.3))^2 + k \\) which is \\( (x + 1.3)^2 + k \\).\n",
      "\n",
      "Now, to find \\( k \\), we can plug in the vertex point into the original equation.\n",
      "\n",
      "The vertex is at \\( x = -1.3 \\), so plug that into \\( x^2 + 2.6x + 3.6 \\):\n",
      "\n",
      "\\( (-1.3)^2 + 2.6*(-1.3) + 3.6 \\).\n",
      "\n",
      "Calculating:\n",
      "\n",
      "\\( 1.69 - 3.38 + 3.6 \\).\n",
      "\n",
      "First, 1.69 - 3.38 = -1.69.\n",
      "\n",
      "Then, -1.69 + 3.6 = 1.91.\n",
      "\n",
      "So, \\( k = 1.91 \\).\n",
      "\n",
      "Therefore, the quadratic can be written as \\( (x + 1.3)^2 + 1.91 \\), so \\( b = 1.3 \\), \\( c = 1.91 \\), and \\( b + c = 3.21 \\).\n",
      "\n",
      "So, that confirms it.\n",
      "\n",
      "Wait, so why did I get confused earlier? Because I thought the constant term was 36, but it's actually 3.6. So, that was my mistake.\n",
      "\n",
      "So, the correct answer is 3.21.\n",
      "\n",
      "Wait, but let me make sure that I didn't make any calculation errors in the vertex method.\n",
      "\n",
      "Calculating \\( (-1.3)^2 = 1.69 \\).\n",
      "\n",
      "Calculating \\( 2.6*(-1.3) = -3.38 \\).\n",
      "\n",
      "Adding 3.6: 1.69 - 3.38 + 3.6.\n",
      "\n",
      "1.69 - 3.38 is -1.69.\n",
      "\n",
      "-1.69 + 3.6 is 1.91.\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "So, \\( k = 1.91 \\).\n",
      "\n",
      "Therefore, \\( b = 1.3 \\), \\( c = 1.91 \\), so \\( b + c = 3.21 \\).\n",
      "\n",
      "So, the answer is 3.21.\n",
      "\n",
      "Wait, but let me think again. The problem says \"the quadratic \\( x^2 + 2.6x + 3.6 \\) can be written in the form \\( (x + b)^2 + c \\), where \\( b \\) and \\( c \\) are constants. What is \\( b + c \\) (as a decimal)?\"\n",
      "\n",
      "So, according to both methods, it's 3.21.\n",
      "\n",
      "But wait, in my first method, I thought \\( b^2 + c = 36 \\), which was incorrect, but in the vertex method, it's 3.6.\n",
      "\n",
      "So, that was my mistake.\n",
      "\n",
      "So, the correct answer is 3.21.\n",
      "\n",
      "Wait, but let me check another way.\n",
      "\n",
      "Let me use the formula for completing the square.\n",
      "\n",
      "Given \\( x^2 + bx + c \\), the completed square is \\( (x + d)^2 + e \\), where \\( d = b/2 \\) and \\( e = c - d^2 \\).\n",
      "\n",
      "So, in this case, \\( b = 2.6 \\), so \\( d = 2.6 / 2 = 1.3 \\).\n",
      "\n",
      "Then, \\( e = c - d^2 = 3.6 - (1.3)^2 = 3.6 - 1.69 = 1.91 \\).\n",
      "\n",
      "So, \\( e = 1.91 \\).\n",
      "\n",
      "Therefore, the quadratic can be written as \\( (x + 1.3)^2 + 1.91 \\), so \\( b = 1.3 \\), \\( c = 1.91 \\), and \\( b + c = 3.21 \\).\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Therefore, the answer is 3.21.\n",
      "\n",
      "Wait, but let me think if there's another way to approach this.\n",
      "\n",
      "Alternatively, I can use the quadratic formula to find the vertex.\n",
      "\n",
      "The vertex of a quadratic \\( ax^2 + bx + c \\) is at \\( x = -b/(2a) \\).\n",
      "\n",
      "In this case, \\( a = 1 \\), \\( b = 2.6 \\), so \\( x = -2.6 / (2*1) = -1.3 \\).\n",
      "\n",
      "Then, the y-coordinate of the vertex is \\( f(-1.3) \\), which is \\( (-1.3)^2 + 2.6*(-1.3) + 3.6 \\).\n",
      "\n",
      "Calculating:\n",
      "\n",
      "1.69 - 3.38 + 3.6 = 1.91.\n",
      "\n",
      "So, the vertex is at \\( (-1.3, 1.91) \\), which means the quadratic can be written as \\( (x + 1.3)^2 + 1.91 \\).\n",
      "\n",
      "Therefore, \\( b = 1.3 \\), \\( c = 1.91 \\), so \\( b + c = 3.21 \\).\n",
      "\n",
      "So, that's consistent with all methods.\n",
      "\n",
      "Therefore, the answer is 3.21.\n",
      "\n",
      "Wait, but in my first method, I thought that \\( b^2 + c = 36 \\), which was incorrect, but in the vertex method, it's 3.6.\n",
      "\n",
      "So, that was my mistake.\n",
      "\n",
      "Therefore, the correct answer is 3.21.\n",
      "\n",
      "So, I think I've gone through all possible ways to verify this, and each time I get 3.21.\n",
      "\n",
      "Therefore, the answer is 3.21.\n",
      "\n",
      "**Final Answer**\n",
      "The value of \\( b + c \\) is \\boxed{3.21}.\n",
      "</think>\n",
      "\n",
      "To rewrite the quadratic \\( x^2 + 2.6x + 3.6 \\) in the form \\( (x + b)^2 + c \\), we need to complete the square.\n",
      "\n",
      "1. Start with the quadratic \\( x^2 + 2.6x + 3.6 \\).\n",
      "2. To complete the square, take half of the coefficient of \\( x \\), which is \\( 2.6 \\). Half of this is \\( 1.3 \\).\n",
      "3. Square \\( 1.3 \\) to get \\( 1.69 \\).\n",
      "4. Rewrite the quadratic as \\( (x + 1.3)^2 + c \\).\n",
      "5. Expand \\( (x + 1.3)^2 \\) to get \\( x^2 + 2.6x + 1.69 \\).\n",
      "6. Set the constant term equal to \\( 3.6 \\) and solve for \\( c \\):\n",
      "   \\[\n",
      "   1.69 + c = 3.6 \\implies\n",
      "4096 800 4496 1639\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG \\frac 59\n",
      " That is, 7 - 4 + 2 over 9.\n",
      "\n",
      "Calculating the numerator: 7 - 4 is 3, and 3 + 2 is 5. So, the numerator is 5, and the denominator is 9.\n",
      "\n",
      "Therefore, the result is \\(\\frac{5}{9}\\).\n",
      "\n",
      "Wait, let me double-check that. So, 7/9 minus 4/9 is 3/9, and then adding 2/9 gives 5/9. Yeah, that seems right.\n",
      "\n",
      "But just to make sure I didn't make any mistakes in converting the repeating decimals. Let me verify each conversion:\n",
      "\n",
      "For \\(0.\\overline{7}\\):\n",
      "\n",
      "Let x = 0.7777...\n",
      "\n",
      "10x = 7.7777...\n",
      "\n",
      "Subtract x: 10x - x = 7.7777... - 0.7777... = 7\n",
      "\n",
      "So, 9x = 7 => x = 7/9. Correct.\n",
      "\n",
      "For \\(0.\\overline{4}\\):\n",
      "\n",
      "Let y = 0.4444...\n",
      "\n",
      "10y = 4.4444...\n",
      "\n",
      "Subtract y: 10y - y = 4.4444... - 0.4444... = 4\n",
      "\n",
      "So, 9y = 4 => y = 4/9. Correct.\n",
      "\n",
      "For \\(0.\\overline{2}\\):\n",
      "\n",
      "Let z = 0.2222...\n",
      "\n",
      "10z = 2.2222...\n",
      "\n",
      "Subtract z: 10z - z = 2.2222... - 0.2222... = 2\n",
      "\n",
      "So, 9z = 2 => z = 2/9. Correct.\n",
      "\n",
      "So, all conversions are accurate. Then, substituting into the original expression:\n",
      "\n",
      "7/9 - 4/9 + 2/9. Since all denominators are 9, I can combine the numerators:\n",
      "\n",
      "7 - 4 + 2 = 5. So, 5/9. That seems correct.\n",
      "\n",
      "Wait, just to make sure, let me compute the decimal values to check if 5/9 is approximately equal to 0.7 - 0.4 + 0.2.\n",
      "\n",
      "Compute each decimal:\n",
      "\n",
      "0.7 is approximately 0.7\n",
      "\n",
      "0.4 is approximately 0.4\n",
      "\n",
      "0.2 is approximately 0.2\n",
      "\n",
      "So, 0.7 - 0.4 is 0.3, and 0.3 + 0.2 is 0.5.\n",
      "\n",
      "Now, 5/9 is approximately 0.5555... So, 0.5555... is slightly more than 0.5. Hmm, that seems a bit off. Wait, is that correct?\n",
      "\n",
      "Wait, let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 - 0.4 is 0.3, and 0.3 + 0.2 is 0.5. So, the exact value is 0.5, which is 1/2. But 5/9 is approximately 0.5555..., which is more than 0.5. So, that seems contradictory.\n",
      "\n",
      "Wait, so there must be a mistake here. Let me check my calculations again.\n",
      "\n",
      "Wait, hold on. Maybe I made a mistake in the arithmetic when combining the fractions.\n",
      "\n",
      "Wait, let me re-examine the original problem:\n",
      "\n",
      "\\(0.\\overline{7} - 0.\\overline{4} + 0.\\overline{2}\\)\n",
      "\n",
      "I converted each to fractions:\n",
      "\n",
      "7/9 - 4/9 + 2/9\n",
      "\n",
      "So, 7/9 - 4/9 is 3/9, which is 1/3, and then 1/3 + 2/9 is 3/9 + 2/9 = 5/9. So, that's correct.\n",
      "\n",
      "But when I converted 0.7 - 0.4 + 0.2, I get 0.5, which is 1/2. So, why is there a discrepancy?\n",
      "\n",
      "Wait, maybe I made a mistake in the decimal conversions. Let me double-check each one.\n",
      "\n",
      "First, \\(0.\\overline{7}\\):\n",
      "\n",
      "Let x = 0.7777...\n",
      "\n",
      "10x = 7.7777...\n",
      "\n",
      "10x - x = 7.7777... - 0.7777... = 7\n",
      "\n",
      "So, 9x = 7 => x = 7/9. Correct.\n",
      "\n",
      "Next, \\(0.\\overline{4}\\):\n",
      "\n",
      "Let y = 0.4444...\n",
      "\n",
      "10y = 4.4444...\n",
      "\n",
      "10y - y = 4.4444... - 0.4444... = 4\n",
      "\n",
      "So, 9y = 4 => y = 4/9. Correct.\n",
      "\n",
      "Next, \\(0.\\overline{2}\\):\n",
      "\n",
      "Let z = 0.2222...\n",
      "\n",
      "10z = 2.2222...\n",
      "\n",
      "10z - z = 2.2222... - 0.2222... = 2\n",
      "\n",
      "So, 9z = 2 => z = 2/9. Correct.\n",
      "\n",
      "So, the fractions are correct. So, 7/9 - 4/9 + 2/9 is indeed 5/9.\n",
      "\n",
      "But when I compute 0.7 - 0.4 + 0.2, I get 0.5, which is 1/2. So, why is there a difference?\n",
      "\n",
      "Wait, maybe I made a mistake in the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means there's a discrepancy here. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the arithmetic when combining the fractions. Let me check that again.\n",
      "\n",
      "So, 7/9 - 4/9 + 2/9.\n",
      "\n",
      "First, 7/9 - 4/9 = (7 - 4)/9 = 3/9 = 1/3.\n",
      "\n",
      "Then, 1/3 + 2/9.\n",
      "\n",
      "To add 1/3 and 2/9, I need a common denominator. The common denominator of 3 and 9 is 9.\n",
      "\n",
      "So, 1/3 is equal to 3/9.\n",
      "\n",
      "Therefore, 3/9 + 2/9 = 5/9.\n",
      "\n",
      "So, that's correct. So, 5/9 is the correct result.\n",
      "\n",
      "But when I compute the decimals, 0.7 - 0.4 + 0.2 is 0.5, which is 1/2. So, why is there a difference?\n",
      "\n",
      "Wait, maybe I made a mistake in the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me check each one again.\n",
      "\n",
      "First, \\(0.\\overline{7}\\):\n",
      "\n",
      "Let x = 0.7777...\n",
      "\n",
      "10x = 7.7777...\n",
      "\n",
      "10x - x = 7.7777... - 0.7777... = 7\n",
      "\n",
      "So, 9x = 7 => x = 7/9. Correct.\n",
      "\n",
      "Next, \\(0.\\overline{4}\\):\n",
      "\n",
      "Let y = 0.4444...\n",
      "\n",
      "10y = 4.4444...\n",
      "\n",
      "10y - y = 4.4444... - 0.4444... = 4\n",
      "\n",
      "So, 9y = 4 => y = 4/9. Correct.\n",
      "\n",
      "Next, \\(0.\\overline{2}\\):\n",
      "\n",
      "Let z = 0.2222...\n",
      "\n",
      "10z = 2.2222...\n",
      "\n",
      "10z - z = 2.2222... - 0.2222... = 2\n",
      "\n",
      "So, 9z = 2 => z = 2/9. Correct.\n",
      "\n",
      "So, the fractions are correct. So, 7/9 - 4/9 + 2/9 is 5/9.\n",
      "\n",
      "But when I compute 0.7 - 0.4 + 0.2 exactly, I get 0.5, which is 1/2. So, that's a problem.\n",
      "\n",
      "Wait, maybe I made a mistake in the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the arithmetic when combining the fractions. Let me check that again.\n",
      "\n",
      "So, 7/9 - 4/9 + 2/9.\n",
      "\n",
      "First, 7/9 - 4/9 = (7 - 4)/9 = 3/9 = 1/3.\n",
      "\n",
      "Then, 1/3 + 2/9.\n",
      "\n",
      "To add 1/3 and 2/9, I need a common denominator. The common denominator of 3 and 9 is 9.\n",
      "\n",
      "So, 1/3 is equal to 3/9.\n",
      "\n",
      "Therefore, 3/9 + 2/9 = 5/9.\n",
      "\n",
      "So, that's correct. So, 5/9 is the correct result.\n",
      "\n",
      "But when I compute the decimals, 0.7 - 0.4 + 0.2 is 0.5, which is 1/2. So, that's a problem.\n",
      "\n",
      "Wait, maybe I made a mistake in the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me check each one again.\n",
      "\n",
      "First, \\(0.\\overline{7}\\):\n",
      "\n",
      "Let x = 0.7777...\n",
      "\n",
      "10x = 7.7777...\n",
      "\n",
      "10x - x = 7.7777... - 0.7777... = 7\n",
      "\n",
      "So, 9x = 7 => x = 7/9. Correct.\n",
      "\n",
      "Next, \\(0.\\overline{4}\\):\n",
      "\n",
      "Let y = 0.4444...\n",
      "\n",
      "10y = 4.4444...\n",
      "\n",
      "10y - y = 4.4444... - 0.4444... = 4\n",
      "\n",
      "So, 9y = 4 => y = 4/9. Correct.\n",
      "\n",
      "Next, \\(0.\\overline{2}\\):\n",
      "\n",
      "Let z = 0.2222...\n",
      "\n",
      "10z = 2.2222...\n",
      "\n",
      "10z - z = 2.2222... - 0.2222... = 2\n",
      "\n",
      "So, 9z = 2 => z = 2/9. Correct.\n",
      "\n",
      "So, the fractions are correct. So, 7/9 - 4/9 + 2/9 is 5/9.\n",
      "\n",
      "But when I compute the decimals, 0.7 - 0.4 + 0.2 is 0.5, which is 1/2. So, that's a problem.\n",
      "\n",
      "Wait, maybe I made a mistake in the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them, I get 5/9, which is approximately 0.5555...\n",
      "\n",
      "So, that means that the two results are different. That can't be. So, where is the mistake?\n",
      "\n",
      "Wait, maybe I messed up the decimal conversions. Let me compute 0.7 - 0.4 + 0.2 exactly.\n",
      "\n",
      "0.7 is 7/10, 0.4 is 4/10, 0.2 is 2/10.\n",
      "\n",
      "So, 7/10 - 4/10 + 2/10 = (7 - 4 + 2)/10 = 5/10 = 1/2.\n",
      "\n",
      "Wait, so 0.7 - 0.4 + 0.2 is 0.5, which is 1/2, but when I convert each to fractions and add them,\n",
      "4096 800 4496 1732\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "393 800 793 1198\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 9\n",
      " 9 elements. Let me count them again: 3,5,7,11,13,17,19,23,29. Yep, that's 9 numbers. So, that's consistent.\n",
      "\n",
      "But wait, hold on a second. Is 1 considered an odd number? Because sometimes people get confused about whether 1 is odd or even. But no, 1 is odd because it's not divisible by 2. So, 1 is included in the second set. But in the first set, the primes less than 30 include 2, but not 1. So, 1 is only in the second set, not in the first. So, 1 is not in the intersection.\n",
      "\n",
      "Similarly, 9 is odd, but 9 is not a prime number. So, 9 is in the second set but not in the first. So, 9 is not in the intersection. Same with 15, 21, 25, 27, 29. These are odd but not prime, so they're not in the intersection.\n",
      "\n",
      "So, the intersection is indeed all the primes less than 30 except for 2. So, that's 9 elements. So, the answer should be 9.\n",
      "\n",
      "Wait, but let me make sure I didn't make a mistake in counting. Let me list out the primes less than 30 again: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 10 primes. Now, the odd numbers greater than zero less than 30 are: 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29. That's 15 numbers. So, the intersection is the numbers that are in both lists. So, looking at the primes: 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 9 numbers. So, that's correct.\n",
      "\n",
      "Alternatively, another way to think about it is that since all odd numbers greater than zero are in the second set, the intersection is just the set of primes in the first set that are also odd. But since all primes except 2 are odd, the intersection is all primes less than 30 except 2. So, that's 9 elements.\n",
      "\n",
      "Wait, but let me think again. Is 1 considered an odd number? Yes, 1 is odd. But 1 is not a prime number. So, it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is indeed all primes less than 30 except 2.\n",
      "\n",
      "So, the number of elements in the intersection is 9.\n",
      "\n",
      "But just to be thorough, let me list out the primes less than 30 again: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 10 primes. Now, the odd numbers greater than zero less than 30 are: 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29. That's 15 numbers. So, the intersection is the numbers that are in both lists. So, looking at the primes: 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 9 numbers. So, that's consistent.\n",
      "\n",
      "Alternatively, another way to think about it is that the intersection of the two sets is the set of numbers that are both prime and odd. Since all primes except 2 are odd, the intersection is all primes less than 30 except 2. So, that's 9 elements.\n",
      "\n",
      "Wait, but let me make sure I didn't miscount. Let me count the primes less than 30: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 10 primes. So, if I exclude 2, that's 9 primes. So, the intersection has 9 elements.\n",
      "\n",
      "Alternatively, if I think about the second set, which is all odd numbers greater than zero less than 30. So, that's 15 numbers. The intersection is the overlap between these two sets. So, the primes in the second set are the odd primes less than 30. So, that's 9 numbers. So, that's consistent.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2.\n",
      "\n",
      "So, that's 9 elements.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can use set theory to find the intersection. The intersection of two sets A and B is A ∩ B. So, A is the set of primes less than 30, and B is the set of odd numbers greater than zero. So, A ∩ B is the set of numbers that are both prime and odd and less than 30. Since all primes except 2 are odd, and 2 is the only even prime, so A ∩ B is all primes less than 30 except 2. So, that's 9 elements.\n",
      "\n",
      "Alternatively, if I think about it in terms of counting, the number of primes less than 30 is 10, as listed earlier. The number of odd numbers greater than zero less than 30 is 15. But the intersection is the overlap between these two sets. Since all primes except 2 are odd, the intersection is 10 - 1 = 9.\n",
      "\n",
      "Wait, that's another way to think about it. So, the total number of primes less than 30 is 10. The total number of odd numbers greater than zero less than 30 is 15. But the intersection is the number of primes that are also odd, which is 9, because 2 is the only even prime. So, that's another way to see it.\n",
      "\n",
      "So, in conclusion, the number of elements in the intersection is 9.\n",
      "\n",
      "But just to make sure, let me list out the primes less than 30 again: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 10 primes. Now, the odd numbers greater than zero less than 30 are: 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29. That's 15 numbers. So, the intersection is the numbers that are in both lists. So, looking at the primes: 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 9 numbers. So, that's consistent.\n",
      "\n",
      "Alternatively, if I think about it in terms of Venn diagrams, the intersection would be the part of the prime set that doesn't include 2, so that's 9 elements.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can use the principle of inclusion-exclusion. But in this case, since we're looking for the intersection, not the union, inclusion-exclusion might not be necessary. But just for fun, let me see.\n",
      "\n",
      "The number of elements in the intersection is equal to the number of primes less than 30 minus the number of primes less than 30 that are even. But since the only even prime is 2, that's 1. So, 10 - 1 = 9. So, that's another way to see it.\n",
      "\n",
      "So, that's consistent as well.\n",
      "\n",
      "Wait, but let me make sure I didn't make a mistake in counting the primes less than 30. Let me list them again: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 10 primes. So, that's correct.\n",
      "\n",
      "So, the intersection is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, I think that's consistent.\n",
      "\n",
      "Wait, but let me think about another way. Maybe I can list out the primes less than 30 and then cross out the even ones. So, primes less than 30: 2, 3, 5, 7, 11, 13, 17, 19, 23, 29. Now, cross out 2, which is the only even prime. So, the remaining primes are 3, 5, 7, 11, 13, 17, 19, 23, 29. That's 9 numbers. So, that's another way to see it.\n",
      "\n",
      "So, that's consistent as well.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can think about the definition of the intersection. The intersection of two sets is the set of elements that are in both sets. So, in this case, the first set is all primes less than 30, and the second set is all odd numbers greater than zero. So, the intersection is the set of numbers that are both prime and odd and less than 30. Since all primes except 2 are odd, the intersection is all primes less than 30 except 2. So, that's 9 elements.\n",
      "\n",
      "Alternatively, if I think about it in terms of counting, the number of primes less than 30 is 10, as listed earlier. The number of odd numbers greater than zero less than 30 is 15. But the intersection is the number of primes that are also odd, which is 9, because 2 is the only even prime. So, that's another way to see it.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another way. Maybe I can use the formula for the intersection of two sets. The formula is |A ∩ B| = |A| + |B| - |A ∪ B|. But wait, that's for the union. For the intersection, I don't think there's a direct formula. So, maybe that's not helpful here.\n",
      "\n",
      "Alternatively, if I think about the Venn diagram, the intersection would be the part of the prime set that doesn't include 2, so that's 9 elements.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can think about the definition of odd numbers. An odd number is any integer that can be written as 2k + 1, where k is an integer. So, all odd numbers greater than zero are numbers like 1, 3, 5, 7, etc. So, the second set is all such numbers. The first set is all primes less than 30. So, the intersection is the set of numbers that are both prime and odd and less than 30. Since all primes except 2 are odd, the intersection is all primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another way. Maybe I can think about the definition of odd numbers. An odd number is any integer that is not divisible by 2. So, the second set is all numbers greater than zero that are not divisible by 2. The first set is all primes less than 30. So, the intersection is the set of numbers that are both prime and not divisible by 2 and less than 30. Since all primes except 2 are not divisible by 2, the intersection is all primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can think about the definition of prime numbers. A prime number is a number greater than 1 that has no positive divisors other than 1 and itself. So, all primes except 2 are odd because 2 is the only even prime. So, the intersection of the two sets is all primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another way. Maybe I can think about the definition of odd numbers. An odd number is any integer that can be written as 2k + 1, where k is an integer. So, all odd numbers greater than zero are numbers like 1, 3, 5, 7, etc. So, the second set is all such numbers. The first set is all primes less than 30. So, the intersection is the set of numbers that are both prime and odd and less than 30. Since all primes except 2 are odd, the intersection is all primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can think about the definition of odd numbers. An odd number is any integer that is not divisible by 2. So, the second set is all numbers greater than zero that are not divisible by 2. The first set is all primes less than 30. So, the intersection is the set of numbers that are both prime and not divisible by 2 and less than 30. Since all primes except 2 are not divisible by 2, the intersection is all primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so it's not in the first set. So, 1 is not in the intersection. Similarly, 9 is odd but not prime, so it's not in the intersection. So, the intersection is all the primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "So, that's consistent.\n",
      "\n",
      "Wait, but let me think about another angle. Maybe I can think about the definition of odd numbers. An odd number is any integer that is not divisible by 2. So, the second set is all numbers greater than zero that are not divisible by 2. The first set is all primes less than 30. So, the intersection is the set of numbers that are both prime and not divisible by 2 and less than 30. Since all primes except 2 are not divisible by 2, the intersection is all primes less than 30 except 2, which is 9 elements.\n",
      "\n",
      "Wait, but let me think about whether 1 is included in the second set. Yes, 1 is an odd number, so it's in the second set. But 1 is not a prime number, so\n",
      "4096 800 4496 2314\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "922 800 1322 1262\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "914 800 1314 1176\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "980 800 1380 1482\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "270 800 670 814\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG x^5 - x^4 + x^3 - x^2 + x - 1\n",
      "^2 - 3 \\). \n",
      "\n",
      "Next, divide \\( x^2 \\) by \\( x \\) to get \\( x \\). That's the next term in the quotient. \n",
      "\n",
      "Multiply \\( x + 1 \\) by \\( x \\): \\( x*(x + 1) = x^2 + x \\). \n",
      "\n",
      "Subtract this from the current dividend: \\( (x^2 - 3) - (x^2 + x) = -x - 3 \\). \n",
      "\n",
      "Now, divide \\( -x \\) by \\( x \\) to get \\( -1 \\). That's the next term in the quotient. \n",
      "\n",
      "Multiply \\( x + 1 \\) by \\( -1 \\): \\( -1*(x + 1) = -x - 1 \\). \n",
      "\n",
      "Subtract this from the current dividend: \\( (-x - 3) - (-x - 1) = -2 \\). \n",
      "\n",
      "So, the remainder is \\( -2 \\), and the quotient is \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\). \n",
      "\n",
      "Let me double-check my work to make sure I didn't make any mistakes. \n",
      "\n",
      "Starting with \\( x^6 - 3 \\), I divided by \\( x + 1 \\) and got a quotient of \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\) with a remainder of \\( -2 \\). \n",
      "\n",
      "To verify, I can multiply the divisor by the quotient and add the remainder to see if I get the original dividend. \n",
      "\n",
      "So, let's compute \\( (x + 1)*(x^5 - x^4 + x^3 - x^2 + x - 1) \\). \n",
      "\n",
      "First, multiply \\( x \\) by each term in the quotient: \n",
      "- \\( x * x^5 = x^6 \\)\n",
      "- \\( x * (-x^4) = -x^5 \\)\n",
      "- \\( x * x^3 = x^4 \\)\n",
      "- \\( x * (-x^2) = -x^3 \\)\n",
      "- \\( x * x = x^2 \\)\n",
      "- \\( x * (-1) = x \\)\n",
      "\n",
      "Next, multiply \\( 1 \\) by each term in the quotient: \n",
      "- \\( 1 * x^5 = x^5 \\)\n",
      "- \\( 1 * (-x^4) = -x^4 \\)\n",
      "- \\( 1 * x^3 = x^3 \\)\n",
      "- \\( 1 * (-x^2) = -x^2 \\)\n",
      "- \\( 1 * x = x \\)\n",
      "- \\( 1 * (-1) = -1 \\)\n",
      "\n",
      "Now, add all these terms together:\n",
      "- \\( x^6 \\)\n",
      "- \\( -x^5 + x^5 = 0 \\)\n",
      "- \\( x^4 - x^4 = 0 \\)\n",
      "- \\( -x^3 + x^3 = 0 \\)\n",
      "- \\( x^2 - x^2 = 0 \\)\n",
      "- \\( x + x = 2x \\)\n",
      "- \\( -1 \\)\n",
      "\n",
      "So, the result is \\( x^6 + 2x - 1 \\). \n",
      "\n",
      "Wait, but the original dividend was \\( x^6 - 3 \\). Hmm, that's not the same. So, where did I go wrong? \n",
      "\n",
      "Let me check the multiplication again. Maybe I made a mistake in the multiplication or subtraction steps. \n",
      "\n",
      "Let me try multiplying \\( (x + 1) \\) by the quotient \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\) again, step by step.\n",
      "\n",
      "First, multiply \\( x \\) by each term:\n",
      "- \\( x * x^5 = x^6 \\)\n",
      "- \\( x * (-x^4) = -x^5 \\)\n",
      "- \\( x * x^3 = x^4 \\)\n",
      "- \\( x * (-x^2) = -x^3 \\)\n",
      "- \\( x * x = x^2 \\)\n",
      "- \\( x * (-1) = x \\)\n",
      "\n",
      "Then, multiply \\( 1 \\) by each term:\n",
      "- \\( 1 * x^5 = x^5 \\)\n",
      "- \\( 1 * (-x^4) = -x^4 \\)\n",
      "- \\( 1 * x^3 = x^3 \\)\n",
      "- \\( 1 * (-x^2) = -x^2 \\)\n",
      "- \\( 1 * x = x \\)\n",
      "- \\( 1 * (-1) = -1 \\)\n",
      "\n",
      "Now, add all these terms together:\n",
      "- \\( x^6 \\)\n",
      "- \\( -x^5 + x^5 = 0 \\)\n",
      "- \\( x^4 - x^4 = 0 \\)\n",
      "- \\( -x^3 + x^3 = 0 \\)\n",
      "- \\( x^2 - x^2 = 0 \\)\n",
      "- \\( x + x = 2x \\)\n",
      "- \\( -1 \\)\n",
      "\n",
      "So, the result is \\( x^6 + 2x - 1 \\). \n",
      "\n",
      "But the original dividend is \\( x^6 - 3 \\). So, the remainder is \\( x^6 + 2x - 1 - (x^6 - 3) = 2x + 2 \\). Wait, that can't be right. \n",
      "\n",
      "Wait, no, actually, when I multiply the divisor by the quotient, I should get the dividend plus the remainder. So, if I have \\( (x + 1)*(quotient) = dividend + remainder \\). \n",
      "\n",
      "So, in this case, \\( (x + 1)*(x^5 - x^4 + x^3 - x^2 + x - 1) = x^6 - 3 + remainder \\). \n",
      "\n",
      "But when I computed the product, I got \\( x^6 + 2x - 1 \\). So, that means the remainder is \\( x^6 + 2x - 1 - (x^6 - 3) = 2x + 2 \\). \n",
      "\n",
      "Wait, that doesn't make sense because the remainder should be a constant. So, where is the mistake? \n",
      "\n",
      "Let me check the multiplication again. Maybe I messed up the signs somewhere. \n",
      "\n",
      "Let me write down the multiplication step by step:\n",
      "\n",
      "First, multiply \\( x \\) by each term in the quotient:\n",
      "- \\( x * x^5 = x^6 \\)\n",
      "- \\( x * (-x^4) = -x^5 \\)\n",
      "- \\( x * x^3 = x^4 \\)\n",
      "- \\( x * (-x^2) = -x^3 \\)\n",
      "- \\( x * x = x^2 \\)\n",
      "- \\( x * (-1) = x \\)\n",
      "\n",
      "Then, multiply \\( 1 \\) by each term:\n",
      "- \\( 1 * x^5 = x^5 \\)\n",
      "- \\( 1 * (-x^4) = -x^4 \\)\n",
      "- \\( 1 * x^3 = x^3 \\)\n",
      "- \\( 1 * (-x^2) = -x^2 \\)\n",
      "- \\( 1 * x = x \\)\n",
      "- \\( 1 * (-1) = -1 \\)\n",
      "\n",
      "Now, add all these terms together:\n",
      "- \\( x^6 \\)\n",
      "- \\( -x^5 + x^5 = 0 \\)\n",
      "- \\( x^4 - x^4 = 0 \\)\n",
      "- \\( -x^3 + x^3 = 0 \\)\n",
      "- \\( x^2 - x^2 = 0 \\)\n",
      "- \\( x + x = 2x \\)\n",
      "- \\( -1 \\)\n",
      "\n",
      "So, the product is \\( x^6 + 2x - 1 \\). \n",
      "\n",
      "But the original dividend is \\( x^6 - 3 \\). So, the difference between the product and the dividend is \\( (x^6 + 2x - 1) - (x^6 - 3) = 2x + 2 \\). \n",
      "\n",
      "Wait, that means the remainder is \\( 2x + 2 \\), but the remainder should be of degree less than 1, i.e., a constant. So, where is the mistake? \n",
      "\n",
      "Hmm, maybe I made a mistake in the polynomial division process. Let me try a different approach. Maybe I should use synthetic division instead. \n",
      "\n",
      "Synthetic division is usually quicker when dividing by a linear term of the form \\( x - c \\). In this case, the divisor is \\( x + 1 \\), which can be written as \\( x - (-1) \\). So, c is -1. \n",
      "\n",
      "Let me set up synthetic division with c = -1 and the coefficients of the dividend \\( x^6 - 3 \\). \n",
      "\n",
      "The dividend is \\( x^6 + 0x^5 + 0x^4 + 0x^3 + 0x^2 + 0x - 3 \\). So, the coefficients are 1, 0, 0, 0, 0, 0, -3. \n",
      "\n",
      "Now, I'll write down the coefficients: 1, 0, 0, 0, 0, 0, -3. \n",
      "\n",
      "Bring down the first coefficient: 1. \n",
      "\n",
      "Multiply by c = -1: 1 * (-1) = -1. \n",
      "\n",
      "Add to the next coefficient: 0 + (-1) = -1. \n",
      "\n",
      "Multiply by c = -1: -1 * (-1) = 1. \n",
      "\n",
      "Add to the next coefficient: 0 + 1 = 1. \n",
      "\n",
      "Multiply by c = -1: 1 * (-1) = -1. \n",
      "\n",
      "Add to the next coefficient: 0 + (-1) = -1. \n",
      "\n",
      "Multiply by c = -1: -1 * (-1) = 1. \n",
      "\n",
      "Add to the next coefficient: 0 + 1 = 1. \n",
      "\n",
      "Multiply by c = -1: 1 * (-1) = -1. \n",
      "\n",
      "Add to the next coefficient: -3 + (-1) = -4. \n",
      "\n",
      "So, the last coefficient is the remainder, which is -4, and the other coefficients are the quotient coefficients. \n",
      "\n",
      "So, the quotient is \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\) with a remainder of -4. \n",
      "\n",
      "Wait, but earlier, when I multiplied the divisor by the quotient, I got a remainder of \\( 2x + 2 \\), which is conflicting with this result. \n",
      "\n",
      "Hmm, maybe I made a mistake in the multiplication. Let me try multiplying \\( (x + 1) \\) by the quotient \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\) again. \n",
      "\n",
      "First, multiply \\( x \\) by each term:\n",
      "- \\( x * x^5 = x^6 \\)\n",
      "- \\( x * (-x^4) = -x^5 \\)\n",
      "- \\( x * x^3 = x^4 \\)\n",
      "- \\( x * (-x^2) = -x^3 \\)\n",
      "- \\( x * x = x^2 \\)\n",
      "- \\( x * (-1) = x \\)\n",
      "\n",
      "Then, multiply \\( 1 \\) by each term:\n",
      "- \\( 1 * x^5 = x^5 \\)\n",
      "- \\( 1 * (-x^4) = -x^4 \\)\n",
      "- \\( 1 * x^3 = x^3 \\)\n",
      "- \\( 1 * (-x^2) = -x^2 \\)\n",
      "- \\( 1 * x = x \\)\n",
      "- \\( 1 * (-1) = -1 \\)\n",
      "\n",
      "Now, add all these terms together:\n",
      "- \\( x^6 \\)\n",
      "- \\( -x^5 + x^5 = 0 \\)\n",
      "- \\( x^4 - x^4 = 0 \\)\n",
      "- \\( -x^3 + x^3 = 0 \\)\n",
      "- \\( x^2 - x^2 = 0 \\)\n",
      "- \\( x + x = 2x \\)\n",
      "- \\( -1 \\)\n",
      "\n",
      "So, the product is \\( x^6 + 2x - 1 \\). \n",
      "\n",
      "But the original dividend is \\( x^6 - 3 \\). So, the difference is \\( (x^6 + 2x - 1) - (x^6 - 3) = 2x + 2 \\). \n",
      "\n",
      "Wait, that means the remainder is \\( 2x + 2 \\), but the remainder should be a constant. So, where is the mistake? \n",
      "\n",
      "Wait, maybe I made a mistake in the synthetic division process. Let me check the synthetic division again. \n",
      "\n",
      "Coefficients: 1, 0, 0, 0, 0, 0, -3. \n",
      "\n",
      "Bring down the 1. \n",
      "\n",
      "Multiply by -1: 1 * (-1) = -1. Add to next coefficient: 0 + (-1) = -1. \n",
      "\n",
      "Multiply by -1: -1 * (-1) = 1. Add to next coefficient: 0 + 1 = 1. \n",
      "\n",
      "Multiply by -1: 1 * (-1) = -1. Add to next coefficient: 0 + (-1) = -1. \n",
      "\n",
      "Multiply by -1: -1 * (-1) = 1. Add to next coefficient: 0 + 1 = 1. \n",
      "\n",
      "Multiply by -1: 1 * (-1) = -1. Add to next coefficient: -3 + (-1) = -4. \n",
      "\n",
      "So, the quotient is \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\) and the remainder is -4. \n",
      "\n",
      "But when I multiply the divisor by the quotient, I get \\( x^6 + 2x - 1 \\), which is not equal to the original dividend \\( x^6 - 3 \\). \n",
      "\n",
      "Wait, so there must be a mistake in the synthetic division. Let me try another approach. \n",
      "\n",
      "Alternatively, maybe I should use polynomial long division step by step, keeping track of the remainder. \n",
      "\n",
      "Let me try that. \n",
      "\n",
      "Dividend: \\( x^6 - 3 \\). Divisor: \\( x + 1 \\). \n",
      "\n",
      "First, divide \\( x^6 \\) by \\( x \\) to get \\( x^5 \\). Multiply \\( x + 1 \\) by \\( x^5 \\) to get \\( x^6 + x^5 \\). Subtract this from the dividend: \\( (x^6 - 3) - (x^6 + x^5) = -x^5 - 3 \\). \n",
      "\n",
      "Next, divide \\( -x^5 \\) by \\( x \\) to get \\( -x^4 \\). Multiply \\( x + 1 \\) by \\( -x^4 \\) to get \\( -x^5 - x^4 \\). Subtract this from the current dividend: \\( (-x^5 - 3) - (-x^5 - x^4) = x^4 - 3 \\). \n",
      "\n",
      "Next, divide \\( x^4 \\) by \\( x \\) to get \\( x^3 \\). Multiply \\( x + 1 \\) by \\( x^3 \\) to get \\( x^4 + x^3 \\). Subtract this from the current dividend: \\( (x^4 - 3) - (x^4 + x^3) = -x^3 - 3 \\). \n",
      "\n",
      "Next, divide \\( -x^3 \\) by \\( x \\) to get \\( -x^2 \\). Multiply \\( x + 1 \\) by \\( -x^2 \\) to get \\( -x^3 - x^2 \\). Subtract this from the current dividend: \\( (-x^3 - 3) - (-x^3 - x^2) = x^2 - 3 \\). \n",
      "\n",
      "Next, divide \\( x^2 \\) by \\( x \\) to get \\( x \\). Multiply \\( x + 1 \\) by \\( x \\) to get \\( x^2 + x \\). Subtract this from the current dividend: \\( (x^2 - 3) - (x^2 + x) = -x - 3 \\). \n",
      "\n",
      "Next, divide \\( -x \\) by \\( x \\) to get \\( -1 \\). Multiply \\( x + 1 \\) by \\( -1 \\) to get \\( -x - 1 \\). Subtract this from the current dividend: \\( (-x - 3) - (-x - 1) = -2 \\). \n",
      "\n",
      "So, the quotient is \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\) and the remainder is \\( -2 \\). \n",
      "\n",
      "Wait, but when I multiplied the divisor by the quotient, I got \\( x^6 + 2x - 1 \\), which is not equal to the original dividend \\( x^6 - 3 \\). So, where is the mistake? \n",
      "\n",
      "Wait, let me check the multiplication again. \n",
      "\n",
      "Quotient: \\( x^5 - x^4 + x^3 - x^2 + x - 1 \\). \n",
      "\n",
      "Multiply by \\( x + 1 \\):\n",
      "\n",
      "First, \\( x^5 * x = x^6 \\). \n",
      "\n",
      "Then, \\( x^5 * 1 = x^5 \\). \n",
      "\n",
      "Next, \\( -x^4 * x = -x^5 \\). \n",
      "\n",
      "Then, \\( -x^4 * 1 = -x^4 \\). \n",
      "\n",
      "Next, \\( x^3 * x = x^4 \\). \n",
      "\n",
      "Then, \\( x^3 * 1 = x^3 \\). \n",
      "\n",
      "Next, \\( -x^2 * x = -x^3 \\). \n",
      "\n",
      "Then, \\( -x^2 * 1 = -x^2 \\). \n",
      "\n",
      "Next, \\( x * x = x^2 \\). \n",
      "\n",
      "Then, \\( x * 1 = x \\). \n",
      "\n",
      "Finally, \\( -1 * x = -x \\). \n",
      "\n",
      "And \\( -1 * 1 = -1 \\). \n",
      "\n",
      "Now, add all these terms together:\n",
      "\n",
      "- \\( x^6 \\)\n",
      "- \\( x^5 - x^5 = 0 \\)\n",
      "- \\( -x^4 + x^4 = 0 \\)\n",
      "- \\( x^3 - x^3 = 0 \\)\n",
      "- \\( -x^2 + x^2 = 0 \\)\n",
      "- \\( x - x = 0 \\)\n",
      "- \\( -1 \\)\n",
      "\n",
      "So, the product is \\( x^6 - 1 \\). \n",
      "\n",
      "But the original dividend is \\( x^6 - 3 \\). So, the difference is \\( (x^6 - 1) - (x^6 - 3) = 2 \\). \n",
      "\n",
      "Wait, that means the remainder is 2, but the remainder should be a constant. So, where is the mistake? \n",
      "\n",
      "Wait, no, actually, the remainder is \\( -1 \\) when I multiply the divisor by the quotient, but the original dividend is \\( x^6 - 3 \\). So, the difference is \\( (x^6 - 1) - (x^6 - 3) = 2 \\). \n",
      "\n",
      "So, that means the remainder is 2, but the remainder should be a constant. So, where is the mistake? \n",
      "\n",
      "Wait, no, actually, the remainder is \\( -1 \\), but\n",
      "4096 800 4496 2318\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1711 800 2111 2469\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1129 800 1529 1907\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG -13x+3\n",
      "7) - (-1)^6 - 12*(-1)^5 + 4*(-1)^4 - 8*(-1)^3 + 12*(-1)^2 -5*(-1) -5\n",
      "\n",
      "Wait, that seems complicated. Let me compute each term step by step.\n",
      "\n",
      "First, let's write out each term:\n",
      "\n",
      "1. (-1)^10 = 1\n",
      "\n",
      "2. 5*(-1)^9 = 5*(-1) = -5\n",
      "\n",
      "3. -8*(-1)^8 = -8*(1) = -8\n",
      "\n",
      "4. 7*(-1)^7 = 7*(-1) = -7\n",
      "\n",
      "5. -12*(-1)^6 = -12*(1) = -12\n",
      "\n",
      "6. 4*(-1)^4 = 4*(1) = 4\n",
      "\n",
      "7. -8*(-1)^3 = -8*(-1) = 8\n",
      "\n",
      "8. 12*(-1)^2 = 12*(1) = 12\n",
      "\n",
      "9. -5*(-1) = 5\n",
      "\n",
      "10. -5\n",
      "\n",
      "Now, let's add them all up:\n",
      "\n",
      "1 - 5 - 8 - 7 -12 + 4 + 8 + 12 + 5 -5\n",
      "\n",
      "Let me compute step by step:\n",
      "\n",
      "Start with 1.\n",
      "\n",
      "1 - 5 = -4\n",
      "\n",
      "-4 -8 = -12\n",
      "\n",
      "-12 -7 = -19\n",
      "\n",
      "-19 -12 = -31\n",
      "\n",
      "-31 +4 = -27\n",
      "\n",
      "-27 +8 = -19\n",
      "\n",
      "-19 +12 = -7\n",
      "\n",
      "-7 +5 = -2\n",
      "\n",
      "-2 -5 = -7\n",
      "\n",
      "So, f(-1) = -7.\n",
      "\n",
      "So now, we have two equations:\n",
      "\n",
      "1. f(1) = a + b = -10\n",
      "\n",
      "2. f(-1) = -a + b = -7\n",
      "\n",
      "So, we have:\n",
      "\n",
      "a + b = -10\n",
      "\n",
      "-a + b = -7\n",
      "\n",
      "Let me write them down:\n",
      "\n",
      "Equation 1: a + b = -10\n",
      "\n",
      "Equation 2: -a + b = -7\n",
      "\n",
      "If I add these two equations together, the a terms will cancel:\n",
      "\n",
      "(a + b) + (-a + b) = -10 + (-7)\n",
      "\n",
      "Simplify:\n",
      "\n",
      "0a + 2b = -17\n",
      "\n",
      "So, 2b = -17 => b = -17/2\n",
      "\n",
      "Then, plugging back into Equation 1:\n",
      "\n",
      "a + (-17/2) = -10\n",
      "\n",
      "So, a = -10 + 17/2\n",
      "\n",
      "Convert -10 to halves: -20/2 + 17/2 = (-20 + 17)/2 = -3/2\n",
      "\n",
      "So, a = -3/2 and b = -17/2\n",
      "\n",
      "Therefore, the remainder R(x) = ax + b = (-3/2)x -17/2\n",
      "\n",
      "But wait, the problem says to find the remainder without using long division. Hmm, but I think I just used the Remainder Theorem, which is a form of polynomial remainder theorem. So, maybe that's acceptable.\n",
      "\n",
      "But just to make sure, let me double-check my calculations.\n",
      "\n",
      "First, f(1):\n",
      "\n",
      "1^10 = 1\n",
      "\n",
      "5*1^9 = 5\n",
      "\n",
      "-8*1^8 = -8\n",
      "\n",
      "7*1^7 = 7\n",
      "\n",
      "-12*1^6 = -12\n",
      "\n",
      "4*1^4 = 4\n",
      "\n",
      "-8*1^3 = -8\n",
      "\n",
      "12*1^2 = 12\n",
      "\n",
      "-5*1 = -5\n",
      "\n",
      "-5\n",
      "\n",
      "Adding them up: 1 + 5 -8 +7 -12 +4 -8 +12 -5 -5\n",
      "\n",
      "Let me add them step by step:\n",
      "\n",
      "1 + 5 = 6\n",
      "\n",
      "6 -8 = -2\n",
      "\n",
      "-2 +7 = 5\n",
      "\n",
      "5 -12 = -7\n",
      "\n",
      "-7 +4 = -3\n",
      "\n",
      "-3 -8 = -11\n",
      "\n",
      "-11 +12 = 1\n",
      "\n",
      "1 -5 = -4\n",
      "\n",
      "-4 -5 = -9\n",
      "\n",
      "Wait, hold on, earlier I thought f(1) was -10, but now I'm getting -9. Hmm, that's a discrepancy. Let me check my calculations again.\n",
      "\n",
      "Wait, maybe I made a mistake in the exponents.\n",
      "\n",
      "Wait, f(x) = x^10 +5x^9 -8x^8 +7x^7 -x^6 -12x^5 +4x^4 -8x^3 +12x^2 -5x -5\n",
      "\n",
      "So, f(1) = 1 +5 -8 +7 -1 -12 +4 -8 +12 -5 -5\n",
      "\n",
      "Wait, hold on, I think I missed a term. Let me count the exponents:\n",
      "\n",
      "x^10, x^9, x^8, x^7, x^6, x^5, x^4, x^3, x^2, x, constant.\n",
      "\n",
      "So, f(1) should be:\n",
      "\n",
      "1^10 +5*1^9 -8*1^8 +7*1^7 -1*1^6 -12*1^5 +4*1^4 -8*1^3 +12*1^2 -5*1 -5\n",
      "\n",
      "So, that's:\n",
      "\n",
      "1 +5 -8 +7 -1 -12 +4 -8 +12 -5 -5\n",
      "\n",
      "Let me compute this step by step:\n",
      "\n",
      "Start with 1.\n",
      "\n",
      "1 +5 = 6\n",
      "\n",
      "6 -8 = -2\n",
      "\n",
      "-2 +7 = 5\n",
      "\n",
      "5 -1 = 4\n",
      "\n",
      "4 -12 = -8\n",
      "\n",
      "-8 +4 = -4\n",
      "\n",
      "-4 -8 = -12\n",
      "\n",
      "-12 +12 = 0\n",
      "\n",
      "0 -5 = -5\n",
      "\n",
      "-5 -5 = -10\n",
      "\n",
      "Wait, so f(1) is -10, not -9. So, my initial calculation was wrong because I missed the last two terms: -5x and -5.\n",
      "\n",
      "So, f(1) is indeed -10. So, that was correct.\n",
      "\n",
      "Similarly, f(-1):\n",
      "\n",
      "Let me compute f(-1):\n",
      "\n",
      "(-1)^10 +5*(-1)^9 -8*(-1)^8 +7*(-1)^7 -(-1)^6 -12*(-1)^5 +4*(-1)^4 -8*(-1)^3 +12*(-1)^2 -5*(-1) -5\n",
      "\n",
      "Compute each term:\n",
      "\n",
      "1. (-1)^10 = 1\n",
      "\n",
      "2. 5*(-1)^9 = 5*(-1) = -5\n",
      "\n",
      "3. -8*(-1)^8 = -8*(1) = -8\n",
      "\n",
      "4. 7*(-1)^7 = 7*(-1) = -7\n",
      "\n",
      "5. -(-1)^6 = -1\n",
      "\n",
      "6. -12*(-1)^5 = -12*(-1) = 12\n",
      "\n",
      "7. 4*(-1)^4 = 4*(1) = 4\n",
      "\n",
      "8. -8*(-1)^3 = -8*(-1) = 8\n",
      "\n",
      "9. 12*(-1)^2 = 12*(1) = 12\n",
      "\n",
      "10. -5*(-1) = 5\n",
      "\n",
      "11. -5\n",
      "\n",
      "Now, add them all up:\n",
      "\n",
      "1 -5 -8 -7 -1 +12 +4 +8 +12 +5 -5\n",
      "\n",
      "Let me compute step by step:\n",
      "\n",
      "Start with 1.\n",
      "\n",
      "1 -5 = -4\n",
      "\n",
      "-4 -8 = -12\n",
      "\n",
      "-12 -7 = -19\n",
      "\n",
      "-19 -1 = -20\n",
      "\n",
      "-20 +12 = -8\n",
      "\n",
      "-8 +4 = -4\n",
      "\n",
      "-4 +8 = 4\n",
      "\n",
      "4 +12 = 16\n",
      "\n",
      "16 +5 = 21\n",
      "\n",
      "21 -5 = 16\n",
      "\n",
      "So, f(-1) = 16.\n",
      "\n",
      "Wait, earlier I thought it was -7, but now I get 16. That's a big difference. So, I must have made a mistake in my initial calculation.\n",
      "\n",
      "Let me double-check f(-1):\n",
      "\n",
      "f(-1) = (-1)^10 +5*(-1)^9 -8*(-1)^8 +7*(-1)^7 -(-1)^6 -12*(-1)^5 +4*(-1)^4 -8*(-1)^3 +12*(-1)^2 -5*(-1) -5\n",
      "\n",
      "Compute each term:\n",
      "\n",
      "1. (-1)^10 = 1\n",
      "\n",
      "2. 5*(-1)^9 = 5*(-1) = -5\n",
      "\n",
      "3. -8*(-1)^8 = -8*(1) = -8\n",
      "\n",
      "4. 7*(-1)^7 = 7*(-1) = -7\n",
      "\n",
      "5. -(-1)^6 = -1 (since (-1)^6 = 1, so -1*1 = -1)\n",
      "\n",
      "6. -12*(-1)^5 = -12*(-1) = 12 (since (-1)^5 = -1, so -12*(-1) = 12)\n",
      "\n",
      "7. 4*(-1)^4 = 4*(1) = 4\n",
      "\n",
      "8. -8*(-1)^3 = -8*(-1) = 8 (since (-1)^3 = -1, so -8*(-1) = 8)\n",
      "\n",
      "9. 12*(-1)^2 = 12*(1) = 12\n",
      "\n",
      "10. -5*(-1) = 5 (since (-1)*(-5) = 5)\n",
      "\n",
      "11. -5\n",
      "\n",
      "Now, add them up:\n",
      "\n",
      "1 -5 -8 -7 -1 +12 +4 +8 +12 +5 -5\n",
      "\n",
      "Let me add them step by step:\n",
      "\n",
      "Start with 1.\n",
      "\n",
      "1 -5 = -4\n",
      "\n",
      "-4 -8 = -12\n",
      "\n",
      "-12 -7 = -19\n",
      "\n",
      "-19 -1 = -20\n",
      "\n",
      "-20 +12 = -8\n",
      "\n",
      "-8 +4 = -4\n",
      "\n",
      "-4 +8 = 4\n",
      "\n",
      "4 +12 = 16\n",
      "\n",
      "16 +5 = 21\n",
      "\n",
      "21 -5 = 16\n",
      "\n",
      "So, f(-1) = 16.\n",
      "\n",
      "Wait, so earlier I thought it was -7, but now it's 16. So, that's a big difference. So, I must have made a mistake in my initial calculation.\n",
      "\n",
      "So, f(1) = -10 and f(-1) = 16.\n",
      "\n",
      "So, now, going back to the equations:\n",
      "\n",
      "a + b = -10\n",
      "\n",
      "-a + b = 16\n",
      "\n",
      "Wait, hold on, no. Wait, f(-1) = 16, so:\n",
      "\n",
      "Equation 1: a + b = -10\n",
      "\n",
      "Equation 2: -a + b = 16\n",
      "\n",
      "So, let's solve these equations.\n",
      "\n",
      "Add equation 1 and equation 2:\n",
      "\n",
      "(a + b) + (-a + b) = -10 + 16\n",
      "\n",
      "Simplify:\n",
      "\n",
      "0a + 2b = 6\n",
      "\n",
      "So, 2b = 6 => b = 3\n",
      "\n",
      "Then, plugging back into equation 1:\n",
      "\n",
      "a + 3 = -10 => a = -13\n",
      "\n",
      "So, the remainder R(x) = ax + b = -13x + 3\n",
      "\n",
      "Wait, but let me verify this because earlier I thought f(-1) was -7, but now it's 16. So, maybe I made a mistake in the initial calculation.\n",
      "\n",
      "Let me double-check f(-1):\n",
      "\n",
      "f(-1) = (-1)^10 +5*(-1)^9 -8*(-1)^8 +7*(-1)^7 -(-1)^6 -12*(-1)^5 +4*(-1)^4 -8*(-1)^3 +12*(-1)^2 -5*(-1) -5\n",
      "\n",
      "Compute each term:\n",
      "\n",
      "1. (-1)^10 = 1\n",
      "\n",
      "2. 5*(-1)^9 = 5*(-1) = -5\n",
      "\n",
      "3. -8*(-1)^8 = -8*(1) = -8\n",
      "\n",
      "4. 7*(-1)^7 = 7*(-1) = -7\n",
      "\n",
      "5. -(-1)^6 = -1 (since (-1)^6 = 1, so -1*1 = -1)\n",
      "\n",
      "6. -12*(-1)^5 = -12*(-1) = 12 (since (-1)^5 = -1, so -12*(-1) = 12)\n",
      "\n",
      "7. 4*(-1)^4 = 4*(1) = 4\n",
      "\n",
      "8. -8*(-1)^3 = -8*(-1) = 8 (since (-1)^3 = -1, so -8*(-1) = 8)\n",
      "\n",
      "9. 12*(-1)^2 = 12*(1) = 12\n",
      "\n",
      "10. -5*(-1) = 5 (since (-1)*(-5) = 5)\n",
      "\n",
      "11. -5\n",
      "\n",
      "Now, add them up:\n",
      "\n",
      "1 -5 -8 -7 -1 +12 +4 +8 +12 +5 -5\n",
      "\n",
      "Let me compute step by step:\n",
      "\n",
      "Start with 1.\n",
      "\n",
      "1 -5 = -4\n",
      "\n",
      "-4 -8 = -12\n",
      "\n",
      "-12 -7 = -19\n",
      "\n",
      "-19 -1 = -20\n",
      "\n",
      "-20 +12 = -8\n",
      "\n",
      "-8 +4 = -4\n",
      "\n",
      "-4 +8 = 4\n",
      "\n",
      "4 +12 = 16\n",
      "\n",
      "16 +5 = 21\n",
      "\n",
      "21 -5 = 16\n",
      "\n",
      "So, f(-1) = 16.\n",
      "\n",
      "So, earlier I thought it was -7, but now it's 16. So, that was a mistake. So, f(-1) is indeed 16.\n",
      "\n",
      "So, now, the equations are:\n",
      "\n",
      "a + b = -10\n",
      "\n",
      "-a + b = 16\n",
      "\n",
      "Adding them:\n",
      "\n",
      "2b = 6 => b = 3\n",
      "\n",
      "Then, a = -10 - b = -10 -3 = -13\n",
      "\n",
      "So, R(x) = -13x + 3\n",
      "\n",
      "Wait, but let me verify this because I feel like the remainder should be a linear polynomial, but maybe I made a mistake in the calculations.\n",
      "\n",
      "Alternatively, maybe I can use another method to verify.\n",
      "\n",
      "Another method to find the remainder when dividing by x^2 -1 is to use the fact that the remainder is a linear polynomial, so R(x) = ax + b.\n",
      "\n",
      "Then, since x^2 ≡ 1 mod (x^2 -1), we can reduce the polynomial f(x) modulo x^2 -1 by replacing every occurrence of x^2 with 1, x^3 with x, and so on.\n",
      "\n",
      "So, let's try that.\n",
      "\n",
      "Given f(x) = x^10 +5x^9 -8x^8 +7x^7 -x^6 -12x^5 +4x^4 -8x^3 +12x^2 -5x -5\n",
      "\n",
      "We can reduce each term:\n",
      "\n",
      "x^10 = x^(2*5) = (x^2)^5 ≡ 1^5 = 1\n",
      "\n",
      "5x^9 = 5x^(2*4 +1) = 5x^(2*4 +1) = 5x^(2*4)*x = 5*(x^2)^4 *x ≡ 5*1^4 *x = 5x\n",
      "\n",
      "-8x^8 = -8x^(2*4) = -8*(x^2)^4 ≡ -8*1^4 = -8\n",
      "\n",
      "7x^7 = 7x^(2*3 +1) = 7*(x^2)^3 *x ≡ 7*1^3 *x = 7x\n",
      "\n",
      "-x^6 = -x^(2*3) = - (x^2)^3 ≡ -1^3 = -1\n",
      "\n",
      "-12x^5 = -12x^(2*2 +1) = -12*(x^2)^2 *x ≡ -12*1^2 *x = -12x\n",
      "\n",
      "4x^4 = 4x^(2*2) = 4*(x^2)^2 ≡ 4*1^2 = 4\n",
      "\n",
      "-8x^3 = -8x^(2*1 +1) = -8*(x^2)^1 *x ≡ -8*1*x = -8x\n",
      "\n",
      "12x^2 = 12*(x^2) ≡ 12*1 = 12\n",
      "\n",
      "-5x = -5x\n",
      "\n",
      "-5 = -5\n",
      "\n",
      "Now, let's add all these reduced terms together:\n",
      "\n",
      "1 (from x^10) + 5x (from 5x^9) -8 (from -8x^8) +7x (from 7x^7) -1 (from -x^6) -12x (from -12x^5) +4 (from 4x^4) -8x (from -8x^3) +12 (from 12x^2) -5x (from -5x) -5 (from -5)\n",
      "\n",
      "Now, let's collect like terms:\n",
      "\n",
      "Constant terms:\n",
      "\n",
      "1 -8 -1 +4 +12 -5\n",
      "\n",
      "Compute step by step:\n",
      "\n",
      "1 -8 = -7\n",
      "\n",
      "-7 -1 = -8\n",
      "\n",
      "-8 +4 = -4\n",
      "\n",
      "-4 +12 = 8\n",
      "\n",
      "8 -5 = 3\n",
      "\n",
      "So, constant term is 3.\n",
      "\n",
      "x terms:\n",
      "\n",
      "5x +7x -12x -8x -5x\n",
      "\n",
      "Compute step by step:\n",
      "\n",
      "5x +7x = 12x\n",
      "\n",
      "12x -12x = 0x\n",
      "\n",
      "0x -8x = -8x\n",
      "\n",
      "-8x -5x = -13x\n",
      "\n",
      "So, x term is -13x.\n",
      "\n",
      "Therefore, the reduced polynomial is R(x) = -13x + 3.\n",
      "\n",
      "Which matches our earlier result.\n",
      "\n",
      "So, the remainder is -13x + 3.\n",
      "\n",
      "Therefore, the answer is R(x) = -13x + 3.\n",
      "\n",
      "But let me check once more because I feel like I might have made a mistake in the initial calculation.\n",
      "\n",
      "Wait, f(-1) = 16, so:\n",
      "\n",
      "Equation 1: a + b = -10\n",
      "\n",
      "Equation 2: -a + b = 16\n",
      "\n",
      "Adding equations:\n",
      "\n",
      "2b = 6 => b = 3\n",
      "\n",
      "Then, a = -10 - b = -13\n",
      "\n",
      "So, R(x) = -13x + 3\n",
      "\n",
      "Yes, that seems consistent.\n",
      "\n",
      "Alternatively, another way to compute f(-\n",
      "4096 800 4496 2678\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1129 800 1529 2664\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "482 800 882 1143\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "755 800 1155 1759\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2726 800 3126 3001\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "343 800 743 1554\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1454 800 1854 2260\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "956 800 1356 1478\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1791 800 2191 3321\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1094 800 1494 1269\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 3\n",
      " Wait, 53 is less than 55, so 11 squared is 121, which is more than 53, so 53 is prime.\n",
      "\n",
      "6. 62: Even number, so divisible by 2. Not prime.\n",
      "\n",
      "7. 71: Let's see, 71 divided by 2 is 35.5, not integer. Divided by 3: 71 ÷ 3 is about 23.666, not integer. Divided by 5: Doesn't end with 0 or 5. Divided by 7: 7*10 is 70, so 71-70 is 1, so not divisible by 7. Next prime is 11: 11*6 is 66, 11*7 is 77, which is more than 71. So 71 is prime.\n",
      "\n",
      "8. 80: Ends with 0, so divisible by 10, hence not prime.\n",
      "\n",
      "So, from the list, the primes are 17, 35, 44, 53, 62, 71, and 80. Wait, hold on, 35, 44, 62, and 80 are not primes, so that leaves us with 17, 53, and 71. So that's three numbers.\n",
      "\n",
      "Wait, but let me double-check. 17 is prime, 26 is not, 35 is not, 44 is not, 53 is prime, 62 is not, 71 is prime, 80 is not. So that's three primes: 17, 53, and 71.\n",
      "\n",
      "But wait, hold on a second. I think I might have missed some numbers. Let me think again. When I listed the numbers, I considered 'a' from 1 to 9, but maybe I should consider if 'a' can be 0? But no, because it's a two-digit number, so 'a' can't be 0. So, 'a' is from 1 to 9, and 'b' is from 0 to 9, but since a + b = 8, 'b' is from 0 to 8.\n",
      "\n",
      "Wait, but when I listed the numbers, I included 80, which is 8 and 0, but 80 is not prime. So, that's correct.\n",
      "\n",
      "But let me think if there's another way to approach this problem. Maybe instead of listing all possibilities, I can think about the properties of two-digit primes with digit sum 8.\n",
      "\n",
      "So, the digit sum is 8, which means the number is congruent to 8 modulo 9, because the sum of the digits of a number is congruent to the number itself modulo 9. So, 8 mod 9 is 8, so the number is congruent to 8 mod 9. So, the possible two-digit primes that are congruent to 8 mod 9.\n",
      "\n",
      "Let me recall that two-digit primes are from 11 to 97. So, let's list all two-digit primes and check which ones have digits summing to 8.\n",
      "\n",
      "But that might take longer, but maybe it's a good way to verify.\n",
      "\n",
      "Two-digit primes:\n",
      "\n",
      "11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97.\n",
      "\n",
      "Now, let's check each one:\n",
      "\n",
      "11: 1 + 1 = 2 ≠ 8.\n",
      "13: 1 + 3 = 4 ≠ 8.\n",
      "17: 1 + 7 = 8. So, that's one.\n",
      "19: 1 + 9 = 10 ≠ 8.\n",
      "23: 2 + 3 = 5 ≠ 8.\n",
      "29: 2 + 9 = 11 ≠ 8.\n",
      "31: 3 + 1 = 4 ≠ 8.\n",
      "37: 3 + 7 = 10 ≠ 8.\n",
      "41: 4 + 1 = 5 ≠ 8.\n",
      "43: 4 + 3 = 7 ≠ 8.\n",
      "47: 4 + 7 = 11 ≠ 8.\n",
      "53: 5 + 3 = 8. That's another one.\n",
      "59: 5 + 9 = 14 ≠ 8.\n",
      "61: 6 + 1 = 7 ≠ 8.\n",
      "67: 6 + 7 = 13 ≠ 8.\n",
      "71: 7 + 1 = 8. That's the third one.\n",
      "73: 7 + 3 = 10 ≠ 8.\n",
      "79: 7 + 9 = 16 ≠ 8.\n",
      "83: 8 + 3 = 11 ≠ 8.\n",
      "89: 8 + 9 = 17 ≠ 8.\n",
      "97: 9 + 7 = 16 ≠ 8.\n",
      "\n",
      "So, from this list, the primes that have digits summing to 8 are 17, 53, and 71. So, that's three primes.\n",
      "\n",
      "Wait, but earlier when I thought about the modular arithmetic, I thought that the number is congruent to 8 mod 9. Let me check if that's the case.\n",
      "\n",
      "Take 17: 17 ÷ 9 = 1 with remainder 8. So, 17 ≡ 8 mod 9. Correct.\n",
      "53: 53 ÷ 9 = 5 with remainder 8. So, 53 ≡ 8 mod 9. Correct.\n",
      "71: 71 ÷ 9 = 7 with remainder 8. So, 71 ≡ 8 mod 9. Correct.\n",
      "\n",
      "So, all three primes are congruent to 8 mod 9. That's consistent.\n",
      "\n",
      "But wait, are there any other primes that are congruent to 8 mod 9? Let me think. The next number after 97 is 107, which is a three-digit number, so beyond our range.\n",
      "\n",
      "So, in the two-digit range, only 17, 53, and 71 are primes with digits summing to 8.\n",
      "\n",
      "Wait, but let me think again. Is 17 the only one? Or are there others?\n",
      "\n",
      "Wait, 17 is 1 and 7, sum 8. 53 is 5 and 3, sum 8. 71 is 7 and 1, sum 8. Are there any others?\n",
      "\n",
      "Let me think about the numbers where the digits add up to 8. So, the possible two-digit numbers are:\n",
      "\n",
      "17, 26, 35, 44, 53, 62, 71, 80, 89, 98.\n",
      "\n",
      "Wait, hold on, I think I missed some numbers earlier. Because when I listed the numbers with digits summing to 8, I thought of 'a' from 1 to 9, but actually, 'b' can be from 0 to 8, so the numbers are:\n",
      "\n",
      "17, 26, 35, 44, 53, 62, 71, 80, 89, 98.\n",
      "\n",
      "Wait, so that's 10 numbers. But when I checked earlier, 17, 53, 71 are primes, but 26, 35, 44, 62, 80, 98 are not primes.\n",
      "\n",
      "But wait, 89: 8 + 9 = 17, which is not 8, so 89 is not in our list. Wait, no, 89 is a prime, but its digits sum to 17, so it's not in our list.\n",
      "\n",
      "Wait, no, 89 is a prime, but it's not in our list because 8 + 9 = 17, not 8. So, 89 is not included.\n",
      "\n",
      "Similarly, 98: 9 + 8 = 17, not 8, so not included.\n",
      "\n",
      "So, in the list of numbers with digits summing to 8, only 17, 53, and 71 are primes.\n",
      "\n",
      "But wait, let me think again. Is 89 a two-digit number? Yes, but it's not in our list because its digits sum to 17, not 8. So, 89 is not included.\n",
      "\n",
      "Similarly, 98 is not included.\n",
      "\n",
      "So, in the list of numbers with digits summing to 8, only 17, 53, and 71 are primes.\n",
      "\n",
      "Wait, but hold on, 89 is a prime, but it's not in our list because its digits sum to 17. So, it's not included.\n",
      "\n",
      "So, that's three primes.\n",
      "\n",
      "But wait, let me think if there's another way to approach this problem. Maybe using the properties of primes.\n",
      "\n",
      "Since the sum of the digits is 8, which is even, and the number itself is a two-digit number, which is even if the units digit is even. So, 17 is odd, 26 is even, 35 is odd, 44 is even, 53 is odd, 62 is even, 71 is odd, 80 is even, 89 is odd, 98 is even.\n",
      "\n",
      "So, the primes among these are 17, 53, and 71, which are the odd ones. So, that's three primes.\n",
      "\n",
      "But wait, 89 is a prime, but it's not in our list because its digits sum to 17, not 8. So, 89 is not included.\n",
      "\n",
      "So, that's three primes.\n",
      "\n",
      "Wait, but let me think if there's another way to approach this problem. Maybe using the fact that a two-digit prime with digits summing to 8 must satisfy certain conditions.\n",
      "\n",
      "For example, a two-digit number can be written as 10a + b, where a is from 1 to 9 and b is from 0 to 9, and a + b = 8.\n",
      "\n",
      "So, as I did earlier, the possible numbers are 17, 26, 35, 44, 53, 62, 71, 80, 89, 98.\n",
      "\n",
      "But among these, only 17, 53, and 71 are primes.\n",
      "\n",
      "So, that's three primes.\n",
      "\n",
      "But wait, let me think if there's another way to approach this problem. Maybe using the fact that a two-digit prime must be congruent to 1, 7, 9, or 3 mod 9, but I'm not sure if that helps here.\n",
      "\n",
      "Alternatively, maybe I can think about the possible two-digit primes and check their digit sums.\n",
      "\n",
      "But that might take longer, but perhaps it's a good way to verify.\n",
      "\n",
      "So, let's list all two-digit primes and check their digit sums:\n",
      "\n",
      "11: 1 + 1 = 2 ≠ 8.\n",
      "13: 1 + 3 = 4 ≠ 8.\n",
      "17: 1 + 7 = 8. So, that's one.\n",
      "19: 1 + 9 = 10 ≠ 8.\n",
      "23: 2 + 3 = 5 ≠ 8.\n",
      "29: 2 + 9 = 11 ≠ 8.\n",
      "31: 3 + 1 = 4 ≠ 8.\n",
      "37: 3 + 7 = 10 ≠ 8.\n",
      "41: 4 + 1 = 5 ≠ 8.\n",
      "43: 4 + 3 = 7 ≠ 8.\n",
      "47: 4 + 7 = 11 ≠ 8.\n",
      "53: 5 + 3 = 8. That's another one.\n",
      "59: 5 + 9 = 14 ≠ 8.\n",
      "61: 6 + 1 = 7 ≠ 8.\n",
      "67: 6 + 7 = 13 ≠ 8.\n",
      "71: 7 + 1 = 8. That's the third one.\n",
      "73: 7 + 3 = 10 ≠ 8.\n",
      "79: 7 + 9 = 16 ≠ 8.\n",
      "83: 8 + 3 = 11 ≠ 8.\n",
      "89: 8 + 9 = 17 ≠ 8.\n",
      "97: 9 + 7 = 16 ≠ 8.\n",
      "\n",
      "So, from this list, the primes with digit sums of 8 are 17, 53, and 71. That's three primes.\n",
      "\n",
      "Wait, but hold on a second. I think I might have missed some numbers. Let me think again. When I listed the numbers with digits summing to 8, I considered 'a' from 1 to 9 and 'b' from 0 to 8, but maybe I should consider all possible two-digit numbers where a + b = 8, including those where 'a' is 0, but 'a' can't be 0 because it's a two-digit number.\n",
      "\n",
      "Wait, no, 'a' is from 1 to 9, so 'b' is from 0 to 8. So, the numbers are 17, 26, 35, 44, 53, 62, 71, 80, 89, 98. That's 10 numbers.\n",
      "\n",
      "But among these, only 17, 53, and 71 are primes. So, that's three primes.\n",
      "\n",
      "Wait, but let me think if there's another way to approach this problem. Maybe using the fact that a two-digit prime must be congruent to 1, 7, 9, or 3 mod 9, but I'm not sure if that helps here.\n",
      "\n",
      "Alternatively, maybe I can think about the possible two-digit primes and their digit sums.\n",
      "\n",
      "But I think the way I did it earlier is solid. I listed all possible two-digit numbers with digits summing to 8, checked which ones are primes, and found three primes: 17, 53, and 71.\n",
      "\n",
      "Wait, but let me think if there's another number I might have missed. For example, 89: 8 + 9 = 17, which is not 8, so it's not included. 98: 9 + 8 = 17, not 8. 71: 7 + 1 = 8, which is included. 53: 5 + 3 = 8, included. 17: 1 + 7 = 8, included. 26: 2 + 6 = 8, not prime. 35: 3 + 5 = 8, not prime. 44: 4 + 4 = 8, not prime. 62: 6 + 2 = 8, not prime. 80: 8 + 0 = 8, not prime. 89: 8 + 9 = 17, not included. 97: 9 + 7 = 16, not included.\n",
      "\n",
      "So, that's three primes: 17, 53, and 71.\n",
      "\n",
      "Wait, but let me think if there's another way to approach this problem. Maybe using the fact that a two-digit prime must be congruent to 1, 7, 9, or 3 mod 9, but I'm not sure if that helps here.\n",
      "\n",
      "Alternatively, maybe I can think about the possible two-digit primes and their digit sums.\n",
      "\n",
      "But I think the way I did it earlier is correct. So, the answer is three two-digit primes where the sum of the digits is 8.\n",
      "\n",
      "Wait, but let me double-check. 17: 1 + 7 = 8, prime. 26: 2 + 6 = 8, not prime. 35: 3 + 5 = 8, not prime. 44: 4 + 4 = 8, not prime. 53: 5 + 3 = 8, prime. 62: 6 + 2 = 8, not prime. 71: 7 + 1 = 8, prime. 80: 8 + 0 = 8, not prime. 89: 8 + 9 = 17, not prime. 98: 9 + 8 = 17, not prime.\n",
      "\n",
      "So, that's three primes: 17, 53, and 71.\n",
      "\n",
      "Wait, but let me think if there's another number I might have missed. For example, 89: 8 + 9 = 17, not 8. 98: 9 + 8 = 17, not 8. 71: 7 + 1 = 8, included. 53: 5 + 3 = 8, included. 17: 1 + 7 = 8, included. 26: 2 + 6 = 8, not prime. 35: 3 + 5 = 8, not prime. 44: 4 + 4 = 8, not prime. 62: 6 + 2 = 8, not prime. 80: 8 + 0 = 8, not prime. 89: 8 + 9 = 17, not included. 98: 9 + 8 = 17, not included.\n",
      "\n",
      "So, that's three primes. So, the answer is three.\n",
      "\n",
      "Wait, but let me think again. Is 17 the only prime where the digits sum to 8? Or are there others?\n",
      "\n",
      "Wait, 17: 1 + 7 = 8, prime. 26: 2 + 6 = 8, not prime. 35: 3 + 5 = 8, not prime. 44: 4 + 4 = 8, not prime. 53: 5 + 3 = 8, prime. 62: 6 + 2 = 8, not prime. 71: 7 + 1 = 8, prime. 80: 8 + 0 = 8, not prime. 89: 8 + 9 = 17, not included. \n",
      "4096 800 4496 2693\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "529 800 929 1346\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "367 800 767 2159\n",
      "===\n",
      "===\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct_items = 0\n",
    "torch.manual_seed(0)\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "evaluation_dataset = []\n",
    "\n",
    "for dataset_pos in tqdm(range(len(correct_dataset))):\n",
    "    # dataset_pos = 11\n",
    "    input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "    # print(input_ids)\n",
    "    # print(\"===\")\n",
    "    # print(\"===\")\n",
    "\n",
    "    input_ids = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": base_prompt.format(question=input_ids),\n",
    "                },\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # input_ids = dataset_item[\"input_ids\"]\n",
    "    # generated_ids = dataset_item[\"generated_ids\"]\n",
    "    generated_ids = [\n",
    "        tokenizer.encode(\n",
    "            correct_dataset[dataset_pos][\"model_answer\"],\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "        )\n",
    "        end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "        )\n",
    "        input_ids = torch.tensor(input_ids).cuda()\n",
    "        input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "        # windows_amount = 100\n",
    "        # windows_amount = 200\n",
    "        # windows_amount = 300\n",
    "        windows_amount = 400\n",
    "        # windows_amount = 500\n",
    "        # windows_amount = 2\n",
    "        generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "        original_total_len = torch.tensor(generated_ids).shape[1]\n",
    "        if generated_tokens_amount > original_total_len:\n",
    "            windows_amount = original_total_len // WINDOW_SIZE\n",
    "            generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "\n",
    "        next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "            :, :generated_tokens_amount\n",
    "        ]\n",
    "\n",
    "        # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "        original_embeds = (model.get_input_embeddings()(next_true_tokens)).to(\n",
    "            torch.float32\n",
    "        )\n",
    "\n",
    "        # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        new_embeds_for_compression = original_embeds.reshape(\n",
    "            windows_amount, WINDOW_SIZE, -1\n",
    "        )\n",
    "        compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "        # start_embed = torch.rand_like(start_embed)\n",
    "        # compressed_part = torch.rand_like(compressed_part)\n",
    "        # end_embed = torch.rand_like(end_embed)\n",
    "        generated_embeds = torch.cat(\n",
    "            [\n",
    "                input_ids_embeds,\n",
    "                start_embed,\n",
    "                compressed_part,\n",
    "                end_embed,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "        # print(\"===\")\n",
    "        generated_ids_compressed = model.generate(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            # attention_mask=torch.ones_like(generated_embeds),\n",
    "            attention_mask=torch.ones(\n",
    "                generated_embeds.shape[:2],\n",
    "                device=\"cuda\",\n",
    "            ).long(),\n",
    "            max_new_tokens=4096,\n",
    "            # max_new_tokens=5,\n",
    "            do_sample=False,\n",
    "            # do_sample=True,\n",
    "            # temperature=0.6,\n",
    "            # top_p=0.95,\n",
    "        )\n",
    "        # break\n",
    "    generated_result = tokenizer.decode(generated_ids_compressed[-1])\n",
    "    # print()\n",
    "    gold_answer = correct_dataset[dataset_pos][\"answer\"]\n",
    "    answer = dataset_answer_filter(gold_answer)\n",
    "    model_answer = model_answer_filter(generated_result)\n",
    "    if is_equiv(answer, model_answer):\n",
    "        correct_items += 1\n",
    "        print(\"CORRECT\")\n",
    "    else:\n",
    "        print(\"WRONG\", gold_answer)\n",
    "        print(generated_result)\n",
    "    compressed_total_len = generated_ids_compressed.shape[1] + compressed_part.shape[1]\n",
    "    print(\n",
    "        generated_ids_compressed.shape[1],\n",
    "        next_true_tokens.shape[1],\n",
    "        compressed_total_len,\n",
    "        torch.tensor(generated_ids).shape[1],\n",
    "    )\n",
    "    evaluation_dataset.append(\n",
    "        {\n",
    "            **correct_dataset[dataset_pos],\n",
    "            \"compressed_input_part\": tokenizer.decode(next_true_tokens[-1]),\n",
    "            \"compressed_output_generation\": generated_result,\n",
    "            \"compressed_compression_size\": generated_tokens_amount,\n",
    "            \"original_total_len\": torch.tensor(generated_ids).shape[1],\n",
    "            \"compressed_total_len\": compressed_total_len,\n",
    "        }\n",
    "    )\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    # break\n",
    "    # embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 656])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 719, 1536])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(next_true_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.18404907975460122, 0.147239263803681, 0.8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset) / len(dataset), correct_items / len(dataset), correct_items / len(\n",
    "    correct_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.base_model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Below is a magic square, meaning that the sum of the numbers in each row, in each column, and in each of the $2$ main diagonals are equal. What is the value of $n$?\\n\\n[asy]size(125);\\nfor(int i = 0; i<4; ++i)\\n{\\n\\ndraw((0,i)--(3,i),linewidth(1));\\n}\\n\\nfor(int j = 0; j<4; ++j)\\n{\\n\\ndraw((j,0)--(j,3),linewidth(1));\\n}\\n\\nlabel(\"$n-3$\",(.5,.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"$n+1$\",(.5,2.5));\\n\\nlabel(\"$n+2$\",(1.5,.5));\\nlabel(\"$2n-9$\",(1.5,1.5));\\nlabel(\"$1$\",(1.5,2.5));\\n\\nlabel(\"$2$\",(2.5,.5));\\nlabel(\"$n$\",(2.5,1.5));\\nlabel(\"$n-1$\",(2.5,2.5));\\n[/asy]',\n",
       " 'solution': 'First, we can evaluate the sum across the first row, which gives $(n+1)+1+(n-1)=2n+1$.  Evaluate the sum of the entries across the second row, $3+(2n-9)+n=3n-6$. Now, since we have a magic square, these two sums are equal.  So $2n+1=3n-6$. Isolating $n$, we obtain $n = \\\\boxed{7}$.\\n\\nThe square will look like: [asy] size(2cm);\\ndraw((0,0)--(3,0)--(3,3)--(0,3)--cycle,linewidth(1));\\ndraw((1,0)--(1,3),linewidth(1));\\ndraw((2,0)--(2,3),linewidth(1));\\ndraw((0,1)--(3,1),linewidth(1));\\ndraw((0,2)--(3,2),linewidth(1));\\nlabel(\"8\",(.5,2.5));\\nlabel(\"1\",(1.5,2.5));\\nlabel(\"6\",(2.5,2.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"5\",(1.5,1.5));\\nlabel(\"7\",(2.5,1.5));\\nlabel(\"4\",(.5,.5));\\nlabel(\"9\",(1.5,.5));\\nlabel(\"2\",(2.5,.5));\\n[/asy]',\n",
       " 'answer': '7',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1930.json',\n",
       " 'model_answer': \"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). A magic square is one where the sums of the numbers in each row, each column, and both main diagonals are all equal. The Asymptote code is provided, which I can visualize. Let me try to reconstruct the magic square based on the labels given.\\n\\nFirst, I'll try to draw it out mentally. The Asymptote code is creating a 3x3 grid. Each cell is labeled with some expression involving \\\\( n \\\\). Let me write down the positions and the expressions.\\n\\nLooking at the Asymptote code:\\n\\n- The first row (top row) is labeled at positions (0.5, 0.5), (0.5, 1.5), and (0.5, 2.5), so that's the top row. The labels are:\\n  - \\\\( n - 3 \\\\) at the left,\\n  - \\\\( 3 \\\\) in the center,\\n  - \\\\( n + 1 \\\\) at the right.\\n  \\nSo, the top row is: \\\\( n - 3 \\\\), \\\\( 3 \\\\), \\\\( n + 1 \\\\).\\n\\n- The second row (middle row) is labeled at positions (1.5, 0.5), (1.5, 1.5), and (1.5, 2.5). The labels are:\\n  - \\\\( n + 2 \\\\) on the left,\\n  - \\\\( 2n - 9 \\\\) in the center,\\n  - \\\\( 1 \\\\) on the right.\\n  \\nSo, the middle row is: \\\\( n + 2 \\\\), \\\\( 2n - 9 \\\\), \\\\( 1 \\\\).\\n\\n- The third row (bottom row) is labeled at positions (2.5, 0.5), (2.5, 1.5), and (2.5, 2.5). The labels are:\\n  - \\\\( 2 \\\\) on the left,\\n  - \\\\( n \\\\) in the center,\\n  - \\\\( n - 1 \\\\) on the right.\\n  \\nSo, the bottom row is: \\\\( 2 \\\\), \\\\( n \\\\), \\\\( n - 1 \\\\).\\n\\nLet me write this down as a table for clarity:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, so now I need to find \\\\( n \\\\) such that the sums of each row, column, and both main diagonals are equal. Let's denote the magic constant (the common sum) as \\\\( S \\\\). So, I need to express \\\\( S \\\\) in terms of \\\\( n \\\\) and set up equations accordingly.\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That gives me one equation.\\n\\nNext, let me check the sum of the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since it's a magic square, this should also equal \\\\( S \\\\). Therefore, I have:\\n\\n\\\\( 2n + 1 = 3n - 6 \\\\)\\n\\nLet me solve this equation for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( 1 = n - 6 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( 7 = n \\\\)\\n\\nSo, \\\\( n = 7 \\\\). Hmm, let me check if this is consistent with the other rows, columns, and diagonals.\\n\\nLet's compute the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nSo, the sum is 15. Let's verify if this holds with the columns and diagonals.\\n\\nFirst, the first column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nAlso 15.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (8) + 1 + 6 = 15 \\\\)\\n\\nGood.\\n\\nNow, the main diagonals.\\n\\nFirst diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (4) + (14 - 9) + 6 = 4 + 5 + 6 = 15 \\\\)\\n\\nSecond diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (8) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals sum to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\).\\n\\nWait, but let me double-check the initial row sum. When \\\\( n = 7 \\\\), the first row sum was \\\\( 2n + 1 = 14 + 1 = 15 \\\\). Yep, that's consistent.\\n\\nSo, it seems that \\\\( n = 7 \\\\) is the correct value.\\n\\nBut just to be thorough, let me check the second row sum when \\\\( n = 7 \\\\):\\n\\nSecond row: \\\\( (7 + 2) + (14 - 9) + 1 = 9 + 5 + 1 = 15 \\\\). Yep, that's correct.\\n\\nSimilarly, the third row was 2 + 7 + 6 = 15.\\n\\nAll columns, diagonals, and rows check out.\\n\\nSo, I think \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nGiven a magic square where the sum of the numbers in each row, column, and the two main diagonals are equal, we need to find the value of \\\\( n \\\\).\\n\\nThe magic square is reconstructed as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nWe denote the magic constant (the common sum) as \\\\( S \\\\).\\n\\n1. Calculate the sum of the first row:\\n   \\\\[\\n   (n - 3) + 3 + (n + 1) = 2n + 1\\n   \\\\]\\n   This gives us the equation:\\n   \\\\[\\n   2n + 1 = S\\n   \\\\]\\n\\n2. Calculate the sum of the second row:\\n   \\\\[\\n   (n + 2) + (2n - 9) + 1 = 3n - 6\\n   \\\\]\\n   This gives us the equation:\\n   \\\\[\\n   3n - 6 = S\\n   \\\\]\\n\\n3. Equate the two expressions for \\\\( S \\\\):\\n   \\\\[\\n   2n + 1 = 3n - 6\\n   \\\\]\\n   Solving for \\\\( n \\\\):\\n   \\\\[\\n   1 = n - 6 \\\\implies n = 7\\n   \\\\]\\n\\n4. Verify the value of \\\\( n \\\\) by checking the sums of the third row, columns, and diagonals:\\n   - Third row: \\\\( 2 + 7 + 6 = 15 \\\\)\\n   - First column: \\\\( 4 + 9 + 2 = 15 \\\\)\\n   - Second column: \\\\( 3 + 5 + 7 = 15 \\\\)\\n   - Third column: \\\\( 8 + 1 + 6 = 15 \\\\)\\n   - First diagonal: \\\\( 4 + 5 + 6 = 15 \\\\)\\n   - Second diagonal: \\\\( 8 + 5 + 2 = 15 \\\\)\\n\\nAll sums are consistent and equal to 15 when \\\\( n = 7 \\\\).\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\",\n",
       " 'compressed_input_part': \"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). A magic square is one where the sums of the numbers in each row, each column, and both main diagonals are all equal. The Asymptote code is provided, which I can visualize. Let me try to reconstruct the magic square based on the labels given.\\n\\nFirst, I'll try to draw it out mentally. The Asymptote code is creating a 3x3 grid. Each cell is labeled with some expression involving \\\\( n \\\\). Let me write down the positions and the expressions.\\n\\nLooking at the Asymptote code:\\n\\n- The first row (top row) is labeled at positions (0.5, 0.5), (0.5, 1.5), and (0.5, 2.5), so that's the top row. The labels are:\\n  - \\\\( n - 3 \\\\) at the left,\\n  - \\\\( 3 \\\\) in the center,\\n  - \\\\( n + 1 \\\\) at the right.\\n  \\nSo, the top row is: \\\\( n - 3 \\\\), \\\\( 3 \\\\), \\\\( n + 1 \\\\).\\n\\n- The second row (middle row) is labeled at positions (1.5, 0.5), (1.5, 1.5), and (1.5, 2.5). The labels are:\\n  - \\\\( n + 2 \\\\) on the left,\\n  - \\\\( 2n - 9 \\\\) in the center,\\n  - \\\\( 1 \\\\) on the right.\\n  \\nSo, the middle row is: \\\\( n + 2 \\\\), \\\\( 2n - 9 \\\\), \\\\( 1 \\\\).\\n\\n- The third row (bottom row) is labeled at positions (2.5, 0.5), (2.5, 1.5),\",\n",
       " 'compressed_output_generation': \" (2.5, 2.5). The labels are:\\n  - \\\\( 2 \\\\) on the left,\\n  - \\\\( n \\\\) in the center,\\n  - \\\\( n - 1 \\\\) on the right.\\n\\nSo, the bottom row is: \\\\( 2 \\\\), \\\\( n \\\\), \\\\( n - 1 \\\\).\\n\\nNow, let me summarize all the labels:\\n\\n- Row 1 (Top): \\\\( n - 3 \\\\), \\\\( 3 \\\\), \\\\( n + 1 \\\\)\\n- Row 2 (Middle): \\\\( n + 2 \\\\), \\\\( 2n - 9 \\\\), \\\\( 1 \\\\)\\n- Row 3 (Bottom): \\\\( 2 \\\\), \\\\( n \\\\), \\\\( n - 1 \\\\)\\n\\nI can calculate the sums of the rows and set them equal to each other since it's a magic square.\\n\\nLet me compute the sum of Row 1: \\\\( (n - 3) + 3 + (n + 1) \\\\). Simplify that: \\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\).\\n\\nSum of Row 2: \\\\( (n + 2) + (2n - 9) + 1 \\\\). Simplify: \\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\).\\n\\nSum of Row 3: \\\\( 2 + n + (n - 1) \\\\). Simplify: \\\\( 2 + n + n - 1 = 2n + 1 \\\\).\\n\\nSo, Row 1 and Row 3 both sum to \\\\( 2n + 1 \\\\). Row 2 sums to \\\\( 3n - 6 \\\\). Since it's a magic square, all rows must sum to the same value. Therefore, I can set Row 1 equal to Row 2:\\n\\n\\\\( 2n + 1 = 3n - 6 \\\\)\\n\\nSolving for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides: \\\\( 1 = n - 6 \\\\)\\n\\nAdd 6 to both sides: \\\\( n = 7 \\\\)\\n\\nWait, is that it? Let me check if this value of \\\\( n \\\\) works for the columns as well.\\n\\nLet me compute the sums of the columns to verify.\\n\\nFirst, label the magic square based on \\\\( n = 7 \\\\):\\n\\n- Row 1: \\\\( 7 - 3 = 4 \\\\), \\\\( 3 \\\\), \\\\( 7 + 1 = 8 \\\\)\\n- Row 2: \\\\( 7 + 2 = 9 \\\\), \\\\( 2*7 - 9 = 14 - 9 = 5 \\\\), \\\\( 1 \\\\)\\n- Row 3: \\\\( 2 \\\\), \\\\( 7 \\\\), \\\\( 7 - 1 = 6 \\\\)\\n\\nSo, the matrix is:\\n\\n4 | 3 | 8\\n\\n9 | 5 | 1\\n\\n2 | 7 | 6\\n\\nNow, let's check the columns:\\n\\n- Column 1: 4 + 9 + 2 = 15\\n- Column 2: 3 + 5 + 7 = 15\\n- Column 3: 8 + 1 + 6 = 15\\n\\nGood, all columns sum to 15.\\n\\nNow, let's check the diagonals.\\n\\nMain diagonal (top-left to bottom-right): 4, 5, 6. Sum: 4 + 5 + 6 = 15.\\n\\nOther diagonal (top-right to bottom-left): 8, 5, 2. Sum: 8 + 5 + 2 = 15.\\n\\nPerfect, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\).\\n\\nTherefore, the value of \\\\( n \\\\) is 7.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we start by noting the labels of each cell based on the Asymptote code. The matrix is reconstructed as follows:\\n\\n- Row 1 (Top): \\\\( n - 3 \\\\), \\\\( 3 \\\\), \\\\( n + 1 \\\\)\\n- Row 2 (Middle): \\\\( n + 2 \\\\), \\\\( 2n - 9 \\\\), \\\\( 1 \\\\)\\n- Row 3 (Bottom): \\\\( 2 \\\\), \\\\( n \\\\), \\\\( n - 1 \\\\)\\n\\nWe calculate the sums of the rows:\\n\\n- Sum of Row 1: \\\\( (n - 3) + 3 + (n + 1) = 2n + 1 \\\\)\\n- Sum of Row 2: \\\\( (n + 2) + (2n - 9) + 1 = 3n - 6 \\\\)\\n- Sum of Row 3: \\\\( 2 + n + (n - 1) = 2n + 1 \\\\)\\n\\nSince it is a magic square, all rows must sum to the same value. Setting the sum of Row 1 equal to Row 2:\\n\\n\\\\[ 2n + 1 = 3n - 6 \\\\]\\n\\nSolving for \\\\( n \\\\):\\n\\n\\\\[ 1 = n - 6 \\\\]\\n\\\\[ n = 7 \\\\]\\n\\nTo verify, we check the columns and diagonals with \\\\( n = 7 \\\\):\\n\\n- The matrix becomes:\\n  \\\\[\\n  \\\\begin{array}{ccc}\\n  4 & 3 & 8 \\\\\\\\\\n  9 & 5 & 1 \\\\\\\\\\n  2 & 7 & 6 \\\\\\\\\\n  \\\\end{array}\\n  \\\\]\\n\\n- Column sums: 4 + 9 + 2 = 15, 3 + 5 + 7 = 15, 8 + 1 + 6 = 15\\n- Diagonals: 4 + 5 + 6 = 15, 8 + 5 + 2 = 15\\n\\nAll sums are equal to 15, confirming the magic square. Therefore, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).<｜end▁of▁sentence｜>\",\n",
       " 'compressed_compression_size': 400,\n",
       " 'original_total_len': 2019,\n",
       " 'compressed_total_len': 1502}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "base_path = \"hidden_capacity_reasoning/evaluation/math_500/evals/compression_tests\"\n",
    "save_id = f\"test_correct_dataset_{len(correct_dataset)}_compressed_window_amount=400,window=2__2025_04_22_01_43_43_347583__10000\"\n",
    "with open(f\"{base_path}/{save_id}.json\", \"w\") as f:\n",
    "    json.dump(evaluation_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    f\"hidden_capacity_reasoning/evaluation/math_500/evals/compression_tests/correct_dataset_155_compressed_window_amount=400,window=2__2025_04_22_01_43_43_347583__90000.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    evaluation_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56056, 60494, 1.079170829170829)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_total_len = 0\n",
    "compressed_total_len = 0\n",
    "for item in evaluation_dataset:\n",
    "    original_total_len += item[\"original_total_len\"]\n",
    "    compressed_total_len += item[\"compressed_total_len\"]\n",
    "original_total_len, compressed_total_len, compressed_total_len / original_total_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
