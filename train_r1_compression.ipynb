{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ef7a7bb00246348e4b40a104ceaa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f085db131e654d64964a7040ecfed546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/312 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1580\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1580\u001b[0m     dataset_script_path \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _require_custom_configs \u001b[38;5;129;01mor\u001b[39;00m (revision \u001b[38;5;129;01mand\u001b[39;00m revision \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:5475\u001b[0m, in \u001b[0;36mHfApi.hf_hub_download\u001b[0;34m(self, repo_id, filename, subfolder, repo_type, revision, cache_dir, local_dir, force_download, proxies, etag_timeout, token, local_files_only, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   5473\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m-> 5475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5478\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5487\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5491\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5496\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:961\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1024\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[0;32m-> 1024\u001b[0m (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) \u001b[38;5;241m=\u001b[39m \u001b[43m_get_metadata_or_catch_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelative_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1484\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1484\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1401\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1409\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:285\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 285\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 309\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:420\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    419\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntry Not Found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(EntryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-68128578-0ea274e125dba3cb1d1ac5b6;c8d72666-fbda-4390-b0c3-c9d217194594)\n\nEntry Not Found for url: https://huggingface.co/datasets/dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B/resolve/82cf73531b7b8daaee327e4813aa774abbc0fcc4/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B.py.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 89\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# model = model.to(torch.bfloat16)\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     91\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:2062\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2058\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2059\u001b[0m )\n\u001b[1;32m   2061\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2062\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2075\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2079\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1782\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1781\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1782\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1795\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1629\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m         use_exported_dataset_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_exported_dataset_infos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1631\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a gated dataset on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/load.py:1019\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1018\u001b[0m     patterns \u001b[38;5;241m=\u001b[39m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m-> 1019\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALL_ALLOWED_EXTENSIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m   1026\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1027\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1028\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1030\u001b[0m data_files \u001b[38;5;241m=\u001b[39m data_files\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m   1031\u001b[0m     extensions\u001b[38;5;241m=\u001b[39m_MODULE_TO_EXTENSIONS[module_name], file_names\u001b[38;5;241m=\u001b[39m_MODULE_TO_METADATA_FILE_NAMES[module_name]\n\u001b[1;32m   1032\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:690\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    685\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    687\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    688\u001b[0m         patterns_for_key\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[0;32m--> 690\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m     )\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:583\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 583\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m         )\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/data_files.py:361\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mHF_HUB_VERSION \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.20.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# 10 times faster glob with detail=True (ignores costly info like lastCommit)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     glob_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    359\u001b[0m matched_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    360\u001b[0m     filepath \u001b[38;5;28;01mif\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mstartswith(protocol_prefix) \u001b[38;5;28;01melse\u001b[39;00m protocol_prefix \u001b[38;5;241m+\u001b[39m filepath\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filepath, info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mglob_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mislink\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(filepath))))\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (xbasename(filepath) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m files_to_ignore)\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_inside_unrequested_special_dir(filepath, fs_pattern)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_unrequested_hidden_file_or_is_inside_unrequested_hidden_dir(filepath, fs_pattern)\n\u001b[1;32m    366\u001b[0m ]  \u001b[38;5;66;03m# ignore .ipynb and __pycache__, but keep /../\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     out \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    369\u001b[0m         filepath\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m filepath \u001b[38;5;129;01min\u001b[39;00m matched_paths\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix \u001b[38;5;129;01min\u001b[39;00m allowed_extensions \u001b[38;5;28;01mfor\u001b[39;00m suffix \u001b[38;5;129;01min\u001b[39;00m xbasename(filepath)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m    372\u001b[0m     ]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:521\u001b[0m, in \u001b[0;36mHfFileSystem.glob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    520\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:609\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    607\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m pattern \u001b[38;5;241m=\u001b[39m glob_translate(path \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ends_with_sep \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    612\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:556\u001b[0m, in \u001b[0;36mHfFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;124;03mList all files below path.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;124;03m    `Union[List[str], Dict[str, Dict[str, Any]]]`: List of paths or dict of file information.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxdepth:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwithdirs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwithdirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m resolved_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    560\u001b[0m path \u001b[38;5;241m=\u001b[39m resolved_path\u001b[38;5;241m.\u001b[39munresolve()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/fsspec/spec.py:500\u001b[0m, in \u001b[0;36mAbstractFileSystem.find\u001b[0;34m(self, path, maxdepth, withdirs, detail, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Add the root directory if withdirs is requested\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# This is needed for posix glob compliance\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m withdirs \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(path):\n\u001b[0;32m--> 500\u001b[0m     out[path] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwalk(path, maxdepth, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m withdirs:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_file_system.py:719\u001b[0m, in \u001b[0;36mHfFileSystem.info\u001b[0;34m(self, path, refresh, revision, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m     out \u001b[38;5;241m=\u001b[39m out1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh \u001b[38;5;129;01mor\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (expand_info \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mand\u001b[39;00m out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_commit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 719\u001b[0m     paths_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_paths_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths_info:\n\u001b[1;32m    727\u001b[0m         _raise_file_not_found(path, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:3354\u001b[0m, in \u001b[0;36mHfApi.get_paths_info\u001b[0;34m(self, repo_id, paths, expand, revision, repo_type, token)\u001b[0m\n\u001b[1;32m   3351\u001b[0m revision \u001b[38;5;241m=\u001b[39m quote(revision, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mDEFAULT_REVISION\n\u001b[1;32m   3352\u001b[0m headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_hf_headers(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m-> 3354\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/api/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43ms/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrepo_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/paths-info/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrevision\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3358\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m   3363\u001b[0m paths_info \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"hidden_capacity_reasoning\"\n",
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from trl import (\n",
    "    ModelConfig,\n",
    "    ScriptArguments,\n",
    "    SFTConfig,\n",
    "    SFTTrainer,\n",
    "    TrlParser,\n",
    "    get_kbit_device_map,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    generate_train_examples,\n",
    "    pad_train_examples,\n",
    "    tokenize_single_turn,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import gc\n",
    "import types\n",
    "\n",
    "# need for auto SFTTrainer patch(possible increase speed)\n",
    "from unsloth import is_bfloat16_supported\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    EOS_TOKEN_ID,\n",
    "    TEXT_TOKEN_ID,\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    find_all_linear_names_v3,\n",
    ")\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    "    Qwen2ForCausalLMCompressionV3,\n",
    "    Qwen2ModelEmbedPoolerV3,\n",
    ")\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"my_r1_model_v3\"\n",
    "model = Qwen2ForCausalLMCompressionV3.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model.model.requires_grad_(False)\n",
    "# model = model.to(torch.bfloat16)\n",
    "\n",
    "# temp_model = Qwen2ModelEmbedPoolerV3.from_pretrained(\n",
    "#     model_name,\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map={\"\": 0},\n",
    "#     # quantization_config=BitsAndBytesConfig(load_in_4bit=True),\n",
    "# )\n",
    "# print(\n",
    "#     model.embed_pooler.load_state_dict(\n",
    "#         temp_model.state_dict(),\n",
    "#         strict=False,\n",
    "#     ),\n",
    "# )\n",
    "# temp_model = temp_model.cpu()\n",
    "# del temp_model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# dataset = load_dataset(\"dim/open_orca_905_DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "# dataset = dataset[\"train\"]\n",
    "# dataset = dataset.train_test_split(test_size=10, seed=42)\n",
    "\n",
    "# # test pass\n",
    "# tokenize_single_turn(\n",
    "#     question=dataset[\"train\"][0][\"question\"],\n",
    "#     answer=dataset[\"train\"][0][\"answer\"],\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "# train_examples = [\n",
    "#     tokenize_single_turn(tokenizer=tokenizer, **item)\n",
    "#     for item in tqdm(dataset[\"train\"].to_list()[:3])\n",
    "# ]\n",
    "\n",
    "# prepared_train_examples = []\n",
    "# for item in tqdm(train_examples):\n",
    "#     for example in generate_train_examples(\n",
    "#         dataset_batch=[item],\n",
    "#         window_size=WINDOW_SIZE,\n",
    "#     ):\n",
    "#         prepared_train_examples.append(example)\n",
    "\n",
    "# print(\n",
    "#     \"max_len\",\n",
    "#     max([len(item[\"original_tokens\"]) for item in prepared_train_examples]),\n",
    "# )\n",
    "\n",
    "# new_dataset = Dataset.from_list(prepared_train_examples)\n",
    "# print(dataset)\n",
    "\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     padded_batch = pad_train_examples(\n",
    "#         train_examples=batch,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )\n",
    "#     padded_batch = {\n",
    "#         \"replaced_original_tokens\": padded_batch[\"replaced_original_tokens\"][\n",
    "#             \"input_ids\"\n",
    "#         ],\n",
    "#         \"compressed_input_ids\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "#         \"original_tokens\": padded_batch[\"original_tokens\"][\"input_ids\"],\n",
    "#         \"attention_mask\": padded_batch[\"compressed_input_ids\"][\"attention_mask\"],\n",
    "#         \"labels\": padded_batch[\"compressed_input_ids\"][\"input_ids\"],\n",
    "#         \"content_compression_mask\": padded_batch[\"content_compression_mask\"][\n",
    "#             \"input_ids\"\n",
    "#         ],\n",
    "#     }\n",
    "#     for key in padded_batch.keys():\n",
    "#         padded_batch[key] = torch.tensor(padded_batch[key])\n",
    "#     skip_ids = [\n",
    "#         TEXT_TOKEN_ID,\n",
    "#         EOS_TOKEN_ID,\n",
    "#         VISION_START,\n",
    "#         VISION_END,\n",
    "#     ]\n",
    "#     for skip_id in skip_ids:\n",
    "#         padded_batch[\"labels\"][padded_batch[\"labels\"] == skip_id] = -100\n",
    "#     #    \n",
    "#     last_index = (padded_batch[\"content_compression_mask\"] == 1).long().nonzero()[-1][1]\n",
    "#     padded_batch[\"labels\"][:, :last_index][\n",
    "#         padded_batch[\"content_compression_mask\"][:, :last_index] == 1\n",
    "#     ] = -100\n",
    "#     # print(padded_batch)\n",
    "#     return padded_batch\n",
    "\n",
    "\n",
    "# peft_config = LoraConfig(\n",
    "#     r=16,\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.0,\n",
    "#     bias=\"none\",\n",
    "#     target_modules=find_all_linear_names_v3(model=model),\n",
    "#     modules_to_save=[\n",
    "#         \"embed_pooler.model.embed_tokens\",\n",
    "#         \"embed_pooler.weight_pooler\",\n",
    "#     ],\n",
    "# )\n",
    "\n",
    "# formatted_date = datetime.fromtimestamp(time.time()).strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "# model.embed_pooler = prepare_model_for_kbit_training(model.embed_pooler)\n",
    "# peft_model = get_peft_model(model, peft_config)\n",
    "# peft_model.print_trainable_parameters()\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     train_dataset=new_dataset,\n",
    "#     data_collator=collate_fn,\n",
    "#     peft_config=peft_config,\n",
    "#     args=SFTConfig(\n",
    "#         per_device_train_batch_size=2,\n",
    "#         gradient_accumulation_steps=2,\n",
    "#         warmup_steps=5,\n",
    "#         num_train_epochs=1,  # 90,  # Set this for 1 full training run.\n",
    "#         # num_train_epochs=90,  # Set this for 1 full training run.\n",
    "#         # max_steps=10000,\n",
    "#         learning_rate=1e-4,\n",
    "#         bf16=True,\n",
    "#         # fp16=model.dtype == torch.float16,\n",
    "#         logging_steps=8,\n",
    "#         optim=\"adamw_8bit\",\n",
    "#         weight_decay=0.01,\n",
    "#         lr_scheduler_type=\"linear\",\n",
    "#         seed=3407,\n",
    "#         output_dir=f\"outputs/{formatted_date}\",\n",
    "#         # report_to=\"wandb\",\n",
    "#         report_to=\"none\",\n",
    "#         remove_unused_columns=False,\n",
    "#         dataset_kwargs={\"skip_prepare_dataset\": True},\n",
    "#         # gradient_checkpointing=True,\n",
    "#         save_steps=10000,\n",
    "#         run_name=formatted_date,\n",
    "#     ),\n",
    "# )\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLets denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLets assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLets let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLets denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('my_r1_model_v3/tokenizer_config.json',\n",
       " 'my_r1_model_v3/special_tokens_map.json',\n",
       " 'my_r1_model_v3/tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"my_r1_model_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.base_model.embed_pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(torch.bfloat16)\n",
    "model.embed_pooler(\n",
    "    torch.randn(\n",
    "        2,\n",
    "        2,\n",
    "        1536,\n",
    "        device=\"cuda\",\n",
    "        dtype=torch.bfloat16,\n",
    "    )\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: embed_pooler.weight_pooler.modules_to_save.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: base_model.model.embed_pooler.model.embed_tokens.modules_to_save.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.0.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.1.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.2.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.3.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.4.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.5.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.6.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.7.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.8.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.9.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.10.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.11.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.12.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.13.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.14.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.15.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.16.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.17.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.18.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.19.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.20.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.21.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.22.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.23.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.24.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.25.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.26.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.q_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.k_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.v_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.self_attn.o_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.gate_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.up_proj.lora_B.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_A.default.weight, Requires Gradient: True\n",
      "Layer: base_model.model.embed_pooler.model.layers.27.mlp.down_proj.lora_B.default.weight, Requires Gradient: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in trainer.model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      " Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from peft import PeftModel\n",
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV1,\n",
    "    Qwen2ModelEmbedPoolerV1,\n",
    "    Qwen2ForCausalLMCompressionV2,\n",
    "    Qwen2ForCausalLMCompressionV5,\n",
    "    Qwen2ModelEmbedPoolerV2,\n",
    ")\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "# model_name = \"r1_compressor_v2\"\n",
    "# model = Qwen2ForCausalLMCompressionV2.from_pretrained(\n",
    "#     model_name,\n",
    "#     # torch_dtype=torch.bfloat16,\n",
    "#     torch_dtype=torch.float32,\n",
    "#     device_map={\"\": 0},\n",
    "#     # attn_implementation=\"flash_attention_2\",\n",
    "#     attn_implementation=\"sdpa\",\n",
    "# )\n",
    "# model = PeftModel.from_pretrained(\n",
    "#     model,\n",
    "#     # \"outputs/2025_04_19_17_17_34_493839/checkpoint-210000\",\n",
    "#     # \"outputs/2025_04_19_17_17_34_493839/checkpoint-50000\",\n",
    "#     # \"outputs/2025_04_21_19_23_11_642509/checkpoint-10000\",\n",
    "#     # \"outputs/2025_04_22_01_43_43_347583/checkpoint-90000\",\n",
    "#     # \"outputs/2025_04_22_01_43_43_347583/checkpoint-10000\",\n",
    "#     # 'outputs/2025_04_23_00_46_10_062896/checkpoint-2794'\n",
    "#     # \"outputs/2025_04_29_21_24_17_071961/checkpoint-588\",\n",
    "#     # \"outputs/2025_04_30_01_16_22_692562/checkpoint-140000\",\n",
    "#     # \"outputs/2025_04_30_01_16_22_692562/checkpoint-10000\",\n",
    "#     # \"outputs/2025_05_01_14_33_36_096886/checkpoint-10000\",\n",
    "#     \"outputs/2025_05_02_00_34_41_878309/checkpoint-60000\",\n",
    "#     # \"outputs/2025_05_02_00_34_41_878309/checkpoint-10000\",\n",
    "#     # \"outputs/2025_05_04_22_59_34_768602/checkpoint-160000\",\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "###\n",
    "\n",
    "model_name = \"outputs/2025_05_06_01_19_17_860068/checkpoint-300000\"\n",
    "# model_name = \"outputs/2025_05_06_01_19_17_860068/checkpoint-100000\"\n",
    "# model_name = \"outputs/2025_05_07_00_29_16_600547/checkpoint-448762\"\n",
    "# model_name = \"outputs/2025_05_08_13_26_40_258983/checkpoint-7010\"\n",
    "model = Qwen2ForCausalLMCompressionV5.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "224 202 0.9017857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    # \"dim/hendrycks_math_train_12k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    # \"dim/hendrycks_math_train_1k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(\n",
    "    # test_size=250,\n",
    "    test_size=350,\n",
    "    # test_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dataset = dataset[\"test\"].filter(lambda x: x[\"model_answer\"].count(\"</think>\") == 1)\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "\n",
    "correct_dataset = []\n",
    "\n",
    "for pos, item in enumerate(dataset):\n",
    "    try:\n",
    "        answer = dataset_answer_filter(item[\"answer\"])\n",
    "        model_answer = model_answer_filter(item[\"model_answer\"])\n",
    "        # print(answer, model_answer)\n",
    "        # break\n",
    "        if is_equiv(answer, model_answer):\n",
    "            correct_dataset.append(item)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(dataset), len(correct_dataset), len(correct_dataset) / len(dataset))\n",
    "\n",
    "correct_dataset = correct_dataset[:30]\n",
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<beginofsentence><User>Problem: If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<Assistant><think>\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "# prompt = \"how many wings has a bird?\"\n",
    "prompt = correct_dataset[0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(text)\n",
    "model_inputs = tokenizer(\n",
    "    [text],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"longest\",\n",
    "    truncation=False,\n",
    "    add_special_tokens=False,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # generated_ids = model.generate(\n",
    "    #     model_inputs.input_ids,\n",
    "    #     max_new_tokens=1,\n",
    "    #     do_sample=False,\n",
    "    # )\n",
    "    generated_ids = model.generate(\n",
    "        # **model_inputs.input_ids,\n",
    "        **model_inputs,\n",
    "        max_new_tokens=4096,\n",
    "        do_sample=False,\n",
    "        # do_sample=not False,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?',\n",
       " 'solution': 'Every hour, the lion runs 24 miles while the elephant runs 19.  Thus, the distance between the two animals closes at a rate of 5 miles every hour.  The lion catches the elephant after this distance has closed 1 mile, which takes $\\\\frac{1}{5}$ hours to do, or $\\\\frac{1}{5}\\\\cdot 60 = \\\\boxed{12}$ minutes.',\n",
       " 'answer': '12',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1820.json',\n",
       " 'model_answer': \"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLets denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLets assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLets let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLets denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response == correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<beginofsentence><User>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<Assistant><think>\n",
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<endofsentence><beginofsentence>\n",
      "\n",
      "To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "prompt = correct_dataset[:5][0][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": base_prompt.format(question=prompt)},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "# initial_len = generated_tokens.shape\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    max_steps = 1200\n",
    "    past_key_values = None\n",
    "    for step in range(max_steps):\n",
    "        if step == 0:\n",
    "            logits = model(\n",
    "                inputs_embeds=generated_embeds,\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.arange(generated_embeds.shape[1])\n",
    "                .cuda()\n",
    "                .unsqueeze(0),\n",
    "                use_cache=True,\n",
    "                past_key_values=None,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "        else:\n",
    "            logits = model(\n",
    "                # input_ids=generated_tokens[-1][-1:].unsqueeze(0),\n",
    "                inputs_embeds=generated_embeds[:, -1:, :],\n",
    "                attention_mask=torch.ones(1, generated_embeds.shape[1]).long().cuda(),\n",
    "                position_ids=torch.tensor(generated_embeds.shape[1] - 1)\n",
    "                .reshape(1, 1)\n",
    "                .cuda(),\n",
    "                use_cache=True,\n",
    "                past_key_values=past_key_values,\n",
    "            )\n",
    "            past_key_values = logits.past_key_values\n",
    "\n",
    "            logits = logits.logits[:, -1, :].clone().float()\n",
    "\n",
    "        top_token = logits.argmax(-1)[-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(step, tokenizer.decode(generated_tokens[-1]))\n",
    "    # break\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "# break\n",
    "embeds_generation_tokens = generated_tokens[-1]\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<beginofsentence><User>Problem: An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?\\n\\nPlease reason step by step, and put your final answer within \\\\boxed{}.<Assistant><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\\n\\nLet me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\\n\\nSo, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\\n\\nTime = Distance / Speed\\n\\nSo, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\\n\\nLet's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\\n\\nSo, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\\n\\nSo, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\\n\\nAlternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\\n\\nI think that's solid. So, the lion will catch the elephant in 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \\n\\nTo find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\\n\\n\\\\[\\n24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph}\\n\\\\]\\n\\nThe initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\\n\\n\\\\[\\n\\\\text{Time} = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = 0.2 \\\\text{ hours}\\n\\\\]\\n\\nConverting 0.2 hours to minutes:\\n\\n\\\\[\\n0.2 \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes.<endofsentence><beginofsentence>\\n\\nTo determine how long it will take for the lion to catch the elephant, we need to consider their relative speed. The elephant is running away at \""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "from transformers.generation import utils\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "dataset_pos = 0\n",
    "prompt = correct_dataset[dataset_pos][\"problem\"]\n",
    "\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": base_prompt.format(question=prompt),\n",
    "        },\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "with torch.no_grad():\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=4096,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] == correct_dataset[\n",
    "    dataset_pos\n",
    "][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': \"Alicia's average on her five tests is 88 points. The score range for each test is 0 points to 100 points, inclusive. What is the lowest possible score that Alicia could have earned on one of the five tests?\",\n",
       " 'solution': \"If Alicia's average score on her five tests is 88 points, then the sum of her scores must be $88 \\\\times 5 = 440$ points. If she earned   100 points on four of the tests, then she could have earned a score as low as $\\\\boxed{40\\\\text{ points}}$ on the other test.\",\n",
       " 'answer': '40\\\\text{ points}',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 4,\n",
       " 'unique_id': 'test/prealgebra/1697.json',\n",
       " 'model_answer': \"Okay, so I need to figure out the lowest possible score Alicia could have earned on one of her five tests. She has an average of 88 points, and each test is scored between 0 and 100, inclusive. Hmm, let me think about this step by step.\\n\\nFirst, I know that an average is calculated by taking the sum of all the test scores and dividing it by the number of tests. In this case, she has five tests, and her average is 88. So, to find the total points she has across all five tests, I can multiply the average by the number of tests.\\n\\nLet me write that down:\\n\\nTotal points = Average  Number of tests\\nTotal points = 88  5\\n\\nLet me calculate that. 88 times 5 is... 440. So, the total points she has across all five tests is 440.\\n\\nNow, the question is asking for the lowest possible score she could have earned on one of these tests. To minimize one of the test scores, I need to maximize the other scores because the total is fixed at 440.\\n\\nBut there are constraints: each test can only have a score between 0 and 100, inclusive. So, the maximum score on any test is 100. If I try to maximize the other four test scores, each being 100, that would give me the maximum possible sum for four tests.\\n\\nLet me calculate that:\\n\\nMaximizing four tests:\\nMax sum = 100  4 = 400\\n\\nSo, if four tests are 100 each, that's 400 points. Then, the fifth test must make up the remaining points to reach the total of 440.\\n\\nLet me find the score for the fifth test:\\n\\nScore on fifth test = Total points - Max sum of four tests\\nScore = 440 - 400\\nScore = 40\\n\\nWait, so that means if four tests are 100 each, the fifth test must be 40? That seems low, but it's mathematically correct because 100 + 100 + 100 + 100 + 40 = 440.\\n\\nBut hold on, the question is asking for the lowest possible score on one of the tests. So, if I set the other four tests as high as possible (100 each), the fifth test would be 40. But is there a way to get a lower score? Let me think.\\n\\nIf I make one of the other tests lower than 100, does that allow the fifth test to be lower than 40? Wait, no, because if I lower one test, I have to raise the others to compensate, but they can't go above 100. So, actually, to minimize one test, you need to maximize the others as much as possible, which is 100 each. So, 40 is indeed the minimal possible score.\\n\\nBut just to double-check, let's think about it differently. Suppose I try to set four tests to 100, which gives me 400. The fifth test is 40. If I tried to make the fifth test lower, say 30, then the sum of the other four tests would have to be 440 - 30 = 410. But if I have four tests, each can be at most 100, so 100  4 is 400. 410 is more than 400, which isn't possible. So, it's not possible to have a lower score on the fifth test than 40 because the other four tests can't exceed 400.\\n\\nTherefore, 40 is the lowest possible score Alicia could have earned on one of the five tests.\\n\\nWait, but another thought: what if one test is 0? Would that allow the others to be higher? Let me see. If one test is 0, then the total of the other four tests would have to be 440 - 0 = 440. But each of those four tests can only go up to 100, so 100  4 is 400. But 440 is more than 400, which is impossible. Therefore, having a 0 on one test would require the others to sum to 440, which isn't possible since the maximum they can sum to is 400. So, 0 is too low.\\n\\nSo, 40 is indeed the lowest possible score because it's the only score that allows the other four tests to be 100 each without exceeding the maximum.\\n\\nAnother angle: Let's think about the formula for the average. The average is the total divided by the number of tests. So, if I want to minimize one test, I have to maximize the others, but they can't exceed 100. So, the maximum sum of four tests is 400, as we had before. Therefore, the minimal fifth test is 40.\\n\\nWait, let me make sure I'm not missing any other constraints. The problem says each test is between 0 and 100, inclusive. So, 0 is allowed, but in this case, if we tried to set four tests to 100, the fifth must be 40. If we set one test to 100, the others could be higher, but that doesn't help in minimizing a single test. Alternatively, if I set two tests to 100, the others can be higher, but again, that doesn't help.\\n\\nTherefore, the only way to minimize a single test score is to maximize the other four, which is 100 each. So, the minimal possible score is 40.\\n\\nI think that's solid reasoning. I don't see any other way to lower one test score without violating the test score range or the total points.\\n\\n**Final Answer**\\nThe lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\\n</think>\\n\\nAlicia's average score on her five tests is 88 points. To find the total points she has across all five tests, we multiply the average by the number of tests:\\n\\n\\\\[\\n\\\\text{Total points} = 88 \\\\times 5 = 440\\n\\\\]\\n\\nTo find the lowest possible score on one of the tests, we need to maximize the scores of the other four tests. Since each test can score a maximum of 100, the maximum sum of four tests is:\\n\\n\\\\[\\n\\\\text{Max sum of four tests} = 100 \\\\times 4 = 400\\n\\\\]\\n\\nThe score on the fifth test must then be:\\n\\n\\\\[\\n\\\\text{Score on fifth test} = 440 - 400 = 40\\n\\\\]\\n\\nThus, the lowest possible score Alicia could have earned on one of the five tests is \\\\boxed{40}.\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "example_id = correct_dataset[dataset_pos][\"unique_id\"].replace(\"/\", \"_\")\n",
    "with open(f\"./temp/{example_id}\", \"w\") as f:\n",
    "    temp = {\n",
    "        \"generated_ids\": generated_ids.tolist(),\n",
    "        \"input_ids\": generated_tokens.tolist(),\n",
    "    }\n",
    "    json.dump(temp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\n",
    "    correct_dataset[dataset_pos][\"model_answer\"],\n",
    "    add_special_tokens=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<beginofsentence><User>An elephant and a lion are currently 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour.  How many minutes will it take for the lion to catch the elephant?<Assistant><think>\\nOkay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them will be changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should think of the relative speed as the lion's speed minus the elephant's speed? Wait, no, that might not be right.\\n\\nLet me clarify. If the lion is moving towards the elephant at 24 mph, and the elephant is moving away from the lion at 19 mph, then the lion is effectively closing the gap at a rate of 24 mph minus 19 mph. That makes sense because the lion is moving towards the elephant, but the elephant is moving away. So, the net speed at which the distance between them is decreasing is 24 - 19 = 5 mph.\\n\\nSo, the distance between them is decreasing at 5 miles per hour. They start 1 mile apart, so I can use the formula:\\n\\nTime = Distance / Speed\\n\\nHere, the distance is 1 mile, and the speed is 5 mph. So, time = 1 / 5 hours. But the question asks for the time in minutes, so I need to convert hours to minutes. There are 60 minutes in an hour, so 1/5 hours * 60 minutes/hour = 12 minutes.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph towards the elephant, and the elephant is moving away at 19 mph, then the relative speed is indeed 24 - 19 = 5 mph. So, the lion is gaining on the elephant at 5 miles per hour. Since they start 1 mile apart, the time it takes to close that distance is 1 / 5 hours, which is 12 minutes. That seems right.\\n\\nBut just to make sure, let me think about it another way. Maybe set up an equation for their positions as functions of time and see when they meet.\\n\\nLet me denote t as the time in hours. The position of the elephant as a function of time would be starting from some point and moving away at 19 mph. Let's say the initial position of the elephant is at position 0, and the lion is at position 1 mile. Then, the position of the elephant at time t is 0 + 19t, and the position of the lion is 1 - 24t. They meet when their positions are equal, so:\\n\\n19t = 1 - 24t\\n\\nAdding 24t to both sides:\\n\\n19t + 24t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours\\n\\nWait, that's different from what I got before. Hmm, so which one is correct? 12 minutes or 1/43 hours?\\n\\nWait, 1/43 hours is approximately 1.395 minutes, which is about 1 minute and 23 seconds. But earlier, I got 12 minutes. That's a big difference. So, I must have made a mistake somewhere.\\n\\nLet me go back. When I thought about the relative speed, I considered the lion moving towards the elephant and the elephant moving away, so the relative speed is 24 - 19 = 5 mph. So, the time should be 1/5 hours, which is 12 minutes. But when I set up the equations, I got t = 1/43 hours, which is about 1.395 minutes. That's conflicting.\\n\\nWait, maybe I messed up the initial positions. Let me define the positions more carefully. Let's say the lion starts at position 0, and the elephant starts at position 1 mile. Then, the lion is moving towards the elephant, so its position as a function of time is 0 + 24t. The elephant is moving away from the lion, so its position is 1 + 19t. They meet when their positions are equal:\\n\\n24t = 1 + 19t\\n\\nSubtracting 19t from both sides:\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. Okay, that makes sense. So, why did I get 1/43 hours earlier?\\n\\nWait, in my second approach, I set the lion's position as 1 - 24t, but that might be incorrect. If the lion starts at position 0, moving towards the elephant, which is at position 1, then the lion's position is 24t. The elephant is moving away from the lion, so its position is 1 + 19t. So, setting them equal:\\n\\n24t = 1 + 19t\\n\\nWhich gives t = 1/5 hours, which is 12 minutes. So, that seems correct.\\n\\nWait, so why did I get 1/43 hours earlier? Maybe I confused the starting positions. Let me re-examine that.\\n\\nIn the second approach, I set the lion's position as 1 - 24t, which would be incorrect because if the lion is moving towards the elephant, starting from position 0, its position should be increasing, not decreasing. So, that was my mistake. I should have set the lion's position as 24t, not 1 - 24t.\\n\\nSo, correcting that, the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes. So, that's consistent with the first method.\\n\\nTherefore, the correct answer is 12 minutes.\\n\\nWait, but just to make sure, let me think about it in another way. Suppose the lion is moving at 24 mph towards the elephant, and the elephant is\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\\n\\nFirst, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards the elephant at 24 mph. So, their speeds are different, which means the distance between them is changing over time. I need to find the time it takes for the lion to close that 1 mile gap.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the elephant is moving away, so it's like the lion is chasing the elephant, but the elephant is moving away. So, maybe I should consider the relative speed between the lion and the elephant.\\n\\nWait, actually, since the elephant is moving away, the lion has to cover the initial distance plus any additional distance the elephant might cover while the lion is chasing. But since the lion is faster, it should eventually catch up. So, maybe I can model this as a relative speed problem.\\n\\nLet me denote the speed of the lion as \\\\( v_l = 24 \\\\) mph and the speed of the elephant as \\\\( v_e = 19 \\\\) mph. The initial distance between them is \\\\( d = 1 \\\\) mile.\\n\\nSince the lion is moving towards the elephant and the elephant is moving away, the relative speed at which the distance between them is decreasing is the difference between the lion's speed and the elephant's speed. So, the relative speed \\\\( v_{relative} = v_l - v_e = 24 - 19 = 5 \\\\) mph.\\n\\nWait, is that right? If the lion is moving towards the elephant and the elephant is moving away, then the lion is effectively closing the gap at a rate of 5 mph. So, the time it takes to close the 1 mile gap would be the initial distance divided by the relative speed.\\n\\nSo, time \\\\( t = \\\\frac{d}{v_{relative}} = \\\\frac{1}{5} \\\\) hours. But the question asks for the time in minutes, so I need to convert that.\\n\\nSince 1 hour is 60 minutes, \\\\( \\\\frac{1}{5} \\\\) hours is \\\\( \\\\frac{1}{5} \\\\times 60 = 12 \\\\) minutes. So, it should take 12 minutes for the lion to catch the elephant.\\n\\nWait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, then the lion is gaining on the elephant at a rate of 5 mph. So, to cover the 1 mile gap, it would take \\\\( \\\\frac{1}{5} \\\\) hours, which is indeed 12 minutes. That seems correct.\\n\\nAlternatively, I can model this with equations. Let me set up a coordinate system where at time \\\\( t \\\\) hours, the position of the lion is \\\\( 24t \\\\) miles from its starting point, and the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion. Wait, actually, hold on. If the elephant is moving away from the lion, then the distance between them is increasing. So, the position of the elephant is \\\\( 1 + 19t \\\\) miles from the starting point of the lion, and the position of the lion is \\\\( 24t \\\\) miles from the same starting point.\\n\\nWait, but initially, they are 1 mile apart. So, if the lion starts at position 0 and the elephant starts at position 1 mile, then the distance between them at time \\\\( t \\\\) is \\\\( |24t - (1 + 19t)| \\\\). We want this distance to be 0 when the lion catches the elephant.\\n\\nSo, setting up the equation:\\n\\n\\\\( 24t - (1 + 19t) = 0 \\\\)\\n\\nSimplify:\\n\\n\\\\( 24t - 19t - 1 = 0 \\\\)\\n\\n\\\\( 5t - 1 = 0 \\\\)\\n\\n\\\\( 5t = 1 \\\\)\\n\\n\\\\( t = \\\\frac{1}{5} \\\\) hours, which is 12 minutes. So, that confirms my earlier result.\\n\\nAlternatively, I can think about it in terms of distance covered. The lion needs to cover the initial 1 mile plus whatever distance the elephant covers in that time. But since the lion is faster, the time is determined by the relative speed.\\n\\nWait, another way to think about it is using the concept of relative velocity. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the relative speed is 24 - 19 = 5 mph. So, the lion is closing the gap at 5 mph. Therefore, the time to close 1 mile is 1/5 hours, which is 12 minutes.\\n\\nI think that's solid. I can't see any mistakes in this reasoning. So, I think the answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. To determine how long it will take for the lion to catch the elephant, we need to consider their relative speed.\\n\\nThe relative speed at which the lion is closing the gap is the difference between their speeds:\\n\\\\[ v_{\\\\text{relative}} = v_l - v_e = 24 \\\\text{ mph} - 19 \\\\text{ mph} = 5 \\\\text{ mph} \\\\]\\n\\nThe time it takes to close the 1 mile gap is calculated by dividing the initial distance by the relative speed:\\n\\\\[ t = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours} \\\\]\\n\\nConverting this time into minutes:\\n\\\\[ \\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes} \\\\]\\n\\nThus, the lion will catch the elephant in \\\\boxed{12} minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate with compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If $A=2+i$, $O=-4$, $P=-i$, and $S=2+4i$, find $A-O+P+S$.\n",
      "===\n",
      "===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPRESSED PART Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\n",
      "\n",
      "First, let me write down each term:\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4\n",
      "\n",
      "P = -i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "And the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\n",
      "\n",
      "Let me start by substituting the values:\n",
      "\n",
      "A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Wait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Okay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\n",
      "\n",
      "First, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\n",
      "\n",
      "(2 + i) - (-4) = (2 + i) + 4\n",
      "\n",
      "So, that simplifies to 2 + 4 + i, which is 6 + i.\n",
      "\n",
      "Alright, so now the expression becomes:\n",
      "\n",
      "6 + i + (-i) + (2 + 4i)\n",
      "\n",
      "Wait, let me write that again:\n",
      "\n",
      "= (6 + i) + (-i) + (2 + 4i)\n",
      "\n",
      "Now,\n",
      "===\n",
      " let's handle the imaginary parts and the real parts separately.\n",
      "\n",
      "Imaginary parts: i + (-i) = i - i = 0i, which is just 0.\n",
      "\n",
      "Real parts: 6 + 2 = 8.\n",
      "\n",
      "So, adding them together: 8 + 0i = 8.\n",
      "\n",
      "Wait, that seems too straightforward. Let me check my steps again to make sure I didn't make a mistake.\n",
      "\n",
      "Starting over:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, handle the subtraction:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P: 6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S: 6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Wait, hold on, that's different from what I had before. Hmm, so I must have made a mistake in my initial breakdown.\n",
      "\n",
      "Let me do it step by step again:\n",
      "\n",
      "Start with A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Wait, so now I get 8 + 4i. But earlier, I thought it was 8. So, which one is correct?\n",
      "\n",
      "Let me count the steps again.\n",
      "\n",
      "1. Compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "2. Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "3. Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "So, that's 8 + 4i. Hmm, so why did I get 8 earlier? Because I thought that adding 6 and 2 gives 8, but actually, 6 is already a real number, and then adding 2 gives 8, but the imaginary parts cancel out, leaving just 8 + 4i.\n",
      "\n",
      "Wait, so perhaps I made a mistake in my initial breakdown when I thought it was 8. So, actually, the correct answer is 8 + 4i.\n",
      "\n",
      "Wait, let me check the arithmetic again.\n",
      "\n",
      "Starting over:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that seems correct. So, the final answer is 8 + 4i.\n",
      "\n",
      "Wait, but in my initial thought process, I thought it was 8, but now I see it's 8 + 4i. So, I need to make sure I don't make that mistake again.\n",
      "\n",
      "Alternatively, maybe I can approach it differently. Let me group the real parts and the imaginary parts separately.\n",
      "\n",
      "So, starting with:\n",
      "\n",
      "A - O + P + S\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, let's handle the real parts:\n",
      "\n",
      "Real parts: 2 (from A) + 4 (from O) + 2 (from S) = 2 + 4 + 2 = 8\n",
      "\n",
      "Imaginary parts: 1 (from A) + 0 (from O) - 1 (from P) + 4 (from S) = 1 + 0 - 1 + 4 = 4\n",
      "\n",
      "So, combining them: 8 + 4i\n",
      "\n",
      "Yes, that's consistent with the previous result.\n",
      "\n",
      "So, I think I initially made a mistake by not properly grouping the real and imaginary parts, but now that I've broken it down separately, it's clear that the answer is 8 + 4i.\n",
      "\n",
      "Wait, but let me make sure I didn't misplace any signs. Let's go step by step again.\n",
      "\n",
      "Compute A - O + P + S:\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4\n",
      "\n",
      "P = -i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "First, compute (2 + i) - (-4):\n",
      "\n",
      "Subtracting a negative is adding a positive, so:\n",
      "\n",
      "2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P: 6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "Then, add S: 6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Alternatively, if I were to write it as:\n",
      "\n",
      "(A - O) + (P + S)\n",
      "\n",
      "Compute A - O:\n",
      "\n",
      "(2 + i) - (-4) = 6 + i\n",
      "\n",
      "Compute P + S:\n",
      "\n",
      "(-i) + (2 + 4i) = 2 + 3i\n",
      "\n",
      "Then, add those results: (6 + i) + (2 + 3i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "So, I think I can confidently say that the answer is 8 + 4i.\n",
      "\n",
      "Wait, but just to make sure, let me plug in the values into the original expression and see if it matches.\n",
      "\n",
      "Compute A - O + P + S:\n",
      "\n",
      "= (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\n",
      "Compute each operation step by step:\n",
      "\n",
      "First, A - O:\n",
      "\n",
      "(2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (-i) = 6 + 0i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Alternatively, if I were to write it as:\n",
      "\n",
      "(A + P + S) - O\n",
      "\n",
      "Compute A + P + S:\n",
      "\n",
      "(2 + i) + (-i) + (2 + 4i) = 2 + i - i + 2 + 4i = (2 + 2) + (i - i + 4i) = 4 + 4i\n",
      "\n",
      "Then, subtract O: 4 + 4i - (-4) = 4 + 4i + 4 = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "So, regardless of the order in which I group the operations, I still get 8 + 4i.\n",
      "\n",
      "Therefore, I think I can be confident that the correct answer is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another method. Maybe convert all complex numbers to their standard form and then add them.\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4 (which is -4 + 0i)\n",
      "\n",
      "P = -i (which is 0 - i)\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\n",
      "\n",
      "Compute each operation:\n",
      "\n",
      "First, A - O:\n",
      "\n",
      "(2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + (0 - i) = 6 + i - i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Alternatively, if I write all the complex numbers in a column:\n",
      "\n",
      "A: 2 + i\n",
      "\n",
      "-O: +4 + 0i\n",
      "\n",
      "P: 0 - i\n",
      "\n",
      "S: 2 + 4i\n",
      "\n",
      "Adding them up:\n",
      "\n",
      "Real parts: 2 + 4 + 0 + 2 = 8\n",
      "\n",
      "Imaginary parts: 1 + 0 - 1 + 4 = 4\n",
      "\n",
      "So, 8 + 4i.\n",
      "\n",
      "Yes, that's consistent.\n",
      "\n",
      "Therefore, I think I can conclude that the value of A - O + P + S is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another approach. Maybe convert all complex numbers to their rectangular form and then add them step by step.\n",
      "\n",
      "A = 2 + i\n",
      "\n",
      "O = -4 = -4 + 0i\n",
      "\n",
      "P = -i = 0 - i\n",
      "\n",
      "S = 2 + 4i\n",
      "\n",
      "So, A - O + P + S = (2 + i) - (-4 + 0i) + (0 - i) + (2 + 4i)\n",
      "\n",
      "Compute A - O:\n",
      "\n",
      "(2 + i) - (-4 + 0i) = 2 + i + 4 - 0i = 6 + i\n",
      "\n",
      "Then, add P:\n",
      "\n",
      "6 + i + 0 - i = 6 + 0i = 6\n",
      "\n",
      "Then, add S:\n",
      "\n",
      "6 + (2 + 4i) = 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Alternatively, if I write all the operations together:\n",
      "\n",
      "A - O + P + S = (2 + i) + 4 + (-i) + 2 + 4i\n",
      "\n",
      "Wait, hold on, that's another way to think about it. Let me see.\n",
      "\n",
      "A - O + P + S = A + (-O) + P + S\n",
      "\n",
      "Since O = -4, -O = 4\n",
      "\n",
      "So, A + 4 + P + S\n",
      "\n",
      "Now, substitute A, P, S:\n",
      "\n",
      "(2 + i) + 4 + (-i) + (2 + 4i)\n",
      "\n",
      "Now, combine like terms:\n",
      "\n",
      "Real parts: 2 + 4 + 2 = 8\n",
      "\n",
      "Imaginary parts: i - i + 4i = 4i\n",
      "\n",
      "So, 8 + 4i\n",
      "\n",
      "Same result.\n",
      "\n",
      "Therefore, I think I can be absolutely sure that the answer is 8 + 4i.\n",
      "\n",
      "Wait, just to make sure, let me compute it using another method. Maybe using vectors or something.\n",
      "\n",
      "But actually, since all the operations are straightforward addition and subtraction of complex numbers, I think the above methods are sufficient.\n",
      "\n",
      "Therefore, I think the answer is 8 + 4i.\n",
      "\n",
      "**Final Answer**\n",
      "The value of \\( A - O + P + S \\) is \\boxed{8 + 4i}.\n",
      "</think>\n",
      "\n",
      "Given the values \\( A = 2 + i \\), \\( O = -4 \\), \\( P = -i \\), and \\( S = 2 + 4i \\), we need to find the value of \\( A - O + P + S \\).\n",
      "\n",
      "First, substitute the given values into the expression:\n",
      "\n",
      "\\[\n",
      "A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\n",
      "\\]\n",
      "\n",
      "Simplify each term step by step:\n",
      "\n",
      "1. Compute \\( A - O \\):\n",
      "   \\[\n",
      "   (2 + i) - (-4) = 2 + i + 4 = 6 + i\n",
      "   \\]\n",
      "\n",
      "2. Add \\( P \\) to the result:\n",
      "   \\[\n",
      "   6 + i + (-i) = 6 + 0i = 6\n",
      "   \\]\n",
      "\n",
      "3. Add \\( S \\) to the result:\n",
      "   \\[\n",
      "   6 + (2 + 4i) = 8 + 4i\n",
      "   \\]\n",
      "\n",
      "Thus, the value of \\( A - O + P + S \\) is \\(\\boxed{8 + 4i}\\).<endofsentence>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "dataset_pos = 0\n",
    "input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "print(input_ids)\n",
    "print(\"===\")\n",
    "print(\"===\")\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "input_ids = [\n",
    "    tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": base_prompt.format(question=input_ids),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "# input_ids = dataset_item[\"input_ids\"]\n",
    "# generated_ids = dataset_item[\"generated_ids\"]\n",
    "generated_ids = [\n",
    "    tokenizer.encode(\n",
    "        correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = \"cuda\"\n",
    "\n",
    "# generated_tokens = tokenizer.apply_chat_template(\n",
    "#     [\n",
    "#         # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "#         {\"role\": \"user\", \"content\": example[\"question\"]},\n",
    "#     ],\n",
    "#     tokenize=True,\n",
    "#     add_generation_prompt=True,\n",
    "# )\n",
    "generated_tokens = input_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # start_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        # end_embed = model.base_model.embed_pooler.model.embed_tokens.modules_to_save.default(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    input_ids = torch.tensor(input_ids).cuda()\n",
    "    input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "    # input_ids_embeds = model.base_model.embed_pooler.model.get_input_embeddings()(input_ids)\n",
    "    # windows_amount = 100\n",
    "    windows_amount = 200\n",
    "    # windows_amount = 300\n",
    "    # windows_amount = 400\n",
    "    # windows_amount = 500\n",
    "    # windows_amount = 2\n",
    "    next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "        :, : WINDOW_SIZE * windows_amount\n",
    "    ]\n",
    "\n",
    "    # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "    original_embeds = (\n",
    "        model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.base_model.model.get_input_embeddings()(next_true_tokens)\n",
    "        # model.get_input_embeddings()(next_true_tokens)\n",
    "    ).to(torch.float32)\n",
    "    # ).to(torch.bfloat16)\n",
    "\n",
    "    # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    new_embeds_for_compression = original_embeds.reshape(\n",
    "        windows_amount, WINDOW_SIZE, -1\n",
    "    )\n",
    "    compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "    compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "    # start_embed = torch.rand_like(start_embed)\n",
    "    # compressed_part = torch.rand_like(compressed_part)\n",
    "    # end_embed = torch.rand_like(end_embed)\n",
    "    generated_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds,\n",
    "            start_embed,\n",
    "            compressed_part,\n",
    "            end_embed,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "    print(\"===\")\n",
    "    generated_ids_compressed = model.generate(\n",
    "        inputs_embeds=generated_embeds,\n",
    "        max_new_tokens=2800,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        # do_sample=True,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "    # break\n",
    "print(tokenizer.decode(generated_ids_compressed[-1]))\n",
    "# break\n",
    "# embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'problem': 'Below is a magic square, meaning that the sum of the numbers in each row, in each column, and in each of the $2$ main diagonals are equal. What is the value of $n$?\\n\\n[asy]size(125);\\nfor(int i = 0; i<4; ++i)\\n{\\n\\ndraw((0,i)--(3,i),linewidth(1));\\n}\\n\\nfor(int j = 0; j<4; ++j)\\n{\\n\\ndraw((j,0)--(j,3),linewidth(1));\\n}\\n\\nlabel(\"$n-3$\",(.5,.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"$n+1$\",(.5,2.5));\\n\\nlabel(\"$n+2$\",(1.5,.5));\\nlabel(\"$2n-9$\",(1.5,1.5));\\nlabel(\"$1$\",(1.5,2.5));\\n\\nlabel(\"$2$\",(2.5,.5));\\nlabel(\"$n$\",(2.5,1.5));\\nlabel(\"$n-1$\",(2.5,2.5));\\n[/asy]',\n",
       " 'solution': 'First, we can evaluate the sum across the first row, which gives $(n+1)+1+(n-1)=2n+1$.  Evaluate the sum of the entries across the second row, $3+(2n-9)+n=3n-6$. Now, since we have a magic square, these two sums are equal.  So $2n+1=3n-6$. Isolating $n$, we obtain $n = \\\\boxed{7}$.\\n\\nThe square will look like: [asy] size(2cm);\\ndraw((0,0)--(3,0)--(3,3)--(0,3)--cycle,linewidth(1));\\ndraw((1,0)--(1,3),linewidth(1));\\ndraw((2,0)--(2,3),linewidth(1));\\ndraw((0,1)--(3,1),linewidth(1));\\ndraw((0,2)--(3,2),linewidth(1));\\nlabel(\"8\",(.5,2.5));\\nlabel(\"1\",(1.5,2.5));\\nlabel(\"6\",(2.5,2.5));\\nlabel(\"3\",(.5,1.5));\\nlabel(\"5\",(1.5,1.5));\\nlabel(\"7\",(2.5,1.5));\\nlabel(\"4\",(.5,.5));\\nlabel(\"9\",(1.5,.5));\\nlabel(\"2\",(2.5,.5));\\n[/asy]',\n",
       " 'answer': '7',\n",
       " 'subject': 'Prealgebra',\n",
       " 'level': 5,\n",
       " 'unique_id': 'test/prealgebra/1930.json',\n",
       " 'model_answer': \"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). Let me try to figure this out step by step. \\n\\nFirst, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\\\( n \\\\) such that all these sums are equal.\\n\\nLooking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\\n\\n- The top row has three cells: \\\\( n-3 \\\\), \\\\( 3 \\\\), and \\\\( n+1 \\\\).\\n- The middle row has \\\\( n+2 \\\\), \\\\( 2n-9 \\\\), and \\\\( 1 \\\\).\\n- The bottom row has \\\\( 2 \\\\), \\\\( n \\\\), and \\\\( n-1 \\\\).\\n\\nSo, writing this out, the magic square looks like this:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, now I need to find \\\\( n \\\\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\\\( S \\\\).\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That means the magic constant \\\\( S = 2n + 1 \\\\).\\n\\nLet me check the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since this must equal \\\\( S \\\\), we have:\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nLet me solve for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( n = 7 \\\\)\\n\\nWait, hold on. Let me verify this because I might have made a mistake. If \\\\( n = 7 \\\\), let me check the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nBut according to the first row, \\\\( 2n + 1 = 2*7 + 1 = 15 \\\\). So, that's consistent.\\n\\nLet me check the columns as well to make sure.\\n\\nFirst column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nPerfect.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + 1 + (7 - 1) = 8 + 1 + 6 = 15 \\\\)\\n\\nAll columns add up to 15.\\n\\nNow, let me check the diagonals.\\n\\nMain diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (14 - 9) + (7 - 1) = 4 + 5 + 6 = 15 \\\\)\\n\\nGood.\\n\\nOther diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals add up to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\). Therefore, \\\\( n = 7 \\\\) is the solution.\\n\\nBut wait, just to be thorough, let me check if all the individual cells are integers and if there are any constraints on \\\\( n \\\\). The problem doesn't specify that \\\\( n \\\\) has to be an integer, but in magic squares, often the numbers are integers. Let me see if \\\\( n = 7 \\\\) makes all the cells integers.\\n\\nLooking at the cells:\\n\\n- \\\\( n - 3 = 7 - 3 = 4 \\\\)\\n- \\\\( 3 \\\\) is already an integer.\\n- \\\\( n + 1 = 7 + 1 = 8 \\\\)\\n- \\\\( n + 2 = 7 + 2 = 9 \\\\)\\n- \\\\( 2n - 9 = 14 - 9 = 5 \\\\)\\n- \\\\( 1 \\\\) is an integer.\\n- \\\\( 2 \\\\) is an integer.\\n- \\\\( n = 7 \\\\)\\n- \\\\( n - 1 = 6 \\\\)\\n\\nAll of these are integers, so that's good.\\n\\nIs there any other constraint? The problem doesn't specify, so I think \\\\( n = 7 \\\\) is the correct answer.\\n\\nBut just to make sure, let me go back to the second row sum. I had:\\n\\nSecond row sum: \\\\( 3n - 6 \\\\)\\n\\nSet equal to \\\\( S = 2n + 1 \\\\):\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nSubtract \\\\( 2n \\\\):\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6:\\n\\n\\\\( n = 7 \\\\)\\n\\nYes, that's consistent.\\n\\nAlternatively, I could have used another row or column to solve for \\\\( n \\\\), but since all rows, columns, and diagonals give the same equation, it's redundant, but it's a good check.\\n\\nSo, I think I'm confident that \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we need to ensure that the sums of all rows, columns, and diagonals are equal. The magic square is as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nFirst, we calculate the sum of the first row:\\n\\\\[\\n(n - 3) + 3 + (n + 1) = 2n + 1\\n\\\\]\\nThis sum is the magic constant \\\\( S \\\\).\\n\\nNext, we calculate the sum of the second row:\\n\\\\[\\n(n + 2) + (2n - 9) + 1 = 3n - 6\\n\\\\]\\nSince this must equal \\\\( S \\\\), we set up the equation:\\n\\\\[\\n3n - 6 = 2n + 1\\n\\\\]\\nSolving for \\\\( n \\\\):\\n\\\\[\\n3n - 6 = 2n + 1 \\\\\\\\\\nn - 6 = 1 \\\\\\\\\\nn = 7\\n\\\\]\\n\\nWe verify this value by checking the sums of the columns and diagonals with \\\\( n = 7 \\\\):\\n- First column: \\\\( (7 - 3) + (7 + 2) + 2 = 15 \\\\)\\n- Second column: \\\\( 3 + (14 - 9) + 7 = 15 \\\\)\\n- Third column: \\\\( (7 + 1) + 1 + (7 - 1) = 15 \\\\)\\n- Main diagonal: \\\\( (7 - 3) + (14 - 9) + (7 - 1) = 15 \\\\)\\n- Other diagonal: \\\\( (7 + 1) + (14 - 9) + 2 = 15 \\\\)\\n\\nAll sums are equal to 15, confirming that \\\\( n = 7 \\\\) is correct.\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[dataset_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2601, 400, 2801, torch.Size([1, 2356]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids_compressed.shape[1], next_true_tokens.shape[\n",
    "    1\n",
    "], generated_ids_compressed.shape[1] + compressed_part.shape[1], torch.tensor(\n",
    "    generated_ids\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_dataset[0][\"model_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "# \"Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2 + i, O is -4, P is -i, and S is 2 + 4i. So, replacing each term:\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nOkay, that looks right. Now, let me simplify this step by step. I think I should handle the operations one at a time.\\n\\nFirst, let's handle the subtraction of O, which is -(-4). Subtracting a negative is the same as adding a positive, so:\\n\\n(2 + i) - (-4) = (2 + i) + 4\\n\\nSo, that simplifies to 2 + 4 + i, which is 6 + i.\\n\\nAlright, so now the expression becomes:\\n\\n6 + i + (-i) + (2 + 4i)\\n\\nWait, let me write that again:\\n\\n= (6 + i) + (-i) + (2 + 4i)\\n\\nNow, let's combine the real parts and the imaginary parts separately.\\n\\nFirst, the real parts: 6, 0 (since there's no real part in -i), and 2.\\n\\nSo, 6 + 0 + 2 = 8.\\n\\nNow, the imaginary parts: i, -i, and 4i.\\n\\nSo, let's add those up:\\n\\ni - i + 4i\\n\\nHmm, i minus i is 0, so that leaves us with 4i.\\n\\nSo, putting it all together, the real part is 8 and the imaginary part is 4i, so the result is 8 + 4i.\\n\\nWait, let me double-check that. Maybe I made a mistake in the signs somewhere.\\n\\nStarting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle the subtraction:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + i - i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems consistent. So, the final result is 8 + 4i.\\n\\nWait, hold on, let me make sure I didn't skip any steps or make a mistake in the signs.\\n\\nSo, starting over:\\n\\nA - O + P + S\\n\\n= (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, compute (2 + i) - (-4):\\n\\nSubtracting a negative is adding, so 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i:\\n\\n6 + i + (-i) = 6 + (i - i) = 6 + 0 = 6.\\n\\nThen, add S, which is 2 + 4i:\\n\\n6 + (2 + 4i) = (6 + 2) + 4i = 8 + 4i.\\n\\nYes, that seems correct. So, the final answer is 8 + 4i.\\n\\nAlternatively, maybe I can approach this problem by grouping the real and imaginary parts differently.\\n\\nLet me try that.\\n\\nGiven:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S can be rewritten as:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nLet me group the real numbers and the imaginary numbers separately.\\n\\nReal parts: 2, 0 (since O is -4, which is real), -0 (since P is -i, which is imaginary), and 2.\\n\\nImaginary parts: 1 (from A), 0 (from O), -1 (from P), and 4 (from S).\\n\\nSo, real parts: 2 + 0 + 0 + 2 = 4\\n\\nImaginary parts: 1 + 0 - 1 + 4 = 4\\n\\nWait, hold on, that doesn't seem right. Because when I grouped them earlier, I had 8 + 4i, but now grouping separately, I get 4 + 4i. That's a discrepancy. Hmm, so I must have made a mistake in my grouping.\\n\\nWait, let me check again.\\n\\nWait, no, actually, in the expression A - O + P + S, O is a real number, so it's just -(-4) which is +4. So, in the real parts, we have 2 (from A) + 4 (from -O) + 0 (from P) + 2 (from S). So, 2 + 4 + 2 = 8.\\n\\nImaginary parts: 1 (from A) + 0 (from -O) -1 (from P) + 4 (from S). So, 1 -1 + 4 = 4.\\n\\nSo, that gives 8 + 4i, which matches my previous result.\\n\\nWait, so why did I get 4 + 4i when I grouped them? Because I think I miscounted the real parts.\\n\\nWait, let me write it step by step.\\n\\nReal parts:\\n\\nFrom A: 2\\n\\nFrom -O: -(-4) = +4\\n\\nFrom P: 0 (since P is -i, which is purely imaginary)\\n\\nFrom S: 2\\n\\nSo, total real parts: 2 + 4 + 0 + 2 = 8\\n\\nImaginary parts:\\n\\nFrom A: 1\\n\\nFrom -O: 0 (since O is real)\\n\\nFrom P: -1\\n\\nFrom S: 4\\n\\nTotal imaginary parts: 1 + 0 -1 + 4 = 4\\n\\nSo, 8 + 4i. That's correct.\\n\\nSo, my initial grouping was wrong because I didn't account for all the real parts correctly. So, the correct answer is 8 + 4i.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = A + (-O) + P + S\\n\\nSo, substituting:\\n\\n= (2 + i) + (4) + (-i) + (2 + 4i)\\n\\nThen, combine like terms:\\n\\nReal parts: 2 + 4 + 2 = 8\\n\\nImaginary parts: i - i + 4i = 4i\\n\\nSo, 8 + 4i.\\n\\nYes, that's consistent.\\n\\nAlternatively, maybe I can think of it as:\\n\\nA - O + P + S = (A + P) + (-O + S)\\n\\nCompute A + P first:\\n\\nA = 2 + i\\n\\nP = -i\\n\\nSo, A + P = 2 + i + (-i) = 2 + 0i = 2\\n\\nThen, compute -O + S:\\n\\nO = -4, so -O = 4\\n\\nS = 2 + 4i\\n\\nSo, -O + S = 4 + (2 + 4i) = 6 + 4i\\n\\nNow, add A + P and -O + S:\\n\\n2 + (6 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the method, I get 8 + 4i.\\n\\nTherefore, I think that's the correct answer.\\n\\nWait, just to make sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nSo, A - O = (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nYep, same result.\\n\\nAlternatively, if I compute A - O + P + S step by step:\\n\\nStart with A: 2 + i\\n\\nSubtract O: 2 + i - (-4) = 2 + i + 4 = 6 + i\\n\\nAdd P: 6 + i + (-i) = 6 + 0i = 6\\n\\nAdd S: 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, I think I can confidently say that the answer is 8 + 4i.\\n\\nJust to recap, the steps are:\\n\\n1. Substitute each term into the expression.\\n\\n2. Simplify the expression by handling the operations step by step.\\n\\n3. Combine like terms (real and imaginary parts separately).\\n\\n4. Verify the result using different methods to ensure accuracy.\\n\\nSo, yeah, 8 + 4i is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify each term step by step:\\n\\n1. Subtract \\\\( O \\\\) from \\\\( A \\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) to the result:\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) to the result:\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).\"\n",
    "\n",
    "# compressed\n",
    "# 'Okay, so I have this problem here where I need to find the value of A minus O plus P plus S. The given values are A = 2 + i, O = -4, P = -i, and S = 2 + 4i. Hmm, let me write that down to make it clearer.\\n\\nFirst, let me write down each term:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nAnd the expression I need to compute is A - O + P + S. Hmm, okay. So, I think I need to substitute these values into the expression and then simplify it step by step.\\n\\nLet me start by substituting the values:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nWait, hold on. Let me make sure I substitute correctly. So, A is 2'\n",
    "\n",
    "# generated\n",
    "# \" + i, O is -4, P is -i, and S is 2 + 4i. So, the expression is A - O + P + S, which is (2 + i) - (-4) + (-i) + (2 + 4i). That seems right.\\n\\nNow, let me simplify this step by step. First, I can handle the subtraction of O, which is -(-4). Subtracting a negative is like adding a positive, so -(-4) is +4. So, that part becomes +4.\\n\\nSo, now the expression is:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNext, I can combine the real parts and the imaginary parts separately. Let me rewrite the expression grouping the real numbers and the imaginary numbers together:\\n\\nReal parts: 2 + 4 + 2\\n\\nImaginary parts: i - i + 4i\\n\\nLet me compute the real parts first. 2 + 4 is 6, and then 6 + 2 is 8. So, the real part is 8.\\n\\nNow, the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, the imaginary part is 4i.\\n\\nPutting it all together, the expression simplifies to 8 + 4i.\\n\\nWait, let me double-check that. So, starting from A - O + P + S:\\n\\nA is 2 + i, subtract O which is -4, so that becomes +4. Then add P which is -i, and add S which is 2 + 4i.\\n\\nSo, writing it out:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNow, let's combine the constants first. 2 + 4 is 6, and then 6 + 2 is 8. So, that's the real part.\\n\\nFor the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, that's correct.\\n\\nTherefore, the result is 8 + 4i.\\n\\nWait, but let me think again. Is there another way to approach this? Maybe by distributing the negative sign first.\\n\\nSo, A - O + P + S can be rewritten as A + (-O) + P + S. Since O is -4, -O is +4. So, that's the same as before.\\n\\nAlternatively, maybe I can think of it as A + (-O + P + S). Let me compute -O + P + S first.\\n\\nO is -4, so -O is +4. P is -i, and S is 2 + 4i. So, -O + P + S is 4 + (-i) + (2 + 4i).\\n\\nAgain, combining constants: 4 + 2 is 6, and then 6 + 0 is 6. For the imaginary parts: -i + 4i is 3i. So, that's 6 + 3i.\\n\\nThen, adding A, which is 2 + i, to that: (2 + i) + (6 + 3i) = 8 + 4i. So, same result.\\n\\nAlternatively, maybe I can add A and S first, then subtract O and add P.\\n\\nLet me try that approach.\\n\\nA is 2 + i, S is 2 + 4i. So, A + S is (2 + 2) + (i + 4i) = 4 + 5i.\\n\\nThen, subtract O, which is -4. So, A + S - O is 4 + 5i - (-4) = 4 + 5i + 4 = 8 + 5i.\\n\\nThen, add P, which is -i. So, 8 + 5i + (-i) = 8 + 4i. Again, same result.\\n\\nSo, regardless of the order in which I perform the operations, I end up with 8 + 4i.\\n\\nWait, let me make sure I didn't make any mistakes in my calculations. Sometimes, when dealing with complex numbers, it's easy to mix up the real and imaginary parts.\\n\\nLet me write down each step again:\\n\\n1. Start with A - O + P + S.\\n\\n2. Substitute the values:\\n\\n   (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\n3. Simplify the subtraction of O:\\n\\n   (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n4. Combine constants and imaginary parts:\\n\\n   Real parts: 2 + 4 + 2 = 8\\n\\n   Imaginary parts: i - i + 4i = 4i\\n\\n5. Combine them: 8 + 4i\\n\\nAlternatively, if I group the constants first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine constants: 2 + 4 + 2 = 8\\n\\n4. Combine imaginary parts: i - i + 4i = 4i\\n\\n5. Result: 8 + 4i\\n\\nAlternatively, if I group the imaginary parts first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine imaginary parts: i - i + 4i = 4i\\n\\n4. Combine real parts: 2 + 4 + 2 = 8\\n\\n5. Result: 8 + 4i\\n\\nSo, regardless of the order, I get the same result. Therefore, I think 8 + 4i is the correct answer.\\n\\nWait, just to be absolutely sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA is 2 + i, O is -4. So, A - O is (2 + i) - (-4) = 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i: 6 + i + (-i) = 6 + 0i = 6.\\n\\nThen, add S, which is 2 + 4i: 6 + (2 + 4i) = 8 + 4i.\\n\\nSo, that's another way to compute it step by step:\\n\\nA - O = 6 + i\\n\\nThen, A - O + P = 6 + i - i = 6\\n\\nThen, A - O + P + S = 6 + 2 + 4i = 8 + 4i.\\n\\nSame result.\\n\\nAlternatively, if I compute A - O + P + S step by step without grouping:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation one by one:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the approach, I end up with 8 + 4i.\\n\\nTherefore, I think I can confidently say that the value of A - O + P + S is 8 + 4i.\\n\\nJust to recap, the steps I took were:\\n\\n1. Substitute the given values into the expression.\\n\\n2. Simplify the expression by handling the subtraction of O, which turned into addition of 4.\\n\\n3. Combine the real parts and the imaginary parts separately.\\n\\n4. Verify the result by computing in different orders or by breaking it down into smaller steps.\\n\\n5. Ensure that each step is correct and that I didn't make any arithmetic errors.\\n\\nSo, I think I'm good. The answer is 8 + 4i.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Subtract \\\\( O \\\\) which is \\\\(-4\\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) which is \\\\(-i\\\\):\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) which is \\\\( 2 + 4i \\\\):\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this magic square problem here, and I need to find the value of \\\\( n \\\\). Let me try to figure this out step by step. \\n\\nFirst, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\\\( n \\\\) such that all these sums are equal.\\n\\nLooking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\\n\\n- The top row has three cells: \\\\( n-3 \\\\), \\\\( 3 \\\\), and \\\\( n+1 \\\\).\\n- The middle row has \\\\( n+2 \\\\), \\\\( 2n-9 \\\\), and \\\\( 1 \\\\).\\n- The bottom row has \\\\( 2 \\\\), \\\\( n \\\\), and \\\\( n-1 \\\\).\\n\\nSo, writing this out, the magic square looks like this:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nAlright, now I need to find \\\\( n \\\\) such that all rows, columns, and diagonals add up to the same sum. Let me denote this common sum as \\\\( S \\\\).\\n\\nFirst, let me compute the sum of the first row:\\n\\n\\\\( (n - 3) + 3 + (n + 1) \\\\)\\n\\nSimplify that:\\n\\n\\\\( n - 3 + 3 + n + 1 = 2n + 1 \\\\)\\n\\nSo, the sum of the first row is \\\\( 2n + 1 \\\\). That means the magic constant \\\\( S = 2n + 1 \\\\).\\n\\nLet me check the second row:\\n\\n\\\\( (n + 2) + (2n - 9) + 1 \\\\)\\n\\nSimplify:\\n\\n\\\\( n + 2 + 2n - 9 + 1 = 3n - 6 \\\\)\\n\\nSo, the sum of the second row is \\\\( 3n - 6 \\\\). Since this must equal \\\\( S \\\\), we have:\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nLet me solve for \\\\( n \\\\):\\n\\nSubtract \\\\( 2n \\\\) from both sides:\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6 to both sides:\\n\\n\\\\( n = 7 \\\\)\\n\\nWait, hold on. Let me verify this because I might have made a mistake. If \\\\( n = 7 \\\\), let me check the third row:\\n\\n\\\\( 2 + 7 + (7 - 1) = 2 + 7 + 6 = 15 \\\\)\\n\\nBut according to the first row, \\\\( 2n + 1 = 2*7 + 1 = 15 \\\\). So, that's consistent.\\n\\nLet me check the columns as well to make sure.\\n\\nFirst column:\\n\\n\\\\( (n - 3) + (n + 2) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (7 + 2) + 2 = 4 + 9 + 2 = 15 \\\\)\\n\\nGood, that's 15.\\n\\nSecond column:\\n\\n\\\\( 3 + (2n - 9) + n \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( 3 + (14 - 9) + 7 = 3 + 5 + 7 = 15 \\\\)\\n\\nPerfect.\\n\\nThird column:\\n\\n\\\\( (n + 1) + 1 + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + 1 + (7 - 1) = 8 + 1 + 6 = 15 \\\\)\\n\\nAll columns add up to 15.\\n\\nNow, let me check the diagonals.\\n\\nMain diagonal (top-left to bottom-right):\\n\\n\\\\( (n - 3) + (2n - 9) + (n - 1) \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 - 3) + (14 - 9) + (7 - 1) = 4 + 5 + 6 = 15 \\\\)\\n\\nGood.\\n\\nOther diagonal (top-right to bottom-left):\\n\\n\\\\( (n + 1) + (2n - 9) + 2 \\\\)\\n\\nSubstitute \\\\( n = 7 \\\\):\\n\\n\\\\( (7 + 1) + (14 - 9) + 2 = 8 + 5 + 2 = 15 \\\\)\\n\\nPerfect, both diagonals add up to 15.\\n\\nSo, all rows, columns, and diagonals sum to 15 when \\\\( n = 7 \\\\). Therefore, \\\\( n = 7 \\\\) is the solution.\\n\\nBut wait, just to be thorough, let me check if all the individual cells are integers and if there are any constraints on \\\\( n \\\\). The problem doesn't specify that \\\\( n \\\\) has to be an integer, but in magic squares, often the numbers are integers. Let me see if \\\\( n = 7 \\\\) makes all the cells integers.\\n\\nLooking at the cells:\\n\\n- \\\\( n - 3 = 7 - 3 = 4 \\\\)\\n- \\\\( 3 \\\\) is already an integer.\\n- \\\\( n + 1 = 7 + 1 = 8 \\\\)\\n- \\\\( n + 2 = 7 + 2 = 9 \\\\)\\n- \\\\( 2n - 9 = 14 - 9 = 5 \\\\)\\n- \\\\( 1 \\\\) is an integer.\\n- \\\\( 2 \\\\) is an integer.\\n- \\\\( n = 7 \\\\)\\n- \\\\( n - 1 = 6 \\\\)\\n\\nAll of these are integers, so that's good.\\n\\nIs there any other constraint? The problem doesn't specify, so I think \\\\( n = 7 \\\\) is the correct answer.\\n\\nBut just to make sure, let me go back to the second row sum. I had:\\n\\nSecond row sum: \\\\( 3n - 6 \\\\)\\n\\nSet equal to \\\\( S = 2n + 1 \\\\):\\n\\n\\\\( 3n - 6 = 2n + 1 \\\\)\\n\\nSubtract \\\\( 2n \\\\):\\n\\n\\\\( n - 6 = 1 \\\\)\\n\\nAdd 6:\\n\\n\\\\( n = 7 \\\\)\\n\\nYes, that's consistent.\\n\\nAlternatively, I could have used another row or column to solve for \\\\( n \\\\), but since all rows, columns, and diagonals give the same equation, it's redundant, but it's a good check.\\n\\nSo, I think I'm confident that \\\\( n = 7 \\\\) is the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( n \\\\) is \\\\boxed{7}.\\n</think>\\n\\nTo find the value of \\\\( n \\\\) in the given magic square, we need to ensure that the sums of all rows, columns, and diagonals are equal. The magic square is as follows:\\n\\n\\\\[\\n\\\\begin{array}{|c|c|c|}\\n\\\\hline\\nn - 3 & 3 & n + 1 \\\\\\\\\\n\\\\hline\\nn + 2 & 2n - 9 & 1 \\\\\\\\\\n\\\\hline\\n2 & n & n - 1 \\\\\\\\\\n\\\\hline\\n\\\\end{array}\\n\\\\]\\n\\nFirst, we calculate the sum of the first row:\\n\\\\[\\n(n - 3) + 3 + (n + 1) = 2n + 1\\n\\\\]\\nThis sum is the magic constant \\\\( S \\\\).\\n\\nNext, we calculate the sum of the second row:\\n\\\\[\\n(n + 2) + (2n - 9) + 1 = 3n - 6\\n\\\\]\\nSince this must equal \\\\( S \\\\), we set up the equation:\\n\\\\[\\n3n - 6 = 2n + 1\\n\\\\]\\nSolving for \\\\( n \\\\):\\n\\\\[\\n3n - 6 = 2n + 1 \\\\\\\\\\nn - 6 = 1 \\\\\\\\\\nn = 7\\n\\\\]\\n\\nWe verify this value by checking the sums of the columns and diagonals with \\\\( n = 7 \\\\):\\n- First column: \\\\( (7 - 3) + (7 + 2) + 2 = 15 \\\\)\\n- Second column: \\\\( 3 + (14 - 9) + 7 = 15 \\\\)\\n- Third column: \\\\( (7 + 1) + 1 + (7 - 1) = 15 \\\\)\\n- Main diagonal: \\\\( (7 - 3) + (14 - 9) + (7 - 1) = 15 \\\\)\\n- Other diagonal: \\\\( (7 + 1) + (14 - 9) + 2 = 15 \\\\)\\n\\nAll sums are equal to 15, confirming that \\\\( n = 7 \\\\) is correct.\\n\\nThus, the value of \\\\( n \\\\) is \\\\(\\\\boxed{7}\\\\).\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" + i, O is -4, P is -i, and S is 2 + 4i. So, the expression is A - O + P + S, which is (2 + i) - (-4) + (-i) + (2 + 4i). That seems right.\\n\\nNow, let me simplify this step by step. First, I can handle the subtraction of O, which is -(-4). Subtracting a negative is like adding a positive, so -(-4) is +4. So, that part becomes +4.\\n\\nSo, now the expression is:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNext, I can combine the real parts and the imaginary parts separately. Let me rewrite the expression grouping the real numbers and the imaginary numbers together:\\n\\nReal parts: 2 + 4 + 2\\n\\nImaginary parts: i - i + 4i\\n\\nLet me compute the real parts first. 2 + 4 is 6, and then 6 + 2 is 8. So, the real part is 8.\\n\\nNow, the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, the imaginary part is 4i.\\n\\nPutting it all together, the expression simplifies to 8 + 4i.\\n\\nWait, let me double-check that. So, starting from A - O + P + S:\\n\\nA is 2 + i, subtract O which is -4, so that becomes +4. Then add P which is -i, and add S which is 2 + 4i.\\n\\nSo, writing it out:\\n\\n(2 + i) + 4 + (-i) + (2 + 4i)\\n\\nNow, let's combine the constants first. 2 + 4 is 6, and then 6 + 2 is 8. So, that's the real part.\\n\\nFor the imaginary parts: i - i is 0, and then 0 + 4i is 4i. So, that's correct.\\n\\nTherefore, the result is 8 + 4i.\\n\\nWait, but let me think again. Is there another way to approach this? Maybe by distributing the negative sign first.\\n\\nSo, A - O + P + S can be rewritten as A + (-O) + P + S. Since O is -4, -O is +4. So, that's the same as before.\\n\\nAlternatively, maybe I can think of it as A + (-O + P + S). Let me compute -O + P + S first.\\n\\nO is -4, so -O is +4. P is -i, and S is 2 + 4i. So, -O + P + S is 4 + (-i) + (2 + 4i).\\n\\nAgain, combining constants: 4 + 2 is 6, and then 6 + 0 is 6. For the imaginary parts: -i + 4i is 3i. So, that's 6 + 3i.\\n\\nThen, adding A, which is 2 + i, to that: (2 + i) + (6 + 3i) = 8 + 4i. So, same result.\\n\\nAlternatively, maybe I can add A and S first, then subtract O and add P.\\n\\nLet me try that approach.\\n\\nA is 2 + i, S is 2 + 4i. So, A + S is (2 + 2) + (i + 4i) = 4 + 5i.\\n\\nThen, subtract O, which is -4. So, A + S - O is 4 + 5i - (-4) = 4 + 5i + 4 = 8 + 5i.\\n\\nThen, add P, which is -i. So, 8 + 5i + (-i) = 8 + 4i. Again, same result.\\n\\nSo, regardless of the order in which I perform the operations, I end up with 8 + 4i.\\n\\nWait, let me make sure I didn't make any mistakes in my calculations. Sometimes, when dealing with complex numbers, it's easy to mix up the real and imaginary parts.\\n\\nLet me write down each step again:\\n\\n1. Start with A - O + P + S.\\n\\n2. Substitute the values:\\n\\n   (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\n3. Simplify the subtraction of O:\\n\\n   (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n4. Combine constants and imaginary parts:\\n\\n   Real parts: 2 + 4 + 2 = 8\\n\\n   Imaginary parts: i - i + 4i = 4i\\n\\n5. Combine them: 8 + 4i\\n\\nAlternatively, if I group the constants first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine constants: 2 + 4 + 2 = 8\\n\\n4. Combine imaginary parts: i - i + 4i = 4i\\n\\n5. Result: 8 + 4i\\n\\nAlternatively, if I group the imaginary parts first:\\n\\n1. (2 + i) + (-(-4)) + (-i) + (2 + 4i)\\n\\n2. (2 + i) + 4 + (-i) + (2 + 4i)\\n\\n3. Combine imaginary parts: i - i + 4i = 4i\\n\\n4. Combine real parts: 2 + 4 + 2 = 8\\n\\n5. Result: 8 + 4i\\n\\nSo, regardless of the order, I get the same result. Therefore, I think 8 + 4i is the correct answer.\\n\\nWait, just to be absolutely sure, let me compute each step numerically.\\n\\nCompute A - O:\\n\\nA is 2 + i, O is -4. So, A - O is (2 + i) - (-4) = 2 + i + 4 = 6 + i.\\n\\nThen, add P, which is -i: 6 + i + (-i) = 6 + 0i = 6.\\n\\nThen, add S, which is 2 + 4i: 6 + (2 + 4i) = 8 + 4i.\\n\\nSo, that's another way to compute it step by step:\\n\\nA - O = 6 + i\\n\\nThen, A - O + P = 6 + i - i = 6\\n\\nThen, A - O + P + S = 6 + 2 + 4i = 8 + 4i.\\n\\nSame result.\\n\\nAlternatively, if I compute A - O + P + S step by step without grouping:\\n\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation one by one:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, 6 + (2 + 4i) = 8 + 4i\\n\\nSame result.\\n\\nSo, regardless of the approach, I end up with 8 + 4i.\\n\\nTherefore, I think I can confidently say that the value of A - O + P + S is 8 + 4i.\\n\\nJust to recap, the steps I took were:\\n\\n1. Substitute the given values into the expression.\\n\\n2. Simplify the expression by handling the subtraction of O, which turned into addition of 4.\\n\\n3. Combine the real parts and the imaginary parts separately.\\n\\n4. Verify the result by computing in different orders or by breaking it down into smaller steps.\\n\\n5. Ensure that each step is correct and that I didn't make any arithmetic errors.\\n\\nSo, I think I'm good. The answer is 8 + 4i.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nFirst, substitute the given values into the expression:\\n\\n\\\\[\\nA - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\\\]\\n\\nSimplify the expression step by step:\\n\\n1. Subtract \\\\( O \\\\) which is \\\\(-4\\\\):\\n   \\\\[\\n   (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n   \\\\]\\n\\n2. Add \\\\( P \\\\) which is \\\\(-i\\\\):\\n   \\\\[\\n   6 + i + (-i) = 6 + 0i = 6\\n   \\\\]\\n\\n3. Add \\\\( S \\\\) which is \\\\( 2 + 4i \\\\):\\n   \\\\[\\n   6 + (2 + 4i) = 8 + 4i\\n   \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_think = tokenizer.encode(\"</think>\", add_special_tokens=False)[0]\n",
    "generated_ids[-1].index(end_think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(generated_ids_compressed[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_true_tokens[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nNow, let's add the real parts and the imaginary parts separately.\\n\\nReal parts: 2 (from A) + (-4) (from O) + 0 (from P) + 2 (from S) = 0\\n\\nImaginary parts: 1 (from A) + 0 (from O) + (-1) (from P) + 4 (from S) = 4\\n\\nSo, putting it all together, the expression simplifies to 0 + 4i, which is just 4i.\\n\\nWait, hold on, that doesn't seem right. Let me check my steps again.\\n\\nWait, when I separated the real and imaginary parts, I think I might have made a mistake in the signs.\\n\\nLet me try that again.\\n\\nStarting over:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nExpression: A - O + P + S\\n\\nSubstitute the values:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nNow, distribute the negative sign to O:\\n\\n2 + i + 4 - i + (-i) + 2 + 4i\\n\\nWait, hold on, that doesn't seem right. Let me do it step by step.\\n\\nFirst, A - O: (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nWait, that makes more sense. So, the expression simplifies to 8 + 4i.\\n\\nWait, so earlier I messed up the distribution. Let me correct that.\\n\\nSo, starting over:\\n\\nExpression: A - O + P + S\\n\\nSubstitute:\\n\\n(2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nFirst, handle A - O:\\n\\n(2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P:\\n\\n6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S:\\n\\n6 + (2 + 4i) = 8 + 4i\\n\\nSo, the final result is 8 + 4i.\\n\\nWait, so earlier I thought it was 4i, but that was incorrect. I must have made a mistake in distributing the negative sign or something.\\n\\nSo, the correct answer is 8 + 4i.\\n\\nBut let me verify once more.\\n\\nCompute A - O + P + S:\\n\\nA = 2 + i\\n\\nO = -4\\n\\nP = -i\\n\\nS = 2 + 4i\\n\\nSo, A - O + P + S = (2 + i) - (-4) + (-i) + (2 + 4i)\\n\\nCompute each operation step by step:\\n\\nFirst, (2 + i) - (-4) = 2 + i + 4 = 6 + i\\n\\nThen, add P: 6 + i + (-i) = 6 + 0i = 6\\n\\nThen, add S: 6 + (2 + 4i) = 8 + 4i\\n\\nYes, that seems correct. So, the final result is 8 + 4i.\\n\\nI think I initially made a mistake in the distribution step, but upon redoing it, I arrived at the correct answer.\\n\\n**Final Answer**\\nThe value of \\\\( A - O + P + S \\\\) is \\\\boxed{8 + 4i}.\\n</think>\\n\\nGiven the values \\\\( A = 2 + i \\\\), \\\\( O = -4 \\\\), \\\\( P = -i \\\\), and \\\\( S = 2 + 4i \\\\), we need to find the value of \\\\( A - O + P + S \\\\).\\n\\nStarting with the expression:\\n\\\\[ A - O + P + S \\\\]\\n\\nSubstitute the given values:\\n\\\\[ (2 + i) - (-4) + (-i) + (2 + 4i) \\\\]\\n\\nSimplify each operation step by step:\\n1. Compute \\\\( (2 + i) - (-4) \\\\):\\n   \\\\[ 2 + i + 4 = 6 + i \\\\]\\n2. Add \\\\( P \\\\):\\n   \\\\[ 6 + i + (-i) = 6 + 0i = 6 \\\\]\\n3. Add \\\\( S \\\\):\\n   \\\\[ 6 + (2 + 4i) = 8 + 4i \\\\]\\n\\nThus, the value of \\\\( A - O + P + S \\\\) is \\\\(\\\\boxed{8 + 4i}\\\\).<endofsentence>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids_compressed[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200, 1536])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, so I have this problem where an elephant and a lion are 1 mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I know that both the elephant and the lion are moving towards or away from each other. The elephant is moving away at 19 mph, and the lion is moving towards it at 24 mph. So, their relative speed is the difference between their speeds because they're moving towards each other. Wait, no, actually, since the elephant is moving away, the lion has to cover the distance that the elephant is moving away plus the distance the elephant covers while the lion is moving towards it.\n",
      "\n",
      "Let me clarify. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So, the lion is closing the gap at a rate of 24 mph minus 19 mph, which is 5 mph. That makes sense because if two objects are moving towards each other, their relative speed is the sum of their speeds, but in this case, one is moving away and the other is moving towards, so it's the difference.\n",
      "\n",
      "So, the initial distance between them is 1 mile. The lion is closing the gap at 5 mph. To find the time it takes to catch up, I can use the formula:\n",
      "\n",
      "Time = Distance / Speed\n",
      "\n",
      "So, plugging in the numbers, the time should be 1 mile divided by 5 mph. That gives me 0.2 hours. But the question asks for the time in minutes, so I need to convert 0.2 hours to minutes. Since 1 hour is 60 minutes, 0.2 hours is 0.2 * 60 = 12 minutes.\n",
      "\n",
      "Wait, let me double-check that. If the lion is moving at 24 mph and the elephant is moving away at 19 mph, the relative speed is 24 - 19 = 5 mph. So, yes, the lion is gaining on the elephant at 5 mph. So, 1 mile divided by 5 mph is indeed 0.2 hours, which is 12 minutes. That seems right.\n",
      "\n",
      "But just to make sure I didn't make a mistake, let me think about it another way. Maybe set up an equation for their positions as functions of time and see if I get the same result.\n",
      "\n",
      "Let's denote t as the time in hours it takes for the lion to catch the elephant. In that time, the elephant will have moved a distance of 19t miles away from the starting point, and the lion will have moved 24t miles towards the elephant. Since they start 1 mile apart, the distance between them when the lion catches the elephant will be zero.\n",
      "\n",
      "So, the distance the lion covers plus the distance the elephant covers should equal the initial distance between them. Wait, no, actually, the lion is moving towards the elephant, so the distance the lion covers is 24t, and the distance the elephant covers is 19t. But since the elephant is moving away, the total distance between them when the lion catches up is 24t - 19t = 5t. This should equal the initial distance, which is 1 mile.\n",
      "\n",
      "So, 5t = 1 mile. Solving for t, we get t = 1/5 hours, which is 0.2 hours. Converting that to minutes, 0.2 * 60 = 12 minutes. Yep, same result. So, that seems consistent.\n",
      "\n",
      "Alternatively, maybe I can think about it in terms of how much distance the lion needs to cover relative to the elephant. Since the lion is moving faster, it's gaining on the elephant at 5 mph. So, the lion needs to cover the 1 mile gap at a relative speed of 5 mph. So, time = distance / speed = 1 / 5 hours, which is 12 minutes. Yep, same answer.\n",
      "\n",
      "I think that's solid. So, the lion will catch the elephant in 12 minutes.\n",
      "\n",
      "**Final Answer**\n",
      "The lion will catch the elephant in \\boxed{12} minutes.\n",
      "</think>\n",
      "\n",
      "The elephant and the lion are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. \n",
      "\n",
      "To find the time it takes for the lion to catch the elephant, we first determine their relative speed. Since the lion is moving towards the elephant and the elephant is moving away, their relative speed is the difference between their speeds:\n",
      "\n",
      "\\[\n",
      "24 \\text{ mph} - 19 \\text{ mph} = 5 \\text{ mph}\n",
      "\\]\n",
      "\n",
      "The initial distance between them is 1 mile. Using the formula for time, which is distance divided by speed, we get:\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ mile}}{5 \\text{ mph}} = 0.2 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "Converting 0.2 hours to minutes:\n",
      "\n",
      "\\[\n",
      "0.2 \\text{ hours} \\times 60 \\text{ minutes per hour} = 12 \\text{ minutes}\n",
      "\\]\n",
      "\n",
      "Thus, the lion will catch the elephant in \\boxed{12} minutes.<endofsentence>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(torch.tensor(generated_ids[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, so I have this problem here where an elephant and a lion are one mile apart. The elephant is running directly away from the lion at 19 miles per hour, and the lion is running towards the elephant at 24 miles per hour. I need to figure out how many minutes it will take for the lion to catch the elephant. Hmm, sounds like a relative speed problem. Let me think about how to approach this.\\n\\nFirst, let me visualize the situation. There's a lion and an elephant, one mile apart. The lion is running towards the elephant, and the elephant is running away from the lion. Since both are moving towards or away from each other, their speeds will affect the time it takes for the lion to catch up.\\n\\nI remember that when two objects are moving towards each other, their relative speed is the sum of their individual speeds. But in this case, the lion is moving towards the elephant, and the elephant is moving away from the lion, so their speeds are in opposite directions. Wait, no, actually, the lion is moving towards the elephant, so their relative speed is the lion's speed minus the elephant's speed, because they are moving in the same direction. Wait, no, hold on. Let me make sure.\\n\\nThe lion is moving towards the elephant, which is moving away. So from the lion's perspective, the elephant is moving away at 19 mph. So the relative speed between the lion and the elephant is the lion's speed minus the elephant's speed because they're moving in the same direction. Wait, no, actually, if both are moving, the relative speed is the difference when moving in the same direction. Wait, maybe I'm getting confused.\\n\\nLet me recall the formula: when two objects are moving towards each other, their relative speed is the sum of their speeds. But when moving in the same direction, it's the difference. But in this case, the lion is chasing the elephant. So if the lion is moving towards the elephant, and the elephant is moving away, their speeds are in the same direction. So the relative speed is lion's speed minus elephant's speed.\\n\\nWait, hold on. Let me think in terms of distance. The initial distance is 1 mile. The lion is moving towards the elephant at 24 mph, and the elephant is moving away at 19 mph. So relative to the lion, the elephant is approaching at (24 - 19) mph, which is 5 mph. So the lion is gaining on the elephant at 5 miles per hour.\\n\\nTherefore, the time it takes for the lion to catch the elephant would be the initial distance divided by the relative speed. So 1 mile divided by 5 mph, which is 1/5 hours. To convert that into minutes, since 1 hour is 60 minutes, 1/5 hours is 12 minutes.\\n\\nWait, that seems straightforward, but let me verify. Let me think of it in terms of equations.\\n\\nLets denote the time it takes for the lion to catch the elephant as t hours.\\n\\nIn t hours, the lion will cover a distance of 24t miles.\\n\\nIn the same t hours, the elephant will cover a distance of 19t miles, but since the elephant is moving away, the distance between the lion and the elephant will decrease at a rate of (24 - 19) mph, which is 5 mph.\\n\\nSo the distance between them decreases by 5 miles every hour. Since they start 1 mile apart, the time it takes for the lion to catch the elephant is 1 / 5 hours, which is 12 minutes. So that seems consistent.\\n\\nAlternatively, I can model the positions of the lion and the elephant as functions of time and find when they meet.\\n\\nLets assume the lion starts at position 0, and the elephant starts at position 1 mile.\\n\\nLets let t be the time in hours. Then, the position of the lion after t hours is 0 + 24t = 24t miles.\\n\\nThe position of the elephant after t hours is 1 - 19t miles.\\n\\nThey meet when their positions are equal, so:\\n\\n24t = 1 - 19t\\n\\nAdding 19t to both sides:\\n\\n24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nWait, hold on, this is different. Earlier, I thought it was 1/5 hours, but now I have 1/43 hours. Which one is correct?\\n\\nWait, that's a big difference. Which approach is correct?\\n\\nLet me check my equations again. Position of lion is 24t, position of elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nSo 24t + 19t = 1\\n\\n43t = 1\\n\\nt = 1/43 hours.\\n\\nHmm, so that's approximately 1.395 minutes, which is about 83.7 seconds. But that seems too fast. Wait, but 1/43 of an hour is roughly 1.395 minutes, which is 83.7 seconds, but 1/5 is 12 minutes, which is 720 seconds. That seems like a huge difference.\\n\\nSo there's a discrepancy here. Which one is right?\\n\\nWait, maybe I made a mistake in setting up the equations. Let me think.\\n\\nWait, if the lion is moving towards the elephant, which is moving away, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph. So the time should be 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut in the equation above, I set the positions equal, which gives me t = 1/43 hours. So which is correct?\\n\\nWait, no, the position of the lion is 24t, and the position of the elephant is 1 - 19t. So when they meet, 24t = 1 - 19t.\\n\\nWait, that would mean that the lion is moving towards the elephant, and the elephant is moving away, so the distance between them is decreasing. So the correct equation should be 24t = 1 - 19t.\\n\\nBut solving that gives t = 1/43 hours, which is approximately 1.395 minutes, which seems contradictory.\\n\\nWait, that can't be. Because if the lion is moving at 24 mph and the elephant is moving away at 19 mph, the lion is closing the distance at 5 mph.\\n\\nBut in the equation, the lion is moving at 24t, which is 24 miles per hour, but the elephant is moving away at 19 mph, so the relative speed is 24 - 19 = 5 mph.\\n\\nWait, so maybe the correct equation is that the lion is moving towards the elephant at 5 mph, so the time is 1 mile / 5 mph = 1/5 hours, which is 12 minutes.\\n\\nBut then why does the position equation give me a different answer?\\n\\nWait, perhaps I have a sign error in the position equation.\\n\\nLet me think about the coordinate system. Let's say the lion starts at position 0, and the elephant starts at position 1.\\n\\nSo the lion is moving towards the positive direction at 24 mph, so its position at time t is 24t.\\n\\nThe elephant is moving away from the lion, so its position at time t is 1 + 19t.\\n\\nWait, hold on, if the elephant is moving away from the lion, which is at position 0, then yes, the elephant's position is 1 + 19t.\\n\\nBut wait, if the lion is moving towards the elephant, which is at 1 mile, so if the lion is at position 0, and the elephant is at position 1, and the lion is moving towards the elephant, so the distance between them is decreasing.\\n\\nWait, so if the lion is moving towards the elephant, then the elephant is moving away from the lion, so the distance between them is decreasing at a rate of (24 - 19) mph, which is 5 mph.\\n\\nTherefore, the relative speed is 5 mph, so the time is 1 mile / 5 mph = 1/5 hours = 12 minutes.\\n\\nBut if I model the positions, the lion is at 24t, the elephant is at 1 + 19t. Setting them equal:\\n\\n24t = 1 + 19t\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours, which is 12 minutes. So that's consistent.\\n\\nWait, so earlier, I thought the position of the elephant was 1 - 19t, but that was incorrect. The correct position of the elephant is 1 + 19t because it's moving away from the lion.\\n\\nSo my initial setup was wrong. I think I confused the direction. So the correct equation is 24t = 1 + 19t, leading to t = 1/5 hours, which is 12 minutes.\\n\\nTherefore, the lion will catch the elephant in 12 minutes.\\n\\nWait, so that contradicts my initial thought that the relative speed is 5 mph. But why was I getting confused earlier?\\n\\nI think the confusion was in the direction of the elephant's movement. If the elephant is moving away from the lion, then the distance between them is increasing at 19 mph, so the relative speed at which the distance is decreasing is 24 - 19 = 5 mph.\\n\\nBut in the position equation, if the lion is moving towards the elephant, and the elephant is moving away, then the distance between them is decreasing at 5 mph. Therefore, the time to close 1 mile is 1 / 5 hours, which is 12 minutes.\\n\\nSo in summary, the correct answer is 12 minutes.\\n\\nBut let me just double-check the equations.\\n\\nLets denote t as the time in hours.\\n\\nPosition of the lion: 24t.\\n\\nPosition of the elephant: 1 + 19t.\\n\\nThey meet when 24t = 1 + 19t.\\n\\n24t - 19t = 1\\n\\n5t = 1\\n\\nt = 1/5 hours = 12 minutes.\\n\\nYes, that seems correct. So the initial mistake was in the position equation for the elephant, thinking it was moving towards, but it's actually moving away. So the correct equation is 24t = 1 + 19t.\\n\\nSo the answer is 12 minutes.\\n\\nI think that makes sense. Let me think about it another way.\\n\\nIf both were moving towards each other, their relative speed would be 24 + 19 = 43 mph, and the time would be 1/43 hours, which is about 1.395 minutes, but that's if they were moving towards each other. But in this case, they are moving away from each other in the same direction, so the relative speed is 24 - 19 = 5 mph, hence 1/5 hours.\\n\\nAlternatively, if I think about the distance between them decreasing at 5 mph, so 1 mile at 5 mph is 1/5 hours, which is 12 minutes.\\n\\nYes, that seems consistent.\\n\\nSo I think my initial setup was wrong because I thought the elephant was moving towards the lion, but it's actually moving away. So the correct answer is 12 minutes.\\n\\n**Final Answer**\\nThe lion will catch the elephant in \\\\boxed{12} minutes.\\n</think>\\n\\nThe problem involves an elephant and a lion that are initially 1 mile apart. The elephant runs directly away from the lion at 19 miles per hour, while the lion runs directly towards the elephant at 24 miles per hour. We need to determine how many minutes it will take for the lion to catch the elephant.\\n\\nFirst, we recognize that the lion is moving towards the elephant, and the elephant is moving away. Therefore, the relative speed at which the lion is approaching the elephant is the difference between their speeds: \\\\(24 - 19 = 5\\\\) miles per hour.\\n\\nThe time it takes for the lion to catch the elephant can be calculated by dividing the initial distance between them by their relative speed. The initial distance is 1 mile, and the relative speed is 5 miles per hour. Thus, the time \\\\(t\\\\) in hours is given by:\\n\\n\\\\[\\nt = \\\\frac{1 \\\\text{ mile}}{5 \\\\text{ mph}} = \\\\frac{1}{5} \\\\text{ hours}\\n\\\\]\\n\\nTo convert this time into minutes, we multiply by 60:\\n\\n\\\\[\\n\\\\frac{1}{5} \\\\text{ hours} \\\\times 60 \\\\text{ minutes per hour} = 12 \\\\text{ minutes}\\n\\\\]\\n\\nThus, the lion will catch the elephant in \\\\(\\\\boxed{12}\\\\) minutes.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(generated_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_true_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1536])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 224256])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_embeds torch.Size([1, 62, 1536])\n",
      "<beginofsentence><User>Here's a question: What do many people believe happens after you die?  Here are possible answers to this question: - stop moving - nothing - go to heaven - stop living - stop breathing  I believe the correct choice is \"go to heaven\", here's why:\n",
      "Answer:<Assistant><think>\n",
      "Okay, so I'm trying to figure out the answer is correct. Let me think about it again. I think the user is trying to figure out the correct answer to the question they're asking. They provided a list of answers, and I need to heaven, but I'm not sure if I'm sure if I'm on the right track. Let me break it down step by step. The question is about what people believe happens after you die. I know that when someone dies, they believe that people often believe in something called the afterlife, which is the belief that after you die, you don't need to move or anything else. So, the correct answer is \"go to heaven\", which is the correct answer. The other options, like stopping moving, nothing, stop breathing, etc., aren't correct\n"
     ]
    }
   ],
   "source": [
    "from hidden_capacity_reasoning.utils import WINDOW_SIZE, VISION_START, VISION_END\n",
    "from transformers.cache_utils import DynamicCache\n",
    "\n",
    "\n",
    "def _crop_past_key_values(model, past_key_values, max_length):\n",
    "    \"\"\"Crops the past key values up to a certain maximum length.\"\"\"\n",
    "    new_past = []\n",
    "    if model.config.is_encoder_decoder:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            new_past.append(\n",
    "                (\n",
    "                    past_key_values[idx][0][:, :, :max_length, :],\n",
    "                    past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    past_key_values[idx][2],\n",
    "                    past_key_values[idx][3],\n",
    "                )\n",
    "            )\n",
    "        past_key_values = tuple(new_past)\n",
    "    # gptbigcode is special and stores kv in shape (batch_size, seq_len, dim), if it's a multi_query model\n",
    "    elif \"gptbigcode\" in model.__class__.__name__.lower() or (\n",
    "        model.config.architectures is not None\n",
    "        and \"gptbigcode\" in model.config.architectures[0].lower()\n",
    "    ):\n",
    "        if model.config.multi_query:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :max_length, :]\n",
    "        else:\n",
    "            for idx in range(len(past_key_values)):\n",
    "                past_key_values[idx] = past_key_values[idx][:, :, :max_length, :]\n",
    "    elif isinstance(past_key_values, DynamicCache):\n",
    "        past_key_values.crop(max_length)\n",
    "    elif past_key_values is not None:\n",
    "        for idx in range(len(past_key_values)):\n",
    "            if past_key_values[idx] != ([], []):\n",
    "                new_past.append(\n",
    "                    (\n",
    "                        past_key_values[idx][0][:, :, :max_length, :],\n",
    "                        past_key_values[idx][1][:, :, :max_length, :],\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                new_past.append((past_key_values[idx][0], past_key_values[idx][1]))\n",
    "        past_key_values = tuple(new_past)\n",
    "    return past_key_values\n",
    "\n",
    "\n",
    "# model = trainer.model\n",
    "generated_tokens = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        # {\"role\": \"user\", \"content\": \"how many wings has a bird?\"},\n",
    "        {\"role\": \"user\", \"content\": dataset[\"test\"].to_list()[:5][0][\"question\"]},\n",
    "    ],\n",
    "    tokenize=True,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "with torch.no_grad(), torch.autocast(device_type=\"cuda\"):\n",
    "    start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "    )\n",
    "    end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "    )\n",
    "    generated_tokens = torch.tensor(generated_tokens).unsqueeze(0).cuda()\n",
    "    generated_embeds = model.get_input_embeddings()(generated_tokens)\n",
    "    temp_gen_size = 0\n",
    "    window_size = WINDOW_SIZE  # + 1\n",
    "    # new_tokens = 4\n",
    "    new_tokens = 1\n",
    "    generation_started = False\n",
    "    max_steps = (new_tokens + window_size) * 15\n",
    "    past_key_values_big = None\n",
    "    print(\"generated_embeds\", generated_embeds.shape)\n",
    "    for step in range(max_steps):\n",
    "        if temp_gen_size == window_size + new_tokens:\n",
    "            # print(\n",
    "            #     \"TOKENS FOR EMDED\",\n",
    "            #     tokenizer.decode(\n",
    "            #         generated_tokens[:, -(window_size + new_tokens) :][:, :WINDOW_SIZE]\n",
    "            #         .cpu()\n",
    "            #         .tolist()[0]\n",
    "            #     ),\n",
    "            # )\n",
    "            # tokenizer.decode(generated_tokens[:, : -window_size ].cpu().tolist()[0])\n",
    "            if hasattr(model.base_model, \"embed_pooler\"):\n",
    "                new_embeds_for_compression = (\n",
    "                    model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "                        generated_tokens[:, -(window_size + new_tokens) :][\n",
    "                            :, :WINDOW_SIZE\n",
    "                        ]\n",
    "                    )\n",
    "                ).to(torch.bfloat16)\n",
    "                compressed_part = model.base_model.embed_pooler(\n",
    "                    new_embeds_for_compression\n",
    "                )\n",
    "            else:\n",
    "                compressed_part = model.embed_pooler(new_embeds_for_compression)\n",
    "            # gen_embeds_prev = generated_tokens.shape[1]\n",
    "            if generation_started:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens + 1)],\n",
    "                        # generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        compressed_part,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            else:\n",
    "                # past_key_values_big = _crop_past_key_values(\n",
    "                #     model=model,\n",
    "                #     past_key_values=past_key_values_big,\n",
    "                #     max_length=generated_embeds.shape[1] - new_tokens - 3,\n",
    "                # )\n",
    "                generated_embeds = torch.cat(\n",
    "                    [\n",
    "                        generated_embeds[:, : -(window_size + new_tokens)],\n",
    "                        start_embed,\n",
    "                        # torch.randn(1, 1, 1536, device=\"cuda\"),\n",
    "                        compressed_part,\n",
    "                        end_embed,\n",
    "                        generated_embeds[:, -new_tokens:],\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "                generation_started = True\n",
    "            past_key_values_big = _crop_past_key_values(\n",
    "                model=model,\n",
    "                past_key_values=past_key_values_big,\n",
    "                max_length=generated_embeds.shape[1] - new_tokens - 2,\n",
    "            )\n",
    "            temp_gen_size = 1\n",
    "\n",
    "        outputs = model(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            past_key_values=past_key_values_big,\n",
    "            # use_cache=False,\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        past_key_values_big = outputs.past_key_values\n",
    "        top_token = logits.argmax(-1)[-1][-1]\n",
    "        top_token_embed = model.get_input_embeddings()(top_token)\n",
    "        # print(top)\n",
    "        generated_tokens = torch.cat([generated_tokens, top_token.reshape(1, 1)], dim=1)\n",
    "\n",
    "        generated_embeds = torch.cat(\n",
    "            [generated_embeds, top_token_embed.reshape(1, 1, -1)], dim=1\n",
    "        )\n",
    "        # print(temp_gen_size, tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "        temp_gen_size += 1\n",
    "\n",
    "print(tokenizer.decode(generated_tokens[-1]))\n",
    "\n",
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   ,       KV-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 1536])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds_for_compression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4, 5, 6, 7, 8][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"test\"][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 1536])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 227])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   MATH-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6911fc254e30429bb1a19210c2e320bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "1768 200 1868 1959\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1017 200 1117 1125\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2275 200 2375 1548\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2718 200 2818 3960\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "638 200 738 748\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1533 200 1633 1080\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1170 200 1270 1639\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1340 200 1440 1732\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "746 200 846 1198\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2652 200 2752 2314\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1025 200 1125 1262\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1060 200 1160 1176\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "910 200 1010 1482\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1033 200 1133 814\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2477 200 2577 2318\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG (8,-2)\n",
      " line. So, the line segment AP is perpendicular to the line y = -x + 6. That makes sense.\n",
      "\n",
      "So, to find point P, I need to find the equation of the line that is perpendicular to y = -x + 6 and passes through point A(10, -10). Once I have that equation, I can find the intersection point P between this perpendicular line and the given line y = -x + 6.\n",
      "\n",
      "Okay, let's recall that the slope of a perpendicular line is the negative reciprocal of the original line's slope. The given line has a slope of -1, so the slope of the perpendicular line should be 1, because -1 * 1 = -1, which satisfies the condition for perpendicularity.\n",
      "\n",
      "So, the equation of the perpendicular line passing through A(10, -10) with slope 1 can be written using the point-slope form:\n",
      "\n",
      "y - y1 = m(x - x1)\n",
      "\n",
      "Where m is the slope, and (x1, y1) is the point. Plugging in the values:\n",
      "\n",
      "y - (-10) = 1*(x - 10)\n",
      "\n",
      "Simplify that:\n",
      "\n",
      "y + 10 = x - 10\n",
      "\n",
      "Subtract 10 from both sides:\n",
      "\n",
      "y = x - 20\n",
      "\n",
      "So, the equation of the perpendicular line is y = x - 20.\n",
      "\n",
      "Now, I need to find the intersection point P of this line with the given line y = -x + 6. To find the intersection, I can set the two equations equal to each other:\n",
      "\n",
      "x - 20 = -x + 6\n",
      "\n",
      "Solve for x:\n",
      "\n",
      "x + x = 6 + 20\n",
      "\n",
      "2x = 26\n",
      "\n",
      "x = 13\n",
      "\n",
      "Now, substitute x = 13 into one of the equations to find y. Let's use y = -x + 6:\n",
      "\n",
      "y = -13 + 6 = -7\n",
      "\n",
      "So, the coordinates of point P are (13, -7).\n",
      "\n",
      "Wait, let me double-check that. If I plug x = 13 into y = x - 20, I get y = 13 - 20 = -7. Yes, that's correct. And plugging x = 13 into y = -x + 6, I get y = -13 + 6 = -7. So, both equations give y = -7 when x = 13. That seems consistent.\n",
      "\n",
      "Now, let me verify that PA is indeed equal to PO. So, point P is (13, -7), point A is (10, -10), and point O is (0, 0).\n",
      "\n",
      "First, let's compute the distance PA. The distance formula is sqrt[(x2 - x1)^2 + (y2 - y1)^2].\n",
      "\n",
      "So, PA = sqrt[(13 - 10)^2 + (-7 - (-10))^2] = sqrt[(3)^2 + (3)^2] = sqrt[9 + 9] = sqrt[18] = 3*sqrt(2).\n",
      "\n",
      "Now, let's compute the distance PO. PO is the distance from P(13, -7) to O(0, 0).\n",
      "\n",
      "PO = sqrt[(13 - 0)^2 + (-7 - 0)^2] = sqrt[169 + 49] = sqrt[218].\n",
      "\n",
      "Wait, hold on, that's not equal to PA. Hmm, that's a problem. I thought PA should be equal to PO, but according to this, PA is 3*sqrt(2) and PO is sqrt(218). That can't be right.\n",
      "\n",
      "Wait, maybe I made a mistake in calculating PO. Let me recalculate PO.\n",
      "\n",
      "PO = sqrt[(13 - 0)^2 + (-7 - 0)^2] = sqrt[169 + 49] = sqrt[218]. Hmm, 218 is 2*109, which is a prime number, so sqrt(218) is irrational. Similarly, PA is 3*sqrt(2), which is also irrational. But they shouldn't be equal unless I made a mistake in finding the coordinates of P.\n",
      "\n",
      "Wait, perhaps I made a mistake in finding the equation of the perpendicular line. Let me go back through that step.\n",
      "\n",
      "So, the given line is y = -x + 6, which has a slope of -1. The perpendicular line should have a slope of 1. So, the equation is y - y1 = m(x - x1). Plugging in A(10, -10):\n",
      "\n",
      "y - (-10) = 1*(x - 10) => y + 10 = x - 10 => y = x - 20. That seems correct.\n",
      "\n",
      "Then, finding the intersection with y = -x + 6:\n",
      "\n",
      "x - 20 = -x + 6 => 2x = 26 => x = 13. Then y = -13 + 6 = -7. So, P is (13, -7). That seems correct.\n",
      "\n",
      "But then, when I compute PA and PO, they aren't equal. So, where is the mistake?\n",
      "\n",
      "Wait, perhaps I misapplied the concept. The problem says that P is equidistant from A and O, so PA = PO. But according to my calculations, PA is 3*sqrt(2) and PO is sqrt(218). Let me compute both values numerically to see if they are equal.\n",
      "\n",
      "3*sqrt(2) is approximately 3*1.4142 = 4.2426.\n",
      "\n",
      "sqrt(218) is approximately 14.764.\n",
      "\n",
      "Wait, that's not equal. So, that means either my coordinates are wrong, or my assumption is wrong.\n",
      "\n",
      "Wait, perhaps the point P is not in the same half of the line y = -x + 6 as point A. Because when I solved for x, I got x = 13, which is to the right of point A(10, -10). But the line y = -x + 6 extends infinitely in both directions, so maybe there's another intersection point on the other side of the line.\n",
      "\n",
      "Wait, but the line y = -x + 6 goes from the second quadrant to the fourth quadrant. Point A is in the fourth quadrant, so the perpendicular line from A should intersect the line y = -x + 6 at two points: one closer to A and one further away. But since we are looking for a point P on the line y = -x + 6 such that PA = PO, perhaps P is the reflection of O over the line y = -x + 6?\n",
      "\n",
      "Wait, that might be another approach. Reflecting a point over a line can sometimes give a point that is equidistant from the original point and its reflection. So, if P is the reflection of O over the line y = -x + 6, then PO = PA.\n",
      "\n",
      "Wait, that might be a better approach. Let me recall how to reflect a point over a line.\n",
      "\n",
      "The formula for reflecting a point (x, y) over the line ax + by + c = 0 is given by:\n",
      "\n",
      "x' = (x - 2a(ax + by + c)/(a^2 + b^2))\n",
      "\n",
      "y' = (y - 2b(ax + by + c)/(a^2 + b^2))\n",
      "\n",
      "Wait, that seems a bit complicated. Alternatively, perhaps I can use the formula for reflection over a line.\n",
      "\n",
      "Alternatively, since the line is y = -x + 6, which can be written as x + y - 6 = 0. So, a = 1, b = 1, c = -6.\n",
      "\n",
      "So, the reflection of point O(0, 0) over the line x + y - 6 = 0 can be found using the reflection formula.\n",
      "\n",
      "The formula for reflecting a point (x, y) over the line ax + by + c = 0 is:\n",
      "\n",
      "x' = x - 2a(ax + by + c)/(a^2 + b^2)\n",
      "\n",
      "y' = y - 2b(ax + by + c)/(a^2 + b^2)\n",
      "\n",
      "So, plugging in a = 1, b = 1, c = -6, and point (0, 0):\n",
      "\n",
      "First, compute ax + by + c = 1*0 + 1*0 - 6 = -6.\n",
      "\n",
      "Then, compute the denominator a^2 + b^2 = 1 + 1 = 2.\n",
      "\n",
      "So, x' = 0 - 2*1*(-6)/2 = 0 - (-12)/2 = 0 + 6 = 6\n",
      "\n",
      "Similarly, y' = 0 - 2*1*(-6)/2 = 0 - (-12)/2 = 0 + 6 = 6\n",
      "\n",
      "So, the reflection of O(0, 0) over the line x + y - 6 = 0 is P'(6, 6).\n",
      "\n",
      "Wait, so P' is (6, 6). Let me check if that's on the line y = -x + 6.\n",
      "\n",
      "Plugging x = 6 into y = -x + 6, we get y = -6 + 6 = 0. So, y = 0, but P' is (6, 6). Wait, that's not on the line. Hmm, that can't be.\n",
      "\n",
      "Wait, perhaps I made a mistake in the reflection formula. Let me double-check the formula.\n",
      "\n",
      "Wait, the reflection formula is:\n",
      "\n",
      "x' = x - 2a(ax + by + c)/(a^2 + b^2)\n",
      "\n",
      "y' = y - 2b(ax + by + c)/(a^2 + b^2)\n",
      "\n",
      "So, for point (0, 0):\n",
      "\n",
      "ax + by + c = 0 + 0 - 6 = -6\n",
      "\n",
      "a^2 + b^2 = 1 + 1 = 2\n",
      "\n",
      "So, x' = 0 - 2*1*(-6)/2 = 0 - (-12)/2 = 0 + 6 = 6\n",
      "\n",
      "y' = 0 - 2*1*(-6)/2 = 0 - (-12)/2 = 0 + 6 = 6\n",
      "\n",
      "So, P' is (6, 6). But wait, (6, 6) is not on the line y = -x + 6 because 6 = -6 + 6 = 0, which is not true. So, that can't be.\n",
      "\n",
      "Wait, so perhaps the reflection formula is incorrect for this case. Alternatively, maybe I applied it incorrectly.\n",
      "\n",
      "Alternatively, perhaps I should use a different method to find the reflection.\n",
      "\n",
      "Alternatively, since the line is y = -x + 6, which is the same as x + y = 6. So, the reflection of a point over this line can be found by solving the system of equations: the line perpendicular to x + y = 6 passing through the point, and the line x + y = 6 itself.\n",
      "\n",
      "So, let's try that.\n",
      "\n",
      "The line x + y = 6 has a slope of -1, so the perpendicular line has a slope of 1.\n",
      "\n",
      "So, the equation of the perpendicular line through O(0, 0) is y = x.\n",
      "\n",
      "So, to find the intersection of y = x and x + y = 6.\n",
      "\n",
      "Substitute y = x into x + y = 6:\n",
      "\n",
      "x + x = 6 => 2x = 6 => x = 3\n",
      "\n",
      "Then, y = 3.\n",
      "\n",
      "So, the reflection of O(0, 0) over the line x + y = 6 is P'(3, 3).\n",
      "\n",
      "Wait, but (3, 3) is on the line x + y = 6 because 3 + 3 = 6. So, that's correct.\n",
      "\n",
      "Wait, but in my previous calculation using the reflection formula, I got (6, 6), which is not on the line. So, perhaps I made a mistake in the reflection formula.\n",
      "\n",
      "Let me double-check the reflection formula.\n",
      "\n",
      "The formula is:\n",
      "\n",
      "x' = x - 2a(ax + by + c)/(a^2 + b^2)\n",
      "\n",
      "y' = y - 2b(ax + by + c)/(a^2 + b^2)\n",
      "\n",
      "Where the line is ax + by + c = 0.\n",
      "\n",
      "In our case, the line is x + y - 6 = 0, so a = 1, b = 1, c = -6.\n",
      "\n",
      "So, for point (0, 0):\n",
      "\n",
      "ax + by + c = 0 + 0 - 6 = -6\n",
      "\n",
      "a^2 + b^2 = 1 + 1 = 2\n",
      "\n",
      "So,\n",
      "\n",
      "x' = 0 - 2*1*(-6)/2 = 0 - (-12)/2 = 0 + 6 = 6\n",
      "\n",
      "y' = 0 - 2*1*(-6)/2 = 0 - (-12)/2 = 0 + 6 = 6\n",
      "\n",
      "So, P' is (6, 6). But (6, 6) is not on the line x + y = 6 because 6 + 6 = 12  6. So, that's incorrect.\n",
      "\n",
      "Wait, so perhaps the reflection formula is not applicable here because the line is not through the origin? Or perhaps I applied it incorrectly.\n",
      "\n",
      "Alternatively, maybe I should use a different method.\n",
      "\n",
      "Alternatively, since the line is x + y = 6, which is the same as y = -x + 6, which is the given line. So, perhaps the reflection of O over this line is P'(3, 3), as I found earlier using the perpendicular line method.\n",
      "\n",
      "So, if P' is (3, 3), then PA = PO because P' is the reflection of O over the line y = -x + 6. So, P' is the point such that PO = P'O, but wait, no, P' is the reflection, so PO = P'O, but P' is not necessarily equidistant from A and O.\n",
      "\n",
      "Wait, no, actually, if P' is the reflection of O over the line, then PO = P'O, but P' is not necessarily equidistant from A and O.\n",
      "\n",
      "Wait, perhaps I need to think differently.\n",
      "\n",
      "Alternatively, since P is on the line y = -x + 6, and PA = PO, then P lies on the perpendicular bisector of segment AO.\n",
      "\n",
      "So, perhaps another way to solve this is to find the perpendicular bisector of AO and find its intersection with y = -x + 6.\n",
      "\n",
      "Let me try that.\n",
      "\n",
      "First, find the midpoint of AO. Point A is (10, -10), and point O is (0, 0). So, the midpoint M is:\n",
      "\n",
      "M = ((10 + 0)/2, (-10 + 0)/2) = (5, -5)\n",
      "\n",
      "So, the midpoint is (5, -5).\n",
      "\n",
      "Now, the slope of AO is (0 - (-10))/(0 - 10) = 10 / (-10) = -1.\n",
      "\n",
      "So, the slope of AO is -1. Therefore, the slope of the perpendicular bisector is the negative reciprocal, which is 1.\n",
      "\n",
      "So, the equation of the perpendicular bisector is y - y1 = m(x - x1), where m = 1 and (x1, y1) = (5, -5).\n",
      "\n",
      "So, y - (-5) = 1*(x - 5) => y + 5 = x - 5 => y = x - 10.\n",
      "\n",
      "So, the perpendicular bisector of AO is y = x - 10.\n",
      "\n",
      "Now, we need to find the intersection of this perpendicular bisector with the given line y = -x + 6.\n",
      "\n",
      "So, set y = x - 10 equal to y = -x + 6:\n",
      "\n",
      "x - 10 = -x + 6\n",
      "\n",
      "Add x to both sides:\n",
      "\n",
      "2x - 10 = 6\n",
      "\n",
      "Add 10 to both sides:\n",
      "\n",
      "2x = 16\n",
      "\n",
      "Divide by 2:\n",
      "\n",
      "x = 8\n",
      "\n",
      "Then, substitute x = 8 into y = -x + 6:\n",
      "\n",
      "y = -8 + 6 = -2\n",
      "\n",
      "So, the intersection point P is (8, -2).\n",
      "\n",
      "Wait, so now I have two different answers: one using the perpendicular line from A to the given line, which gave me (13, -7), and another using the perpendicular bisector of AO, which gave me (8, -2). These are two different points, so I must have made a mistake somewhere.\n",
      "\n",
      "Let me check both methods again.\n",
      "\n",
      "First method: Found the perpendicular line from A(10, -10) to the given line y = -x + 6, which gave me P(13, -7). Then, checked if PA = PO, but they weren't equal. So, that must be incorrect.\n",
      "\n",
      "Second method: Found the perpendicular bisector of AO, which gave me P(8, -2). Let me check if PA = PO for this point.\n",
      "\n",
      "Compute PA: distance from (10, -10) to (8, -2):\n",
      "\n",
      "PA = sqrt[(10 - 8)^2 + (-10 - (-2))^2] = sqrt[(2)^2 + (-8)^2] = sqrt[4 + 64] = sqrt[68] = 2*sqrt(17)\n",
      "\n",
      "Compute PO: distance from (8, -2) to (0, 0):\n",
      "\n",
      "PO = sqrt[(8 - 0)^2 + (-2 - 0)^2] = sqrt[64 + 4] = sqrt[68] = 2*sqrt(17)\n",
      "\n",
      "Ah, okay, so PA = PO = 2*sqrt(17). So, that works.\n",
      "\n",
      "But why did the first method give a different point? Let me check the first method again.\n",
      "\n",
      "First method: Found the perpendicular line from A(10, -10) to the given line y = -x + 6, which gave me P(13, -7). Then, checked if PA = PO, but they weren't equal. So, that must be incorrect.\n",
      "\n",
      "Wait, perhaps the first method is wrong because it's not necessarily the case that the perpendicular line from A to the given line intersects the given line at P such that PA = PO. In fact, in general, the perpendicular line from a point to a line is the shortest distance, but it doesn't necessarily mean that the point is equidistant from the original point and its reflection.\n",
      "\n",
      "Wait, so in this case, the first method gave me a point P(13, -7), which is not equidistant from A and O. So, that must be incorrect.\n",
      "\n",
      "Therefore, the correct point is P(8, -2), which is equidistant from A and O.\n",
      "\n",
      "So, where did I go wrong in the first method? Let me think.\n",
      "\n",
      "I found the equation of the perpendicular line from A(10, -10\n",
      "4096 200 4196 2469\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2865 200 2965 1907\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG -13x+3\n",
      " right? So, if I can express the divisor as a product of two linear factors, then I can use the Remainder Theorem for each factor separately. That is, the remainder when dividing by (x - a)(x + a) is the same as the remainder when dividing by x - a, which is -a - a = -2a? Wait, no, that doesn't seem right.\n",
      "\n",
      "Wait, no, the Remainder Theorem says that the remainder when dividing by (x - a) is f(a). So, if I have a divisor that's a product of two linear factors, (x - a)(x + a), then the remainder when dividing f(x) by this would be a linear polynomial, say mx + n. But I can also express this remainder in terms of the Remainder Theorem for each factor.\n",
      "\n",
      "So, if I let d(x) = (x - a)(x + a) = x - a, then f(x) = q(x)*d(x) + mx + n. But since d(x) is divisible by both (x - a) and (x + a), then f(a) = ma + n and f(-a) = -ma + n. So, if I can find f(a) and f(-a), I can set up a system of equations to solve for m and n.\n",
      "\n",
      "In this case, the divisor is x - 1, which is (x - 1)(x + 1). So, a is 1 and -1. Therefore, I can compute f(1) and f(-1) to get two equations:\n",
      "\n",
      "1. f(1) = m*1 + n = m + n\n",
      "2. f(-1) = m*(-1) + n = -m + n\n",
      "\n",
      "Then, I can solve for m and n.\n",
      "\n",
      "Let me compute f(1) first. Plugging in x=1:\n",
      "\n",
      "f(1) = 1^10 + 5*1^9 - 8*1^8 + 7*1^7 - 1*1^6 - 12*1^5 + 4*1^4 - 8*1^3 + 12*1^2 - 5*1 - 5\n",
      "\n",
      "Calculating each term:\n",
      "\n",
      "1 + 5 - 8 + 7 - 1 - 12 + 4 - 8 + 12 - 5 - 5\n",
      "\n",
      "Let me add them step by step:\n",
      "\n",
      "1 + 5 = 6\n",
      "\n",
      "6 - 8 = -2\n",
      "\n",
      "-2 + 7 = 5\n",
      "\n",
      "5 - 1 = 4\n",
      "\n",
      "4 - 12 = -8\n",
      "\n",
      "-8 + 4 = -4\n",
      "\n",
      "-4 - 8 = -12\n",
      "\n",
      "-12 + 12 = 0\n",
      "\n",
      "0 - 5 = -5\n",
      "\n",
      "-5 - 5 = -10\n",
      "\n",
      "So, f(1) = -10.\n",
      "\n",
      "Now, f(-1):\n",
      "\n",
      "f(-1) = (-1)^10 + 5*(-1)^9 - 8*(-1)^8 + 7*(-1)^7 - (-1)^6 - 12*(-1)^5 + 4*(-1)^4 - 8*(-1)^3 + 12*(-1)^2 - 5*(-1) - 5\n",
      "\n",
      "Calculating each term:\n",
      "\n",
      "(-1)^10 = 1\n",
      "\n",
      "5*(-1)^9 = 5*(-1) = -5\n",
      "\n",
      "-8*(-1)^8 = -8*(1) = -8\n",
      "\n",
      "7*(-1)^7 = 7*(-1) = -7\n",
      "\n",
      "(-1)^6 = 1\n",
      "\n",
      "-12*(-1)^5 = -12*(-1) = 12\n",
      "\n",
      "4*(-1)^4 = 4*(1) = 4\n",
      "\n",
      "-8*(-1)^3 = -8*(-1) = 8\n",
      "\n",
      "12*(-1)^2 = 12*(1) = 12\n",
      "\n",
      "-5*(-1) = 5\n",
      "\n",
      "-5\n",
      "\n",
      "Now, let's add them step by step:\n",
      "\n",
      "1 - 5 = -4\n",
      "\n",
      "-4 - 8 = -12\n",
      "\n",
      "-12 - 7 = -19\n",
      "\n",
      "-19 + 1 = -18\n",
      "\n",
      "-18 + 12 = -6\n",
      "\n",
      "-6 + 4 = -2\n",
      "\n",
      "-2 + 8 = 6\n",
      "\n",
      "6 + 12 = 18\n",
      "\n",
      "18 + 5 = 23\n",
      "\n",
      "23 - 5 = 18\n",
      "\n",
      "So, f(-1) = 18.\n",
      "\n",
      "Now, we have two equations:\n",
      "\n",
      "1. f(1) = m + n = -10\n",
      "\n",
      "2. f(-1) = -m + n = 18\n",
      "\n",
      "So, we can set up the system:\n",
      "\n",
      "m + n = -10\n",
      "\n",
      "-m + n = 18\n",
      "\n",
      "Let me write them down:\n",
      "\n",
      "Equation 1: m + n = -10\n",
      "\n",
      "Equation 2: -m + n = 18\n",
      "\n",
      "If I add both equations, the m terms will cancel:\n",
      "\n",
      "(m + n) + (-m + n) = -10 + 18\n",
      "\n",
      "0 + 2n = 8\n",
      "\n",
      "So, 2n = 8 => n = 4\n",
      "\n",
      "Then, plugging n=4 into Equation 1: m + 4 = -10 => m = -14\n",
      "\n",
      "So, the remainder is mx + n = -14x + 4.\n",
      "\n",
      "Wait, let me double-check my calculations because that seems a bit large.\n",
      "\n",
      "Let me recalculate f(1):\n",
      "\n",
      "f(1) = 1 + 5 - 8 + 7 - 1 - 12 + 4 - 8 + 12 - 5 - 5\n",
      "\n",
      "Let me group them:\n",
      "\n",
      "1 + 5 = 6\n",
      "\n",
      "6 - 8 = -2\n",
      "\n",
      "-2 + 7 = 5\n",
      "\n",
      "5 - 1 = 4\n",
      "\n",
      "4 - 12 = -8\n",
      "\n",
      "-8 + 4 = -4\n",
      "\n",
      "-4 - 8 = -12\n",
      "\n",
      "-12 + 12 = 0\n",
      "\n",
      "0 - 5 = -5\n",
      "\n",
      "-5 - 5 = -10\n",
      "\n",
      "Yes, that's correct.\n",
      "\n",
      "Now, f(-1):\n",
      "\n",
      "1 - 5 - 8 - 7 + 1 + 12 + 4 + 8 + 12 + 5 - 5\n",
      "\n",
      "Wait, let me recalculate:\n",
      "\n",
      "(-1)^10 = 1\n",
      "\n",
      "5*(-1)^9 = -5\n",
      "\n",
      "-8*(-1)^8 = -8\n",
      "\n",
      "7*(-1)^7 = -7\n",
      "\n",
      "(-1)^6 = 1\n",
      "\n",
      "-12*(-1)^5 = 12\n",
      "\n",
      "4*(-1)^4 = 4\n",
      "\n",
      "-8*(-1)^3 = 8\n",
      "\n",
      "12*(-1)^2 = 12\n",
      "\n",
      "-5*(-1) = 5\n",
      "\n",
      "-5\n",
      "\n",
      "So, adding them:\n",
      "\n",
      "1 - 5 = -4\n",
      "\n",
      "-4 - 8 = -12\n",
      "\n",
      "-12 - 7 = -19\n",
      "\n",
      "-19 + 1 = -18\n",
      "\n",
      "-18 + 12 = -6\n",
      "\n",
      "-6 + 4 = -2\n",
      "\n",
      "-2 + 8 = 6\n",
      "\n",
      "6 + 12 = 18\n",
      "\n",
      "18 + 5 = 23\n",
      "\n",
      "23 - 5 = 18\n",
      "\n",
      "Yes, that's correct too.\n",
      "\n",
      "So, the system is:\n",
      "\n",
      "m + n = -10\n",
      "\n",
      "-m + n = 18\n",
      "\n",
      "Adding them: 2n = 8 => n=4\n",
      "\n",
      "Then, m = -10 - n = -10 -4 = -14\n",
      "\n",
      "So, the remainder is -14x + 4.\n",
      "\n",
      "Wait, but let me think again. Is there another method to verify this?\n",
      "\n",
      "Another method is polynomial long division, but since the divisor is quadratic, it's going to be a bit tedious, but maybe I can at least do a few steps to see if the remainder makes sense.\n",
      "\n",
      "Alternatively, I can use the Remainder Theorem for each linear factor separately. So, since x -1 factors into (x -1)(x +1), the remainder when dividing by x -1 is the same as the remainder when dividing by (x -1) and (x +1) separately, but combined.\n",
      "\n",
      "So, if I can find the remainder when dividing by (x -1) and (x +1), then I can express the remainder as a linear polynomial, which is what I did before.\n",
      "\n",
      "Alternatively, I can use the fact that the remainder when dividing by x -1 is the same as the remainder when dividing by (x -1) and (x +1). So, if I let R(x) = mx + n, then R(1) = f(1) and R(-1) = f(-1). Which is exactly what I did.\n",
      "\n",
      "So, I think my method is correct. Therefore, the remainder is -14x + 4.\n",
      "\n",
      "Wait, but let me think if there's another way to verify this. Maybe using synthetic division?\n",
      "\n",
      "Wait, synthetic division is usually for linear divisors, but since we have a quadratic, maybe I can perform synthetic division twice, once for each root.\n",
      "\n",
      "But x -1 has roots at x=1 and x=-1, so if I perform synthetic division on f(x) by (x -1), I can get the quotient and remainder, then perform synthetic division again on the quotient by (x +1) to get the final remainder.\n",
      "\n",
      "Let me try that.\n",
      "\n",
      "First, let's perform synthetic division on f(x) by (x -1).\n",
      "\n",
      "The coefficients of f(x) are:\n",
      "\n",
      "x^10: 1\n",
      "\n",
      "x^9: 5\n",
      "\n",
      "x^8: -8\n",
      "\n",
      "x^7: 7\n",
      "\n",
      "x^6: -1\n",
      "\n",
      "x^5: -12\n",
      "\n",
      "x^4: 4\n",
      "\n",
      "x^3: -8\n",
      "\n",
      "x^2: 12\n",
      "\n",
      "x^1: -5\n",
      "\n",
      "x^0: -5\n",
      "\n",
      "So, writing them out: 1, 5, -8, 7, -1, -12, 4, -8, 12, -5, -5\n",
      "\n",
      "Now, synthetic division with root 1:\n",
      "\n",
      "Bring down the 1.\n",
      "\n",
      "Multiply by 1: 1*1=1. Add to next coefficient: 5 +1=6\n",
      "\n",
      "Multiply by 1: 6*1=6. Add to next coefficient: -8 +6=-2\n",
      "\n",
      "Multiply by 1: -2*1=-2. Add to next coefficient: 7 +(-2)=5\n",
      "\n",
      "Multiply by 1: 5*1=5. Add to next coefficient: -1 +5=4\n",
      "\n",
      "Multiply by 1: 4*1=4. Add to next coefficient: -12 +4=-8\n",
      "\n",
      "Multiply by 1: -8*1=-8. Add to next coefficient: 4 +(-8)=-4\n",
      "\n",
      "Multiply by 1: -4*1=-4. Add to next coefficient: -8 +(-4)=-12\n",
      "\n",
      "Multiply by 1: -12*1=-12. Add to next coefficient: 12 +(-12)=0\n",
      "\n",
      "Multiply by 1: 0*1=0. Add to next coefficient: -5 +0=-5\n",
      "\n",
      "Multiply by 1: -5*1=-5. Add to last coefficient: -5 +(-5)=-10\n",
      "\n",
      "So, the remainder after dividing by (x -1) is -10, which is f(1), as we found before. The quotient polynomial is:\n",
      "\n",
      "x^9 + 6x^8 -2x^7 +5x^6 +4x^5 -8x^4 -4x^3 -12x^2 +0x -5\n",
      "\n",
      "Wait, let me write that out:\n",
      "\n",
      "x^9 + 6x^8 -2x^7 +5x^6 +4x^5 -8x^4 -4x^3 -12x^2 -5\n",
      "\n",
      "Now, let's perform synthetic division on this quotient by (x +1) to get the final remainder.\n",
      "\n",
      "So, the root is -1.\n",
      "\n",
      "Coefficients of the quotient: 1, 6, -2, 5, 4, -8, -4, -12, 0, -5\n",
      "\n",
      "Wait, hold on, the quotient polynomial is degree 9, so it has 10 coefficients. Let me list them:\n",
      "\n",
      "1 (x^9), 6 (x^8), -2 (x^7), 5 (x^6), 4 (x^5), -8 (x^4), -4 (x^3), -12 (x^2), 0 (x), -5 (constant)\n",
      "\n",
      "So, writing them: 1, 6, -2, 5, 4, -8, -4, -12, 0, -5\n",
      "\n",
      "Now, performing synthetic division with root -1:\n",
      "\n",
      "Bring down the 1.\n",
      "\n",
      "Multiply by -1: 1*(-1)=-1. Add to next coefficient: 6 +(-1)=5\n",
      "\n",
      "Multiply by -1: 5*(-1)=-5. Add to next coefficient: -2 +(-5)=-7\n",
      "\n",
      "Multiply by -1: -7*(-1)=7. Add to next coefficient: 5 +7=12\n",
      "\n",
      "Multiply by -1: 12*(-1)=-12. Add to next coefficient: 4 +(-12)=-8\n",
      "\n",
      "Multiply by -1: -8*(-1)=8. Add to next coefficient: -8 +8=0\n",
      "\n",
      "Multiply by -1: 0*(-1)=0. Add to next coefficient: -4 +0=-4\n",
      "\n",
      "Multiply by -1: -4*(-1)=4. Add to next coefficient: -12 +4=-8\n",
      "\n",
      "Multiply by -1: -8*(-1)=8. Add to next coefficient: 0 +8=8\n",
      "\n",
      "Multiply by -1: 8*(-1)=-8. Add to last coefficient: -5 +(-8)=-13\n",
      "\n",
      "So, the remainder after dividing by (x +1) is -13, but wait, that's not matching my previous result of -10.\n",
      "\n",
      "Wait, that can't be. Wait, no, let me check my calculations.\n",
      "\n",
      "Wait, the quotient polynomial after dividing by (x -1) is:\n",
      "\n",
      "x^9 + 6x^8 -2x^7 +5x^6 +4x^5 -8x^4 -4x^3 -12x^2 -5\n",
      "\n",
      "So, the coefficients are: 1, 6, -2, 5, 4, -8, -4, -12, 0, -5\n",
      "\n",
      "So, when performing synthetic division by (x +1), which is root -1, we start with 1.\n",
      "\n",
      "1. Bring down 1.\n",
      "\n",
      "2. Multiply by -1: 1*(-1)=-1. Add to next coefficient: 6 +(-1)=5.\n",
      "\n",
      "3. Multiply by -1: 5*(-1)=-5. Add to next coefficient: -2 +(-5)=-7.\n",
      "\n",
      "4. Multiply by -1: -7*(-1)=7. Add to next coefficient: 5 +7=12.\n",
      "\n",
      "5. Multiply by -1: 12*(-1)=-12. Add to next coefficient: 4 +(-12)=-8.\n",
      "\n",
      "6. Multiply by -1: -8*(-1)=8. Add to next coefficient: -8 +8=0.\n",
      "\n",
      "7. Multiply by -1: 0*(-1)=0. Add to next coefficient: -4 +0=-4.\n",
      "\n",
      "8. Multiply by -1: -4*(-1)=4. Add to next coefficient: -12 +4=-8.\n",
      "\n",
      "9. Multiply by -1: -8*(-1)=8. Add to next coefficient: 0 +8=8.\n",
      "\n",
      "10. Multiply by -1: 8*(-1)=-8. Add to last coefficient: -5 +(-8)=-13.\n",
      "\n",
      "So, the remainder is -13, but earlier, when I used the Remainder Theorem, I got -10. That's a discrepancy.\n",
      "\n",
      "Wait, that means I must have made a mistake somewhere. Let me check the initial calculation of f(1).\n",
      "\n",
      "f(1) = 1 + 5 -8 +7 -1 -12 +4 -8 +12 -5 -5\n",
      "\n",
      "Let me recalculate:\n",
      "\n",
      "1 + 5 = 6\n",
      "\n",
      "6 -8 = -2\n",
      "\n",
      "-2 +7 = 5\n",
      "\n",
      "5 -1 = 4\n",
      "\n",
      "4 -12 = -8\n",
      "\n",
      "-8 +4 = -4\n",
      "\n",
      "-4 -8 = -12\n",
      "\n",
      "-12 +12 = 0\n",
      "\n",
      "0 -5 = -5\n",
      "\n",
      "-5 -5 = -10\n",
      "\n",
      "Yes, that's correct. So, f(1) = -10.\n",
      "\n",
      "But after performing synthetic division twice, I got a remainder of -13. That means I must have made an error in the synthetic division process.\n",
      "\n",
      "Let me double-check the synthetic division steps.\n",
      "\n",
      "First, dividing f(x) by (x -1):\n",
      "\n",
      "Coefficients: 1, 5, -8, 7, -1, -12, 4, -8, 12, -5, -5\n",
      "\n",
      "Root: 1\n",
      "\n",
      "Bring down 1.\n",
      "\n",
      "Multiply by 1: 1*1=1. Add to next coefficient: 5 +1=6.\n",
      "\n",
      "Multiply by 1: 6*1=6. Add to next coefficient: -8 +6=-2.\n",
      "\n",
      "Multiply by 1: -2*1=-2. Add to next coefficient: 7 +(-2)=5.\n",
      "\n",
      "Multiply by 1: 5*1=5. Add to next coefficient: -1 +5=4.\n",
      "\n",
      "Multiply by 1: 4*1=4. Add to next coefficient: -12 +4=-8.\n",
      "\n",
      "Multiply by 1: -8*1=-8. Add to next coefficient: 4 +(-8)=-4.\n",
      "\n",
      "Multiply by 1: -4*1=-4. Add to next coefficient: -8 +(-4)=-12.\n",
      "\n",
      "Multiply by 1: -12*1=-12. Add to next coefficient: 12 +(-12)=0.\n",
      "\n",
      "Multiply by 1: 0*1=0. Add to last coefficient: -5 +0=-5.\n",
      "\n",
      "Multiply by 1: -5*1=-5. Add to last coefficient: -5 +(-5)=-10.\n",
      "\n",
      "So, the remainder is -10, which matches f(1). So, that step is correct.\n",
      "\n",
      "Now, let's perform synthetic division on the quotient by (x +1). The quotient is:\n",
      "\n",
      "x^9 + 6x^8 -2x^7 +5x^6 +4x^5 -8x^4 -4x^3 -12x^2 -5\n",
      "\n",
      "Wait, but when I did the synthetic\n",
      "4096 200 4196 2678\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 11\n",
      " as two terms subtracted: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2)(4x + 1). Wait, that can't be right. Let me check the original problem again.\n",
      "\n",
      "Wait, hold on. The original problem is written as (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. Hmm, so that's (3x - 2)(4x + 1) minus (3x - 2)(4x + 1). Wait, that would make the entire expression zero because both terms are the same. But that can't be right because the problem seems more complicated than that. Maybe I misread the original expression.\n",
      "\n",
      "Let me look again: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. Hmm, so it's (3x - 2)(4x + 1) minus [(3x - 2) times (4x + 1)]. Wait, no, that's not right. The original expression is (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that's a bit confusing. Let me write it out properly. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - [(3x - 2) * (4x + 1)]\n",
      "\n",
      "Wait, no, hold on. The original expression is (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's (3x - 2)(4x + 1) minus (3x - 2)*(4x + 1). Wait, that would be the same as zero because both terms are identical. That can't be right. Maybe I'm interpreting the original expression incorrectly.\n",
      "\n",
      "Let me parse the original expression again: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe the original expression is (3x - 2)(4x + 1) minus (3x - 2) times (4x + 1). But that would be zero, which seems too simple. Maybe I'm misinterpreting the original problem.\n",
      "\n",
      "Wait, let me check the original problem again: \"(3x-2)(4x+1)-(3x-2)4x+1\". Hmm, perhaps the original expression is (3x - 2)(4x + 1) minus (3x - 2) times (4x + 1). But that would be zero. Alternatively, maybe it's (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, that would be two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with parentheses to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe the original expression is (3x - 2)(4x + 1) minus (3x - 2) times (4x + 1). But that would be zero. Alternatively, perhaps the original expression is (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, that would be two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm overcomplicating this. Let me try to parse the original expression differently.\n",
      "\n",
      "The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with parentheses to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe the original expression is (3x - 2)(4x + 1) minus (3x - 2) times (4x + 1). But that would be zero. Alternatively, perhaps the original expression is (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, that would be two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with parentheses to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe the original expression is (3x - 2)(4x + 1) minus (3x - 2) times (4x + 1). But that would be zero. Alternatively, perhaps the original expression is (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, that would be two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm overcomplicating this. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with parentheses to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm overcomplicating this. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm overcomplicating this. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4x + 1)\n",
      "\n",
      "Wait, no, that's still the same as before. Hmm. Maybe I'm misinterpreting the original expression. Let me try to write it differently. The original expression is: (3x - 2)(4x + 1) minus (3x - 2) times 4x plus 1. So, it's two terms: the first term is (3x - 2)(4x + 1), and the second term is (3x - 2) times 4x plus 1. So, it's not subtracting the product of (3x - 2) and (4x + 1) from itself, but rather subtracting (3x - 2) times 4x plus 1 from the first term.\n",
      "\n",
      "Wait, that still doesn't make sense. Let me try to write it with brackets to clarify. The expression is:\n",
      "\n",
      "(3x - 2)(4x + 1) - (3x - 2) * (4\n",
      "4096 200 4196 2664\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "807 200 907 1143\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2112 200 2212 1759\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 12\n",
      " \\). So, for any point on this graph, the y-coordinate is \\( \\frac{1}{\\sqrt{2}}(x^2 - 3) \\). The distance \\( D \\) from the origin (0,0) to a point \\( (x, y) \\) on the graph is given by the distance formula:\n",
      "\n",
      "\\[ D = \\sqrt{(x - 0)^2 + (y - 0)^2} = \\sqrt{x^2 + y^2} \\]\n",
      "\n",
      "Since \\( y \\) is expressed in terms of \\( x \\), I can substitute that into the distance formula:\n",
      "\n",
      "\\[ D = \\sqrt{x^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) \\right)^2} \\]\n",
      "\n",
      "Let me simplify this expression step by step. First, square the y-term:\n",
      "\n",
      "\\[ \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) \\right)^2 = \\frac{1}{2}(x^2 - 3)^2 \\]\n",
      "\n",
      "So, substituting back into the distance formula:\n",
      "\n",
      "\\[ D = \\sqrt{x^2 + \\frac{1}{2}(x^2 - 3)^2} \\]\n",
      "\n",
      "Now, let me expand \\( (x^2 - 3)^2 \\):\n",
      "\n",
      "\\[ (x^2 - 3)^2 = x^4 - 6x^2 + 9 \\]\n",
      "\n",
      "So, plugging that back in:\n",
      "\n",
      "\\[ D = \\sqrt{x^2 + \\frac{1}{2}(x^4 - 6x^2 + 9)} \\]\n",
      "\n",
      "Let me distribute the \\( \\frac{1}{2} \\):\n",
      "\n",
      "\\[ D = \\sqrt{x^2 + \\frac{1}{2}x^4 - 3x^2 + \\frac{9}{2}} \\]\n",
      "\n",
      "Now, combine like terms:\n",
      "\n",
      "The \\( x^2 \\) terms: \\( x^2 - 3x^2 = -2x^2 \\)\n",
      "\n",
      "So, we have:\n",
      "\n",
      "\\[ D = \\sqrt{\\frac{1}{2}x^4 - 2x^2 + \\frac{9}{2}} \\]\n",
      "\n",
      "Hmm, this looks like a quartic equation inside the square root. Maybe I can simplify this further by completing the square or by substituting \\( t = x^2 \\) to make it a quadratic in terms of \\( t \\).\n",
      "\n",
      "Let me try that substitution. Let \\( t = x^2 \\). Then, the expression inside the square root becomes:\n",
      "\n",
      "\\[ \\frac{1}{2}t^2 - 2t + \\frac{9}{2} \\]\n",
      "\n",
      "So, the distance squared is:\n",
      "\n",
      "\\[ D^2 = \\frac{1}{2}t^2 - 2t + \\frac{9}{2} \\]\n",
      "\n",
      "Now, to find the minimum distance, I can minimize \\( D^2 \\) since the square root is a monotonically increasing function. So, minimizing \\( D^2 \\) will also minimize \\( D \\).\n",
      "\n",
      "Let me write \\( D^2 \\) as:\n",
      "\n",
      "\\[ D^2 = \\frac{1}{2}t^2 - 2t + \\frac{9}{2} \\]\n",
      "\n",
      "This is a quadratic in terms of \\( t \\). Since the coefficient of \\( t^2 \\) is positive (\\( \\frac{1}{2} \\)), the parabola opens upwards, so the minimum occurs at the vertex.\n",
      "\n",
      "The vertex of a quadratic \\( at^2 + bt + c \\) is at \\( t = -\\frac{b}{2a} \\).\n",
      "\n",
      "Here, \\( a = \\frac{1}{2} \\) and \\( b = -2 \\). So,\n",
      "\n",
      "\\[ t = -\\frac{-2}{2 \\cdot \\frac{1}{2}} = \\frac{2}{1} = 2 \\]\n",
      "\n",
      "So, the minimum occurs at \\( t = 2 \\). Now, let's find the minimum value of \\( D^2 \\):\n",
      "\n",
      "\\[ D^2 = \\frac{1}{2}(2)^2 - 2(2) + \\frac{9}{2} \\]\n",
      "\n",
      "Calculate each term:\n",
      "\n",
      "\\( \\frac{1}{2}(4) = 2 \\)\n",
      "\n",
      "\\( -2(2) = -4 \\)\n",
      "\n",
      "\\( \\frac{9}{2} = 4.5 \\)\n",
      "\n",
      "So, adding them up:\n",
      "\n",
      "\\( 2 - 4 + 4.5 = 2.5 \\)\n",
      "\n",
      "So, \\( D^2 = 2.5 \\), which is \\( \\frac{5}{2} \\). Therefore, the minimum distance \\( D \\) is \\( \\sqrt{\\frac{5}{2}} \\).\n",
      "\n",
      "Wait, but the problem says the distance can be expressed as \\( \\sqrt{\\frac{a}{b}} \\), where \\( a \\) is not divisible by the square of any integer greater than one. So, \\( \\sqrt{\\frac{5}{2}} \\) can be simplified as \\( \\frac{\\sqrt{10}}{2} \\), right?\n",
      "\n",
      "Because \\( \\sqrt{\\frac{5}{2}} = \\frac{\\sqrt{5 \\cdot 2}}{2} = \\frac{\\sqrt{10}}{2} \\).\n",
      "\n",
      "So, \\( a = 10 \\) and \\( b = 2 \\). Therefore, \\( a + b = 12 \\).\n",
      "\n",
      "Wait, let me double-check my steps to make sure I didn't make a mistake.\n",
      "\n",
      "1. Wrote the distance formula correctly: \\( D = \\sqrt{x^2 + y^2} \\). That seems right.\n",
      "\n",
      "2. Substituted \\( y = \\frac{1}{\\sqrt{2}}(x^2 - 3) \\) into the distance formula: correct.\n",
      "\n",
      "3. Expanded \\( (x^2 - 3)^2 \\): yes, that's \\( x^4 - 6x^2 + 9 \\).\n",
      "\n",
      "4. Substituted back and simplified: yes, \\( \\frac{1}{2}(x^4 - 6x^2 + 9) \\) becomes \\( \\frac{1}{2}x^4 - 3x^2 + \\frac{9}{2} \\).\n",
      "\n",
      "5. Added \\( x^2 \\) to that: \\( x^2 + \\frac{1}{2}x^4 - 3x^2 + \\frac{9}{2} \\) simplifies to \\( \\frac{1}{2}x^4 - 2x^2 + \\frac{9}{2} \\). That seems correct.\n",
      "\n",
      "6. Substituted \\( t = x^2 \\): yes, so \\( D^2 = \\frac{1}{2}t^2 - 2t + \\frac{9}{2} \\). Correct.\n",
      "\n",
      "7. Found the vertex at \\( t = 2 \\): yes, because \\( -b/(2a) = 2/(1) = 2 \\). Correct.\n",
      "\n",
      "8. Plugged \\( t = 2 \\) back into \\( D^2 \\): calculated each term correctly: 2 - 4 + 4.5 = 2.5 = 5/2. Correct.\n",
      "\n",
      "9. Then, expressed \\( \\sqrt{5/2} \\) as \\( \\sqrt{10}/2 \\): yes, because \\( \\sqrt{5/2} = \\sqrt{10}/2 \\). Correct.\n",
      "\n",
      "10. Therefore, \\( a = 10 \\), \\( b = 2 \\), so \\( a + b = 12 \\). That seems right.\n",
      "\n",
      "Wait, just to be thorough, let me check if there's another way to approach this problem, maybe using calculus to find the minimum distance.\n",
      "\n",
      "So, if I consider \\( D^2 = \\frac{1}{2}x^4 - 2x^2 + \\frac{9}{2} \\), and take the derivative with respect to \\( x \\), set it to zero, and solve for \\( x \\).\n",
      "\n",
      "Let me compute \\( d(D^2)/dx \\):\n",
      "\n",
      "\\[ \\frac{d}{dx}\\left( \\frac{1}{2}x^4 - 2x^2 + \\frac{9}{2} \\right) = 2x^3 - 4x \\]\n",
      "\n",
      "Set this equal to zero:\n",
      "\n",
      "\\[ 2x^3 - 4x = 0 \\]\n",
      "\n",
      "Factor out 2x:\n",
      "\n",
      "\\[ 2x(x^2 - 2) = 0 \\]\n",
      "\n",
      "So, critical points at \\( x = 0 \\) and \\( x^2 = 2 \\) => \\( x = \\sqrt{2} \\) and \\( x = -\\sqrt{2} \\).\n",
      "\n",
      "Now, let's evaluate \\( D^2 \\) at these points.\n",
      "\n",
      "At \\( x = 0 \\):\n",
      "\n",
      "\\[ D^2 = \\frac{1}{2}(0)^4 - 2(0)^2 + \\frac{9}{2} = 0 - 0 + \\frac{9}{2} = \\frac{9}{2} \\]\n",
      "\n",
      "So, \\( D = \\sqrt{\\frac{9}{2}} = \\frac{3}{\\sqrt{2}} = \\frac{3\\sqrt{2}}{2} \\).\n",
      "\n",
      "At \\( x = \\sqrt{2} \\):\n",
      "\n",
      "\\[ D^2 = \\frac{1}{2}(\\sqrt{2})^4 - 2(\\sqrt{2})^2 + \\frac{9}{2} \\]\n",
      "\n",
      "Calculate each term:\n",
      "\n",
      "\\( (\\sqrt{2})^4 = (2)^2 = 4 \\)\n",
      "\n",
      "\\( (\\sqrt{2})^2 = 2 \\)\n",
      "\n",
      "So,\n",
      "\n",
      "\\[ D^2 = \\frac{1}{2}(4) - 2(2) + \\frac{9}{2} = 2 - 4 + 4.5 = 2.5 = \\frac{5}{2} \\]\n",
      "\n",
      "So, \\( D = \\sqrt{\\frac{5}{2}} = \\frac{\\sqrt{10}}{2} \\).\n",
      "\n",
      "Similarly, at \\( x = -\\sqrt{2} \\), the value will be the same because all terms are even powers.\n",
      "\n",
      "So, the minimum distance is indeed \\( \\frac{\\sqrt{10}}{2} \\), which is \\( \\sqrt{\\frac{10}{4}} = \\sqrt{\\frac{10}{4}} \\). Wait, no, that's not correct. Wait, \\( \\frac{\\sqrt{10}}{2} \\) is already simplified as \\( \\sqrt{\\frac{10}{4}} \\), but \\( \\frac{10}{4} \\) can be simplified further.\n",
      "\n",
      "Wait, actually, \\( \\frac{\\sqrt{10}}{2} \\) is already in the form \\( \\sqrt{\\frac{10}{4}} \\), but \\( \\frac{10}{4} \\) can be simplified to \\( \\frac{5}{2} \\). So, \\( \\sqrt{\\frac{10}{4}} = \\sqrt{\\frac{5}{2}} \\), which is the same as before. So, either way, the distance is \\( \\sqrt{\\frac{5}{2}} \\) or \\( \\frac{\\sqrt{10}}{2} \\).\n",
      "\n",
      "But the problem says the distance can be expressed as \\( \\sqrt{\\frac{a}{b}} \\), where \\( a \\) is not divisible by the square of any integer greater than one. So, \\( \\sqrt{\\frac{5}{2}} \\) is already in that form, with \\( a = 5 \\) and \\( b = 2 \\). But wait, 5 is square-free, so that's good. Alternatively, \\( \\sqrt{\\frac{10}{4}} \\) would have \\( a = 10 \\) and \\( b = 4 \\), but 4 is divisible by a square (4 = 2^2), so that's not acceptable. Therefore, the correct form is \\( \\sqrt{\\frac{5}{2}} \\), so \\( a = 5 \\), \\( b = 2 \\), and \\( a + b = 7 \\). Wait, wait, hold on, this contradicts my earlier conclusion.\n",
      "\n",
      "Wait, hold on, I think I made a mistake here. Let me clarify.\n",
      "\n",
      "The problem says the distance can be expressed as \\( \\sqrt{\\frac{a}{b}} \\), where \\( a \\) and \\( b \\) are positive integers, and \\( a \\) is not divisible by the square of any integer greater than one. So, \\( \\sqrt{\\frac{5}{2}} \\) is already in that form, with \\( a = 5 \\) and \\( b = 2 \\). However, \\( \\frac{5}{2} \\) is already in lowest terms because 5 is prime and doesn't have any square factors. So, that's acceptable.\n",
      "\n",
      "But earlier, I thought of \\( \\sqrt{\\frac{10}{4}} \\), which is equivalent to \\( \\sqrt{\\frac{5}{2}} \\), but 10 and 4 have a common factor of 2, so if we simplify \\( \\frac{10}{4} \\) to \\( \\frac{5}{2} \\), then \\( a = 5 \\) and \\( b = 2 \\). So, actually, both approaches lead to the same \\( a \\) and \\( b \\).\n",
      "\n",
      "Wait, but in the calculus approach, I got \\( D = \\frac{\\sqrt{10}}{2} \\), which is \\( \\sqrt{\\frac{10}{4}} \\). But \\( \\frac{10}{4} \\) can be simplified to \\( \\frac{5}{2} \\), so both forms are equivalent. However, the problem specifies that \\( a \\) is not divisible by the square of any integer greater than one. So, \\( \\frac{5}{2} \\) is already in lowest terms because 5 is prime, so \\( a = 5 \\) and \\( b = 2 \\).\n",
      "\n",
      "But wait, in the distance formula, I had \\( D = \\sqrt{\\frac{5}{2}} \\), which is the same as \\( \\sqrt{\\frac{10}{4}} \\). So, both are correct, but since \\( \\frac{5}{2} \\) is already in lowest terms, \\( a = 5 \\) and \\( b = 2 \\), so \\( a + b = 7 \\).\n",
      "\n",
      "Wait, but earlier, I thought \\( \\sqrt{\\frac{5}{2}} \\) is the answer, but then I thought of \\( \\sqrt{\\frac{10}{4}} \\) and thought \\( a = 10 \\), \\( b = 4 \\), but that's not correct because 4 is divisible by a square (4 = 2^2). So, the correct form is \\( \\sqrt{\\frac{5}{2}} \\), so \\( a = 5 \\), \\( b = 2 \\), and \\( a + b = 7 \\).\n",
      "\n",
      "Wait, but hold on, in the calculus approach, I got \\( D = \\frac{\\sqrt{10}}{2} \\), which is the same as \\( \\sqrt{\\frac{10}{4}} \\). But \\( \\frac{10}{4} \\) simplifies to \\( \\frac{5}{2} \\), so both are equivalent. However, since \\( \\frac{5}{2} \\) is already in lowest terms, \\( a = 5 \\), \\( b = 2 \\), so \\( a + b = 7 \\).\n",
      "\n",
      "But wait, in the initial substitution, I had \\( D^2 = \\frac{1}{2}x^4 - 2x^2 + \\frac{9}{2} \\), and at \\( x = \\sqrt{2} \\), \\( D^2 = \\frac{5}{2} \\), so \\( D = \\sqrt{\\frac{5}{2}} \\). So, that's correct.\n",
      "\n",
      "But then, in the calculus approach, I got \\( D = \\frac{\\sqrt{10}}{2} \\), which is the same as \\( \\sqrt{\\frac{10}{4}} \\), but since \\( \\frac{10}{4} \\) can be simplified to \\( \\frac{5}{2} \\), which is already in lowest terms, so \\( a = 5 \\), \\( b = 2 \\), so \\( a + b = 7 \\).\n",
      "\n",
      "Wait, but in the initial substitution, I had \\( D^2 = \\frac{5}{2} \\), so \\( D = \\sqrt{\\frac{5}{2}} \\), which is the same as \\( \\sqrt{\\frac{10}{4}} \\), but since \\( \\frac{10}{4} \\) simplifies to \\( \\frac{5}{2} \\), which is already in lowest terms, so \\( a = 5 \\), \\( b = 2 \\), so \\( a + b = 7 \\).\n",
      "\n",
      "But wait, in the initial substitution, I had \\( D^2 = \\frac{5}{2} \\), which is \\( \\sqrt{\\frac{5}{2}} \\), so that's correct. So, why did I think earlier that \\( a = 10 \\), \\( b = 4 \\)? Because I was considering \\( \\sqrt{\\frac{10}{4}} \\), but that's not necessary because \\( \\frac{10}{4} \\) can be simplified.\n",
      "\n",
      "Therefore, the correct answer is \\( a = 5 \\), \\( b = 2 \\), so \\( a + b = 7 \\).\n",
      "\n",
      "Wait, but let me double-check the initial substitution. When I substituted \\( t = x^2 \\), I got \\( D^2 = \\frac{1}{2}t^2 - 2t + \\frac{9}{2} \\). Then, the vertex is at \\( t = 2 \\), so \\( D^2 = \\frac{5}{2} \\). So, \\( D = \\sqrt{\\frac{5}{2}} \\). That's correct.\n",
      "\n",
      "Alternatively, if I didn't substitute \\( t = x^2 \\), but instead used calculus, I got the same result. So, I think the answer is \\( \\sqrt{\\frac{5}{2}} \\), so \\( a = 5 \\), \\( b = 2 \\), and \\( a + b = 7 \\).\n",
      "\n",
      "But wait, hold on, in the initial substitution, I had \\( D^2 = \\frac{5}{2} \\), which is \\( \\sqrt{\\frac{5}{2}} \\). So, that's correct. But in the calculus approach, I got \\( D = \\frac{\\sqrt{10}}{2} \\), which is the same as \\( \\sqrt{\\frac{10}{4}} \\), but since \\( \\frac{10}{4} \\) simplifies to \\( \\frac{5}{2} \\), which is already in lowest terms, so \\( a = 5 \\), \\( b = 2 \\), so \\( a + b = 7 \\).\n",
      "\n",
      "Wait, but in the initial substitution, I had \\( D^2 = \\frac{5}{2} \\), which\n",
      "4096 200 4196 3001\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "644 200 744 1554\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2527 200 2627 2260\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2253 200 2353 1478\n",
      "===\n",
      "===\n",
      "===\n",
      "WRONG 32\n",
      " similar triangles or some area formulas. Let me think.\n",
      "\n",
      "I remember that in a right triangle, the length of the altitude to the hypotenuse can be related to the lengths of the legs. Let me denote the legs as 'a' and 'b', and the hypotenuse as 'c'. Since it's isosceles, a = b. So, the hypotenuse c is \\(a\\sqrt{2}\\).\n",
      "\n",
      "The area of the triangle can be expressed in two ways: one using the legs and one using the hypotenuse and the altitude. So, the area is \\(\\frac{1}{2}ab\\) and also \\(\\frac{1}{2}c \\times h\\), where h is the altitude to the hypotenuse.\n",
      "\n",
      "Since a = b, let's denote them both as 'a'. So, the area is \\(\\frac{1}{2}a^2\\) and also \\(\\frac{1}{2} \\times a\\sqrt{2} \\times 4\\sqrt{2}\\). Let me write that down:\n",
      "\n",
      "\\[\n",
      "\\frac{1}{2}a^2 = \\frac{1}{2} \\times a\\sqrt{2} \\times 4\\sqrt{2}\n",
      "\\]\n",
      "\n",
      "Let me simplify the right side. First, multiply \\(a\\sqrt{2}\\) and \\(4\\sqrt{2}\\):\n",
      "\n",
      "\\(a\\sqrt{2} \\times 4\\sqrt{2} = 4a \\times (\\sqrt{2} \\times \\sqrt{2}) = 4a \\times 2 = 8a\\).\n",
      "\n",
      "So, the right side becomes \\(\\frac{1}{2} \\times 8a = 4a\\).\n",
      "\n",
      "So, we have:\n",
      "\n",
      "\\[\n",
      "\\frac{1}{2}a^2 = 4a\n",
      "\\]\n",
      "\n",
      "Multiply both sides by 2 to eliminate the fraction:\n",
      "\n",
      "\\[\n",
      "a^2 = 8a\n",
      "\\]\n",
      "\n",
      "Subtract 8a from both sides:\n",
      "\n",
      "\\[\n",
      "a^2 - 8a = 0\n",
      "\\]\n",
      "\n",
      "Factor out an 'a':\n",
      "\n",
      "\\[\n",
      "a(a - 8) = 0\n",
      "\\]\n",
      "\n",
      "So, either a = 0 or a = 8. Since a is a length, it can't be 0, so a = 8.\n",
      "\n",
      "Therefore, each leg is 8 units long. Since it's an isosceles right triangle, the hypotenuse c is \\(a\\sqrt{2} = 8\\sqrt{2}\\).\n",
      "\n",
      "Now, the area of the triangle is \\(\\frac{1}{2}a^2 = \\frac{1}{2} \\times 64 = 32\\). Alternatively, using the hypotenuse and the altitude: \\(\\frac{1}{2} \\times 8\\sqrt{2} \\times 4\\sqrt{2} = \\frac{1}{2} \\times 32 \\times 2 = 32\\). So, that checks out.\n",
      "\n",
      "Wait, but let me think again. The problem says the altitude to the hypotenuse is \\(4\\sqrt{2}\\). So, is that correct? Because in an isosceles right triangle, the altitude to the hypotenuse is equal to half the hypotenuse. Wait, is that true?\n",
      "\n",
      "Wait, no. In a right triangle, the altitude to the hypotenuse is equal to the geometric mean of the segments it creates on the hypotenuse. But in an isosceles right triangle, the altitude splits the hypotenuse into two equal parts, each of length \\(4\\sqrt{2}\\), because the hypotenuse is \\(8\\sqrt{2}\\), so each segment is half of that.\n",
      "\n",
      "So, if the hypotenuse is \\(8\\sqrt{2}\\), and the altitude is \\(4\\sqrt{2}\\), then the area is \\(\\frac{1}{2} \\times 8\\sqrt{2} \\times 4\\sqrt{2}\\). Let me compute that:\n",
      "\n",
      "First, multiply \\(8\\sqrt{2} \\times 4\\sqrt{2}\\):\n",
      "\n",
      "\\(8 \\times 4 = 32\\), and \\(\\sqrt{2} \\times \\sqrt{2} = 2\\), so 32 \\times 2 = 64.\n",
      "\n",
      "Then, \\(\\frac{1}{2} \\times 64 = 32\\). So, the area is 32.\n",
      "\n",
      "But wait, I thought in a right triangle, the altitude to the hypotenuse is equal to the leg length divided by \\(\\sqrt{2}\\). Let me check that.\n",
      "\n",
      "In an isosceles right triangle, the legs are equal, say length 'a'. The hypotenuse is \\(a\\sqrt{2}\\). The altitude to the hypotenuse can be found using the formula for the altitude in a right triangle: \\(h = \\frac{a \\times a}{a\\sqrt{2}} = \\frac{a}{\\sqrt{2}}\\).\n",
      "\n",
      "So, if the altitude is \\(4\\sqrt{2}\\), then:\n",
      "\n",
      "\\[\n",
      "\\frac{a}{\\sqrt{2}} = 4\\sqrt{2}\n",
      "\\]\n",
      "\n",
      "Multiply both sides by \\(\\sqrt{2}\\):\n",
      "\n",
      "\\[\n",
      "a = 4\\sqrt{2} \\times \\sqrt{2} = 4 \\times 2 = 8\n",
      "\\]\n",
      "\n",
      "So, each leg is 8, as I found earlier. Therefore, the area is \\(\\frac{1}{2} \\times 8 \\times 8 = 32\\). So, that's consistent.\n",
      "\n",
      "Wait, but I thought in a right triangle, the altitude to the hypotenuse is equal to the leg length divided by \\(\\sqrt{2}\\). So, if the altitude is \\(4\\sqrt{2}\\), then the leg is \\(4\\sqrt{2} \\times \\sqrt{2} = 8\\). So, that's correct.\n",
      "\n",
      "Alternatively, I could think about the area in terms of the hypotenuse and the altitude. Since the hypotenuse is \\(8\\sqrt{2}\\) and the altitude is \\(4\\sqrt{2}\\), the area is \\(\\frac{1}{2} \\times 8\\sqrt{2} \\times 4\\sqrt{2} = 32\\).\n",
      "\n",
      "Alternatively, using the properties of similar triangles. In an isosceles right triangle, when you draw the altitude to the hypotenuse, it creates two smaller isosceles right triangles, each similar to the original triangle.\n",
      "\n",
      "So, the original triangle has legs of 8, hypotenuse \\(8\\sqrt{2}\\), and altitude \\(4\\sqrt{2}\\). The two smaller triangles each have legs of 4, hypotenuse \\(4\\sqrt{2}\\), and altitude \\(2\\sqrt{2}\\).\n",
      "\n",
      "So, the area of the original triangle is twice the area of one of the smaller triangles. The smaller triangle has legs of 4, so area is \\(\\frac{1}{2} \\times 4 \\times 4 = 8\\). So, the original triangle has area \\(8 \\times 2 = 16\\). Wait, that's conflicting with the previous result of 32.\n",
      "\n",
      "Wait, that can't be. So, I must have made a mistake here. Let me recast this.\n",
      "\n",
      "Wait, no. The smaller triangles are similar to the original triangle, but their legs are half the length of the original triangle's legs. So, if the original legs are 8, the smaller legs are 4. So, the area of each smaller triangle is \\(\\frac{1}{2} \\times 4 \\times 4 = 8\\). So, two of them make 16. But that's less than 32. So, where is the mistake?\n",
      "\n",
      "Wait, no, actually, the smaller triangles are not similar in the way I thought. Let me think again.\n",
      "\n",
      "When you draw the altitude to the hypotenuse in an isosceles right triangle, it creates two smaller triangles that are congruent to each other and similar to the original triangle. Each smaller triangle has legs equal to half the length of the original legs. So, if the original legs are 8, the smaller legs are 4. So, each smaller triangle has area \\(\\frac{1}{2} \\times 4 \\times 4 = 8\\). So, two of them make 16. But that's less than the area of the original triangle, which is 32. So, that can't be.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles together make the original triangle. So, if each smaller triangle has area 8, then the original triangle has area 16. But that contradicts the earlier calculation where the area is 32. So, I must have made a mistake in this approach.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that can't be, because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, let me recalculate. If the original triangle has legs of 8, area is 32. When you draw the altitude to the hypotenuse, which is \\(4\\sqrt{2}\\), it splits the triangle into two smaller triangles. Each smaller triangle has base \\(4\\sqrt{2}\\) and height \\(2\\sqrt{2}\\), because the altitude is \\(4\\sqrt{2}\\) and it's split into two equal parts.\n",
      "\n",
      "So, the area of each smaller triangle is \\(\\frac{1}{2} \\times 4\\sqrt{2} \\times 2\\sqrt{2}\\). Let me compute that:\n",
      "\n",
      "First, multiply \\(4\\sqrt{2} \\times 2\\sqrt{2}\\):\n",
      "\n",
      "\\(4 \\times 2 = 8\\), and \\(\\sqrt{2} \\times \\sqrt{2} = 2\\), so 8 \\times 2 = 16.\n",
      "\n",
      "Then, \\(\\frac{1}{2} \\times 16 = 8\\). So, each smaller triangle has area 8, and together they make 16. But the original triangle has area 32, so that's a problem.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles together make the original triangle. So, if each has area 8, then the original triangle has area 16, which is half of 32. So, that's a contradiction. Therefore, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that can't be, because the original triangle's area is 32. So, where is the mistake?\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area 8, so together they make 16, which is half of the original triangle's area. But that's not possible because the original triangle's area is 32. So, I must have made a mistake in the smaller triangle's area.\n",
      "\n",
      "Wait, no, actually, the two smaller triangles each have area \n",
      "4096 200 4196 3321\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "2612 200 2712 1269\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "3969 200 4069 2693\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "1054 200 1154 1346\n",
      "===\n",
      "===\n",
      "===\n",
      "CORRECT\n",
      "969 200 1069 2159\n",
      "===\n",
      "===\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    WINDOW_SIZE,\n",
    "    VISION_START,\n",
    "    VISION_END,\n",
    "    EOS_TOKEN_ID,\n",
    ")\n",
    "import torch\n",
    "import json\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct_items = 0\n",
    "torch.manual_seed(0)\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "evaluation_dataset = []\n",
    "\n",
    "for dataset_pos in tqdm(range(len(correct_dataset))):\n",
    "    # dataset_pos = 11\n",
    "    input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "    # print(input_ids)\n",
    "    # print(\"===\")\n",
    "    # print(\"===\")\n",
    "\n",
    "    input_ids = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": base_prompt.format(question=input_ids),\n",
    "                },\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # input_ids = dataset_item[\"input_ids\"]\n",
    "    # generated_ids = dataset_item[\"generated_ids\"]\n",
    "    generated_ids = [\n",
    "        tokenizer.encode(\n",
    "            correct_dataset[dataset_pos][\"model_answer\"],\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # start_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        start_embed = model.embed_pooler.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_START]], device=\"cuda\")\n",
    "        )\n",
    "        # end_embed = model.base_model.embed_pooler.model.get_input_embeddings()(\n",
    "        end_embed = model.embed_pooler.get_input_embeddings()(\n",
    "            torch.tensor([[VISION_END]], device=\"cuda\")\n",
    "        )\n",
    "        input_ids = torch.tensor(input_ids).cuda()\n",
    "        input_ids_embeds = model.get_input_embeddings()(input_ids)\n",
    "        windows_amount = 100\n",
    "        # windows_amount = 200\n",
    "        # windows_amount = 300\n",
    "        # windows_amount = 400\n",
    "        # windows_amount = 500\n",
    "        # windows_amount = 2\n",
    "        generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "        original_total_len = torch.tensor(generated_ids).shape[1]\n",
    "        if generated_tokens_amount > original_total_len:\n",
    "            windows_amount = original_total_len // WINDOW_SIZE\n",
    "            generated_tokens_amount = WINDOW_SIZE * windows_amount\n",
    "\n",
    "        next_true_tokens = torch.tensor(generated_ids, device=\"cuda\")[\n",
    "            :, :generated_tokens_amount\n",
    "        ]\n",
    "\n",
    "        # next_true_tokens = torch.tensor(next_true_tokens, device=\"cuda\")\n",
    "\n",
    "        # original_embeds = (model.get_input_embeddings()(next_true_tokens)).to(\n",
    "        original_embeds = (\n",
    "            # model.base_model.embed_pooler.model.get_input_embeddings()(next_true_tokens)\n",
    "            model.embed_pooler.get_input_embeddings()(next_true_tokens)\n",
    "        ).to(torch.float32)\n",
    "\n",
    "        # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        new_embeds_for_compression = original_embeds.reshape(\n",
    "            windows_amount, WINDOW_SIZE, -1\n",
    "        )\n",
    "        # compressed_part = model.base_model.embed_pooler(new_embeds_for_compression)\n",
    "        compressed_part = model.embed_pooler(new_embeds_for_compression)\n",
    "        compressed_part = compressed_part.reshape(1, windows_amount, -1)\n",
    "        # start_embed = torch.rand_like(start_embed)\n",
    "        # compressed_part = torch.rand_like(compressed_part)\n",
    "        # end_embed = torch.rand_like(end_embed)\n",
    "        generated_embeds = torch.cat(\n",
    "            [\n",
    "                input_ids_embeds,\n",
    "                start_embed,\n",
    "                compressed_part,\n",
    "                end_embed,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        # print(\"COMPRESSED PART\", tokenizer.decode(next_true_tokens[-1]))\n",
    "        # print(\"===\")\n",
    "        generated_ids_compressed = model.generate(\n",
    "            inputs_embeds=generated_embeds,\n",
    "            # attention_mask=torch.ones_like(generated_embeds),\n",
    "            attention_mask=torch.ones(\n",
    "                generated_embeds.shape[:2],\n",
    "                device=\"cuda\",\n",
    "            ).long(),\n",
    "            max_new_tokens=4096,\n",
    "            # max_new_tokens=5,\n",
    "            do_sample=False,\n",
    "            # do_sample=True,\n",
    "            # temperature=0.6,\n",
    "            # top_p=0.95,\n",
    "        )\n",
    "        # break\n",
    "    generated_result = tokenizer.decode(generated_ids_compressed[-1])\n",
    "    # print()\n",
    "    gold_answer = correct_dataset[dataset_pos][\"answer\"]\n",
    "    answer = dataset_answer_filter(gold_answer)\n",
    "    model_answer = model_answer_filter(generated_result)\n",
    "    if is_equiv(answer, model_answer):\n",
    "        correct_items += 1\n",
    "        print(\"CORRECT\")\n",
    "    else:\n",
    "        print(\"WRONG\", gold_answer)\n",
    "        print(generated_result)\n",
    "    compressed_total_len = generated_ids_compressed.shape[1] + compressed_part.shape[1]\n",
    "    print(\n",
    "        generated_ids_compressed.shape[1],\n",
    "        next_true_tokens.shape[1],\n",
    "        compressed_total_len,\n",
    "        torch.tensor(generated_ids).shape[1],\n",
    "    )\n",
    "    evaluation_dataset.append(\n",
    "        {\n",
    "            **correct_dataset[dataset_pos],\n",
    "            \"compressed_input_part\": tokenizer.decode(next_true_tokens[-1]),\n",
    "            \"compressed_output_generation\": generated_result,\n",
    "            \"compressed_compression_size\": generated_tokens_amount,\n",
    "            \"original_total_len\": torch.tensor(generated_ids).shape[1],\n",
    "            \"compressed_total_len\": compressed_total_len,\n",
    "        }\n",
    "    )\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    print(\"===\")\n",
    "    # break\n",
    "    # embeds_generation_tokens = generated_tokens[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 656])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_embeds.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 719, 1536])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(next_true_tokens[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13392857142857142, 0.11160714285714286, 0.8333333333333334)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset) / len(dataset), correct_items / len(dataset), correct_items / len(\n",
    "    correct_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(correct_dataset) / len(dataset), correct_items / len(dataset), (\n",
    "#     correct_items + 1\n",
    "# ) / len(correct_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.base_model_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56056, 65654, 1.1712216355073497)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_total_len = 0\n",
    "compressed_total_len = 0\n",
    "for item in evaluation_dataset:\n",
    "    original_total_len += item[\"original_total_len\"]\n",
    "    compressed_total_len += item[\"compressed_total_len\"]\n",
    "original_total_len, compressed_total_len, compressed_total_len / original_total_len"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
