{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffdb004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "224 202 0.9017857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "# model = model.eval()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    # \"dim/hendrycks_math_train_12k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    # \"dim/hendrycks_math_train_1k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(\n",
    "    # test_size=250,\n",
    "    test_size=350,\n",
    "    # test_size=999,\n",
    "    # test_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dataset = dataset[\"test\"].filter(lambda x: x[\"model_answer\"].count(\"</think>\") == 1)\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "\n",
    "correct_dataset = []\n",
    "\n",
    "for pos, item in enumerate(dataset):\n",
    "    try:\n",
    "        answer = dataset_answer_filter(item[\"answer\"])\n",
    "        model_answer = model_answer_filter(item[\"model_answer\"])\n",
    "        # print(answer, model_answer)\n",
    "        # break\n",
    "        if is_equiv(answer, model_answer):\n",
    "            correct_dataset.append(item)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(dataset), len(correct_dataset), len(correct_dataset) / len(dataset))\n",
    "\n",
    "correct_dataset = correct_dataset[:30]\n",
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f058fd3",
   "metadata": {},
   "source": [
    "## test time train generation (single train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e6e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1214684/2285348861.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  content_compression_mask = torch.tensor(tokenized_turn[\"content_compression_mask\"])\n",
      "/home/user-name-goes-here/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/user-name-goes-here/.local/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>Problem: Below is a magic square, meaning that the sum of the numbers in each row, in each column, and in each of the $2$ main diagonals are equal. What is the value of $n$?\n",
      "\n",
      "[asy]size(125);\n",
      "for(int i = 0; i<4; ++i)\n",
      "{\n",
      "\n",
      "draw((0,i)--(3,i),linewidth(1));\n",
      "}\n",
      "\n",
      "for(int j = 0; j<4; ++j)\n",
      "{\n",
      "\n",
      "draw((j,0)--(j,3),linewidth(1));\n",
      "}\n",
      "\n",
      "label(\"$n-3$\",(.5,.5));\n",
      "label(\"3\",(.5,1.5));\n",
      "label(\"$n+1$\",(.5,2.5));\n",
      "\n",
      "label(\"$n+2$\",(1.5,.5));\n",
      "label(\"$2n-9$\",(1.5,1.5));\n",
      "label(\"$1$\",(1.5,2.5));\n",
      "\n",
      "label(\"$2$\",(2.5,.5));\n",
      "label(\"$n$\",(2.5,1.5));\n",
      "label(\"$n-1$\",(2.5,2.5));\n",
      "[/asy]\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<｜Assistant｜><think>\n",
      "\n",
      "Okay, so I have this magic square problem here, and I need to find the value of \\( n \\). Let me try to figure this out step by step. \n",
      "\n",
      "First, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\( n \\) such that all these sums are equal.\n",
      "\n",
      "Looking at the Asymptote code provided, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels given:\n",
      "\n",
      "- The top row has three cells: \\( n-3 \\), \\( 3 \\), and \\( n+1 \\).\n",
      "- The middle row has \\( n+2 \\), \\( 2n-9 \\), and \\( 1 \\).\n",
      "- The bottom row has \\( 2 \\), \\( n \\), and \\( n-1 \\).\n",
      "\n",
      "So, writing this out, the magic square looks like this:\n",
      "\n",
      "\\[\n",
      "\\begin{array}{|c|c|c|}\n",
      "\\hline\n",
      "n - 3 & 3 & n + 1 \\\\\n",
      "\\hline\n",
      "n + 2 & 2n - 9 & 1 \\\\\n",
      "\\hline\n",
      "2 & n & n - 1 \\\\\n",
      "\\hline\n",
      "\\end{array}\n",
      "\\]\n",
      "\n",
      "Alright, now I need to find \\( n \\) such that\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from hidden_capacity_reasoning.utils import tokenize_single_turn\n",
    "\n",
    "correct_items = 0\n",
    "torch.manual_seed(0)\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "dataset_pos = 5\n",
    "for dataset_pos in range(len(correct_dataset)):\n",
    "    tokenized_turn = tokenize_single_turn(\n",
    "        question=base_prompt.format(question=correct_dataset[dataset_pos][\"problem\"]),\n",
    "        answer=correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    for key in tokenized_turn.keys():\n",
    "        tokenized_turn[key] = torch.tensor(tokenized_turn[key])\n",
    "\n",
    "    evaluation_dataset = []\n",
    "\n",
    "    input_ids = correct_dataset[dataset_pos][\"problem\"]\n",
    "\n",
    "    input_ids = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": base_prompt.format(question=input_ids),\n",
    "                },\n",
    "            ],\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    content_compression_mask = torch.tensor(tokenized_turn[\"content_compression_mask\"])\n",
    "\n",
    "    input_part_end = (content_compression_mask == 0).nonzero()[-3][0]\n",
    "    question_input_ids = (\n",
    "        tokenized_turn[\"input_ids\"][: int(input_part_end) + 1].unsqueeze(0).cuda()\n",
    "    )\n",
    "    print(tokenizer.decode(question_input_ids[-1]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # input_ids = torch.tensor(question_input_ids).cuda()\n",
    "        input_ids_embeds = model.get_input_embeddings()(question_input_ids)\n",
    "        max_new_tokens = 300\n",
    "\n",
    "        inputs_embeds = torch.cat(\n",
    "            [\n",
    "                input_ids_embeds,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        generated_ids_new = model.generate(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=torch.ones(\n",
    "                inputs_embeds.shape[:2],\n",
    "                device=\"cuda\",\n",
    "            ).long(),\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "        )\n",
    "        # break\n",
    "    generated_result = tokenizer.decode(generated_ids_new[-1])\n",
    "    print(generated_result)\n",
    "    # get original language loss\n",
    "    labels = torch.cat([question_input_ids.cuda(), generated_ids_new.cuda()], dim=1)\n",
    "    print(tokenizer.decode(labels[-1]))\n",
    "\n",
    "    question_content_mask = content_compression_mask[: int(input_part_end) + 1].clone()\n",
    "    question_content_mask[question_content_mask == 0] = 4\n",
    "    question_content_mask[question_content_mask == 1] = 0\n",
    "    question_content_mask[question_content_mask == 4] = 1\n",
    "    train_content_mask_new = torch.cat(\n",
    "        [\n",
    "            question_content_mask,\n",
    "            torch.ones(\n",
    "                generated_ids_new.shape[1],\n",
    "            ),\n",
    "        ]\n",
    "    ).long()\n",
    "    print(question_content_mask)\n",
    "\n",
    "    generated_embeds = model.get_input_embeddings()(generated_ids_new)\n",
    "    new_input_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds,\n",
    "            generated_embeds,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    labels[:, train_content_mask_new == 0] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        original_loss = model(\n",
    "            inputs_embeds=new_input_embeds,\n",
    "            # attention_mask=train_attention_mask.unsqueeze(0).cuda(),\n",
    "            # attention_mask=torch.ones(new_input_embeds.size()[:2]).cuda().long(),\n",
    "            labels=labels,\n",
    "        ).loss\n",
    "    original_loss\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3461495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜><｜User｜>Problem: In right triangle $ABC$ with $\\angle B = 90^\\circ$, we have $\\sin A = 2\\cos A$.  What is $\\tan A$?\n",
      "\n",
      "Please reason step by step, and put your final answer within \\boxed{}.<｜Assistant｜><think>\n",
      "Okay, so I have this problem here: In right triangle ABC with angle B equal to 90 degrees, we know that sin A equals 2 cos A. The question is asking for tan A. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I remember that in a right triangle, the sine of an angle is the ratio of the opposite side to the hypotenuse, and the cosine is the ratio of the adjacent side to the hypotenuse. So, if angle A is one of the non-right angles in triangle ABC, then side opposite to angle A is BC, the side adjacent is AC, and the hypotenuse is AB.\n",
      "\n",
      "Given that sin A = 2 cos A, I can write that as:\n",
      "\n",
      "sin A = 2 cos A\n",
      "\n",
      "I also know that tan A is sin A over cos A, so tan A = sin A / cos A. Since sin A is equal to 2 cos A, substituting that into the tan A equation gives:\n",
      "\n",
      "tan A = (2 cos A) / cos A\n",
      "\n",
      "Wait, that simplifies to 2, right? Because the cos A in the numerator and denominator cancel out. So, tan A is 2? Hmm, that seems straightforward, but let me make sure I didn't skip any steps or make any mistakes.\n",
      "\n",
      "Alternatively, maybe I should use the Pythagorean identity to verify this. I remember that sin² A + cos² A = 1. Since sin A = 2 cos A, I can substitute that into the identity:\n",
      "\n",
      "(2 cos A)² + cos² A = 1\n",
      "\n",
      "Calculating that, it becomes:\n",
      "\n",
      "4 cos² A + cos² A = 1\n",
      "\n",
      "Which simplifies to:\n",
      "\n",
      "5 cos² A = 1\n",
      "\n",
      "So, cos² A = 1/5, which means cos A = ±1/√5. But since angle A is in a right triangle, it must be between 0 and\n",
      "tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[151646, 151644,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100, 151645, 151648,    198,  32313,     11,    773,    358,\n",
       "            614,    419,   3491,   1588,     25,    758,   1290,  21495,  19360,\n",
       "            448,   9210,    425,   6144,    311,    220,     24,     15,  12348,\n",
       "             11,    582,   1414,    429,   7437,    362,  16819,    220,     17,\n",
       "           7960,    362,     13,    576,   3405,    374,  10161,    369,  14197,\n",
       "            362,     13,  88190,     11,   1077,    752,   1744,    911,   1246,\n",
       "            311,   5486,    419,    382,   5338,     11,    358,   6099,    429,\n",
       "            304,    264,   1290,  21495,     11,    279,  57668,    315,    458,\n",
       "           9210,    374,    279,  11341,    315,    279,  14002,   3108,    311,\n",
       "            279,   9751,  65628,    810,     11,    323,    279,  75259,    374,\n",
       "            279,  11341,    315,    279,  23942,   3108,    311,    279,   9751,\n",
       "          65628,    810,     13,   2055,     11,    421,   9210,    362,    374,\n",
       "            825,    315,    279,   2477,   6701,  25941,    304,  21495,  19360,\n",
       "             11,   1221,   3108,  14002,    311,   9210,    362,    374,  18040,\n",
       "             11,    279,   3108,  23942,    374,  10584,     11,    323,    279,\n",
       "           9751,  65628,    810,    374,  14137,    382,  22043,    429,   7437,\n",
       "            362,    284,    220,     17,   7960,    362,     11,    358,    646,\n",
       "           3270,    429,    438,   1447,  15940,    362,    284,    220,     17,\n",
       "           7960,    362,    271,     40,   1083,   1414,    429,  14197,    362,\n",
       "            374,   7437,    362,    916,   7960,    362,     11,    773,  14197,\n",
       "            362,    284,   7437,    362,    608,   7960,    362,     13,   8704,\n",
       "           7437,    362,    374,   6144,    311,    220,     17,   7960,    362,\n",
       "             11,  31334,  10607,    429,   1119,    279,  14197,    362,  23606,\n",
       "           6696,   1447,  52591,    362,    284,    320,     17,   7960,    362,\n",
       "              8,    608,   7960,    362,    271,  14190,     11,    429,  15491,\n",
       "           9606,    311,    220,     17,     11,   1290,     30,   9211,    279,\n",
       "           7960,    362,    304,    279,  63533,    323,  46912,   9121,    700,\n",
       "             13,   2055,     11,  14197,    362,    374,    220,     17,     30,\n",
       "          88190,     11,    429,   4977,  30339,     11,    714,   1077,    752,\n",
       "           1281,   2704,    358,   3207,    944,  10706,    894,   7354,    476,\n",
       "           1281,    894,  20643,    382,  92014,     11,   7196,    358,   1265,\n",
       "            990,    279,   5355,  95362,  45195,   9569,    311,  10146,    419,\n",
       "             13,    358,   6099,    429,   7437,  29456,    362,    488,   7960,\n",
       "          29456,    362,    284,    220,     16,     13,   8704,   7437,    362,\n",
       "            284,    220,     17,   7960,    362,     11,    358,    646,  27679,\n",
       "            429,   1119,    279,   9569,   1447,      7,     17,   7960,    362,\n",
       "              8,  29456,    488,   7960,  29456,    362,    284,    220,     16,\n",
       "            271,  57908,   1095,    429,     11,    432,   9044,   1447,     19,\n",
       "           7960,  29456,    362,    488,   7960,  29456,    362,    284,    220,\n",
       "             16,    271,  23085,  15491,   9606,    311,   1447,     20,   7960,\n",
       "          29456,    362,    284,    220,     16,    271,   4416,     11,   7960,\n",
       "          29456,    362,    284,    220,     16,     14,     20,     11,    892,\n",
       "           3363,   7960,    362,    284,  20287,     16,     14, 144336,     20,\n",
       "             13,   1988,   2474,   9210,    362,    374,    304,    264,   1290,\n",
       "          21495,     11,    432,   1969,    387,   1948,    220,     15,    323]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.cat([question_input_ids.cuda(), generated_ids_new.cuda()], dim=1)\n",
    "print(tokenizer.decode(labels[-1]))\n",
    "\n",
    "question_content_mask = content_compression_mask[: int(input_part_end) + 1].clone()\n",
    "question_content_mask[question_content_mask == 0] = 4\n",
    "question_content_mask[question_content_mask == 1] = 0\n",
    "question_content_mask[question_content_mask == 4] = 1\n",
    "train_content_mask_new = torch.cat(\n",
    "    [\n",
    "        question_content_mask,\n",
    "        torch.ones(\n",
    "            generated_ids_new.shape[1],\n",
    "        ),\n",
    "    ]\n",
    ").long()\n",
    "print(question_content_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_embeds = model.get_input_embeddings()(generated_ids_new)\n",
    "    new_input_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds,\n",
    "            generated_embeds,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "labels[:, train_content_mask_new == 0] = -100\n",
    "# new_input_embeds\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed1bb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_id = tokenizer.eos_token_id\n",
    "bos_id = tokenizer.bos_token_id\n",
    "end_think_id = torch.tensor(tokenizer.encode(\"</think>\", add_special_tokens=False)[0])\n",
    "start_think_id = torch.tensor(\n",
    "    tokenizer.encode(\"<｜Assistant｜><think>\\n\", add_special_tokens=False)\n",
    ")\n",
    "user_id = torch.tensor(tokenizer.encode(\"<｜User｜>\", add_special_tokens=False)[0])\n",
    "\n",
    "# train_attention_mask = (\n",
    "#     input_ids == bos_id | input_ids == start_think_id | input_ids == user_id\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f0154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2882, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    original_loss = model(\n",
    "        inputs_embeds=new_input_embeds,\n",
    "        # attention_mask=train_attention_mask.unsqueeze(0).cuda(),\n",
    "        # attention_mask=torch.ones(new_input_embeds.size()[:2]).cuda().long(),\n",
    "        labels=labels,\n",
    "    ).loss\n",
    "original_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc65f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_tokens = 4\n",
    "# compression_tokens = max_new_tokens // 2\n",
    "# compression_tokens = max_new_tokens // 8\n",
    "compression_tensor = torch.nn.Parameter(\n",
    "    torch.rand_like(\n",
    "        new_input_embeds[:, :compression_tokens, :],\n",
    "    )\n",
    "    * model.get_input_embeddings().weight.data.std(),\n",
    "    requires_grad=True,\n",
    ")\n",
    "compressed_inputs_embeds = torch.cat(\n",
    "    [\n",
    "        input_ids_embeds.detach(),\n",
    "        compression_tensor,\n",
    "        generated_embeds[:, -(max_new_tokens // 2) :, :].detach(),\n",
    "    ],\n",
    "    dim=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7665c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 1536]), 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_tensor.shape, compression_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f2ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_labels = question_input_ids\n",
    "# comp\n",
    "question_labels = question_input_ids.clone()\n",
    "question_labels[0][question_content_mask == 0] = -100\n",
    "question_labels = question_labels.cuda()\n",
    "compressed_part = torch.ones(compression_tensor.shape[:2]).long().cuda()\n",
    "\n",
    "compressed_labels = torch.cat(\n",
    "    [\n",
    "        question_labels,\n",
    "        compressed_part,\n",
    "        generated_ids_new[:, -(max_new_tokens // 2) :],\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "# compressed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b53704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9204, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    compression_loss = model(\n",
    "        inputs_embeds=compressed_inputs_embeds,\n",
    "        labels=compressed_labels,\n",
    "    ).loss\n",
    "\n",
    "compression_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c8bb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}, Requires Gradient: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e7080fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_loss.item() <= original_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b6e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.9204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "1\n",
      "tensor(0.8734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "2\n",
      "tensor(0.8282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "3\n",
      "tensor(0.8105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "4\n",
      "tensor(0.7843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "5\n",
      "tensor(0.7675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "6\n",
      "tensor(0.7508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "7\n",
      "tensor(0.7429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "8\n",
      "tensor(0.7374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "9\n",
      "tensor(0.7302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "10\n",
      "tensor(0.7225, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "11\n",
      "tensor(0.7146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "12\n",
      "tensor(0.7066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "13\n",
      "tensor(0.6994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "14\n",
      "tensor(0.6940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "15\n",
      "tensor(0.6875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "16\n",
      "tensor(0.6809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "17\n",
      "tensor(0.6751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "18\n",
      "tensor(0.6691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "19\n",
      "tensor(0.6630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "20\n",
      "tensor(0.6564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "21\n",
      "tensor(0.6497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "22\n",
      "tensor(0.6422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "23\n",
      "tensor(0.6345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "24\n",
      "tensor(0.6320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "25\n",
      "tensor(0.6161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "26\n",
      "tensor(0.6084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "27\n",
      "tensor(0.6110, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "28\n",
      "tensor(0.5944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "29\n",
      "tensor(0.5864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "30\n",
      "tensor(0.5732, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "31\n",
      "tensor(0.5682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "32\n",
      "tensor(0.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "33\n",
      "tensor(0.5622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "34\n",
      "tensor(0.5496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "35\n",
      "tensor(0.5355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "36\n",
      "tensor(0.5280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "37\n",
      "tensor(0.5143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "38\n",
      "tensor(0.5045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "39\n",
      "tensor(0.4945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "40\n",
      "tensor(0.4839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "41\n",
      "tensor(0.4827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "42\n",
      "tensor(0.4896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "43\n",
      "tensor(0.4765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "44\n",
      "tensor(0.4764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "45\n",
      "tensor(0.4846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "46\n",
      "tensor(0.4785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "47\n",
      "tensor(0.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "48\n",
      "tensor(0.4546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "49\n",
      "tensor(0.4556, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "50\n",
      "tensor(0.4518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "51\n",
      "tensor(0.4574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "52\n",
      "tensor(0.4335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "53\n",
      "tensor(0.4326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "54\n",
      "tensor(0.4265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "55\n",
      "tensor(0.4308, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "56\n",
      "tensor(0.5051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "57\n",
      "tensor(0.4786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "58\n",
      "tensor(0.6095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "59\n",
      "tensor(0.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "60\n",
      "tensor(0.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "61\n",
      "tensor(0.5271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "62\n",
      "tensor(0.5119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "63\n",
      "tensor(0.4930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "64\n",
      "tensor(0.4818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "65\n",
      "tensor(0.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "66\n",
      "tensor(0.4783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "67\n",
      "tensor(0.4651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "68\n",
      "tensor(0.4541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "69\n",
      "tensor(0.4465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "70\n",
      "tensor(0.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "71\n",
      "tensor(0.4344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "72\n",
      "tensor(0.4292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "73\n",
      "tensor(0.4256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "74\n",
      "tensor(0.4206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "75\n",
      "tensor(0.4131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "76\n",
      "tensor(0.4057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "77\n",
      "tensor(0.4004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "78\n",
      "tensor(0.3944, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "79\n",
      "tensor(0.3883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "80\n",
      "tensor(0.3841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "81\n",
      "tensor(0.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "82\n",
      "tensor(0.3752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "83\n",
      "tensor(0.3711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "84\n",
      "tensor(0.3694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "85\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "86\n",
      "tensor(0.3646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "87\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "88\n",
      "tensor(0.3572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "89\n",
      "tensor(0.3537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "90\n",
      "tensor(0.3506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "91\n",
      "tensor(0.3471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "92\n",
      "tensor(0.3434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "93\n",
      "tensor(0.3402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "94\n",
      "tensor(0.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "95\n",
      "tensor(0.3337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "96\n",
      "tensor(0.3316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "97\n",
      "tensor(0.3291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "98\n",
      "tensor(0.3267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "99\n",
      "tensor(0.3248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "100\n",
      "tensor(0.3228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "101\n",
      "tensor(0.3206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "102\n",
      "tensor(0.3182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "103\n",
      "tensor(0.3166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "104\n",
      "tensor(0.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "105\n",
      "tensor(0.3139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "106\n",
      "tensor(0.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "107\n",
      "tensor(0.3088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "108\n",
      "tensor(0.3097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "109\n",
      "tensor(0.3047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "110\n",
      "tensor(0.3059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "111\n",
      "tensor(0.3717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "112\n",
      "tensor(0.3601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "113\n",
      "tensor(0.4008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "114\n",
      "tensor(0.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "115\n",
      "tensor(0.3904, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "116\n",
      "tensor(0.3690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "117\n",
      "tensor(0.3698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "118\n",
      "tensor(0.3694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "119\n",
      "tensor(0.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "120\n",
      "tensor(0.3649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "121\n",
      "tensor(0.3689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "122\n",
      "tensor(0.3495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "123\n",
      "tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "124\n",
      "tensor(0.3476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "125\n",
      "tensor(0.3388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "126\n",
      "tensor(0.3375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "127\n",
      "tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "128\n",
      "tensor(0.3317, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "129\n",
      "tensor(0.3243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "130\n",
      "tensor(0.3210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "131\n",
      "tensor(0.3162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "132\n",
      "tensor(0.3147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "133\n",
      "tensor(0.3119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "134\n",
      "tensor(0.3086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "135\n",
      "tensor(0.3049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "136\n",
      "tensor(0.3021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "137\n",
      "tensor(0.3005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "138\n",
      "tensor(0.3003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "139\n",
      "tensor(0.2964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "140\n",
      "tensor(0.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "141\n",
      "tensor(0.2945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "142\n",
      "tensor(0.2928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "143\n",
      "tensor(0.2907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "144\n",
      "tensor(0.2935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "145\n",
      "tensor(0.3288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "146\n",
      "tensor(0.3184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "147\n",
      "tensor(0.3325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "148\n",
      "tensor(0.3073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "149\n",
      "tensor(0.3104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "150\n",
      "tensor(0.3095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "151\n",
      "tensor(0.3026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "152\n",
      "tensor(0.3021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "153\n",
      "tensor(0.3012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "154\n",
      "tensor(0.2979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "155\n",
      "tensor(0.2971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "156\n",
      "tensor(0.2968, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "157\n",
      "tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "158\n",
      "tensor(0.2902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "159\n",
      "tensor(0.2900, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "160\n",
      "tensor(0.2903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "161\n",
      "tensor(0.2881, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epoch_amount = 500\n",
    "# epoch_amount = 500\n",
    "\n",
    "optimizer = torch.optim.AdamW([compression_tensor], lr=0.001)\n",
    "for epoch in range(epoch_amount):\n",
    "    print(epoch)\n",
    "    compressed_inputs_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds.detach(),\n",
    "            compression_tensor,\n",
    "            generated_embeds[:, -(max_new_tokens // 2) :, :].detach(),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    compression_loss = model(\n",
    "        inputs_embeds=compressed_inputs_embeds,\n",
    "        labels=compressed_labels,\n",
    "    ).loss\n",
    "    print(compression_loss)\n",
    "    compression_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if compression_loss.item() <= original_loss.item():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0689821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.1333, -0.0525,  0.0161,  ...,  0.0050,  0.0536,  0.0615],\n",
       "         [ 0.0280, -0.0860, -0.0381,  ..., -0.0432,  0.0546, -0.0791],\n",
       "         [-0.0107,  0.0577, -0.0345,  ..., -0.0124,  0.1097,  0.0769],\n",
       "         ...,\n",
       "         [ 0.1454,  0.0869,  0.1768,  ...,  0.0386,  0.0551, -0.0129],\n",
       "         [ 0.1206, -0.0238,  0.0889,  ...,  0.0130,  0.0191,  0.0909],\n",
       "         [ 0.1462,  0.2155, -0.0516,  ...,  0.1534,  0.2087,  0.1910]]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "536ffc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input_embeds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbdbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2715, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_loss  # / compressed_inputs_embeds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da0317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2694, device='cuda:0')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_loss  # / new_input_embeds.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ec7578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90 degrees, so cos A is positive. Therefore, cos A = 1/√5.\n",
      "\n",
      "Then, sin A = 2 cos A = 2/√5. Now, tan A is sin A over cos A, so:\n",
      "\n",
      "tan A = (2/√5) / (1/√5) = 2\n",
      "\n",
      "Yep, that confirms it. So, tan A is indeed 2. That makes sense because if tan A is 2, then the sides opposite and adjacent to angle A must be in the ratio 2:1. So, if we imagine a right triangle where angle A has opposite side length 2 and adjacent side length 1, the hypotenuse would be √(1² + 2²) = √5. That fits with what we found earlier.\n",
      "\n",
      "Wait, just to double-check, let's think about the original equation: sin A = 2 cos A. If tan A is 2, then sin A is 2/√5 and cos A is 1/√5, so 2/√5 equals 2*(1/√5), which is 2/√5. Yep, that checks out.\n",
      "\n",
      "I think that's solid. So, the answer should be 2.\n",
      "\n",
      "**Final Answer**\n",
      "The value of $\\tan A$ is \\boxed{2}.\n",
      "</think>\n",
      "\n",
      "Given a right triangle \\(ABC\\) with \\(\\angle B = 90^\\circ\\), we know that \\(\\sin A = 2 \\cos A\\). We need to find \\(\\tan A\\).\n",
      "\n",
      "First, we use the given equation:\n",
      "\\[\n",
      "\\sin A = 2 \\cos A\n",
      "\\]\n",
      "Dividing both sides by \\(\\cos A\\) (assuming \\(\\cos A \\neq 0\\)), we get:\n",
      "\\[\n",
      "\\tan A = 2\n",
      "\\]\n",
      "\n",
      "To verify, we use the Pythagorean identity. Since \\(\\sin A = 2 \\cos A\\), substituting into the identity \\(\\sin^2 A + \\cos^2 A = 1\\) gives:\n",
      "\\[\n",
      "(2 \\cos A)^2 + \\cos^2 A = 1\n",
      "\\]\n",
      "Simplifying, we have:\n",
      "\\[\n",
      "4 \\cos^2 A + \\cos^2 A = 1 \\implies 5 \\cos^2 A = 1 \\implies \\cos^2 A = \\frac{1}{5} \\implies \\cos A = \\frac{1}{\\sqrt{5}}\n",
      "\\]\n",
      "Thus, \\(\\sin A = 2 \\cos A = \\frac{2}{\\sqrt{5}}\\).\n",
      "\n",
      "Therefore, \\(\\tan A\\) is:\n",
      "\\[\n",
      "\\tan A = \\frac{\\sin A}{\\cos A} = \\frac{\\frac{2}{\\sqrt{5}}}{\\frac{1}{\\sqrt{5}}} = 2\n",
      "\\]\n",
      "\n",
      "The value of \\(\\tan A\\) is \\(\\boxed{2}\\).<｜end▁of▁sentence｜>\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    compressed_inputs_embeds = torch.cat(\n",
    "        [\n",
    "            input_ids_embeds.detach(),\n",
    "            compression_tensor,\n",
    "            # torch.rand_like(compression_tensor).cuda(),\n",
    "            generated_embeds[:, -(max_new_tokens // 2) :, :].detach(),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    generated_ids_compressed = model.generate(\n",
    "        inputs_embeds=compressed_inputs_embeds,\n",
    "        attention_mask=torch.ones(\n",
    "            compressed_inputs_embeds.shape[:2],\n",
    "            device=\"cuda\",\n",
    "        ).long(),\n",
    "        max_new_tokens=4096,\n",
    "        # max_new_tokens=5,\n",
    "        do_sample=False,\n",
    "        # do_sample=True,\n",
    "        # temperature=0.6,\n",
    "        # top_p=0.95,\n",
    "    )\n",
    "    # break\n",
    "generated_result = tokenizer.decode(generated_ids_compressed[-1])\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e00a35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "622 622\n"
     ]
    }
   ],
   "source": [
    "# print()\n",
    "gold_answer = correct_dataset[dataset_pos][\"answer\"]\n",
    "answer = dataset_answer_filter(gold_answer)\n",
    "model_answer = model_answer_filter(generated_result)\n",
    "if is_equiv(answer, model_answer):\n",
    "    correct_items += 1\n",
    "    print(\"CORRECT\")\n",
    "else:\n",
    "    print(\"WRONG\", gold_answer)\n",
    "    print(generated_result)\n",
    "compressed_total_len = generated_ids_compressed.shape[1]\n",
    "print(\n",
    "    generated_ids_compressed.shape[1],\n",
    "    compressed_total_len,\n",
    "    # torch.tensor(generated_ids).shape[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab30b57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    compression_tensor.shape[1]\n",
    "    + generated_embeds[:, -(max_new_tokens // 2) :, :].shape[1]\n",
    "    + generated_ids_compressed.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2414c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    tokenizer.encode(\n",
    "        correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
