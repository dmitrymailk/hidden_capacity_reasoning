{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ffdb004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "'NoneType' object has no attribute 'group'\n",
      "224 202 0.9017857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map={\"\": 0},\n",
    "    attn_implementation=\"sdpa\",\n",
    ")\n",
    "# model = model.eval()\n",
    "model.requires_grad_(False)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\n",
    "    # \"dim/hendrycks_math_train_12k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096\"\n",
    "    # \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    # \"dim/hendrycks_math_train_1k_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    "    \"dim/hendrycks_math_test_500_DeepSeek-R1-Distill-Qwen-1.5B_max_len_4096_greedy\"\n",
    ")\n",
    "\n",
    "dataset = dataset[\"train\"].train_test_split(\n",
    "    # test_size=250,\n",
    "    test_size=350,\n",
    "    # test_size=999,\n",
    "    # test_size=1,\n",
    "    seed=42,\n",
    ")\n",
    "dataset = dataset[\"test\"].filter(lambda x: x[\"model_answer\"].count(\"</think>\") == 1)\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "\n",
    "correct_dataset = []\n",
    "\n",
    "for pos, item in enumerate(dataset):\n",
    "    try:\n",
    "        answer = dataset_answer_filter(item[\"answer\"])\n",
    "        model_answer = model_answer_filter(item[\"model_answer\"])\n",
    "        # print(answer, model_answer)\n",
    "        # break\n",
    "        if is_equiv(answer, model_answer):\n",
    "            correct_dataset.append(item)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(dataset), len(correct_dataset), len(correct_dataset) / len(dataset))\n",
    "\n",
    "correct_dataset = correct_dataset[:30]\n",
    "len(correct_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8bdd8",
   "metadata": {},
   "source": [
    "## Обучение по чанкам в цикле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edc0804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32088b259bcc436ca040a4ff1fae20d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8431, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7182, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7118, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7083, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7250, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7804, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7775, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7640, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8841, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8821, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7429, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7621, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9197, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7764, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7202, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7072, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9352, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7070, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7423, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 16/41 [02:08<03:20,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 7\n",
      "Okay, so I have this magic square problem here, and I need to find the value of \\( n \\). Let me try to figure this out step by step. \n",
      "\n",
      "First, I remember that a magic square is a grid where the sums of numbers in each row, each column, and both main diagonals are equal. That common sum is called the magic constant. So, my goal is to find \\( n \\) such that all these sums are equal.\n",
      "\n",
      "Looking at the Asymptote code, it seems like the magic square is a 3x3 grid. Let me visualize it based on the labels provided:\n",
      "\n",
      "- The top row has three cells: \\( n-3 \\), \\( 3 \\), and \\( n+1 \\).\n",
      "- The middle row has: \\( n+2 \\), \\( 2n-9 \\), and \\( 1 \\).\n",
      "- The bottom row has: \\( 2 \\), \\( n \\), and \\( n-1 \\).\n",
      "\n",
      "Now, I'll calculate the sums for each row:\n",
      "\n",
      "1. **First Row:**\n",
      "   - Sum = \\( (n - 3) + 3 + (n + 1) \\)\n",
      "   - Simplify: \\( n - 3 + 3 + n + 1 = 2n + 1 \\)\n",
      "\n",
      "2. **Second Row:**\n",
      "   - Sum = \\( (n + 2) + (2n - 9) + 1 \\)\n",
      "   - \\( = 3n - 6 \\)\n",
      "\n",
      "3. **Third Row:**\n",
      "   - Sum = \\( 2 + n + (n - 1) \\)\n",
      "   - \\( = 2n + 1 \\)\n",
      "\n",
      "4. **Columns:**\n",
      "   - **First Column:**\n",
      "     - Sum = \\( (n - 3) + (n + 2) + 2 \\)\n",
      "     - \\( = 2n + 1 \\)\n",
      "   - **Second Column:**\n",
      "     - Sum = \\( 3 + (2n - 9) + n \\)\n",
      "     - \\( = 3n - 6 \\)\n",
      "   - **Third Column:**\n",
      "     - Sum = \\( (n + 1) + (1) + (n - 1) \\)\n",
      "     - \\( = 2n \\)\n",
      "\n",
      "2. **Main Diagonals:**\n",
      "   - **Primary Diagonal:**\n",
      "     - Sum = \\( (n - 3) + 1 + (n - 1) \\)\n",
      "     - \\( = 2n - 3 \\)\n",
      "   - **Secondary Diagonal:**\n",
      "     - Sum = \\( (n + 2) + (2n - 9) + 1 \\)\n",
      "     - \\( = 3n - 6 \\)\n",
      "   - **Equating the sums:**\n",
      "     - \\( 2n - 3 = 3n - 6 \\)\n",
      "     - \\( -n = -3 \\)\n",
      "     - \\( n = 3 \\)\n",
      "   - **Verification:**\n",
      "     - Substitute \\( n = 3 \\) into all labels:\n",
      "       - Top row: \\( 0, 3, 2 \\)\n",
      "       - Middle row: \\( 3, 0, 1 \\)\n",
      "       - Bottom row: \\( 3, 3, 2 \\)\n",
      "     - All rows, columns, and diagonals sum to \\( 5 \\)\n",
      "   - Therefore, \\( n = 2 \\)\n",
      "   - **Step 2:** Analyze the diagonals.\n",
      "     - Main diagonal: \\( (n-3) + 0 + (n-1) = 2n - 3 \\)\n",
      "       - \\( 2n - 3 = 5 \\) => \\( n = 4 \\)\n",
      "     - Other diagonal: \\( (n+1) + 0 + 2 = 2n + 1 \\)\n",
      "       - \\( 2n + 1 = 5 \\) => \\( n = 2 \\)\n",
      "   - But \\( n \\) cannot be both 4 and 2, so contradiction.\n",
      "   \n",
      "   **Step 2: Re-examining the Asymptote Code**\n",
      "   - The labels are:\n",
      "     - Top row: \\( n-3 \\), 3, \\( n+1 \\)\n",
      "     - Middle row: \\( n+2 \\), \\( 2n-9 \\), \\( 1 \\)\n",
      "     - Bottom row: \\( 2 \\), \\( n \\), \\( n-1 \\)\n",
      "   - Sum of each row should be equal:\n",
      "     - Top row: \\( (n-3) + 3 + (n+1) = 2n - 0 = 2n \\)\n",
      "     - Middle row: \\( (n+2) + (2n-9) + 1 = 3n -6 \\)\n",
      "     - Bottom row: \\( 2 + n + (n-1) = 2n +1 \\)\n",
      "   - All sums must be equal:\n",
      "     - \\( 2n = 3n -6 \\) and \\( 2n = 2n +1 \\)\n",
      "   - Solving \\( 2n = 3n -6 \\) gives \\( n = 6 \\)\n",
      "     - But \\( 2n = 2n +1 \\) leads to \\( 0 = 1 \\), which is impossible\n",
      "   - Therefore, the first row doesn't work\n",
      "\n",
      "2. **Second Row:**\n",
      "   - Sum of the row: \\( 3 + 4 + 5 = 12 \\)\n",
      "   - Total sum of the square \\( S = 12 \\)\n",
      "   - Checking other rows and columns for consistency\n",
      "\n",
      "3. **Third Row:**\n",
      "   - Sum of the row: \\( (n+1) + (2n-9) + (n-1) = 4n - 7 \\)\n",
      "   - Setting equal to \\( S \\): \\( 4n - 7 = 12 \\)\n",
      "   - Solving for \\( n \\): \\( n = \\frac{19}{4} \\)\n",
      "\n",
      "4. **Second Row:**\n",
      "   - Sum of the row: \\( (n-3) + 3 + (n+2) = 2n + 2 \\)\n",
      "   - Setting equal to \\( 2n - 9 \\): \\( 2n + 2 = 2n - 9 \\)\n",
      "   - Solving for \\( n \\): \\( 2 = -9 \\) (Contradiction)\n",
      "\n",
      "5. **Third Row:**\n",
      "   - Sum of the row: \\( (n+1) + (2n-9) + (n-1) = 4n - 7 \\)\n",
      "   - This must equal the common sum \\( S \\), so \\( 4n - 7 = S \\)\n",
      "\n",
      "6. **Second Row:**\n",
      "   - Sum of the row: \\( (n+2) + (2n-9) + 1 = 3n - 6 \\)\n",
      "   - This must also equal \\( S \\), so \\( 3n - 6 = S \\)\n",
      "\n",
      "7. **First Row:**\n",
      "   - Sum of the row: \\( (n - 3) + 3 + (n + 1) = 2n - 1 \\)\n",
      "   - Therefore, \\( 2n - 1 = S \\)\n",
      "\n",
      "8. **Second Row:**\n",
      "   - Sum of the row: \\( (n + 2) + (2n - 9) + 1 = 3n - 6 \\)\n",
      "   - Therefore, \\( 3n - 6 = S \\)\n",
      "\n",
      "9. **Third Row:**\n",
      "   - Sum of the row: \\( n + 2 + n + (-n) + n - 1 = 3 \\)\n",
      "   - Therefore, \\( S = 3 \\)\n",
      "\n",
      "10. **Equating the two expressions for S:**\n",
      "    - \\( 3n - 6 = 3 \\)\n",
      "    - Solving for \\( n \\):\n",
      "      - \\( 3n = 9 \\)\n",
      "      - \\( n = 3 \\)\n",
      "</think>\n",
      "\n",
      "To solve for \\( n \\) in the given magic square, we need to ensure that the sum of the numbers in each row, column, and the two main diagonals are equal. Let's denote the magic constant (the common sum) as \\( S \\).\n",
      "\n",
      "### Step 1: Analyze the First Row\n",
      "The first row contains the numbers:\n",
      "- \\( n - 3 \\)\n",
      "- \\( 3 \\)\n",
      "- \\( n + 1 \\)\n",
      "\n",
      "The sum of the first row is:\n",
      "\\[\n",
      "(n - 3) + 3 + (n + 1) = 2n + 1\n",
      "\\]\n",
      "This sum must equal the magic constant \\( S \\):\n",
      "\\[\n",
      "S = 2n + 1 \\quad \\text{(Equation 1)}\n",
      "\\]\n",
      "\n",
      "### Step 2: Analyze the Second Row\n",
      "The second row contains the numbers:\n",
      "- \\( n + 2 \\)\n",
      "- \\( 2n - 9 \\)\n",
      "- \\( 1 \\)\n",
      "\n",
      "The sum of the second row is:\n",
      "\\[\n",
      "(n + 2) + (2n - 9) + 1 = 3n - 6\n",
      "\\]\n",
      "This sum must also equal the magic constant \\( S \\):\n",
      "\\[\n",
      "S = 3n - 6 \\quad \\text{(Equation 2)}\n",
      "\\]\n",
      "\n",
      "### Step 3: Equate the Two Expressions for \\( S \\)\n",
      "From Equation 1 and Equation 2:\n",
      "\\[\n",
      "2n + 1 = 3n - 6\n",
      "\\]\n",
      "Solving for \\( n \\):\n",
      "\\[\n",
      "2n + 1 = 3n - 6 \\\\\n",
      "1 + 6 = 3n - 2n \\\\\n",
      "7 = n\n",
      "\\]\n",
      "\n",
      "### Step 4: Verify the Solution\n",
      "Let's verify the magic constant \\( S \\) with \\( n = 7 \\):\n",
      "- First row: \\( 7 - 3 = 4 \\), \\( 3 \\), \\( 7 + 1 = 8 \\). Sum: \\( 4 + 3 + 8 = 15 \\)\n",
      "- Second row: \\( 7 + 2 = 9 \\), \\( 2 \\times 7 - 9 = 5 \\), \\( 1 \\). Sum: \\( 9 + 5 + 1 = 15 \\)\n",
      "- Third row: \\( 7 + 2 = 9 \\), \\( 7 + 7 = 14 \\), \\( 7 - 1 = 6 \\). Sum: \\( 9 + 14 + 6 = 29 \\) (Wait, this doesn't match. Let's check the third row again.)\n",
      "\n",
      "Wait, there seems to be a mistake in the third row calculation. Let's re-examine the third row:\n",
      "- Third row: \\( n + 2 = 7 + 2 = 9 \\), \\( n = 7 \\), \\( n - 1 = 7 - 1 = 6 \\). Sum: \\( 9 + 7 + 6 = 22 \\)\n",
      "\n",
      "This discrepancy suggests an error in our initial assumption. Let's re-examine the equations.\n",
      "\n",
      "### Re-examining the Third Row\n",
      "The third row contains the numbers:\n",
      "- \\( n + 2 \\)\n",
      "- \\( n \\)\n",
      "- \\( n - 1 \\)\n",
      "\n",
      "The sum of the third row is:\n",
      "\\[\n",
      "(n + 2) + n + (n - 1) = 3n + 1\n",
      "\\]\n",
      "This sum must also equal the magic constant \\( S \\):\n",
      "\\[\n",
      "S = 3n + 1 \\quad \\text{(Equation 3)}\n",
      "\\]\n",
      "\n",
      "### Step 5: Equate the Correct Expressions for \\( S \\)\n",
      "From Equation 1 and Equation 3:\n",
      "\\[\n",
      "2n + 1 = 3n + 1 \\\\\n",
      "2n + 1 = 3n + 1 \\\\\n",
      "1 - 1 = 3n - 2n \\\\\n",
      "0 = n\n",
      "\\]\n",
      "\n",
      "### Step 6: Verify the Correct Solution\n",
      "Let's verify the magic constant \\( S \\) with \\( n = 0 \\):\n",
      "- First row: \\( 0 - 3 = -3 \\), \\( 3 \\), \\( 0 + 1 = 1 \\). Sum: \\( -3 + 3 + 1 = 1 \\)\n",
      "- Second row: \\( 0 + 2 = 2 \\), \\( 2 \\times 0 - 9 = -9 \\), \\( 1 \\). Sum: \\( 2 - 9 + 1 = -6 \\)\n",
      "- Third row: \\( 0 + 2 = 2 \\), \\( 0 \\), \\( 0 - 1 = -1 \\). Sum: \\( 2 + 0 - 1 = 1 \\)\n",
      "\n",
      "This suggests that \\( n = 0 \\) is a valid solution, but it results in inconsistent sums for the rows. Therefore, there must be an error in the initial setup.\n",
      "\n",
      "### Final Conclusion\n",
      "After re-evaluating the problem and ensuring the correct application of the magic square properties, the correct value of \\( n \\) is:\n",
      "\n",
      "\\[\n",
      "\\boxed{3}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=1521, всего_сгенерированно_токенов=2785 оригинальная_генерация=1959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8121, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7928, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7880, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8396, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8257, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8081, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8047, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6/41 [00:25<02:26,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=366, всего_сгенерированно_токенов=835 оригинальная_генерация=1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8157, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8411, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8371, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8494, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8392, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9259, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8127, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8100, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/41 [00:26<02:07,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=455, всего_сгенерированно_токенов=1035 оригинальная_генерация=1548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8621, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7744, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7720, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8085, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8441, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8294, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8461, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8185, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8214, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8659, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8761, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7963, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7863, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 12/41 [00:43<01:45,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=662, всего_сгенерированно_токенов=1722 оригинальная_генерация=3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9370, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9021, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9136, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9051, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/41 [00:12<02:42,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 12\n",
      "Okay, so I have this problem here where a regular octagon has the same perimeter as a regular hexagon that's shown with a side length of 16 cm. I need to find out how long each side of the octagon is. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, I remember that both a regular hexagon and a regular octagon have all sides equal and all angles equal. So, their perimeters will be just the number of sides multiplied by the length of each side.\n",
      "\n",
      "The problem says the regular octagon has the same perimeter as the regular hexagon shown, which has a side length of 16 cm. So, I need to find the side length of the octagon.\n",
      "\n",
      "Let me write down what I know:\n",
      "\n",
      "- Regular hexagon: 6 sides, each 16 cm.\n",
      "- Regular octagon: 8 sides, each unknown length, let's call it 's'.\n",
      "\n",
      "Since their perimeters are equal, I can set up an equation:\n",
      "\n",
      "Perimeter of hexagon = Perimeter of octagon\n",
      "\n",
      "Calculating the perimeter of the hexagon: 6 sides * 16 cm = 96 cm.\n",
      "\n",
      "So, 96 cm = 8 sides * s.\n",
      "\n",
      "To find 's', I'll divide both sides by 8:\n",
      "\n",
      "s = 96 cm / 8 = 12 cm.\n",
      "\n",
      "Wait, that seems straightforward. But let me double-check. Maybe I made a mistake in the perimeter calculation. The hexagon has 6 sides, each 16 cm, so perimeter is 6*16=96 cm. The octagon has 8 sides, so each side should be 96/8=12 cm. Yeah, that makes sense. I think I did it right.\n",
      "</think>\n",
      "\n",
      "To determine the length of each side of the regular octagon, follow these steps:\n",
      "\n",
      "1. **Calculate the Perimeter of the Regular Hexagon:**\n",
      "   \n",
      "   The hexagon has 6 sides, each with a length of 16 cm.\n",
      "   \n",
      "   \\[\n",
      "   \\text{Perimeter of hexagon} = 6 \\times 16\\, \\text{cm} = 96\\, \\text{cm}\n",
      "   \\]\n",
      "\n",
      "2. **Set Up the Equation for the Perimeter of the Octagon:**\n",
      "   \n",
      "   A regular octagon has 8 sides. Let \\( s \\) be the length of each side.\n",
      "   \n",
      "   \\[\n",
      "   \\text{Perimeter of octagon} = 8 \\times s\n",
      "   \\]\n",
      "   \n",
      "   Since the perimeters are equal:\n",
      "   \n",
      "   \\[\n",
      "   8s = 96\\, \\text{cm}\n",
      "   \\]\n",
      "\n",
      "3. **Solve for \\( s \\):**\n",
      "   \n",
      "   \\[\n",
      "   s = \\frac{96\\, \\text{cm}}{8} = 12\\, \\text{cm}\n",
      "   \\]\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{12\\,\\text{cm}}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=515, всего_сгенерированно_токенов=626 оригинальная_генерация=748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8188, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8177, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9033, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8467, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9670, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8054, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.0131, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0108, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9015, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8194, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8039, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7173, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7168, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/41 [00:34<01:47,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=571, всего_сгенерированно_токенов=1442 оригинальная_генерация=1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8423, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8926, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8459, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7256, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7343, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7325, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/41 [00:22<02:44,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=436, всего_сгенерированно_токенов=803 оригинальная_генерация=1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9346, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7371, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8521, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8284, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7658, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7951, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7943, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6/41 [00:20<02:00,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=742, всего_сгенерированно_токенов=1224 оригинальная_генерация=1732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9463, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8920, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8873, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9196, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8193, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.8780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9878, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9555, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7867, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9423, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9409, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 8/41 [00:33<02:18,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=647, всего_сгенерированно_токенов=1296 оригинальная_генерация=1198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8693, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.1428, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.1369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9562, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7353, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9439, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8374, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8576, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8543, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/41 [00:22<01:48,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=647, всего_сгенерированно_токенов=1229 оригинальная_генерация=2314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.7873, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8106, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8398, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8304, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7839, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8163, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8129, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8723, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9567, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8121, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8880, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7892, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8143, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 12/41 [00:56<02:17,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=420, всего_сгенерированно_токенов=1461 оригинальная_генерация=1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8776, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7426, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8488, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7872, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7836, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9293, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7949, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7929, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6/41 [00:18<01:47,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 1260\n",
      "Okay, so I need to figure out how many ways there are to arrange the letters of the word ELLIPSE. Hmm, let me think. I remember that when dealing with permutations of letters in a word, if all the letters are unique, the number of arrangements is just factorial of the number of letters. But wait, in this case, I notice that some letters are repeated. Let me check the word ELLIPSE.\n",
      "\n",
      "Breaking it down: E, L, L, I, P, S, E. Hmm, so E appears twice, L appears twice, and the rest are unique. So, the formula for permutations of multiset comes into play here.\n",
      "\n",
      "The general formula is:\n",
      "\n",
      "\\[\n",
      "\\frac{n!}{n_1! \\times n_2! \\times \\dots \\times n_k!}\n",
      "\\]\n",
      "\n",
      "Where \\( n \\) is the total number of letters, and \\( n_1, n_2, \\dots, n_k \\) are the counts of each repeating letter.\n",
      "\n",
      "First, I need to figure out how many times each letter appears in \"ELLIPSE.\" Let me write it out: E, L, L, I, P, S, E, E.\n",
      "\n",
      "So, counting each letter:\n",
      "\n",
      "- E appears 4 times.\n",
      "- L appears 2 times.\n",
      "- I appears 1 time.\n",
      "- P appears 1 time.\n",
      "- S appears 1 time.\n",
      "\n",
      "That gives me a total of 8 letters.\n",
      "\n",
      "Now, to find the number of distinct arrangements, I need to divide by the factorial of the number of times each letter repeats. So, the formula is:\n",
      "\n",
      "\\[\n",
      "\\frac{8!}{4! \\times 2! \\times 1! \\times 1! \\times 1!}\n",
      "\\]\n",
      "\n",
      "Calculating that:\n",
      "\n",
      "- 8! is 40320.\n",
      "- 4! is 24.\n",
      "- 2! is 2.\n",
      "\n",
      "So, the number of arrangements is 40320 / (24 * 2) = 40320 / 48 = 840.\n",
      "\n",
      "Wait, that seems high. Let me double-check. The word ELLIPSE has 8 letters, right? Let me count: E, L, L, I, P, S, E, E. Yeah, that's 8 letters. So, the formula should be 8! divided by the factorial of the number of each repeated letter.\n",
      "\n",
      "So, first, I need to figure out how many times each letter repeats. Looking at ELLIPSE:\n",
      "\n",
      "- E appears 3 times.\n",
      "- L appears 2 times.\n",
      "- The other letters (I, P, S) each appear once.\n",
      "\n",
      "So, the formula becomes:\n",
      "\n",
      "\\[\n",
      "\\frac{8!}{3! \\times 2! \\times 1! \\times 1! \\times 1!}\n",
      "\\]\n",
      "\n",
      "Calculating this should give the number of distinct arrangements.\n",
      "</think>\n",
      "\n",
      "To determine the number of ways to arrange the letters of the word **ELLIPSE**, we can use the formula for permutations of a multiset. \n",
      "\n",
      "The word **ELLIPSE** consists of 8 letters with the following frequencies:\n",
      "- **E**: 3 times\n",
      "- **L**: 2 times\n",
      "- **I**: 1 time\n",
      "- **P**: 1 time\n",
      "- **S**: 1 time\n",
      "\n",
      "The formula for the number of distinct permutations of a multiset is:\n",
      "\n",
      "\\[\n",
      "\\frac{n!}{n_1! \\times n_2! \\times \\dots \\times n_k!}\n",
      "\\]\n",
      "\n",
      "where:\n",
      "- \\( n \\) is the total number of items,\n",
      "- \\( n_1, n_2, \\dots, n_k \\) are the frequencies of each distinct item.\n",
      "\n",
      "Applying this to **ELLIPSE**:\n",
      "- \\( n = 8 \\)\n",
      "- \\( n_1 = 3 \\) (for E)\n",
      "- \\( n_2 = 2 \\) (for L)\n",
      "- \\( n_3 = 1 \\) (for I)\n",
      "- \\( n_4 = 1 \\) (for P)\n",
      "- \\( n_5 = 1 \\) (for S)\n",
      "\n",
      "Plugging these values into the formula:\n",
      "\n",
      "\\[\n",
      "\\frac{8!}{3! \\times 2! \\times 1! \\times 1! \\times 1!}\n",
      "\\]\n",
      "\n",
      "Calculating the factorials:\n",
      "- \\( 8! = 40320 \\)\n",
      "- \\( 3! = 6 \\)\n",
      "- \\( 2! = 2 \\)\n",
      "- \\( 1! = 1 \\)\n",
      "\n",
      "So, the number of distinct arrangements is:\n",
      "\n",
      "\\[\n",
      "\\frac{40320}{6 \\times 2 \\times 1 \\times 1 \\times 1} = \\frac{40320}{12} = 3360\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "\\boxed{3360}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=537, всего_сгенерированно_токенов=1036 оригинальная_генерация=1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8977, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8568, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8132, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8340, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8308, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:11<01:48,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=351, всего_сгенерированно_токенов=653 оригинальная_генерация=1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8668, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.0320, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.1533, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9394, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.1989, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8231, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9072, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8422, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8401, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 8/41 [00:25<01:45,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=383, всего_сгенерированно_токенов=1068 оригинальная_генерация=814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8563, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7690, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8237, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8178, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/41 [00:10<02:11,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=1303, всего_сгенерированно_токенов=1503 оригинальная_генерация=2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8680, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8584, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7227, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7338, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7036, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7821, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7810, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 6/41 [00:26<02:35,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=1033, всего_сгенерированно_токенов=1476 оригинальная_генерация=2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8305, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8674, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.1047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7665, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7449, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7430, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:20<03:11,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=769, всего_сгенерированно_токенов=1026 оригинальная_генерация=1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9633, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8914, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8797, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8811, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7228, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.6864, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.6866, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/41 [00:23<02:51,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG -13x+3\n",
      "Okay, so I have this polynomial f(x) and I need to find the remainder when it's divided by x² - 1. Hmm, I remember that when you divide a polynomial by a quadratic, the remainder should be a linear polynomial, right? So, it should look like ax + b, where a and b are constants that I need to find.\n",
      "\n",
      "But the problem says I can't use long division, which would be really messy because the polynomial is degree 10. I need another method. Hmm, maybe I can use the Remainder Theorem or something related to polynomial division.\n",
      "\n",
      "Wait, the Remainder Theorem says that the remainder of a polynomial f(x) divided by (x - c) is just f(c). But here, the divisor is a quadratic, x² - 1, which factors into (x - 1)(x + 1). So, maybe I can use the Remainder Theorem for each root of the divisor.\n",
      "\n",
      "If I recall correctly, the Remainder Theorem states that the remainder of a polynomial f(x) divided by (x - a) is f(a). So, if I can find the remainders when f(x) is divided by (x - 1) and (x + 1), then I can use those to find the remainder when divided by (x² - 1).\n",
      "\n",
      "Let me try that approach. First, I'll find f(1):\n",
      "\n",
      "f(1) = (1)^10 + 5*(1)^9 - 8*(1)^8 + 7*(1)^7 - (1)^6 - 12*(1)^5 + 4*(1)^4 - 8*(1)^3 + 12*(1)^2 - 5*(1) - 5\n",
      "\n",
      "Calculating each term:\n",
      "\n",
      "1 + 5 - 8 + 7 - 1 - 12 + 4 - 8 + 12 - 5 - 5\n",
      "\n",
      "Adding them up:\n",
      "\n",
      "1 + 5 = 6\n",
      "\n",
      "6 - 8 = -2\n",
      "\n",
      "-2 + 7 = 5\n",
      "\n",
      "5 - 1 = 4\n",
      "\n",
      "4 - 12 = -8\n",
      "\n",
      "-8 + 4 = -4\n",
      "\n",
      "-4 - 8 = -12\n",
      "\n",
      "-12 + 12 = 0\n",
      "\n",
      "0 - 5 = -5\n",
      "\n",
      "-5 - 5 = -10\n",
      "\n",
      "So the remainder is -10.\n",
      "</think>\n",
      "\n",
      "To find the remainder when \\( f(x) = x^{10} + 5x^9 - 8x^8 + 7x^7 - x^6 - 12x^5 + 4x^4 - 8x^3 + 12x^2 - 5x - 5 \\) is divided by \\( x^2 - 1 \\), we can use the **Remainder Theorem**. \n",
      "\n",
      "The Remainder Theorem states that the remainder of a polynomial \\( f(x) \\) divided by a linear divisor \\( x - a \\) is \\( f(a) \\). However, since we are dividing by a quadratic polynomial \\( x^2 - 1 \\), we can use the following approach:\n",
      "\n",
      "1. **Factor the Divisor**: \n",
      "   \\[\n",
      "   x^2 - 1 = (x - 1)(x + 1)\n",
      "   \\]\n",
      "   This means the roots of the divisor are \\( x = 1 \\) and \\( x = -1 \\).\n",
      "\n",
      "2. **Evaluate \\( f(x) \\) at the Roots**:\n",
      "   - **At \\( x = 1 \\)**:\n",
      "     \\[\n",
      "     f(1) = (1)^{10} + 5(1)^9 - 8(1)^8 + 7(1)^7 - (1)^6 - 12(1)^5 + 4(1)^4 - 8(1)^3 + 12(1)^2 - 5(1) - 5\n",
      "     \\]\n",
      "     \\[\n",
      "     f(1) = 1 + 5 - 8 + 7 - 1 - 12 + 4 - 8 + 12 - 5 - 5 = -10\n",
      "     \\]\n",
      "   \n",
      "   - **At \\( x = -1 \\)**:\n",
      "     \\[\n",
      "     f(-1) = (-1)^{10} + 5(-1)^9 - 8(-1)^8 + 7(-1)^7 - (-1)^6 - 12(-1)^5 + 4(-1)^4 - 8(-1)^3 + 12(-1)^2 - 5(-1) - 5\n",
      "     \\]\n",
      "     \\[\n",
      "     f(-1) = 1 - 5 - 8 - 7 - 1 + 12 + 4 + 8 + 12 + 5 - 5 = -10\n",
      "     \\]\n",
      "\n",
      "3. **Determine the Remainder**:\n",
      "   Since the divisor is quadratic, the remainder will be a linear polynomial of the form \\( R(x) = ax + b \\). We can set up the following system of equations using the evaluations at \\( x = 1 \\) and \\( x = -1 \\):\n",
      "   \\[\n",
      "   \\begin{cases}\n",
      "   a(1) + b = -10 \\\\\n",
      "   a(-1) + b = -10\n",
      "   \\end{cases}\n",
      "   \\]\n",
      "   Solving this system:\n",
      "   - From the first equation: \\( a + b = -10 \\)\n",
      "   - From the second equation: \\( -a + b = -10 \\)\n",
      "   \n",
      "   Adding both equations:\n",
      "   \\[\n",
      "   (a + b) + (-a + b) = -10 + (-10) \\\\\n",
      "   2b = -20 \\\\\n",
      "   b = -10\n",
      "   \\]\n",
      "   \n",
      "   Substituting \\( b = -10 \\) into the first equation:\n",
      "   \\[\n",
      "   a - 10 = -10 \\\\\n",
      "   a = 0\n",
      "   \\]\n",
      "   \n",
      "   Therefore, the remainder is:\n",
      "   \\[\n",
      "   R(x) = 0 \\cdot x + (-10) = -10\n",
      "   \\]\n",
      "\n",
      "**Final Answer:**\n",
      "\\[\n",
      "\\boxed{-10}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=999, всего_сгенерированно_токенов=1329 оригинальная_генерация=2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9066, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8702, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8215, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8231, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9539, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8496, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9386, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9340, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9738, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9546, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7251, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7164, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 11/41 [00:40<01:50,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=567, всего_сгенерированно_токенов=1537 оригинальная_генерация=2664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8891, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9535, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9487, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8809, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8803, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/41 [00:10<02:06,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=428, всего_сгенерированно_токенов=602 оригинальная_генерация=1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9330, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8332, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8765, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8904, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8653, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8713, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8107, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.6991, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.0452, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8179, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7184, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7551, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8852, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 12/41 [00:45<01:49,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 17\n",
      "Okay, so I have this problem here: I need to find the unique odd integer t such that 0 < t < 23, and t + 2 is the inverse of t modulo 23. Hmm, let me try to understand what this means.\n",
      "\n",
      "First, let me recall what an inverse modulo n is. If I have an integer t, its inverse modulo 23 is another integer, let's call it s, such that t * s ≡ 1 mod 23. So, in this problem, we're told that t + 2 is the inverse of t modulo 23. That means t * (t + 2) ≡ 1 mod 23.\n",
      "\n",
      "So, the equation we need to solve is t(t + 2) ≡ 1 mod 23. Let's write that out:\n",
      "\n",
      "t(t + 2) ≡ 1 mod 23\n",
      "\n",
      "Expanding the left side:\n",
      "\n",
      "t² + 2t ≡ 1 mod 23\n",
      "\n",
      "Now, let's rearrange the equation to bring all terms to one side:\n",
      "\n",
      "t² + 2t - 1 ≡ 0 mod 23\n",
      "\n",
      "This is a quadratic congruence. To solve for t, we can use the quadratic formula, but since we're working modulo a prime number (23 is prime), we can find the discriminant and check if it's a quadratic residue modulo 23.\n",
      "\n",
      "The discriminant D is given by:\n",
      "D = (2)^2 - 4*1*2 = 4 - 8 = -4\n",
      "\n",
      "So, we need to check if -4 is a quadratic residue modulo 23. Since 23 is congruent to 3 mod 4, -1 is not a quadratic residue modulo 23. Therefore, -4 is also not a quadratic residue modulo 23.\n",
      "\n",
      "Wait, that can't be right because the problem states that such a t exists. Maybe I made a mistake in applying the Euler's criterion.\n",
      "\n",
      "Let me double-check. Euler's criterion says that -1 is a quadratic residue modulo p if and only if p ≡ 1 mod 4. Since 23 ≡ 3 mod 4, -1 is not a quadratic residue. Therefore, -4 is also not a quadratic residue modulo 23.\n",
      "\n",
      "But the problem says that t + 2 is the inverse of t modulo 23. So, t(t + 2) ≡ 1 mod 23.\n",
      "\n",
      "Let's compute t(t + 2) mod 23:\n",
      "\n",
      "t^2 + 2t ≡ 1 mod 23.\n",
      "\n",
      "So, t^2 + 2t - 1 ≡ 0 mod 23.\n",
      "\n",
      "We can solve this quadratic congruence for t. Let's compute the discriminant:\n",
      "\n",
      "D = (2)^2 - 4*1*(-1) = 4 + 4 = 8.\n",
      "\n",
      "We need to find the square roots of 8 modulo 23. Let's test some numbers:\n",
      "\n",
      "8 mod 23 is 8.\n",
      "\n",
      "Check if 8 is a quadratic residue modulo 23. We can use Euler's criterion: 8^((23-1)/2) ≡ 8^11 mod 23.\n",
      "\n",
      "Calculating 8^11 mod 23:\n",
      "\n",
      "8^2 = 64 ≡ 64 - 2*23 = 18 mod 23\n",
      "\n",
      "8^4 = (8^2)^2 ≡ 18^2 = 324 ≡ 324 - 14*23 = 324 - 322 = 2 mod 23\n",
      "\n",
      "8^8 = (8^4)^2 ≡ 2^2 = 4 mod 23\n",
      "\n",
      "8^16 ≡ 4^2 = 16 mod 23\n",
      "\n",
      "So, 8^16 ≡ 16 mod 23\n",
      "\n",
      "But we need 8^k ≡ 1 mod 23. Since 8^16 ≡ 16 mod 23, which is not 1, so 8 is not a primitive root.\n",
      "\n",
      "Wait, maybe I made a mistake. Let me try another approach.\n",
      "\n",
      "Let me list the elements of the multiplicative group modulo 23. Since 23 is prime, the group has order 22. So, the possible orders of elements divide 22, which are 1, 2, 11, and 22.\n",
      "\n",
      "We are looking for an element t such that t + 2 ≡ t^{-1} mod 23. So, t(t + 2) ≡ 1 mod 23.\n",
      "\n",
      "Let's try t = 5: 5 * 7 = 35 ≡ 12 mod 23 ≠ 1.\n",
      "\n",
      "t = 6: 6 * 8 = 48 ≡ 48 - 2*23 = 48 - 46 = 2 mod 23 ≠ 1.\n",
      "\n",
      "t = 7: 7 * 9 = 63 ≡ 63 - 2*23 = 63 - 46 = 17 mod 23 ≠ 1.\n",
      "\n",
      "t = 10: 10 * 13 = 130 ≡ 130 - 5*23 = 130 - 115 = 15 mod 23 ≠ 1.\n",
      "\n",
      "t = 12: 12 * 2 = 24 ≡ 24 - 23 = 1 mod 23. So t = 12.\n",
      "\n",
      "**答案**\n",
      "\\boxed{12}\n",
      "</think>\n",
      "\n",
      "为了找到唯一的奇整数 \\( t \\) 满足 \\( 0 < t < 23 \\) 且 \\( t + 2 \\) 是 \\( t \\) 模 23 的逆元，我们可以按照以下步骤进行：\n",
      "\n",
      "1. **理解问题**：我们需要找到一个奇整数 \\( t \\) 使得 \\( t + 2 \\) 是 \\( t \\) 模 23 的逆元。根据数论中的逆元定义，这意味着 \\( t \\times (t + 2) \\equiv 1 \\pmod{23} \\)。\n",
      "\n",
      "2. **转换为方程**：我们需要解方程 \\( t(t + 2) \\equiv 1 \\pmod{23} \\)，即 \\( t^2 + 2t - 1 \\equiv 0 \\pmod{23} \\)。\n",
      "\n",
      "3. **尝试可能的解**：由于 \\( t \\) 是奇数，我们可以尝试所有可能的奇数 \\( t \\) 来找到满足条件的解。\n",
      "\n",
      "4. **验证每个奇数**：\n",
      "   - \\( t = 1 \\): \\( 1 \\times 3 = 3 \\not\\equiv 1 \\pmod{23} \\)\n",
      "   - \\( t = 3 \\): \\( 3 \\times 5 = 15 \\not\\equiv 1 \\pmod{23} \\)\n",
      "   - \\( t = 5 \\): \\( 5 \\times 7 = 35 \\equiv 12 \\pmod{23} \\)\n",
      "   - \\( t = 7 \\): \\( 7 \\times 9 = 63 \\equiv 17 \\pmod{23} \\)\n",
      "   - \\( t = 9 \\): \\( 9 \\times 11 = 99 \\equiv 8 \\pmod{23} \\)\n",
      "   - \\( t = 11 \\): \\( 11 \\times 13 = 143 \\equiv 6 \\pmod{23} \\)\n",
      "   - \\( t = 13 \\): \\( 13 \\times 15 = 195 \\equiv 19 \\pmod{23} \\)\n",
      "   - \\( t = 15 \\): \\( 15 \\times 17 = 255 \\equiv 1 \\pmod{23} \\)\n",
      "   - \\( t = 17 \\): \\( 17 \\times 19 = 323 \\equiv 18 \\pmod{23} \\)\n",
      "   - \\( t = 19 \\): \\( 19 \\times 21 = 399 \\equiv 10 \\pmod{23} \\)\n",
      "   - \\( t = 21 \\): \\( 21 \\times 23 = 483 \\equiv 4 \\pmod{23} \\)\n",
      "\n",
      "5. **找到解**：在上述验证中，当 \\( t = 12 \\) 时，\\( 12 \\times 14 = 168 \\equiv 1 \\pmod{23} \\)。\n",
      "\n",
      "因此，满足条件的唯一奇整数 \\( t \\) 是 12。\n",
      "\n",
      "\\[\n",
      "\\boxed{12}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=869, всего_сгенерированно_токенов=1932 оригинальная_генерация=1759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.7613, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7735, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7323, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7650, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7680, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7544, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7146, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7364, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7513, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8214, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9916, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7990, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7147, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7597, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7577, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7419, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7672, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.6973, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.6970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7388, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8716, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7403, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7829, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7664, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7445, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7362, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8047, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7188, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8658, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7244, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7232, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 28/41 [02:12<01:01,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 12\n",
      "Okay, so I have this problem here: I need to find the smallest distance between the origin and a point on the graph of \\( y = \\frac{1}{\\sqrt{2}}(x^2 - 3) \\). The answer should be expressed as \\( \\sqrt{a}/b \\), where \\( a \\) and \\( b \\) are positive integers, and \\( a \\) isn't divisible by the square of any integer greater than one. Then, I have to find \\( a + b \\). Okay, let's try to figure this out step by step.\n",
      "\n",
      "First, I need to find the smallest distance from the origin to a point on the graph of the given function. The function is \\( y = \\frac{1}{\\sqrt{2}}(x^2 - 3) \\). So, any point on this graph can be represented as \\( (x, y) \\), where \\( y \\) is given in terms of \\( x \\). \n",
      "\n",
      "The problem is asking for the smallest distance between the origin (which is the point \\( (0, 0) \\)) and any point on this graph. To find the smallest distance, I remember that the distance \\( D \\) between two points \\( (x_1, y_1) \\) and \\( (x_2, y_2) \\) is given by the formula:\n",
      "\n",
      "\\[\n",
      "D = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\n",
      "\\]\n",
      "\n",
      "In this problem, one of the points is the origin, which is \\( (0, 0) \\), and the other point is any point \\( (x, y) \\) on the graph of the given function. So, substituting these into the distance formula, we get:\n",
      "\n",
      "\\[\n",
      "D = \\sqrt{(x - 0)^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) - 0 \\right)^2}\n",
      "\\]\n",
      "\n",
      "Simplifying inside the square root:\n",
      "\n",
      "\\[\n",
      "D = \\sqrt{x^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) \\right)^2}\n",
      "\\]\n",
      "\n",
      "Let's square both sides to make it easier to handle:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) - y \\right)^2\n",
      "\\]\n",
      "\n",
      "To find the minimum distance, we need to minimize \\( D^2 \\). Let's expand the expression for \\( D^2 \\):\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) - y \\right)^2\n",
      "\\]\n",
      "\n",
      "Expanding the squared term:\n",
      "\n",
      "\\[\n",
      "\\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) - y \\right)^2 = \\frac{1}{2}(x^2 - 3)^2 - \\sqrt{2}(x^2 - 3)y + y^2\n",
      "\\]\n",
      "\n",
      "So, the distance squared becomes:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{1}{2}(x^2 - 3)^2 - \\sqrt{2}(x^2 - 3)\n",
      "\\]\n",
      "\n",
      "Hmm, that looks a bit complicated. Maybe I should expand and simplify this expression to make it easier to handle.\n",
      "\n",
      "First, let's expand the squared term:\n",
      "\n",
      "\\[\n",
      "\\left(x^2 - 3\\right)^2 = x^4 - 6x^2 + 9\n",
      "\\]\n",
      "\n",
      "So, substituting back into the distance squared:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{1}{2}(x^4 - 6x^2 + 9)\n",
      "\\]\n",
      "\n",
      "Simplifying:\n",
      "\n",
      "\\[\n",
      "D^2 = \\frac{1}{2}x^4 - \\frac{5}{2}x^2 + \\frac{9}{2}\n",
      "\\]\n",
      "\n",
      "To find the minimum, take the derivative with respect to \\( x \\):\n",
      "\n",
      "\\[\n",
      "\\frac{d}{dx}D^2 = 2x^3 - 5x\n",
      "\\]\n",
      "\n",
      "Setting the derivative equal to zero:\n",
      "\n",
      "\\[\n",
      "2x^3 - 5x = 0 \\\\\n",
      "x(2x^2 - 5) = 0\n",
      "\\]\n",
      "\n",
      "So, \\( x = 0 \\) or \\( x = \\pm \\sqrt{\\frac{5}{2}} \\).\n",
      "\n",
      "Plugging these back into the distance squared formula:\n",
      "\n",
      "For \\( x = 0 \\):\n",
      "\n",
      "\\[\n",
      "D^2 = 0^3 - 5 \\times 0 = 0 \\\\\n",
      "D = 0\n",
      "\\]\n",
      "\n",
      "Wait, that can't be right because the point (0, -1.5) is on the graph, and the distance from the origin is \\(\\sqrt{(0)^2 + (-1.5)^2} = 1.5\\), which is \\( \\frac{3}{2} \\). But according to this calculation, it's 0. Hmm, maybe I made a mistake in the derivative.\n",
      "\n",
      "Let me try again. The distance squared is:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) - y \\right)^2\n",
      "\\]\n",
      "\n",
      "Wait, no, actually, the distance squared from the origin to a point \\((x, y)\\) is just \\(x^2 + y^2\\). So, substituting \\(y = \\frac{1}{\\sqrt{2}}(x^2 - 3)\\), we get:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\left(\\frac{1}{\\sqrt{2}}(x^2 - 3)\\right)^2\n",
      "\\]\n",
      "\n",
      "Simplifying this:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{1}{2}(x^2 - 3)^2\n",
      "\\]\n",
      "\n",
      "Expanding the squared term:\n",
      "\n",
      "\\[\n",
      "(x^2 - 3)^2 = x^4 - 6x^2 + 9\n",
      "\\]\n",
      "\n",
      "So,\n",
      "\n",
      "\\[\n",
      "\\text{Total Distance}^2 = x^4 - 6x^2 + 9 + x^2 = x^4 - 5x^2 + 9\n",
      "\\]\n",
      "\n",
      "Now, to find the minimum, take the derivative with respect to \\( x \\):\n",
      "\n",
      "\\[\n",
      "\\frac{d}{dx} \\text{Total Distance}^2 = 4x^3 - 10x\n",
      "\\]\n",
      "\n",
      "Set the derivative equal to zero to find critical points:\n",
      "\n",
      "\\[\n",
      "4x^3 - 10x = 0\n",
      "\\]\n",
      "\n",
      "Factor out \\( x \\):\n",
      "\n",
      "\\[\n",
      "x(4x^2 - 10) = 0\n",
      "\\]\n",
      "\n",
      "So, \\( x = 0 \\) or \\( 4x^2 - 10 = 0 \\). Solving for \\( x \\) in the second equation:\n",
      "\n",
      "\\[\n",
      "x^2 = \\frac{10}{4} = \\frac{5}{2} \\implies x = \\pm \\sqrt{\\frac{5}{2}}\n",
      "\\]\n",
      "\n",
      "So, the critical points are at \\( x = \\sqrt{\\frac{5}{2}} \\) and \\( x = -\\sqrt{\\frac{5}{2}} \\).\n",
      "\n",
      "Evaluating \\( y \\) at these points:\n",
      "\n",
      "\\[\n",
      "y = \\frac{1}{\\sqrt{2}} \\left( \\left( \\sqrt{\\frac{5}{2}} \\right)^2 - 3 \\right) = \\frac{1}{\\sqrt{2}} \\left( \\frac{5}{2} - 3 \\right) = \\frac{1}{\\sqrt{2}} \\left( -\\frac{1}{2} \\right) = -\\frac{1}{2\\sqrt{2}}\n",
      "\\]\n",
      "\n",
      "\\[\n",
      "y = \\frac{1}{\\sqrt{2}} \\left( \\left( \\sqrt{\\frac{1}{2}} \\right)^2 - 3 \\right) = \\frac{1}{\\sqrt{2}} \\left( \\frac{1}{2} - 3 \\right) = \\frac{1}{\\sqrt{2}} \\left( -\\frac{5}{2} \\right) = -\\frac{5}{2\\sqrt{2}}\n",
      "\\]\n",
      "\n",
      "So, the squared distance is:\n",
      "\n",
      "\\[\n",
      "\\text{Distance}^2 = \\left( -\\frac{5}{2\\sqrt{2}} \\right)^2 + \\left( \\frac{5}{2\\sqrt{2}} \\right)^2 = \\frac{25}{8} + \\frac{25}{8} = \\frac{50}{8} = \\frac{25}{4}\n",
      "\\]\n",
      "\n",
      "Wait, that can't be right. I think I made a mistake here. Let me try again.\n",
      "\n",
      "The squared distance should be:\n",
      "\n",
      "\\[\n",
      "D^2 = \\left(x - 0\\right)^2 + \\left(\\sqrt{\\frac{1}{\\sqrt{2}}(x^2 - 3)} - 0\\right)^2\n",
      "\\]\n",
      "\n",
      "Simplify the squared distance:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{1}{\\sqrt{2}}(x^2 - 3)\n",
      "\\]\n",
      "\n",
      "Combine like terms:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{x^2}{\\sqrt{2}} - \\frac{3}{\\sqrt{2}}\n",
      "\\]\n",
      "\n",
      "Factor out \\( x^2 \\):\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 \\left(1 + \\frac{1}{\\sqrt{2}}\\right) - \\frac{3}{\\sqrt{2}}\n",
      "\\]\n",
      "\n",
      "To find the minimum distance, we need to minimize \\( D^2 \\). Since the square root function is monotonically increasing, minimizing \\( D^2 \\) will also minimize \\( D \\).\n",
      "\n",
      "Let \\( f(x) = \\left(\\frac{x^2}{\\sqrt{2}} - 3\\right)^2 + \\left(\\frac{x}{\\sqrt{2}}\\right)^2 \\).\n",
      "\n",
      "Expanding \\( f(x) \\):\n",
      "\n",
      "\\[\n",
      "f(x) = \\left(\\frac{x^4}{2} - 3\\sqrt{2}x^2 + 9\\right) + \\frac{1}{\\sqrt{2}}x^2 - 3\n",
      "\\]\n",
      "\n",
      "Combining like terms:\n",
      "\n",
      "\\[\n",
      "f(x) = \\frac{x^4}{2} - \\frac{5\\sqrt{2}}{2}x^2 + 6\n",
      "\\]\n",
      "\n",
      "Now, take the derivative of \\( f(x) \\) with respect to \\( x \\):\n",
      "\n",
      "\\[\n",
      "f'(x) = 2x^3 - 5\\sqrt{2}x\n",
      "\\]\n",
      "\n",
      "Set the derivative equal to zero to find critical points:\n",
      "\n",
      "\\[\n",
      "2x^3 - 5\\sqrt{2}x = 0\n",
      "\\]\n",
      "\n",
      "Factor out \\( x \\):\n",
      "\n",
      "\\[\n",
      "x(2x^2 - 5\\sqrt{2}) = 0\n",
      "\\]\n",
      "\n",
      "So, \\( x = 0 \\) or \\( 2x^2 - 5\\sqrt{2} = 0 \\)\n",
      "\n",
      "Solving for \\( x \\) in the second equation:\n",
      "\\[\n",
      "2x^2 = 5\\sqrt{2} \\\\\n",
      "x^2 = \\frac{5\\sqrt{2}}{2} \\\\\n",
      "x = \\pm \\sqrt{\\frac{5\\sqrt{2}}{2}}\n",
      "\\]\n",
      "\n",
      "Now, evaluate \\( f(x) \\) at these critical points to find the minimum value.\n",
      "\n",
      "For \\( x = 0 \\):\n",
      "\\[\n",
      "f(0) = \\frac{1}{\\sqrt{2}}(0 - 3) = -\\frac{3}{\\sqrt{2}}\n",
      "\\]\n",
      "\n",
      "For \\( x = 2\\sqrt{2} \\):\n",
      "\\[\n",
      "f(2\\sqrt{2}) = \\frac{1}{\\sqrt{2}}((2\\sqrt{2})^2 - 3) = \\frac{1}{\\sqrt{2}}(8 - 3) = \\frac{5}{\\sqrt{2}}\n",
      "\\]\n",
      "\n",
      "For \\( x = -\\sqrt{2} \\):\n",
      "\\[ f(-\\sqrt{2}) = \\frac{1}{\\sqrt{2}}((- \\sqrt{2})^2 - 3) = \\frac{1}{\\sqrt{2}}(2 - 3) = \\frac{-1}{\\sqrt{2}} \\]\n",
      "\n",
      "So the minimum value is \\( \\frac{-1}{\\sqrt{2}} \\), but since we are looking for the smallest distance, we take the absolute value, which is \\( \\frac{1}{\\sqrt{2}} \\).\n",
      "\n",
      "However, the problem asks for the smallest distance expressed as \\( \\frac{\\sqrt{a}}{b} \\). Therefore, we rationalize the denominator:\n",
      "\n",
      "\\[\n",
      "\\frac{1}{\\sqrt{2}} = \\frac{\\sqrt{2}}{2}\n",
      "\\]\n",
      "\n",
      "Thus, \\( a = 2 \\) and \\( b = 2 \\). Therefore, \\( a + b = 4 \\).\n",
      "\n",
      "\\boxed{4}\n",
      "</think>\n",
      "\n",
      "To find the smallest distance between the origin and a point on the graph of \\( y = \\frac{1}{\\sqrt{2}}(x^2 - 3) \\), we start by expressing the distance \\( D \\) from the origin to a point \\( (x, y) \\) on the graph. The distance formula is:\n",
      "\n",
      "\\[\n",
      "D = \\sqrt{x^2 + y^2}\n",
      "\\]\n",
      "\n",
      "Substituting \\( y = \\frac{1}{\\sqrt{2}}(x^2 - 3) \\) into the distance formula, we get:\n",
      "\n",
      "\\[\n",
      "D = \\sqrt{x^2 + \\left( \\frac{1}{\\sqrt{2}}(x^2 - 3) \\right)^2}\n",
      "\\]\n",
      "\n",
      "Simplifying the expression inside the square root:\n",
      "\n",
      "\\[\n",
      "D = \\sqrt{x^2 + \\frac{(x^2 - 3)^2}{2}}\n",
      "\\]\n",
      "\n",
      "To find the minimum distance, we minimize the square of the distance function \\( D^2 \\):\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{(x^2 - 3)^2}{2}\n",
      "\\]\n",
      "\n",
      "Expanding and simplifying:\n",
      "\n",
      "\\[\n",
      "D^2 = x^2 + \\frac{x^4 - 6x^2 + 9}{2} = \\frac{x^4}{2} - \\frac{5x^2}{2} + \\frac{9}{2}\n",
      "\\]\n",
      "\n",
      "Taking the derivative of \\( D^2 \\) with respect to \\( x \\) and setting it to zero to find critical points:\n",
      "\n",
      "\\[\n",
      "\\frac{d}{dx}\\left( \\frac{x^4}{2} - \\frac{5x^2}{2} + \\frac{9}{2} \\right) = 2x^3 - 5x = 0\n",
      "\\]\n",
      "\n",
      "Factoring:\n",
      "\n",
      "\\[\n",
      "x(2x^2 - 5) = 0\n",
      "\\]\n",
      "\n",
      "This gives \\( x = 0 \\) or \\( x = \\pm \\sqrt{\\frac{5}{2}} \\).\n",
      "\n",
      "Evaluating \\( D^2 \\) at these critical points:\n",
      "\n",
      "- For \\( x = 0 \\):\n",
      "  \\[\n",
      "  D^2 = 0 + \\frac{9}{2} = \\frac{9}{2}\n",
      "  \\]\n",
      "  \\[\n",
      "  D = \\frac{3}{\\sqrt{2}} = \\frac{\\sqrt{2}}{2}\n",
      "  \\]\n",
      "\n",
      "- For \\( x = \\pm \\sqrt{\\frac{5}{2}} \\):\n",
      "  \\[\n",
      "  D^2 = \\frac{25}{8} - \\frac{5}{2} + \\frac{9}{2} = \\frac{25}{8} + 2 = \\frac{41}{8}\n",
      "  \\]\n",
      "  \\[\n",
      "  D = \\sqrt{\\frac{41}{8}} = \\frac{\\sqrt{41}}{2\\sqrt{2}} = \\frac{\\sqrt{82}}{4}\n",
      "  \\]\n",
      "\n",
      "Comparing the distances, the smallest distance is \\( \\frac{\\sqrt{2}}{2} \\).\n",
      "\n",
      "Thus, \\( a = 2 \\) and \\( b = 2 \\), so \\( a + b = 4 \\).\n",
      "\n",
      "\\[\n",
      "\\boxed{4}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=916, всего_сгенерированно_токенов=3506 оригинальная_генерация=3001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8439, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8366, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7683, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8261, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8228, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:13<02:04,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=324, всего_сгенерированно_токенов=602 оригинальная_генерация=1554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8863, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8202, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7342, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8520, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7585, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8113, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7483, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8367, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8359, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 8/41 [00:30<02:05,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 9\n",
      "Okay, so I have this problem here: \n",
      "\n",
      "If \\(\\log_6 (x - y) + \\log_6 (x + y) = 2\\) and \\(\\log_y 5x = 2\\), then find \\(x\\).\n",
      "\n",
      "Hmm, let me try to figure this out step by step. I remember that logarithms can be tricky, but maybe I can use some logarithm properties to simplify these equations.\n",
      "\n",
      "First, looking at the first equation: \\(\\log_6 (x - y) + \\log_6 (x + y) = 2\\). I recall that the sum of two logarithms with the same base can be written as the logarithm of the product of their arguments. So, applying that property here:\n",
      "\n",
      "\\[\n",
      "\\log_6 [(x - y)(x + y)] = 2\n",
      "\\]\n",
      "\n",
      "Simplifying the expression inside the logarithm, I see that \\((x - y)(x + y)\\) is a difference of squares, which equals \\(x^2 - y^2\\). So now the equation becomes:\n",
      "\n",
      "\\[\n",
      "\\log_6 (x^2 - y^2) = 2\n",
      "\\]\n",
      "\n",
      "To eliminate the logarithm, I can rewrite this in exponential form. Remember that \\(\\log_b a = c\\) is equivalent to \\(b^c = a\\). Applying that here:\n",
      "\n",
      "\\[\n",
      "6^2 = x^2 - y^2\n",
      "\\]\n",
      "\n",
      "Simplifying:\n",
      "\n",
      "\\[\n",
      "36 = x^2 - y^2\n",
      "\\]\n",
      "\n",
      "Alright, so that's my first equation: \\(x^2 - y^2 = 36\\).\n",
      "\n",
      "Now, moving on to the second equation: \\(\\log_y 5x = 2\\). Again, I'll convert this logarithmic form to exponential form. The equation \\(\\log_b a = c\\) becomes \\(b^c = a\\). So applying that here, \\(y^2 = 5x\\). Got it.\n",
      "\n",
      "Now, I have two equations:\n",
      "1. \\(x^2 = 6(x^2 - y^2)\\)\n",
      "2. \\(y^2 = 5x\\)\n",
      "\n",
      "Let me simplify the first equation. Expanding the right side: \\(6x^2 - 6y^2\\). So the equation becomes \\(x^2 = 6x^2 - 6y^2\\). Rearranging terms: \\(0 = 5x^2 - 6y^2\\). Therefore, \\(5x^2 = 6y^2\\). So, \\(x^2 = \\frac{6}{5}y^2\\). Therefore, \\(x = \\sqrt{\\frac{6}{5}}y\\). Now, substituting this into the second equation: \\(\\log_y 5x = 2\\). So, \\(y^2 = 5x\\). But \\(x = \\sqrt{\\frac{6}{5}}y\\), so \\(y^2 = 5 \\times \\sqrt{\\frac{6}{5}}y\\). Simplifying, \\(y^2 = \\sqrt{30}y\\). Dividing both sides by y (assuming y ≠ 0), we get \\(y = \\sqrt{30}\\). Finally, substituting back to find x: \\(x = \\sqrt{30} - \\sqrt{10}\\). So, the final answer is \\(x = \\sqrt{30} - \\sqrt{10}\\).**\n",
      "\n",
      "**Summary:**\n",
      "1. Start with the given equation \\(x^2 + y^2 = 30\\).\n",
      "2. Use the second equation \\(\\log_y 5x = 2\\) to express \\(x\\) in terms of \\(y\\).\n",
      "3. Substitute \\(x = y\\sqrt{30}\\) into the first equation and solve for \\(y\\).\n",
      "4. Once \\(y\\) is known, substitute back to find \\(x\\).\n",
      "\n",
      "**Final Answer**\n",
      "The value of \\(x\\) is \\boxed{6\\sqrt{5}}.\n",
      "</think>\n",
      "\n",
      "Given the equations:\n",
      "\n",
      "1. \\(\\log_6 (x - y) + \\log_6 (x + y) = 2\\)\n",
      "2. \\(\\log_y (5x) = 2\\)\n",
      "\n",
      "We start by simplifying the first equation using the properties of logarithms. The sum of logarithms can be written as the logarithm of a product:\n",
      "\n",
      "\\[\n",
      "\\log_6 [(x - y)(x + y)] = 2\n",
      "\\]\n",
      "\n",
      "This simplifies to:\n",
      "\n",
      "\\[\n",
      "\\log_6 (x^2 - y^2) = 2\n",
      "\\]\n",
      "\n",
      "Converting this logarithmic equation to its exponential form, we get:\n",
      "\n",
      "\\[\n",
      "x^2 - y^2 = 6^2\n",
      "\\]\n",
      "\\[\n",
      "x^2 - y^2 = 36\n",
      "\\]\n",
      "\n",
      "Next, we simplify the second equation. Using the definition of logarithms, we convert the equation to its exponential form:\n",
      "\n",
      "\\[\n",
      "\\log_y (5x) = 2 \\implies y^2 = 5x\n",
      "\\]\n",
      "\n",
      "We now have two equations:\n",
      "\n",
      "1. \\(x^2 - y^2 = 36\\)\n",
      "2. \\(y^2 = 5x\\)\n",
      "\n",
      "Substituting \\(y^2 = 5x\\) into the first equation:\n",
      "\n",
      "\\[\n",
      "x^2 - 5x = 36\n",
      "\\]\n",
      "\n",
      "Rearranging this into a standard quadratic equation form:\n",
      "\n",
      "\\[\n",
      "x^2 - 5x - 36 = 0\n",
      "\\]\n",
      "\n",
      "We solve this quadratic equation using the quadratic formula \\(x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\), where \\(a = 1\\), \\(b = -5\\), and \\(c = -36\\):\n",
      "\n",
      "\\[\n",
      "x = \\frac{5 \\pm \\sqrt{25 + 144}}{2}\n",
      "\\]\n",
      "\\[\n",
      "x = \\frac{5 \\pm \\sqrt{169}}{2}\n",
      "\\]\n",
      "\\[\n",
      "x = \\frac{5 \\pm 13}{2}\n",
      "\\]\n",
      "\n",
      "This gives us two potential solutions:\n",
      "\n",
      "\\[\n",
      "x = \\frac{5 + 13}{2} = 9 \\quad \\text{and} \\quad x = \\frac{5 - 13}{2} = -4\n",
      "\\]\n",
      "\n",
      "Since \\(x\\) must be positive (as it is inside a logarithm), we discard \\(x = -4\\). Thus, \\(x = 9\\).\n",
      "\n",
      "However, we need to verify this solution with the original equations. Substituting \\(x = 9\\) into \\(y^2 = 5x\\):\n",
      "\n",
      "\\[\n",
      "y^2 = 5 \\times 9 = 45\n",
      "\\]\n",
      "\\[\n",
      "y = \\sqrt{45} = 3\\sqrt{5}\n",
      "\\]\n",
      "\n",
      "We check if this satisfies the first equation:\n",
      "\n",
      "\\[\n",
      "x^2 - y^2 = 9^2 - (3\\sqrt{5})^2 = 81 - 45 = 36\n",
      "\\]\n",
      "\n",
      "This is correct. Therefore, the value of \\(x\\) is \\(\\boxed{6\\sqrt{5}}\\).<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=857, всего_сгенерированно_токенов=1530 оригинальная_генерация=2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.7706, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7699, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8147, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7940, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7882, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/41 [00:11<02:28,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=668, всего_сгенерированно_токенов=838 оригинальная_генерация=1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8005, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8129, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8034, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7630, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7491, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7440, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9315, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8797, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8289, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7691, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7170, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8329, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9726, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9270, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8900, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8788, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8078, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7915, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8624, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8541, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7681, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7651, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 19/41 [01:14<01:25,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG 32\n",
      "Okay, so I have this problem here: In a certain isosceles right triangle, the altitude to the hypotenuse has length \\(4\\sqrt{2}\\). I need to find the area of the triangle. Hmm, let me think about how to approach this.\n",
      "\n",
      "First, let me recall what an isosceles right triangle is. It's a triangle with two legs of equal length and a hypotenuse. The two non-right angles are each 45 degrees. So, it's a 45-45-90 triangle.\n",
      "\n",
      "In such a triangle, the legs are equal, and the hypotenuse is leg * sqrt(2). That's a key property. So, if I let the length of each leg be 'a', then the hypotenuse will be a * sqrt(2).\n",
      "\n",
      "Now, the problem mentions the altitude to the hypotenuse. In a right triangle, the altitude to the hypotenuse has a special relationship with the legs. I remember that the length of the altitude (let's call it 'h') can be found using the formula:\n",
      "\n",
      "h = (a * b) / c\n",
      "\n",
      "where 'a' and 'b' are the legs, and 'c' is the hypotenuse. But since it's an isosceles right triangle, both legs are equal, so 'a' = 'b'. Therefore, the formula simplifies to:\n",
      "\n",
      "h = (a * a) / c\n",
      "\n",
      "But wait, in an isosceles right triangle, the hypotenuse 'c' can be expressed in terms of the legs. Since both legs are equal, c = a√2. So substituting that into the formula:\n",
      "\n",
      "h = (a^2) / (a√2) = a / √2\n",
      "\n",
      "We are given that the altitude 'h' is 4√2. So:\n",
      "\n",
      "4√2 = a / √2\n",
      "\n",
      "To solve for 'a', multiply both sides by √2:\n",
      "\n",
      "a = 4√2 * √2 = 4 * 2 = 8\n",
      "\n",
      "So, the legs of the triangle are each 8 units long.\n",
      "\n",
      "The area of the triangle is (base * height) / 2. Since it's an isosceles right triangle, both legs are equal, so:\n",
      "\n",
      "Area = (8 * 8) / 2 = 64 / 2 = 32\n",
      "\n",
      "So, the area is 32.\n",
      "\n",
      "Wait, but hold on. The problem mentions the altitude to the hypotenuse is 4√2. I need to make sure that this information is consistent with the area I calculated.\n",
      "\n",
      "In an isosceles right triangle, the altitude to the hypotenuse also acts as a median and an angle bisector. It divides the hypotenuse into two equal parts. Let me recall the relationship between the legs and the altitude.\n",
      "\n",
      "In an isosceles right triangle, the legs are equal, let's call each leg 'a'. The hypotenuse 'c' can be found using the Pythagorean theorem:\n",
      "\n",
      "c = a√2\n",
      "\n",
      "The area of the triangle can also be expressed in terms of the legs:\n",
      "\n",
      "Area = (a * a)/2 = a²/2\n",
      "\n",
      "But we also know that the altitude to the hypotenuse is given as 4√2. Let me denote this altitude as 'h'. In a right triangle, the altitude to the hypotenuse can be related to the legs and the hypotenuse.\n",
      "\n",
      "In an isosceles right triangle, the legs are equal, so let's denote each leg as 'a'. The hypotenuse 'c' can be found using the Pythagorean theorem:\n",
      "\n",
      "c = a√2\n",
      "\n",
      "Now, the area of the triangle can also be expressed in terms of the hypotenuse and the altitude to it. The area is also equal to (1/2)*c*height, where height is 4√2.\n",
      "\n",
      "So, setting the two expressions for the area equal:\n",
      "\n",
      "(1/2)*a² = (1/2)*c*4√2\n",
      "\n",
      "Simplify both sides by multiplying by 2:\n",
      "\n",
      "a² = c*4√2\n",
      "\n",
      "But we know that c = a√2, so substitute that in:\n",
      "\n",
      "a² = (a√2)*4√2\n",
      "\n",
      "Simplify the right side:\n",
      "\n",
      "First, multiply √2 * 4√2. Let's compute that:\n",
      "\n",
      "√2 * √2 = 2, so 4√2 * √2 = 4*2 = 8.\n",
      "\n",
      "So now we have:\n",
      "\n",
      "a² = 8a\n",
      "\n",
      "Subtract 8a from both sides to set the equation to zero:\n",
      "\n",
      "a² - 8a = 0\n",
      "\n",
      "Factor out an 'a':\n",
      "\n",
      "a(a - 8) = 0\n",
      "\n",
      "So, a = 0 or a = 8\n",
      "\n",
      "Since the length can't be zero, a = 8.\n",
      "\n",
      "Now, find the hypotenuse 'c' using the Pythagorean theorem:\n",
      "\n",
      "c = a√2 = 8√2\n",
      "\n",
      "Finally, calculate the area of the triangle:\n",
      "\n",
      "Area = (base × height)/2 = (8 × 8√2)/2 = (64√2)/2 = 32√2\n",
      "\n",
      "Wait, hold on, that doesn't seem right. Let me double-check.\n",
      "\n",
      "Wait, the legs are both 8, so the area should be (8 × 8)/2 = 32. But the altitude to the hypotenuse is given as 4√2. Maybe I made a mistake in the initial step.\n",
      "\n",
      "Let me recall that in an isosceles right triangle, the altitude to the hypotenuse is equal to half the length of the hypotenuse. So if the altitude is 4√2, then the hypotenuse must be 8√2. But wait, that doesn't seem right because in an isosceles right triangle, the legs are equal, and the hypotenuse is leg * sqrt(2). So if the legs are 'a', then hypotenuse is a√2. The altitude to the hypotenuse is (a * a) / (a√2) = a / √2. So if the altitude is 4√2, then a / √2 = 4√2. Solving for 'a', we get a = 4√2 * √2 = 4 * 2 = 8.\n",
      "\n",
      "Now, the area of the triangle is (base * height) / 2 = (8 * 8) / 2 = 64 / 2 = 32.\n",
      "\n",
      "Wait, but hold on, I think I might have made a mistake here. Let me double-check.\n",
      "\n",
      "In an isosceles right triangle, the legs are equal, and the hypotenuse is leg * sqrt(2). The altitude to the hypotenuse in such a triangle is equal to half the length of the leg. So if the altitude is 4√2, then half the leg is 4√2, so the leg is 8. Therefore, the area is (8 * 8) / 2 = 32.\n",
      "\n",
      "But I'm a bit confused because the problem says it's an isosceles right triangle, so both legs are equal, and the hypotenuse is leg * sqrt(2). The altitude to the hypotenuse in an isosceles right triangle should be leg / sqrt(2). So if the altitude is 4√2, then leg / sqrt(2) = 4√2, so leg = 4√2 * sqrt(2) = 8. Then area is (base * height) / 2 = (8 * 8) / 2 = 32.\n",
      "\n",
      "Wait, but I'm not sure if I did that right. Maybe I should draw the triangle to visualize it better. Let me sketch an isosceles right triangle with legs of length 'a' and hypotenuse 'c'. The altitude to the hypotenuse will split the triangle into two smaller isosceles right triangles. Each of these smaller triangles will have legs of length 'a' and hypotenuse 'c'. Using the Pythagorean theorem:\n",
      "\n",
      "a^2 + a^2 = c^2\n",
      "2a^2 = c^2\n",
      "c = a√2\n",
      "\n",
      "Now, the altitude to the hypotenuse can be found using the area of the triangle. The area is (a * a)/2 = a²/2. The area is also (c * h)/2, where h is the altitude. So:\n",
      "\n",
      "a²/2 = c * 4√2 / 2\n",
      "\n",
      "Simplify:\n",
      "\n",
      "a² = 8√2 * c\n",
      "\n",
      "But since c = a√2, substitute:\n",
      "\n",
      "a² = 8√2 * a√2 = 8 * 2 * a = 16a\n",
      "\n",
      "So a² = 16a => a = 16\n",
      "\n",
      "Therefore, the legs are 16 units each, and the area is (16 * 16)/2 = 128\n",
      "\n",
      "**Final Answer**\n",
      "The area of the triangle is \\boxed{128}.\n",
      "</think>\n",
      "\n",
      "Given an isosceles right triangle where the altitude to the hypotenuse has a length of \\(4\\sqrt{2}\\), we need to find the area of the triangle.\n",
      "\n",
      "First, we denote the legs of the triangle as \\(a\\). Since the triangle is isosceles, both legs are equal. The hypotenuse \\(c\\) of the triangle can be expressed as \\(a\\sqrt{2}\\).\n",
      "\n",
      "The altitude to the hypotenuse in a right triangle can be found using the formula:\n",
      "\\[\n",
      "\\text{Altitude} = \\frac{a \\cdot a}{a\\sqrt{2}} = \\frac{a}{\\sqrt{2}}\n",
      "\\]\n",
      "Given that the altitude is \\(4\\sqrt{2}\\), we set up the equation:\n",
      "\\[\n",
      "\\frac{a}{\\sqrt{2}} = 4\\sqrt{2}\n",
      "\\]\n",
      "Solving for \\(a\\), we multiply both sides by \\(\\sqrt{2}\\):\n",
      "\\[\n",
      "a = 4\\sqrt{2} \\cdot \\sqrt{2} = 4 \\cdot 2 = 8\n",
      "\\]\n",
      "\n",
      "Thus, the legs of the triangle are each 8 units long. The area of the triangle is then calculated as:\n",
      "\\[\n",
      "\\text{Area} = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2} \\times 8 \\times 8 = \\frac{1}{2} \\times 64 = 32\n",
      "\\]\n",
      "\n",
      "However, upon re-evaluating the steps, we realize that the correct approach involves recognizing that the altitude to the hypotenuse in an isosceles right triangle is half the length of the legs. Therefore, if the altitude is \\(4\\sqrt{2}\\), the legs must be \\(8\\sqrt{2}\\). This leads to the area being:\n",
      "\\[\n",
      "\\text{Area} = \\frac{1}{2} \\times (8\\sqrt{2}) \\times (8\\sqrt{2}) = \\frac{1}{2} \\times 128 = 64\n",
      "\\]\n",
      "\n",
      "Thus, the correct area of the triangle is:\n",
      "\\[\n",
      "\\boxed{128}\n",
      "\\]<｜end▁of▁sentence｜>\n",
      "вопрос+сжатые+сгенерированные=644, всего_сгенерированно_токенов=2398 оригинальная_генерация=3321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8273, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8844, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8759, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8165, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8158, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/41 [00:09<02:02,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=342, всего_сгенерированно_токенов=547 оригинальная_генерация=1269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9076, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7842, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7360, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7473, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8339, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:13<02:04,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=626, всего_сгенерированно_токенов=929 оригинальная_генерация=2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.9211, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9181, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8010, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7997, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7733, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8153, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.7876, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.7872, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/41 [00:17<02:05,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=475, всего_сгенерированно_токенов=844 оригинальная_генерация=1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "original_loss tensor(0.8948, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.8541, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.8485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(0.9512, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(0.9501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "==================================================\n",
      "original_loss tensor(1.0513, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression_loss tensor(1.0352, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/41 [00:14<02:17,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "вопрос+сжатые+сгенерированные=333, всего_сгенерированно_токенов=640 оригинальная_генерация=2159\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from lm_eval.tasks.hendrycks_math.utils import strip_string, remove_boxed, is_equiv\n",
    "from hidden_capacity_reasoning.evaluation.math_500.utils import (\n",
    "    dataset_answer_filter,\n",
    "    model_answer_filter,\n",
    ")\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm as text_tqdm\n",
    "from hidden_capacity_reasoning.utils import (\n",
    "    tokenize_single_turn,\n",
    "    EOS_TOKEN_ID,\n",
    "    END_THINK_ID,\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "base_prompt = open(\n",
    "    \"hidden_capacity_reasoning/evaluation/math_500/math_500_prompt\"\n",
    ").read()\n",
    "\n",
    "max_new_tokens = 100\n",
    "compression_tokens_amount = 2\n",
    "max_total_tokens = 4096\n",
    "max_total_steps = max_total_tokens // max_new_tokens + 1\n",
    "\n",
    "evaluation_dataset = []\n",
    "correct_items = 0\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "for dataset_pos in tqdm(range(len(correct_dataset))):\n",
    "    # for dataset_pos in tqdm(range(1, len(correct_dataset))):\n",
    "    tokenized_turn = tokenize_single_turn(\n",
    "        question=base_prompt.format(question=correct_dataset[dataset_pos][\"problem\"]),\n",
    "        answer=correct_dataset[dataset_pos][\"model_answer\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    for key in tokenized_turn.keys():\n",
    "        tokenized_turn[key] = torch.tensor(tokenized_turn[key])\n",
    "\n",
    "    device = \"cuda\"\n",
    "\n",
    "    content_compression_mask = tokenized_turn[\"content_compression_mask\"]\n",
    "\n",
    "    input_part_end = (content_compression_mask == 0).nonzero()[-3][0]\n",
    "    # get only question part\n",
    "    question_input_ids = (\n",
    "        tokenized_turn[\"input_ids\"][: int(input_part_end) + 1].unsqueeze(0).cuda()\n",
    "    )\n",
    "    # print(tokenizer.decode(question_input_ids[-1]))\n",
    "\n",
    "    ######## start loop generation\n",
    "    ########\n",
    "    compression_loop = True\n",
    "    input_ids_embeds = model.get_input_embeddings()(question_input_ids)\n",
    "    compression_part = torch.tensor([[0]])\n",
    "    generated_ids_new = None\n",
    "    generated_embeds = None\n",
    "    generated_embeds_prev = None\n",
    "    generated_ids_new_prev = None\n",
    "    end_of_think = False\n",
    "    total_generated_text = \"\"\n",
    "\n",
    "    for compression_step in text_tqdm(range(max_total_steps)):\n",
    "        ######## generate new tokens\n",
    "        ########\n",
    "        inputs_embeds = None\n",
    "        with torch.no_grad():\n",
    "\n",
    "            if compression_part.shape[1] >= compression_tokens_amount:\n",
    "                generated_embeds_prev = generated_embeds[\n",
    "                    :, -(max_new_tokens // 2) :, :\n",
    "                ].clone()\n",
    "                inputs_embeds = torch.cat(\n",
    "                    [\n",
    "                        input_ids_embeds,\n",
    "                        compression_part,\n",
    "                        generated_embeds_prev,\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            else:\n",
    "                # first time generation\n",
    "                inputs_embeds = torch.cat(\n",
    "                    [\n",
    "                        input_ids_embeds,\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            generated_ids_new = model.generate(\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                attention_mask=torch.ones(\n",
    "                    inputs_embeds.shape[:2],\n",
    "                    device=\"cuda\",\n",
    "                ).long(),\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=False,\n",
    "                use_cache=compression_step > 0,\n",
    "            )\n",
    "            # break\n",
    "        generated_result = tokenizer.decode(generated_ids_new[-1])\n",
    "        # print(generated_result)\n",
    "        total_generated_text += generated_result\n",
    "        print(\"=\" * 50)\n",
    "        generated_embeds = model.get_input_embeddings()(generated_ids_new)\n",
    "        if END_THINK_ID in generated_ids_new[-1].tolist():\n",
    "            end_of_think = True\n",
    "            break\n",
    "\n",
    "        ########\n",
    "        ######## get original language loss\n",
    "        ########\n",
    "        labels = None\n",
    "        if compression_part.shape[1] >= compression_tokens_amount:\n",
    "            labels = torch.cat(\n",
    "                [\n",
    "                    question_input_ids.cuda(),\n",
    "                    ((torch.ones(compression_part.shape[:2]) * -100).long()).cuda(),\n",
    "                    (\n",
    "                        (torch.ones(generated_embeds_prev.shape[:2]) * -100).long()\n",
    "                    ).cuda(),\n",
    "                    generated_ids_new.cuda(),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        else:\n",
    "            # first time generation\n",
    "            labels = torch.cat(\n",
    "                [\n",
    "                    question_input_ids.cuda(),\n",
    "                    generated_ids_new.cuda(),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "        question_content_mask = content_compression_mask[\n",
    "            : int(input_part_end) + 1\n",
    "        ].clone()\n",
    "        question_content_mask[question_content_mask == 0] = 4\n",
    "        question_content_mask[question_content_mask == 1] = 0\n",
    "        question_content_mask[question_content_mask == 4] = 1\n",
    "\n",
    "        if compression_part.shape[1] >= compression_tokens_amount:\n",
    "            train_content_mask_new = torch.cat(\n",
    "                [\n",
    "                    question_content_mask,\n",
    "                    torch.zeros(compression_part.shape[1]),\n",
    "                    torch.zeros(generated_embeds_prev.shape[1]),\n",
    "                    torch.zeros(generated_ids_new.shape[1] // 2),\n",
    "                    torch.ones(generated_ids_new.shape[1] // 2),\n",
    "                ]\n",
    "            ).long()\n",
    "        else:\n",
    "            train_content_mask_new = torch.cat(\n",
    "                [\n",
    "                    question_content_mask,\n",
    "                    torch.ones(generated_ids_new.shape[1] // 2) * 0,\n",
    "                    torch.ones(generated_ids_new.shape[1] // 2),\n",
    "                ]\n",
    "            ).long()\n",
    "\n",
    "        generated_ids_new_prev = generated_ids_new.clone()\n",
    "        # generated_embeds = model.get_input_embeddings()(generated_ids_new)\n",
    "\n",
    "        new_input_embeds = None\n",
    "        if compression_part.shape[1] >= compression_tokens_amount:\n",
    "            new_input_embeds = torch.cat(\n",
    "                [\n",
    "                    input_ids_embeds.cuda(),\n",
    "                    compression_part.cuda(),\n",
    "                    generated_embeds_prev.cuda(),\n",
    "                    generated_embeds,\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        else:\n",
    "            new_input_embeds = torch.cat(\n",
    "                [\n",
    "                    input_ids_embeds,\n",
    "                    generated_embeds,\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "\n",
    "        labels[:, train_content_mask_new == 0] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            original_loss = model(\n",
    "                inputs_embeds=new_input_embeds,\n",
    "                labels=labels,\n",
    "            ).loss\n",
    "        print(\"original_loss\", original_loss)\n",
    "        ########\n",
    "        ######## generate compress embeddings\n",
    "        ########\n",
    "        compression_tensor = torch.nn.Parameter(\n",
    "            torch.rand_like(\n",
    "                new_input_embeds[:, :compression_tokens_amount, :],\n",
    "            )\n",
    "            * model.get_input_embeddings().weight.data.std(),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "\n",
    "        question_labels = question_input_ids.clone().cuda()\n",
    "        question_labels[0][question_content_mask == 0] = -100\n",
    "        compression_tensor_labels = (\n",
    "            (torch.ones(compression_tensor.shape[:2]) * -100).long().cuda()\n",
    "        )\n",
    "        if compression_part.shape[1] >= compression_tokens_amount:\n",
    "            compression_part_labels = (\n",
    "                (torch.ones(compression_part.shape[:2]) * -100).long().cuda()\n",
    "            )\n",
    "            compressed_labels = torch.cat(\n",
    "                [\n",
    "                    question_labels,\n",
    "                    compression_part_labels,\n",
    "                    compression_tensor_labels,\n",
    "                    generated_ids_new[:, -(max_new_tokens // 2) :],\n",
    "                ],\n",
    "                dim=-1,\n",
    "            )\n",
    "        else:\n",
    "            compressed_labels = torch.cat(\n",
    "                [\n",
    "                    question_labels,\n",
    "                    compression_tensor_labels,\n",
    "                    generated_ids_new[:, -(max_new_tokens // 2) :],\n",
    "                ],\n",
    "                dim=-1,\n",
    "            )\n",
    "\n",
    "        ########\n",
    "        ######## train\n",
    "        ########\n",
    "        epoch_amount = 100\n",
    "\n",
    "        optimizer = torch.optim.Adam([compression_tensor], lr=0.1)\n",
    "        acclumulation_steps = 1\n",
    "        for epoch in range(epoch_amount):\n",
    "            if compression_part.shape[1] >= compression_tokens_amount:\n",
    "                compressed_inputs_embeds = torch.cat(\n",
    "                    [\n",
    "                        input_ids_embeds.detach(),\n",
    "                        compression_part.detach(),\n",
    "                        compression_tensor,\n",
    "                        generated_embeds[:, -(max_new_tokens // 2) :, :].detach(),\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            else:\n",
    "                compressed_inputs_embeds = torch.cat(\n",
    "                    [\n",
    "                        input_ids_embeds.detach(),\n",
    "                        compression_tensor,\n",
    "                        generated_embeds[:, -(max_new_tokens // 2) :, :].detach(),\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                )\n",
    "            compression_loss = model(\n",
    "                inputs_embeds=compressed_inputs_embeds,\n",
    "                labels=compressed_labels,\n",
    "            ).loss\n",
    "            compression_loss.backward()\n",
    "            if (epoch + 1) % acclumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if compression_loss.item() <= original_loss.item():\n",
    "                break\n",
    "            # if compression_loss.item() <= (original_loss.item() + 0.01):\n",
    "            #     break\n",
    "            # if (compression_loss.item() + 0.05) <= original_loss.item():\n",
    "            #     break\n",
    "        print(\"compression_loss\", compression_loss)\n",
    "        if compression_part.shape[1] >= compression_tokens_amount:\n",
    "            compression_part = torch.cat(\n",
    "                [\n",
    "                    compression_part,\n",
    "                    compression_tensor.detach(),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "        else:\n",
    "            compression_part = compression_tensor.detach()\n",
    "    # if end_of_think:\n",
    "    inputs_embeds = torch.cat(\n",
    "        [\n",
    "            inputs_embeds,\n",
    "            generated_embeds,\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    final_response = model.generate(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        attention_mask=torch.ones(\n",
    "            inputs_embeds.shape[:2],\n",
    "            device=\"cuda\",\n",
    "        ).long(),\n",
    "        max_new_tokens=(max_total_steps - compression_step) * max_new_tokens,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    final_answer = tokenizer.decode(final_response[-1])\n",
    "    total_generated_text += final_answer\n",
    "    # print(\"FINAL ANSWER\", final_answer)\n",
    "\n",
    "    gold_answer = correct_dataset[dataset_pos][\"answer\"]\n",
    "    answer = dataset_answer_filter(gold_answer)\n",
    "    # print(\"GOLD ANSWER\", answer)\n",
    "    model_answer = model_answer_filter(total_generated_text)\n",
    "    if is_equiv(answer, model_answer):\n",
    "        correct_items += 1\n",
    "        print(\"CORRECT\")\n",
    "    else:\n",
    "        print(\"WRONG\", gold_answer)\n",
    "        print(total_generated_text)\n",
    "\n",
    "    compressed_total_len = inputs_embeds.shape[1] + final_response.shape[1]\n",
    "    total_generated_tokens = final_response.shape[1] + max_new_tokens * (\n",
    "        compression_step + 1\n",
    "    )\n",
    "    original_total_len = len(\n",
    "        tokenizer.encode(\n",
    "            correct_dataset[dataset_pos][\"model_answer\"],\n",
    "            add_special_tokens=False,\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        f\"вопрос+сжатые+сгенерированные={compressed_total_len}, всего_сгенерированно_токенов={total_generated_tokens} оригинальная_генерация={original_total_len}\"\n",
    "    )\n",
    "    evaluation_dataset.append(\n",
    "        {\n",
    "            \"original_total_len\": original_total_len,\n",
    "            \"compressed_total_len\": compressed_total_len,\n",
    "        }\n",
    "    )\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f082d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13392857142857142, 0.09821428571428571, 0.7333333333333333)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_dataset) / len(dataset), correct_items / len(dataset), correct_items / len(\n",
    "    correct_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c547f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56056, 19406, 0.3461895247609533)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_total_len = 0\n",
    "compressed_total_len = 0\n",
    "for item in evaluation_dataset:\n",
    "    original_total_len += item[\"original_total_len\"]\n",
    "    compressed_total_len += item[\"compressed_total_len\"]\n",
    "original_total_len, compressed_total_len, compressed_total_len / original_total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0401256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (56056, 21924, 0.39110889110889113) - 0.8333333333333334, 200 токенов, 4 сжимающих\n",
    "# (56056, 29497, 0.5262059369202227) - 0.9666666666666667, 400 токенов, 16 сжимающих\n",
    "# (56056, 27994, 0.499393463679178) - 0.9, 400 токенов, 8 сжимающих\n",
    "# (56056, 23062, 0.4114100185528757) - 0.9, 200 токенов, 16 сжимающих\n",
    "# (56056, 30087, 0.5367311260168403) - 0.8666666666666667, 400, 32\n",
    "# (56056, 19406, 0.3461895247609533) - 0.7333333333333333, 100, 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
