{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953c0eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2ForCausalLM, Qwen2Model, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model = Qwen2ForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce46a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.embed_tokens.padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06318e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, so I need to write a short introduction for a large language model. Let me think about how to approach this. First, I should understand what a large language model is. From what I know, it's a type of AI that can understand and generate human language, including speech and text. It's often referred to as LLM, which stands for Large Language Model.\\n\\nI should start by introducing the concept of LLMs. Maybe mention that they're designed to handle a wide range of tasks like text generation, translation, summarization, etc. I should also highlight their versatility and the various applications they have in different fields.\\n\\nNext, I should think about the key features of LLMs. They're known for being able to understand vast amounts of data, process it quickly, and produce outputs that are both accurate and contextually relevant. It's important to note their ability to adapt to new information and learn from various datasets, which makes them highly efficient.\\n\\nI should also touch upon the benefits of using LLMs. They can help in solving complex problems, improving efficiency in industries like healthcare and finance, and they can also assist in creating content, such as writing articles or composing music. Additionally, they can aid in education, enabling the creation of personalized learning experiences.\\n\\nIt's also worth mentioning the importance of LLMs in today's world. As technology advances, LLMs are playing a crucial role in various sectors, making them indispensable tools for professionals and students alike.\\n\\nI should structure this introduction in a way that flows logically, starting from the basics of LLMs, moving on to their capabilities, and then discussing their impact and applications. I should keep it concise, making sure it's informative yet easy to understand.\\n\\nWait, should I include some examples of tasks LLMs can perform? That might make the introduction more concrete. For instance, mentioning specific tasks like summarization, translation, or creative writing could add depth.\\n\\nAlso, I should ensure that the introduction is engaging and not too technical. It should be accessible to a broad audience, whether they're students, professionals, or anyone interested in AI.\\n\\nLet me try to outline the points I want to cover:\\n\\n1. Introduction to LLMs and their purpose.\\n2. Key capabilities and features.\\n3. Applications across different industries.\\n4. Impact and significance in modern technology.\\n5. Conclusion summarizing the importance of LLMs.\\n\\nI should avoid jargon as much as possible to make it accessible. Maybe use simple terms and avoid complex sentences.\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"Give me a short introduction to large language model..1\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids) :]\n",
    "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87598600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 23, 1536]), torch.bfloat16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_1 = model(\n",
    "    **model_inputs,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "model_output_1.hidden_states[-1].shape, model_output_1.hidden_states[-1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a732ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Qwen2ModelEmbedPooler(Qwen2ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.model = Qwen2Model(config)\n",
    "        self.lm_head = None\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(self, input_embeds):\n",
    "        # print(input_embeds.dtype)\n",
    "        input_embeds = self.model(\n",
    "            inputs_embeds=input_embeds,\n",
    "            output_hidden_states=True,\n",
    "        )[0]\n",
    "        # print(input_embeds.dtype)\n",
    "        input_embeds = input_embeds.sum(1) / torch.tensor(\n",
    "            input_embeds.shape[1],\n",
    "            device=input_embeds.device,\n",
    "            dtype=input_embeds.dtype,\n",
    "        )\n",
    "        # print(input_embeds.dtype)\n",
    "        input_embeds = input_embeds.unsqueeze(1)\n",
    "        return input_embeds\n",
    "\n",
    "\n",
    "embed_pooler = Qwen2ModelEmbedPooler.from_pretrained(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", device_map={\"\": 0}\n",
    ")\n",
    "result = embed_pooler(\n",
    "    # model_output_1.hidden_states[-1],\n",
    "    torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    ")\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, RobertaModel\n",
    "import torch\n",
    "\n",
    "model = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7997f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "from transformers import AutoTokenizer, RobertaModel\n",
    "\n",
    "model_pooler = RobertaModel(\n",
    "    RobertaConfig(\n",
    "        # num_hidden_layers=6,\n",
    "        hidden_size=1536,\n",
    "    )\n",
    ")\n",
    "model_pooler = model_pooler.to(\"cuda\")\n",
    "# RobertaConfig(\n",
    "#     num_hidden_layers=6,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4032b2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307055616"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "count_parameters(model_pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b530fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 1.1631e-02, -3.3355e-01, -7.0888e-01,  ...,  2.5737e-01,\n",
       "           8.5082e-01,  9.7829e-01],\n",
       "         [-6.3120e-02, -9.6038e-01, -1.0395e+00,  ..., -4.8655e-01,\n",
       "           1.5065e+00,  8.5730e-01],\n",
       "         [ 4.6764e-01, -9.1962e-01, -1.0514e+00,  ..., -4.7420e-01,\n",
       "           7.1864e-01,  1.8883e-01],\n",
       "         ...,\n",
       "         [ 8.8619e-01, -9.7937e-01, -1.0135e+00,  ...,  5.4751e-02,\n",
       "           1.3971e+00,  9.3596e-01],\n",
       "         [ 1.6049e-01, -2.5659e-01, -7.5956e-01,  ...,  2.0967e-01,\n",
       "           6.3753e-01,  2.2053e-02],\n",
       "         [ 3.7732e-01, -2.3537e-01, -1.0351e+00,  ...,  1.9910e-01,\n",
       "           7.2457e-01,  7.0338e-01]],\n",
       "\n",
       "        [[-1.8583e-04, -1.2355e+00, -2.2558e-01,  ..., -5.9677e-01,\n",
       "           9.2336e-01,  9.3026e-01],\n",
       "         [ 6.2141e-01, -3.5414e-01, -1.4218e+00,  ..., -4.0025e-01,\n",
       "           9.8164e-01,  1.2630e+00],\n",
       "         [ 5.4169e-01, -1.1041e+00, -1.1333e+00,  ..., -1.4839e+00,\n",
       "           2.2981e-01,  7.2022e-01],\n",
       "         ...,\n",
       "         [ 3.6573e-03, -9.3938e-01, -8.5070e-01,  ..., -3.4680e-01,\n",
       "           1.2030e+00,  1.2431e+00],\n",
       "         [ 5.8500e-01, -4.7803e-01, -1.0366e+00,  ..., -8.1228e-01,\n",
       "           9.0670e-01,  1.2243e+00],\n",
       "         [ 7.5498e-01, -2.7175e-01, -1.4377e+00,  ..., -5.1928e-01,\n",
       "           6.9092e-01,  8.9202e-01]]], device='cuda:0'), pooler_output=tensor([[ 0.6305,  0.5469, -0.6942,  ...,  0.4650, -0.4692,  0.8893],\n",
       "        [ 0.7793,  0.7542, -0.3517,  ...,  0.8003, -0.3370,  0.7685]],\n",
       "       device='cuda:0'), hidden_states=(tensor([[[ 0.9366, -1.2204,  0.9085,  ...,  0.0000,  1.1775,  0.4996],\n",
       "         [ 0.9582, -1.2126,  0.9181,  ...,  0.1145,  1.1544,  0.5014],\n",
       "         [-0.0000, -0.1896,  0.4878,  ..., -0.5575,  0.7686, -0.0639],\n",
       "         ...,\n",
       "         [ 1.6661, -1.3613,  0.0211,  ..., -0.1599, -0.2303,  0.0000],\n",
       "         [ 0.0000, -2.1271,  1.1583,  ...,  0.3923,  0.8978, -1.0458],\n",
       "         [-0.1438, -0.2140, -0.2183,  ..., -0.0000, -0.5798,  0.6856]],\n",
       "\n",
       "        [[ 0.9366, -1.2204,  0.9085,  ...,  0.1108,  1.1775,  0.4996],\n",
       "         [ 0.9582, -1.2126,  0.9181,  ...,  0.1145,  1.1544,  0.0000],\n",
       "         [-0.2492, -0.1896,  0.0000,  ..., -0.5575,  0.7686, -0.0639],\n",
       "         ...,\n",
       "         [ 1.6661, -1.3613,  0.0211,  ..., -0.0000, -0.0000,  0.3210],\n",
       "         [ 0.6241, -2.1271,  1.1583,  ...,  0.3923,  0.8978, -1.0458],\n",
       "         [-0.1438, -0.2140, -0.2183,  ..., -0.0221, -0.5798,  0.6856]]],\n",
       "       device='cuda:0'), tensor([[[ 0.6355, -1.4414,  0.2100,  ..., -0.3964,  0.6182,  0.6441],\n",
       "         [-0.5827, -1.1341, -0.2684,  ...,  0.0505,  0.6950,  0.6207],\n",
       "         [ 0.3164,  0.0880,  0.7139,  ..., -0.9557,  0.4135, -0.2484],\n",
       "         ...,\n",
       "         [ 1.0419, -1.1349, -0.7909,  ...,  0.4028, -0.3573,  0.0613],\n",
       "         [-0.3912, -1.6556,  0.1761,  ...,  0.4875,  0.3719, -0.6438],\n",
       "         [ 0.0875, -0.7384, -0.2110,  ...,  0.3043, -0.3923,  0.3235]],\n",
       "\n",
       "        [[-0.5606, -1.5243,  0.2846,  ..., -0.3884,  0.1939,  0.6183],\n",
       "         [-0.0885, -1.4161, -0.0468,  ..., -0.2443,  0.4544,  0.0510],\n",
       "         [-0.3933,  0.4283,  0.0057,  ..., -0.4878,  0.7863, -0.0868],\n",
       "         ...,\n",
       "         [ 1.0070, -1.2963, -0.3973,  ...,  0.1272, -0.4351,  0.5545],\n",
       "         [-0.4306, -1.8210,  0.0916,  ...,  0.3152,  0.5515, -0.6629],\n",
       "         [-0.0261, -0.3558, -0.2237,  ..., -0.0208, -0.7537,  0.4994]]],\n",
       "       device='cuda:0'), tensor([[[ 6.0380e-01, -5.8698e-01,  4.7785e-01,  ..., -6.1595e-04,\n",
       "           3.2814e-01,  8.5480e-01],\n",
       "         [ 5.6976e-01, -9.9214e-02, -3.5440e-01,  ...,  2.0771e-01,\n",
       "           7.1430e-01,  9.7035e-01],\n",
       "         [ 8.0710e-01, -7.4375e-02,  4.0159e-01,  ..., -7.7029e-01,\n",
       "           1.6190e-01, -2.4933e-01],\n",
       "         ...,\n",
       "         [ 1.2147e+00, -5.7551e-01,  2.8095e-02,  ...,  1.7486e-01,\n",
       "           1.1301e-02,  4.7875e-01],\n",
       "         [-4.5322e-01, -5.8301e-01,  5.6868e-01,  ...,  2.5640e-01,\n",
       "           7.7243e-01, -3.5881e-01],\n",
       "         [ 4.4379e-01, -1.5212e-01, -3.6002e-01,  ...,  9.4230e-02,\n",
       "          -1.3501e-01,  1.0422e-01]],\n",
       "\n",
       "        [[ 2.7121e-01, -6.2314e-01,  3.2887e-01,  ..., -5.2196e-02,\n",
       "           4.9373e-01,  5.2828e-01],\n",
       "         [ 7.1116e-01, -6.4778e-01,  1.0264e-01,  ..., -4.2900e-01,\n",
       "           5.3478e-01,  7.4068e-02],\n",
       "         [ 1.8977e-01,  1.9613e-01, -5.3696e-01,  ..., -3.3905e-01,\n",
       "           5.6762e-01, -1.4769e-01],\n",
       "         ...,\n",
       "         [ 1.3059e+00, -7.7921e-01, -2.6078e-02,  ..., -2.2496e-01,\n",
       "          -4.6448e-01,  1.1944e+00],\n",
       "         [-2.7936e-01, -1.0884e+00,  5.0227e-01,  ...,  4.3313e-01,\n",
       "           7.4462e-01, -5.6726e-01],\n",
       "         [ 6.1666e-01,  2.9868e-01, -2.5577e-01,  ...,  3.4339e-01,\n",
       "          -6.0634e-01,  3.0403e-01]]], device='cuda:0'), tensor([[[ 0.7554, -0.6273, -0.0113,  ..., -0.7550, -0.5404,  0.6816],\n",
       "         [ 0.6128, -0.3304, -0.7078,  ..., -0.4078, -0.2182,  0.7800],\n",
       "         [ 0.7033,  0.1263, -0.1400,  ..., -0.9916, -0.3420,  0.7579],\n",
       "         ...,\n",
       "         [ 0.9336, -0.0387, -0.2343,  ...,  0.0593, -0.9967,  0.6353],\n",
       "         [-0.5579, -0.2340, -0.0781,  ...,  0.1230, -0.3254,  0.3606],\n",
       "         [ 0.6368,  0.2698, -0.7066,  ...,  0.5859, -1.7560,  0.7830]],\n",
       "\n",
       "        [[ 0.6320, -1.0679, -0.2933,  ..., -0.9902, -0.7815,  0.8276],\n",
       "         [ 0.8404, -0.4610, -0.0701,  ..., -0.8798,  0.0838,  0.3868],\n",
       "         [-0.1246,  0.7570, -0.9750,  ...,  0.0253,  0.1189,  0.7384],\n",
       "         ...,\n",
       "         [ 0.5591, -0.0372, -0.1963,  ...,  0.1160, -0.9784,  1.4855],\n",
       "         [-0.6299, -1.1521, -0.1483,  ...,  0.3227, -0.1484, -0.1153],\n",
       "         [ 0.8308,  0.5236, -0.3575,  ...,  0.9514, -1.5089,  0.5650]]],\n",
       "       device='cuda:0'), tensor([[[ 0.7812,  0.4442, -0.1639,  ..., -0.5891,  0.5358,  2.0949],\n",
       "         [ 0.8178,  0.8773, -1.0116,  ..., -0.0682,  1.4522,  2.1387],\n",
       "         [ 0.5653, -0.1093, -0.2497,  ..., -0.8904,  0.5362,  0.9301],\n",
       "         ...,\n",
       "         [ 1.0234, -0.3134, -0.0497,  ...,  0.0456,  0.1018,  1.0229],\n",
       "         [-0.4418,  0.6745, -0.0440,  ..., -0.5516,  0.0937,  0.8755],\n",
       "         [ 0.6141,  0.7261, -0.6563,  ..., -0.0598, -0.5291, -0.0066]],\n",
       "\n",
       "        [[ 0.7192,  0.1870, -0.7096,  ..., -0.7153,  1.0621,  2.5105],\n",
       "         [ 0.3922,  0.8617, -0.0534,  ..., -0.4971,  1.1798,  2.0805],\n",
       "         [ 0.1306,  0.9855, -0.6447,  ..., -0.1780,  0.9829,  0.5993],\n",
       "         ...,\n",
       "         [ 0.2117, -0.3838, -0.3497,  ...,  0.0483,  0.0194,  1.6663],\n",
       "         [ 0.1174,  0.2588, -0.0759,  ..., -0.1773,  0.7183,  0.3503],\n",
       "         [ 1.2550,  0.9382,  0.2098,  ..., -0.0605, -0.0544,  0.5092]]],\n",
       "       device='cuda:0'), tensor([[[ 1.1581,  0.1229, -1.2188,  ..., -1.2629,  0.9716,  1.6096],\n",
       "         [ 0.9099,  0.1594, -0.8043,  ..., -1.0153,  2.3755,  1.3399],\n",
       "         [ 1.2862, -0.4712, -0.2942,  ..., -1.7770,  0.8243,  1.1878],\n",
       "         ...,\n",
       "         [ 1.5036, -1.2572, -0.0631,  ..., -0.2814,  0.6719,  1.7066],\n",
       "         [ 0.1642,  0.1769, -0.0171,  ..., -0.4578,  0.6793,  0.7249],\n",
       "         [ 1.0359,  0.0839, -1.3716,  ..., -0.2430,  0.0908,  0.2677]],\n",
       "\n",
       "        [[ 0.6411,  0.0630, -1.5550,  ..., -0.6137,  1.4715,  1.7897],\n",
       "         [ 0.3691,  0.5358, -0.7887,  ..., -0.7161,  1.4637,  1.8435],\n",
       "         [ 0.3471,  0.6241, -1.0862,  ..., -0.3690,  0.9118,  1.0303],\n",
       "         ...,\n",
       "         [ 0.4172, -1.1968, -0.7719,  ..., -0.6853,  0.5022,  2.1138],\n",
       "         [-0.0386,  0.3036, -0.5881,  ..., -1.1010,  1.1122,  0.5499],\n",
       "         [ 0.9328,  0.6983, -0.4157,  ..., -0.2366,  0.3910,  1.0650]]],\n",
       "       device='cuda:0'), tensor([[[ 6.5538e-01,  1.3213e-01, -7.5171e-01,  ..., -7.2015e-01,\n",
       "           1.1093e+00,  1.5867e+00],\n",
       "         [ 1.6272e-01, -1.8375e-02, -3.6412e-01,  ..., -8.0925e-01,\n",
       "           2.2276e+00,  1.8437e+00],\n",
       "         [ 5.2021e-01, -6.4345e-04, -2.5644e-01,  ..., -1.5868e+00,\n",
       "           1.1034e+00,  2.0746e+00],\n",
       "         ...,\n",
       "         [ 6.3068e-01, -8.5641e-01, -8.5159e-02,  ..., -3.5641e-01,\n",
       "           9.5152e-01,  2.2702e+00],\n",
       "         [-3.0076e-01,  7.3587e-01,  1.3206e-01,  ..., -2.2862e-01,\n",
       "           8.4082e-01,  1.6448e+00],\n",
       "         [ 1.9518e-01,  3.6494e-01, -1.4121e+00,  ...,  2.5019e-01,\n",
       "          -7.6345e-02,  1.2000e+00]],\n",
       "\n",
       "        [[ 3.4142e-01, -4.2930e-01, -1.1243e+00,  ..., -5.5256e-01,\n",
       "           1.3987e+00,  2.0840e+00],\n",
       "         [ 4.7566e-02,  1.6043e-01, -4.9416e-01,  ..., -2.2701e-01,\n",
       "           1.0132e+00,  2.0476e+00],\n",
       "         [-6.3162e-01,  8.7433e-01, -2.7998e-01,  ..., -5.6997e-01,\n",
       "           8.5690e-01,  8.1493e-01],\n",
       "         ...,\n",
       "         [-4.0340e-01, -7.8822e-01, -3.6176e-01,  ..., -8.1528e-01,\n",
       "           5.0138e-01,  2.4956e+00],\n",
       "         [-1.7884e-01,  9.4314e-01, -3.1040e-01,  ..., -1.0695e+00,\n",
       "           1.0836e+00,  1.4870e+00],\n",
       "         [ 2.9244e-01,  5.9952e-01, -5.1702e-01,  ...,  3.5745e-01,\n",
       "          -4.5719e-01,  2.3530e+00]]], device='cuda:0'), tensor([[[ 0.5971,  0.1209, -1.2369,  ..., -0.5563, -0.3573,  1.2755],\n",
       "         [-0.4340, -0.1707, -0.9042,  ..., -0.9426,  0.8533,  0.4103],\n",
       "         [-0.1169, -0.2803, -0.7099,  ..., -1.6285,  0.0679,  0.1316],\n",
       "         ...,\n",
       "         [ 0.4733, -0.7754, -0.4627,  ..., -0.0909, -0.1252,  0.3609],\n",
       "         [-0.5465,  0.2869, -0.3633,  ..., -0.4261, -0.1400,  1.1074],\n",
       "         [ 0.0317, -0.1488, -0.9469,  ..., -0.0591, -0.5003, -0.0444]],\n",
       "\n",
       "        [[ 0.5363, -0.7330, -1.0832,  ..., -1.1264,  0.2800,  0.7487],\n",
       "         [ 0.0612,  0.0819, -0.2332,  ..., -0.4031,  0.5364,  0.8692],\n",
       "         [-0.9056,  0.4489, -0.3916,  ..., -1.6096,  0.5042,  0.0094],\n",
       "         ...,\n",
       "         [-0.5327, -0.9360, -0.4205,  ..., -0.9666, -0.4550,  0.8009],\n",
       "         [-0.2030,  0.9625, -0.4123,  ..., -1.2788, -0.4081,  0.4207],\n",
       "         [-0.0579,  0.2666, -0.6390,  ...,  0.0902, -0.8510,  0.8088]]],\n",
       "       device='cuda:0'), tensor([[[ 1.9693, -0.3817, -0.3357,  ..., -0.4086, -0.2360,  0.6272],\n",
       "         [ 1.1282, -0.3945, -0.3542,  ..., -1.8101,  0.6461, -0.3946],\n",
       "         [ 1.7636, -0.4950,  0.1493,  ..., -2.4069,  0.0381, -0.3415],\n",
       "         ...,\n",
       "         [ 2.1402, -1.4886, -0.1631,  ..., -1.0160, -0.1278, -0.0081],\n",
       "         [ 0.2088,  0.1639,  0.1788,  ..., -0.3165,  0.1730,  0.1131],\n",
       "         [ 1.5792, -0.9035, -0.0796,  ..., -1.0098, -0.3444, -0.6240]],\n",
       "\n",
       "        [[ 1.2847, -0.7100, -0.1833,  ..., -1.5448,  0.0841, -0.0335],\n",
       "         [ 1.1880, -0.3599, -0.2339,  ..., -1.3160,  0.3504,  0.1506],\n",
       "         [ 1.2412, -0.3527,  0.2818,  ..., -2.8636, -0.4052, -0.2150],\n",
       "         ...,\n",
       "         [ 0.2781, -1.3547, -0.5916,  ..., -0.6888, -0.6243,  0.5639],\n",
       "         [ 1.0823,  0.2845,  0.1065,  ..., -2.3365, -0.2615,  0.1989],\n",
       "         [ 0.6586,  0.1405, -0.1351,  ..., -1.1869, -0.7938,  0.5905]]],\n",
       "       device='cuda:0'), tensor([[[ 1.0595, -1.5559, -0.9420,  ...,  0.2784, -0.0594, -0.5596],\n",
       "         [ 0.9449, -1.6791, -0.4065,  ..., -1.4393,  0.4895, -0.8608],\n",
       "         [ 1.0040, -2.0125, -0.3042,  ..., -1.9162, -0.1745, -0.6036],\n",
       "         ...,\n",
       "         [ 1.2751, -1.3706, -0.3656,  ..., -0.7803,  0.3849, -0.1424],\n",
       "         [ 0.1146, -0.7189, -0.0950,  ..., -0.2815,  0.3511,  0.2322],\n",
       "         [ 0.4686, -1.0258, -0.6779,  ..., -0.5994,  0.1645, -0.5894]],\n",
       "\n",
       "        [[ 0.6040, -1.5450, -0.5551,  ..., -1.2145,  0.2123,  0.0045],\n",
       "         [ 0.7839, -1.3513, -0.6093,  ..., -0.5951,  0.7686,  0.1835],\n",
       "         [ 0.9091, -1.6449, -0.0401,  ..., -2.0447, -0.3889, -0.5835],\n",
       "         ...,\n",
       "         [-0.1009, -2.1249, -0.2818,  ..., -0.6228, -0.2553,  0.1402],\n",
       "         [ 0.8086, -0.7797,  0.2988,  ..., -1.7659,  0.0857,  0.0819],\n",
       "         [-0.5720, -0.2217, -0.7224,  ..., -0.5788, -0.0863,  0.4354]]],\n",
       "       device='cuda:0'), tensor([[[ 0.9642, -0.2371, -1.0337,  ...,  0.4019,  0.4739, -0.0993],\n",
       "         [ 0.3850, -1.2158, -0.2794,  ..., -0.9697,  1.1355, -0.3074],\n",
       "         [ 0.6413, -1.4583, -0.7557,  ..., -1.4640,  0.8736, -0.9334],\n",
       "         ...,\n",
       "         [ 1.1387, -0.3982, -0.2881,  ..., -0.6138,  1.1816, -0.0457],\n",
       "         [ 0.0855, -0.0828, -0.6075,  ..., -0.1827,  0.3955, -0.1002],\n",
       "         [ 0.0834,  0.0119, -1.0306,  ..., -0.3207,  0.6428, -0.1313]],\n",
       "\n",
       "        [[ 0.6607, -0.1776, -0.5190,  ..., -0.8662,  0.9738,  0.2127],\n",
       "         [ 1.2392,  0.1355, -1.0638,  ..., -0.7357,  1.0748,  0.3770],\n",
       "         [ 0.8762, -0.9986, -0.3037,  ..., -1.8164,  0.7210, -0.0313],\n",
       "         ...,\n",
       "         [ 0.0886, -0.5113, -0.5975,  ..., -0.6095,  0.7011,  0.2416],\n",
       "         [ 0.5756,  0.0667, -0.0403,  ..., -1.6335,  0.6876,  0.1741],\n",
       "         [ 0.0510,  1.0141, -0.5764,  ..., -0.5730,  0.7283,  0.4779]]],\n",
       "       device='cuda:0'), tensor([[[ 0.1660,  0.0556,  0.0572,  ..., -0.3225,  1.6600,  0.4724],\n",
       "         [-0.3911, -1.0855, -0.1688,  ..., -1.0104,  2.2231,  0.0787],\n",
       "         [ 0.1043, -1.2970, -0.5805,  ..., -1.6188,  1.5505, -0.7457],\n",
       "         ...,\n",
       "         [ 0.4263, -0.8851, -0.6512,  ..., -0.4228,  1.6534,  0.4316],\n",
       "         [-0.4876, -0.3377, -0.4187,  ..., -0.2702,  1.3924,  0.0637],\n",
       "         [-0.3057, -0.3644, -0.5816,  ..., -0.7522,  1.5057,  0.1277]],\n",
       "\n",
       "        [[-0.1399, -0.9608,  0.0858,  ..., -1.0781,  1.8373,  0.5469],\n",
       "         [ 0.7221, -0.0817, -1.5001,  ..., -0.9480,  2.1232,  0.7171],\n",
       "         [-0.0082, -1.2854, -0.7254,  ..., -1.8446,  1.4132,  0.4820],\n",
       "         ...,\n",
       "         [-0.5904, -0.8984, -0.4428,  ..., -0.8270,  1.9946,  0.6858],\n",
       "         [ 0.1522, -0.1517, -0.4584,  ..., -1.6136,  1.7536,  0.3964],\n",
       "         [ 0.3638,  0.4747, -0.7611,  ..., -0.8990,  1.2611,  0.6251]]],\n",
       "       device='cuda:0'), tensor([[[ 1.1631e-02, -3.3355e-01, -7.0888e-01,  ...,  2.5737e-01,\n",
       "           8.5082e-01,  9.7829e-01],\n",
       "         [-6.3120e-02, -9.6038e-01, -1.0395e+00,  ..., -4.8655e-01,\n",
       "           1.5065e+00,  8.5730e-01],\n",
       "         [ 4.6764e-01, -9.1962e-01, -1.0514e+00,  ..., -4.7420e-01,\n",
       "           7.1864e-01,  1.8883e-01],\n",
       "         ...,\n",
       "         [ 8.8619e-01, -9.7937e-01, -1.0135e+00,  ...,  5.4751e-02,\n",
       "           1.3971e+00,  9.3596e-01],\n",
       "         [ 1.6049e-01, -2.5659e-01, -7.5956e-01,  ...,  2.0967e-01,\n",
       "           6.3753e-01,  2.2053e-02],\n",
       "         [ 3.7732e-01, -2.3537e-01, -1.0351e+00,  ...,  1.9910e-01,\n",
       "           7.2457e-01,  7.0338e-01]],\n",
       "\n",
       "        [[-1.8583e-04, -1.2355e+00, -2.2558e-01,  ..., -5.9677e-01,\n",
       "           9.2336e-01,  9.3026e-01],\n",
       "         [ 6.2141e-01, -3.5414e-01, -1.4218e+00,  ..., -4.0025e-01,\n",
       "           9.8164e-01,  1.2630e+00],\n",
       "         [ 5.4169e-01, -1.1041e+00, -1.1333e+00,  ..., -1.4839e+00,\n",
       "           2.2981e-01,  7.2022e-01],\n",
       "         ...,\n",
       "         [ 3.6573e-03, -9.3938e-01, -8.5070e-01,  ..., -3.4680e-01,\n",
       "           1.2030e+00,  1.2431e+00],\n",
       "         [ 5.8500e-01, -4.7803e-01, -1.0366e+00,  ..., -8.1228e-01,\n",
       "           9.0670e-01,  1.2243e+00],\n",
       "         [ 7.5498e-01, -2.7175e-01, -1.4377e+00,  ..., -5.1928e-01,\n",
       "           6.9092e-01,  8.9202e-01]]], device='cuda:0')), past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model_pooler(\n",
    "    # model_output_1.hidden_states[-1],\n",
    "    inputs_embeds=torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d100646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds = result.last_hidden_state  # .shape\n",
    "\n",
    "input_embeds = input_embeds.sum(1) / torch.tensor(\n",
    "    input_embeds.shape[1],\n",
    "    device=input_embeds.device,\n",
    "    dtype=input_embeds.dtype,\n",
    ")\n",
    "# print(input_embeds.dtype)\n",
    "input_embeds = input_embeds.unsqueeze(1)\n",
    "input_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "774ecef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from hidden_capacity_reasoning.models import RobertaModelEmbedPoolerV1\n",
    "from transformers import RobertaConfig\n",
    "\n",
    "roberta_model = RobertaModelEmbedPoolerV1(\n",
    "    RobertaConfig(\n",
    "        # num_hidden_layers=6,\n",
    "        hidden_size=1536,\n",
    "    )\n",
    ")\n",
    "roberta_model = roberta_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda1e360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5889,  0.4153,  1.6604,  ...,  0.9439, -0.3286,  0.7096]],\n",
       "\n",
       "        [[-1.0837,  0.8477,  1.2010,  ...,  1.1526,  0.4869,  1.1255]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = roberta_model(\n",
    "    # model_output_1.hidden_states[-1],\n",
    "    input_embeds=torch.cat(\n",
    "        [\n",
    "            model_output_1.hidden_states[-1],\n",
    "            model_output_1.hidden_states[-1],\n",
    "        ],\n",
    "        dim=0,\n",
    "    ),\n",
    "    # output_hidden_states=True,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5357d70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1536])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb86e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50265, 1536, padding_idx=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.qwen2.modeling_qwen2 import Qwen2RotaryEmbedding, Qwen2Config\n",
    "from torch import nn\n",
    "\n",
    "config = Qwen2Config.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "# config.pad_token_id = tokenizer.pad_token_id\n",
    "emb = nn.Embedding(config.vocab_size, config.hidden_size, config.pad_token_id).cuda()\n",
    "\n",
    "new_embeds = emb(model_inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3485ff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151643"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a3688e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151643"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15d937d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 4096])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a5d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 22016,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"max_window_layers\": 28,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 4096,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.49.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151936\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Qwen2Config, RobertaConfig, PretrainedConfig\n",
    "\n",
    "\n",
    "# PretrainedConfig(new_config)\n",
    "class EmdeddingCompressorConfig(PretrainedConfig):\n",
    "    roberta: RobertaConfig = RobertaConfig(\n",
    "        hidden_size=1568,\n",
    "    )\n",
    "    qwen: Qwen2Config = Qwen2Config()\n",
    "\n",
    "\n",
    "config = EmdeddingCompressorConfig()\n",
    "config.roberta\n",
    "config.qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90e6a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained(\"EmdeddingCompressorConfig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35a69625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1568,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.49.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EmdeddingCompressorConfig.from_pretrained(\"EmdeddingCompressorConfig\").roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fd2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForCausalLMCompressionV3 were not initialized from the model checkpoint at deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B and are newly initialized: ['embed_pooler.embeddings.LayerNorm.bias', 'embed_pooler.embeddings.LayerNorm.weight', 'embed_pooler.embeddings.position_embeddings.weight', 'embed_pooler.embeddings.token_type_embeddings.weight', 'embed_pooler.embeddings.word_embeddings.weight', 'embed_pooler.encoder.layer.0.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.0.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.0.attention.output.dense.bias', 'embed_pooler.encoder.layer.0.attention.output.dense.weight', 'embed_pooler.encoder.layer.0.attention.self.key.bias', 'embed_pooler.encoder.layer.0.attention.self.key.weight', 'embed_pooler.encoder.layer.0.attention.self.query.bias', 'embed_pooler.encoder.layer.0.attention.self.query.weight', 'embed_pooler.encoder.layer.0.attention.self.value.bias', 'embed_pooler.encoder.layer.0.attention.self.value.weight', 'embed_pooler.encoder.layer.0.intermediate.dense.bias', 'embed_pooler.encoder.layer.0.intermediate.dense.weight', 'embed_pooler.encoder.layer.0.output.LayerNorm.bias', 'embed_pooler.encoder.layer.0.output.LayerNorm.weight', 'embed_pooler.encoder.layer.0.output.dense.bias', 'embed_pooler.encoder.layer.0.output.dense.weight', 'embed_pooler.encoder.layer.1.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.1.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.1.attention.output.dense.bias', 'embed_pooler.encoder.layer.1.attention.output.dense.weight', 'embed_pooler.encoder.layer.1.attention.self.key.bias', 'embed_pooler.encoder.layer.1.attention.self.key.weight', 'embed_pooler.encoder.layer.1.attention.self.query.bias', 'embed_pooler.encoder.layer.1.attention.self.query.weight', 'embed_pooler.encoder.layer.1.attention.self.value.bias', 'embed_pooler.encoder.layer.1.attention.self.value.weight', 'embed_pooler.encoder.layer.1.intermediate.dense.bias', 'embed_pooler.encoder.layer.1.intermediate.dense.weight', 'embed_pooler.encoder.layer.1.output.LayerNorm.bias', 'embed_pooler.encoder.layer.1.output.LayerNorm.weight', 'embed_pooler.encoder.layer.1.output.dense.bias', 'embed_pooler.encoder.layer.1.output.dense.weight', 'embed_pooler.encoder.layer.10.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.10.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.10.attention.output.dense.bias', 'embed_pooler.encoder.layer.10.attention.output.dense.weight', 'embed_pooler.encoder.layer.10.attention.self.key.bias', 'embed_pooler.encoder.layer.10.attention.self.key.weight', 'embed_pooler.encoder.layer.10.attention.self.query.bias', 'embed_pooler.encoder.layer.10.attention.self.query.weight', 'embed_pooler.encoder.layer.10.attention.self.value.bias', 'embed_pooler.encoder.layer.10.attention.self.value.weight', 'embed_pooler.encoder.layer.10.intermediate.dense.bias', 'embed_pooler.encoder.layer.10.intermediate.dense.weight', 'embed_pooler.encoder.layer.10.output.LayerNorm.bias', 'embed_pooler.encoder.layer.10.output.LayerNorm.weight', 'embed_pooler.encoder.layer.10.output.dense.bias', 'embed_pooler.encoder.layer.10.output.dense.weight', 'embed_pooler.encoder.layer.11.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.11.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.11.attention.output.dense.bias', 'embed_pooler.encoder.layer.11.attention.output.dense.weight', 'embed_pooler.encoder.layer.11.attention.self.key.bias', 'embed_pooler.encoder.layer.11.attention.self.key.weight', 'embed_pooler.encoder.layer.11.attention.self.query.bias', 'embed_pooler.encoder.layer.11.attention.self.query.weight', 'embed_pooler.encoder.layer.11.attention.self.value.bias', 'embed_pooler.encoder.layer.11.attention.self.value.weight', 'embed_pooler.encoder.layer.11.intermediate.dense.bias', 'embed_pooler.encoder.layer.11.intermediate.dense.weight', 'embed_pooler.encoder.layer.11.output.LayerNorm.bias', 'embed_pooler.encoder.layer.11.output.LayerNorm.weight', 'embed_pooler.encoder.layer.11.output.dense.bias', 'embed_pooler.encoder.layer.11.output.dense.weight', 'embed_pooler.encoder.layer.2.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.2.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.2.attention.output.dense.bias', 'embed_pooler.encoder.layer.2.attention.output.dense.weight', 'embed_pooler.encoder.layer.2.attention.self.key.bias', 'embed_pooler.encoder.layer.2.attention.self.key.weight', 'embed_pooler.encoder.layer.2.attention.self.query.bias', 'embed_pooler.encoder.layer.2.attention.self.query.weight', 'embed_pooler.encoder.layer.2.attention.self.value.bias', 'embed_pooler.encoder.layer.2.attention.self.value.weight', 'embed_pooler.encoder.layer.2.intermediate.dense.bias', 'embed_pooler.encoder.layer.2.intermediate.dense.weight', 'embed_pooler.encoder.layer.2.output.LayerNorm.bias', 'embed_pooler.encoder.layer.2.output.LayerNorm.weight', 'embed_pooler.encoder.layer.2.output.dense.bias', 'embed_pooler.encoder.layer.2.output.dense.weight', 'embed_pooler.encoder.layer.3.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.3.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.3.attention.output.dense.bias', 'embed_pooler.encoder.layer.3.attention.output.dense.weight', 'embed_pooler.encoder.layer.3.attention.self.key.bias', 'embed_pooler.encoder.layer.3.attention.self.key.weight', 'embed_pooler.encoder.layer.3.attention.self.query.bias', 'embed_pooler.encoder.layer.3.attention.self.query.weight', 'embed_pooler.encoder.layer.3.attention.self.value.bias', 'embed_pooler.encoder.layer.3.attention.self.value.weight', 'embed_pooler.encoder.layer.3.intermediate.dense.bias', 'embed_pooler.encoder.layer.3.intermediate.dense.weight', 'embed_pooler.encoder.layer.3.output.LayerNorm.bias', 'embed_pooler.encoder.layer.3.output.LayerNorm.weight', 'embed_pooler.encoder.layer.3.output.dense.bias', 'embed_pooler.encoder.layer.3.output.dense.weight', 'embed_pooler.encoder.layer.4.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.4.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.4.attention.output.dense.bias', 'embed_pooler.encoder.layer.4.attention.output.dense.weight', 'embed_pooler.encoder.layer.4.attention.self.key.bias', 'embed_pooler.encoder.layer.4.attention.self.key.weight', 'embed_pooler.encoder.layer.4.attention.self.query.bias', 'embed_pooler.encoder.layer.4.attention.self.query.weight', 'embed_pooler.encoder.layer.4.attention.self.value.bias', 'embed_pooler.encoder.layer.4.attention.self.value.weight', 'embed_pooler.encoder.layer.4.intermediate.dense.bias', 'embed_pooler.encoder.layer.4.intermediate.dense.weight', 'embed_pooler.encoder.layer.4.output.LayerNorm.bias', 'embed_pooler.encoder.layer.4.output.LayerNorm.weight', 'embed_pooler.encoder.layer.4.output.dense.bias', 'embed_pooler.encoder.layer.4.output.dense.weight', 'embed_pooler.encoder.layer.5.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.5.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.5.attention.output.dense.bias', 'embed_pooler.encoder.layer.5.attention.output.dense.weight', 'embed_pooler.encoder.layer.5.attention.self.key.bias', 'embed_pooler.encoder.layer.5.attention.self.key.weight', 'embed_pooler.encoder.layer.5.attention.self.query.bias', 'embed_pooler.encoder.layer.5.attention.self.query.weight', 'embed_pooler.encoder.layer.5.attention.self.value.bias', 'embed_pooler.encoder.layer.5.attention.self.value.weight', 'embed_pooler.encoder.layer.5.intermediate.dense.bias', 'embed_pooler.encoder.layer.5.intermediate.dense.weight', 'embed_pooler.encoder.layer.5.output.LayerNorm.bias', 'embed_pooler.encoder.layer.5.output.LayerNorm.weight', 'embed_pooler.encoder.layer.5.output.dense.bias', 'embed_pooler.encoder.layer.5.output.dense.weight', 'embed_pooler.encoder.layer.6.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.6.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.6.attention.output.dense.bias', 'embed_pooler.encoder.layer.6.attention.output.dense.weight', 'embed_pooler.encoder.layer.6.attention.self.key.bias', 'embed_pooler.encoder.layer.6.attention.self.key.weight', 'embed_pooler.encoder.layer.6.attention.self.query.bias', 'embed_pooler.encoder.layer.6.attention.self.query.weight', 'embed_pooler.encoder.layer.6.attention.self.value.bias', 'embed_pooler.encoder.layer.6.attention.self.value.weight', 'embed_pooler.encoder.layer.6.intermediate.dense.bias', 'embed_pooler.encoder.layer.6.intermediate.dense.weight', 'embed_pooler.encoder.layer.6.output.LayerNorm.bias', 'embed_pooler.encoder.layer.6.output.LayerNorm.weight', 'embed_pooler.encoder.layer.6.output.dense.bias', 'embed_pooler.encoder.layer.6.output.dense.weight', 'embed_pooler.encoder.layer.7.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.7.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.7.attention.output.dense.bias', 'embed_pooler.encoder.layer.7.attention.output.dense.weight', 'embed_pooler.encoder.layer.7.attention.self.key.bias', 'embed_pooler.encoder.layer.7.attention.self.key.weight', 'embed_pooler.encoder.layer.7.attention.self.query.bias', 'embed_pooler.encoder.layer.7.attention.self.query.weight', 'embed_pooler.encoder.layer.7.attention.self.value.bias', 'embed_pooler.encoder.layer.7.attention.self.value.weight', 'embed_pooler.encoder.layer.7.intermediate.dense.bias', 'embed_pooler.encoder.layer.7.intermediate.dense.weight', 'embed_pooler.encoder.layer.7.output.LayerNorm.bias', 'embed_pooler.encoder.layer.7.output.LayerNorm.weight', 'embed_pooler.encoder.layer.7.output.dense.bias', 'embed_pooler.encoder.layer.7.output.dense.weight', 'embed_pooler.encoder.layer.8.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.8.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.8.attention.output.dense.bias', 'embed_pooler.encoder.layer.8.attention.output.dense.weight', 'embed_pooler.encoder.layer.8.attention.self.key.bias', 'embed_pooler.encoder.layer.8.attention.self.key.weight', 'embed_pooler.encoder.layer.8.attention.self.query.bias', 'embed_pooler.encoder.layer.8.attention.self.query.weight', 'embed_pooler.encoder.layer.8.attention.self.value.bias', 'embed_pooler.encoder.layer.8.attention.self.value.weight', 'embed_pooler.encoder.layer.8.intermediate.dense.bias', 'embed_pooler.encoder.layer.8.intermediate.dense.weight', 'embed_pooler.encoder.layer.8.output.LayerNorm.bias', 'embed_pooler.encoder.layer.8.output.LayerNorm.weight', 'embed_pooler.encoder.layer.8.output.dense.bias', 'embed_pooler.encoder.layer.8.output.dense.weight', 'embed_pooler.encoder.layer.9.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.9.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.9.attention.output.dense.bias', 'embed_pooler.encoder.layer.9.attention.output.dense.weight', 'embed_pooler.encoder.layer.9.attention.self.key.bias', 'embed_pooler.encoder.layer.9.attention.self.key.weight', 'embed_pooler.encoder.layer.9.attention.self.query.bias', 'embed_pooler.encoder.layer.9.attention.self.query.weight', 'embed_pooler.encoder.layer.9.attention.self.value.bias', 'embed_pooler.encoder.layer.9.attention.self.value.weight', 'embed_pooler.encoder.layer.9.intermediate.dense.bias', 'embed_pooler.encoder.layer.9.intermediate.dense.weight', 'embed_pooler.encoder.layer.9.output.LayerNorm.bias', 'embed_pooler.encoder.layer.9.output.LayerNorm.weight', 'embed_pooler.encoder.layer.9.output.dense.bias', 'embed_pooler.encoder.layer.9.output.dense.weight', 'embed_pooler.model.embeddings.LayerNorm.bias', 'embed_pooler.model.embeddings.LayerNorm.weight', 'embed_pooler.model.embeddings.position_embeddings.weight', 'embed_pooler.model.embeddings.token_type_embeddings.weight', 'embed_pooler.model.embeddings.word_embeddings.weight', 'embed_pooler.model.encoder.layer.0.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.0.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.0.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.0.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.0.attention.self.key.bias', 'embed_pooler.model.encoder.layer.0.attention.self.key.weight', 'embed_pooler.model.encoder.layer.0.attention.self.query.bias', 'embed_pooler.model.encoder.layer.0.attention.self.query.weight', 'embed_pooler.model.encoder.layer.0.attention.self.value.bias', 'embed_pooler.model.encoder.layer.0.attention.self.value.weight', 'embed_pooler.model.encoder.layer.0.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.0.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.0.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.0.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.0.output.dense.bias', 'embed_pooler.model.encoder.layer.0.output.dense.weight', 'embed_pooler.model.encoder.layer.1.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.1.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.1.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.1.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.1.attention.self.key.bias', 'embed_pooler.model.encoder.layer.1.attention.self.key.weight', 'embed_pooler.model.encoder.layer.1.attention.self.query.bias', 'embed_pooler.model.encoder.layer.1.attention.self.query.weight', 'embed_pooler.model.encoder.layer.1.attention.self.value.bias', 'embed_pooler.model.encoder.layer.1.attention.self.value.weight', 'embed_pooler.model.encoder.layer.1.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.1.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.1.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.1.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.1.output.dense.bias', 'embed_pooler.model.encoder.layer.1.output.dense.weight', 'embed_pooler.model.encoder.layer.10.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.10.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.10.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.10.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.10.attention.self.key.bias', 'embed_pooler.model.encoder.layer.10.attention.self.key.weight', 'embed_pooler.model.encoder.layer.10.attention.self.query.bias', 'embed_pooler.model.encoder.layer.10.attention.self.query.weight', 'embed_pooler.model.encoder.layer.10.attention.self.value.bias', 'embed_pooler.model.encoder.layer.10.attention.self.value.weight', 'embed_pooler.model.encoder.layer.10.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.10.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.10.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.10.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.10.output.dense.bias', 'embed_pooler.model.encoder.layer.10.output.dense.weight', 'embed_pooler.model.encoder.layer.11.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.11.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.11.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.11.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.11.attention.self.key.bias', 'embed_pooler.model.encoder.layer.11.attention.self.key.weight', 'embed_pooler.model.encoder.layer.11.attention.self.query.bias', 'embed_pooler.model.encoder.layer.11.attention.self.query.weight', 'embed_pooler.model.encoder.layer.11.attention.self.value.bias', 'embed_pooler.model.encoder.layer.11.attention.self.value.weight', 'embed_pooler.model.encoder.layer.11.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.11.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.11.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.11.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.11.output.dense.bias', 'embed_pooler.model.encoder.layer.11.output.dense.weight', 'embed_pooler.model.encoder.layer.2.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.2.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.2.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.2.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.2.attention.self.key.bias', 'embed_pooler.model.encoder.layer.2.attention.self.key.weight', 'embed_pooler.model.encoder.layer.2.attention.self.query.bias', 'embed_pooler.model.encoder.layer.2.attention.self.query.weight', 'embed_pooler.model.encoder.layer.2.attention.self.value.bias', 'embed_pooler.model.encoder.layer.2.attention.self.value.weight', 'embed_pooler.model.encoder.layer.2.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.2.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.2.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.2.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.2.output.dense.bias', 'embed_pooler.model.encoder.layer.2.output.dense.weight', 'embed_pooler.model.encoder.layer.3.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.3.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.3.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.3.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.3.attention.self.key.bias', 'embed_pooler.model.encoder.layer.3.attention.self.key.weight', 'embed_pooler.model.encoder.layer.3.attention.self.query.bias', 'embed_pooler.model.encoder.layer.3.attention.self.query.weight', 'embed_pooler.model.encoder.layer.3.attention.self.value.bias', 'embed_pooler.model.encoder.layer.3.attention.self.value.weight', 'embed_pooler.model.encoder.layer.3.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.3.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.3.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.3.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.3.output.dense.bias', 'embed_pooler.model.encoder.layer.3.output.dense.weight', 'embed_pooler.model.encoder.layer.4.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.4.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.4.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.4.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.4.attention.self.key.bias', 'embed_pooler.model.encoder.layer.4.attention.self.key.weight', 'embed_pooler.model.encoder.layer.4.attention.self.query.bias', 'embed_pooler.model.encoder.layer.4.attention.self.query.weight', 'embed_pooler.model.encoder.layer.4.attention.self.value.bias', 'embed_pooler.model.encoder.layer.4.attention.self.value.weight', 'embed_pooler.model.encoder.layer.4.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.4.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.4.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.4.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.4.output.dense.bias', 'embed_pooler.model.encoder.layer.4.output.dense.weight', 'embed_pooler.model.encoder.layer.5.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.5.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.5.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.5.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.5.attention.self.key.bias', 'embed_pooler.model.encoder.layer.5.attention.self.key.weight', 'embed_pooler.model.encoder.layer.5.attention.self.query.bias', 'embed_pooler.model.encoder.layer.5.attention.self.query.weight', 'embed_pooler.model.encoder.layer.5.attention.self.value.bias', 'embed_pooler.model.encoder.layer.5.attention.self.value.weight', 'embed_pooler.model.encoder.layer.5.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.5.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.5.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.5.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.5.output.dense.bias', 'embed_pooler.model.encoder.layer.5.output.dense.weight', 'embed_pooler.model.encoder.layer.6.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.6.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.6.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.6.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.6.attention.self.key.bias', 'embed_pooler.model.encoder.layer.6.attention.self.key.weight', 'embed_pooler.model.encoder.layer.6.attention.self.query.bias', 'embed_pooler.model.encoder.layer.6.attention.self.query.weight', 'embed_pooler.model.encoder.layer.6.attention.self.value.bias', 'embed_pooler.model.encoder.layer.6.attention.self.value.weight', 'embed_pooler.model.encoder.layer.6.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.6.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.6.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.6.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.6.output.dense.bias', 'embed_pooler.model.encoder.layer.6.output.dense.weight', 'embed_pooler.model.encoder.layer.7.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.7.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.7.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.7.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.7.attention.self.key.bias', 'embed_pooler.model.encoder.layer.7.attention.self.key.weight', 'embed_pooler.model.encoder.layer.7.attention.self.query.bias', 'embed_pooler.model.encoder.layer.7.attention.self.query.weight', 'embed_pooler.model.encoder.layer.7.attention.self.value.bias', 'embed_pooler.model.encoder.layer.7.attention.self.value.weight', 'embed_pooler.model.encoder.layer.7.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.7.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.7.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.7.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.7.output.dense.bias', 'embed_pooler.model.encoder.layer.7.output.dense.weight', 'embed_pooler.model.encoder.layer.8.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.8.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.8.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.8.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.8.attention.self.key.bias', 'embed_pooler.model.encoder.layer.8.attention.self.key.weight', 'embed_pooler.model.encoder.layer.8.attention.self.query.bias', 'embed_pooler.model.encoder.layer.8.attention.self.query.weight', 'embed_pooler.model.encoder.layer.8.attention.self.value.bias', 'embed_pooler.model.encoder.layer.8.attention.self.value.weight', 'embed_pooler.model.encoder.layer.8.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.8.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.8.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.8.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.8.output.dense.bias', 'embed_pooler.model.encoder.layer.8.output.dense.weight', 'embed_pooler.model.encoder.layer.9.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.9.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.9.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.9.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.9.attention.self.key.bias', 'embed_pooler.model.encoder.layer.9.attention.self.key.weight', 'embed_pooler.model.encoder.layer.9.attention.self.query.bias', 'embed_pooler.model.encoder.layer.9.attention.self.query.weight', 'embed_pooler.model.encoder.layer.9.attention.self.value.bias', 'embed_pooler.model.encoder.layer.9.attention.self.value.weight', 'embed_pooler.model.encoder.layer.9.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.9.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.9.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.9.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.9.output.dense.bias', 'embed_pooler.model.encoder.layer.9.output.dense.weight', 'embed_pooler.model.pooler.dense.bias', 'embed_pooler.model.pooler.dense.weight', 'embed_pooler.pooler.dense.bias', 'embed_pooler.pooler.dense.weight', 'pooler_embeds.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from hidden_capacity_reasoning.models import (\n",
    "    Qwen2ForCausalLMCompressionV3,\n",
    "    EmdeddingCompressorConfigV1,\n",
    ")\n",
    "from transformers import Qwen2Config, RobertaConfig\n",
    "\n",
    "# config = EmdeddingCompressorConfigV1()\n",
    "config = Qwen2Config.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "config.pooler = RobertaConfig(\n",
    "    hidden_size=1536,\n",
    ")\n",
    "# config.pad_token_id = tokenizer.pad_token_id\n",
    "# new_model = Qwen2ForCausalLMCompressionV3.from_pretrained(\n",
    "new_model = Qwen2ForCausalLMCompressionV3.from_pretrained(\n",
    "    \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    config=config,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    # **config,\n",
    "    # \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e64bd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLMCompressionV3(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1536)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "          (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
       "          (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (up_proj): Linear(in_features=1536, out_features=8960, bias=False)\n",
       "          (down_proj): Linear(in_features=8960, out_features=1536, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
       "  (embed_pooler): RobertaModelEmbedPoolerV1(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1536, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 1536, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 1536)\n",
       "      (LayerNorm): LayerNorm((1536,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (key): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (value): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "            (LayerNorm): LayerNorm((1536,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (model): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1536, padding_idx=1)\n",
       "        (position_embeddings): Embedding(512, 1536, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(2, 1536)\n",
       "        (LayerNorm): LayerNorm((1536,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (key): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (value): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "                (LayerNorm): LayerNorm((1536,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=1536, bias=True)\n",
       "              (LayerNorm): LayerNorm((1536,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler_embeds): Embedding(151936, 1536)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d492557f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['embed_pooler.embeddings.word_embeddings.weight', 'embed_pooler.embeddings.position_embeddings.weight', 'embed_pooler.embeddings.token_type_embeddings.weight', 'embed_pooler.embeddings.LayerNorm.weight', 'embed_pooler.embeddings.LayerNorm.bias', 'embed_pooler.encoder.layer.0.attention.self.query.weight', 'embed_pooler.encoder.layer.0.attention.self.query.bias', 'embed_pooler.encoder.layer.0.attention.self.key.weight', 'embed_pooler.encoder.layer.0.attention.self.key.bias', 'embed_pooler.encoder.layer.0.attention.self.value.weight', 'embed_pooler.encoder.layer.0.attention.self.value.bias', 'embed_pooler.encoder.layer.0.attention.output.dense.weight', 'embed_pooler.encoder.layer.0.attention.output.dense.bias', 'embed_pooler.encoder.layer.0.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.0.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.0.intermediate.dense.weight', 'embed_pooler.encoder.layer.0.intermediate.dense.bias', 'embed_pooler.encoder.layer.0.output.dense.weight', 'embed_pooler.encoder.layer.0.output.dense.bias', 'embed_pooler.encoder.layer.0.output.LayerNorm.weight', 'embed_pooler.encoder.layer.0.output.LayerNorm.bias', 'embed_pooler.encoder.layer.1.attention.self.query.weight', 'embed_pooler.encoder.layer.1.attention.self.query.bias', 'embed_pooler.encoder.layer.1.attention.self.key.weight', 'embed_pooler.encoder.layer.1.attention.self.key.bias', 'embed_pooler.encoder.layer.1.attention.self.value.weight', 'embed_pooler.encoder.layer.1.attention.self.value.bias', 'embed_pooler.encoder.layer.1.attention.output.dense.weight', 'embed_pooler.encoder.layer.1.attention.output.dense.bias', 'embed_pooler.encoder.layer.1.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.1.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.1.intermediate.dense.weight', 'embed_pooler.encoder.layer.1.intermediate.dense.bias', 'embed_pooler.encoder.layer.1.output.dense.weight', 'embed_pooler.encoder.layer.1.output.dense.bias', 'embed_pooler.encoder.layer.1.output.LayerNorm.weight', 'embed_pooler.encoder.layer.1.output.LayerNorm.bias', 'embed_pooler.encoder.layer.2.attention.self.query.weight', 'embed_pooler.encoder.layer.2.attention.self.query.bias', 'embed_pooler.encoder.layer.2.attention.self.key.weight', 'embed_pooler.encoder.layer.2.attention.self.key.bias', 'embed_pooler.encoder.layer.2.attention.self.value.weight', 'embed_pooler.encoder.layer.2.attention.self.value.bias', 'embed_pooler.encoder.layer.2.attention.output.dense.weight', 'embed_pooler.encoder.layer.2.attention.output.dense.bias', 'embed_pooler.encoder.layer.2.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.2.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.2.intermediate.dense.weight', 'embed_pooler.encoder.layer.2.intermediate.dense.bias', 'embed_pooler.encoder.layer.2.output.dense.weight', 'embed_pooler.encoder.layer.2.output.dense.bias', 'embed_pooler.encoder.layer.2.output.LayerNorm.weight', 'embed_pooler.encoder.layer.2.output.LayerNorm.bias', 'embed_pooler.encoder.layer.3.attention.self.query.weight', 'embed_pooler.encoder.layer.3.attention.self.query.bias', 'embed_pooler.encoder.layer.3.attention.self.key.weight', 'embed_pooler.encoder.layer.3.attention.self.key.bias', 'embed_pooler.encoder.layer.3.attention.self.value.weight', 'embed_pooler.encoder.layer.3.attention.self.value.bias', 'embed_pooler.encoder.layer.3.attention.output.dense.weight', 'embed_pooler.encoder.layer.3.attention.output.dense.bias', 'embed_pooler.encoder.layer.3.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.3.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.3.intermediate.dense.weight', 'embed_pooler.encoder.layer.3.intermediate.dense.bias', 'embed_pooler.encoder.layer.3.output.dense.weight', 'embed_pooler.encoder.layer.3.output.dense.bias', 'embed_pooler.encoder.layer.3.output.LayerNorm.weight', 'embed_pooler.encoder.layer.3.output.LayerNorm.bias', 'embed_pooler.encoder.layer.4.attention.self.query.weight', 'embed_pooler.encoder.layer.4.attention.self.query.bias', 'embed_pooler.encoder.layer.4.attention.self.key.weight', 'embed_pooler.encoder.layer.4.attention.self.key.bias', 'embed_pooler.encoder.layer.4.attention.self.value.weight', 'embed_pooler.encoder.layer.4.attention.self.value.bias', 'embed_pooler.encoder.layer.4.attention.output.dense.weight', 'embed_pooler.encoder.layer.4.attention.output.dense.bias', 'embed_pooler.encoder.layer.4.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.4.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.4.intermediate.dense.weight', 'embed_pooler.encoder.layer.4.intermediate.dense.bias', 'embed_pooler.encoder.layer.4.output.dense.weight', 'embed_pooler.encoder.layer.4.output.dense.bias', 'embed_pooler.encoder.layer.4.output.LayerNorm.weight', 'embed_pooler.encoder.layer.4.output.LayerNorm.bias', 'embed_pooler.encoder.layer.5.attention.self.query.weight', 'embed_pooler.encoder.layer.5.attention.self.query.bias', 'embed_pooler.encoder.layer.5.attention.self.key.weight', 'embed_pooler.encoder.layer.5.attention.self.key.bias', 'embed_pooler.encoder.layer.5.attention.self.value.weight', 'embed_pooler.encoder.layer.5.attention.self.value.bias', 'embed_pooler.encoder.layer.5.attention.output.dense.weight', 'embed_pooler.encoder.layer.5.attention.output.dense.bias', 'embed_pooler.encoder.layer.5.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.5.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.5.intermediate.dense.weight', 'embed_pooler.encoder.layer.5.intermediate.dense.bias', 'embed_pooler.encoder.layer.5.output.dense.weight', 'embed_pooler.encoder.layer.5.output.dense.bias', 'embed_pooler.encoder.layer.5.output.LayerNorm.weight', 'embed_pooler.encoder.layer.5.output.LayerNorm.bias', 'embed_pooler.encoder.layer.6.attention.self.query.weight', 'embed_pooler.encoder.layer.6.attention.self.query.bias', 'embed_pooler.encoder.layer.6.attention.self.key.weight', 'embed_pooler.encoder.layer.6.attention.self.key.bias', 'embed_pooler.encoder.layer.6.attention.self.value.weight', 'embed_pooler.encoder.layer.6.attention.self.value.bias', 'embed_pooler.encoder.layer.6.attention.output.dense.weight', 'embed_pooler.encoder.layer.6.attention.output.dense.bias', 'embed_pooler.encoder.layer.6.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.6.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.6.intermediate.dense.weight', 'embed_pooler.encoder.layer.6.intermediate.dense.bias', 'embed_pooler.encoder.layer.6.output.dense.weight', 'embed_pooler.encoder.layer.6.output.dense.bias', 'embed_pooler.encoder.layer.6.output.LayerNorm.weight', 'embed_pooler.encoder.layer.6.output.LayerNorm.bias', 'embed_pooler.encoder.layer.7.attention.self.query.weight', 'embed_pooler.encoder.layer.7.attention.self.query.bias', 'embed_pooler.encoder.layer.7.attention.self.key.weight', 'embed_pooler.encoder.layer.7.attention.self.key.bias', 'embed_pooler.encoder.layer.7.attention.self.value.weight', 'embed_pooler.encoder.layer.7.attention.self.value.bias', 'embed_pooler.encoder.layer.7.attention.output.dense.weight', 'embed_pooler.encoder.layer.7.attention.output.dense.bias', 'embed_pooler.encoder.layer.7.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.7.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.7.intermediate.dense.weight', 'embed_pooler.encoder.layer.7.intermediate.dense.bias', 'embed_pooler.encoder.layer.7.output.dense.weight', 'embed_pooler.encoder.layer.7.output.dense.bias', 'embed_pooler.encoder.layer.7.output.LayerNorm.weight', 'embed_pooler.encoder.layer.7.output.LayerNorm.bias', 'embed_pooler.encoder.layer.8.attention.self.query.weight', 'embed_pooler.encoder.layer.8.attention.self.query.bias', 'embed_pooler.encoder.layer.8.attention.self.key.weight', 'embed_pooler.encoder.layer.8.attention.self.key.bias', 'embed_pooler.encoder.layer.8.attention.self.value.weight', 'embed_pooler.encoder.layer.8.attention.self.value.bias', 'embed_pooler.encoder.layer.8.attention.output.dense.weight', 'embed_pooler.encoder.layer.8.attention.output.dense.bias', 'embed_pooler.encoder.layer.8.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.8.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.8.intermediate.dense.weight', 'embed_pooler.encoder.layer.8.intermediate.dense.bias', 'embed_pooler.encoder.layer.8.output.dense.weight', 'embed_pooler.encoder.layer.8.output.dense.bias', 'embed_pooler.encoder.layer.8.output.LayerNorm.weight', 'embed_pooler.encoder.layer.8.output.LayerNorm.bias', 'embed_pooler.encoder.layer.9.attention.self.query.weight', 'embed_pooler.encoder.layer.9.attention.self.query.bias', 'embed_pooler.encoder.layer.9.attention.self.key.weight', 'embed_pooler.encoder.layer.9.attention.self.key.bias', 'embed_pooler.encoder.layer.9.attention.self.value.weight', 'embed_pooler.encoder.layer.9.attention.self.value.bias', 'embed_pooler.encoder.layer.9.attention.output.dense.weight', 'embed_pooler.encoder.layer.9.attention.output.dense.bias', 'embed_pooler.encoder.layer.9.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.9.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.9.intermediate.dense.weight', 'embed_pooler.encoder.layer.9.intermediate.dense.bias', 'embed_pooler.encoder.layer.9.output.dense.weight', 'embed_pooler.encoder.layer.9.output.dense.bias', 'embed_pooler.encoder.layer.9.output.LayerNorm.weight', 'embed_pooler.encoder.layer.9.output.LayerNorm.bias', 'embed_pooler.encoder.layer.10.attention.self.query.weight', 'embed_pooler.encoder.layer.10.attention.self.query.bias', 'embed_pooler.encoder.layer.10.attention.self.key.weight', 'embed_pooler.encoder.layer.10.attention.self.key.bias', 'embed_pooler.encoder.layer.10.attention.self.value.weight', 'embed_pooler.encoder.layer.10.attention.self.value.bias', 'embed_pooler.encoder.layer.10.attention.output.dense.weight', 'embed_pooler.encoder.layer.10.attention.output.dense.bias', 'embed_pooler.encoder.layer.10.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.10.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.10.intermediate.dense.weight', 'embed_pooler.encoder.layer.10.intermediate.dense.bias', 'embed_pooler.encoder.layer.10.output.dense.weight', 'embed_pooler.encoder.layer.10.output.dense.bias', 'embed_pooler.encoder.layer.10.output.LayerNorm.weight', 'embed_pooler.encoder.layer.10.output.LayerNorm.bias', 'embed_pooler.encoder.layer.11.attention.self.query.weight', 'embed_pooler.encoder.layer.11.attention.self.query.bias', 'embed_pooler.encoder.layer.11.attention.self.key.weight', 'embed_pooler.encoder.layer.11.attention.self.key.bias', 'embed_pooler.encoder.layer.11.attention.self.value.weight', 'embed_pooler.encoder.layer.11.attention.self.value.bias', 'embed_pooler.encoder.layer.11.attention.output.dense.weight', 'embed_pooler.encoder.layer.11.attention.output.dense.bias', 'embed_pooler.encoder.layer.11.attention.output.LayerNorm.weight', 'embed_pooler.encoder.layer.11.attention.output.LayerNorm.bias', 'embed_pooler.encoder.layer.11.intermediate.dense.weight', 'embed_pooler.encoder.layer.11.intermediate.dense.bias', 'embed_pooler.encoder.layer.11.output.dense.weight', 'embed_pooler.encoder.layer.11.output.dense.bias', 'embed_pooler.encoder.layer.11.output.LayerNorm.weight', 'embed_pooler.encoder.layer.11.output.LayerNorm.bias', 'embed_pooler.pooler.dense.weight', 'embed_pooler.pooler.dense.bias', 'embed_pooler.model.embeddings.word_embeddings.weight', 'embed_pooler.model.embeddings.position_embeddings.weight', 'embed_pooler.model.embeddings.token_type_embeddings.weight', 'embed_pooler.model.embeddings.LayerNorm.weight', 'embed_pooler.model.embeddings.LayerNorm.bias', 'embed_pooler.model.encoder.layer.0.attention.self.query.weight', 'embed_pooler.model.encoder.layer.0.attention.self.query.bias', 'embed_pooler.model.encoder.layer.0.attention.self.key.weight', 'embed_pooler.model.encoder.layer.0.attention.self.key.bias', 'embed_pooler.model.encoder.layer.0.attention.self.value.weight', 'embed_pooler.model.encoder.layer.0.attention.self.value.bias', 'embed_pooler.model.encoder.layer.0.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.0.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.0.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.0.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.0.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.0.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.0.output.dense.weight', 'embed_pooler.model.encoder.layer.0.output.dense.bias', 'embed_pooler.model.encoder.layer.0.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.0.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.1.attention.self.query.weight', 'embed_pooler.model.encoder.layer.1.attention.self.query.bias', 'embed_pooler.model.encoder.layer.1.attention.self.key.weight', 'embed_pooler.model.encoder.layer.1.attention.self.key.bias', 'embed_pooler.model.encoder.layer.1.attention.self.value.weight', 'embed_pooler.model.encoder.layer.1.attention.self.value.bias', 'embed_pooler.model.encoder.layer.1.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.1.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.1.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.1.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.1.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.1.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.1.output.dense.weight', 'embed_pooler.model.encoder.layer.1.output.dense.bias', 'embed_pooler.model.encoder.layer.1.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.1.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.2.attention.self.query.weight', 'embed_pooler.model.encoder.layer.2.attention.self.query.bias', 'embed_pooler.model.encoder.layer.2.attention.self.key.weight', 'embed_pooler.model.encoder.layer.2.attention.self.key.bias', 'embed_pooler.model.encoder.layer.2.attention.self.value.weight', 'embed_pooler.model.encoder.layer.2.attention.self.value.bias', 'embed_pooler.model.encoder.layer.2.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.2.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.2.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.2.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.2.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.2.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.2.output.dense.weight', 'embed_pooler.model.encoder.layer.2.output.dense.bias', 'embed_pooler.model.encoder.layer.2.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.2.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.3.attention.self.query.weight', 'embed_pooler.model.encoder.layer.3.attention.self.query.bias', 'embed_pooler.model.encoder.layer.3.attention.self.key.weight', 'embed_pooler.model.encoder.layer.3.attention.self.key.bias', 'embed_pooler.model.encoder.layer.3.attention.self.value.weight', 'embed_pooler.model.encoder.layer.3.attention.self.value.bias', 'embed_pooler.model.encoder.layer.3.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.3.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.3.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.3.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.3.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.3.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.3.output.dense.weight', 'embed_pooler.model.encoder.layer.3.output.dense.bias', 'embed_pooler.model.encoder.layer.3.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.3.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.4.attention.self.query.weight', 'embed_pooler.model.encoder.layer.4.attention.self.query.bias', 'embed_pooler.model.encoder.layer.4.attention.self.key.weight', 'embed_pooler.model.encoder.layer.4.attention.self.key.bias', 'embed_pooler.model.encoder.layer.4.attention.self.value.weight', 'embed_pooler.model.encoder.layer.4.attention.self.value.bias', 'embed_pooler.model.encoder.layer.4.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.4.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.4.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.4.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.4.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.4.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.4.output.dense.weight', 'embed_pooler.model.encoder.layer.4.output.dense.bias', 'embed_pooler.model.encoder.layer.4.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.4.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.5.attention.self.query.weight', 'embed_pooler.model.encoder.layer.5.attention.self.query.bias', 'embed_pooler.model.encoder.layer.5.attention.self.key.weight', 'embed_pooler.model.encoder.layer.5.attention.self.key.bias', 'embed_pooler.model.encoder.layer.5.attention.self.value.weight', 'embed_pooler.model.encoder.layer.5.attention.self.value.bias', 'embed_pooler.model.encoder.layer.5.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.5.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.5.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.5.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.5.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.5.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.5.output.dense.weight', 'embed_pooler.model.encoder.layer.5.output.dense.bias', 'embed_pooler.model.encoder.layer.5.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.5.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.6.attention.self.query.weight', 'embed_pooler.model.encoder.layer.6.attention.self.query.bias', 'embed_pooler.model.encoder.layer.6.attention.self.key.weight', 'embed_pooler.model.encoder.layer.6.attention.self.key.bias', 'embed_pooler.model.encoder.layer.6.attention.self.value.weight', 'embed_pooler.model.encoder.layer.6.attention.self.value.bias', 'embed_pooler.model.encoder.layer.6.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.6.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.6.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.6.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.6.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.6.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.6.output.dense.weight', 'embed_pooler.model.encoder.layer.6.output.dense.bias', 'embed_pooler.model.encoder.layer.6.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.6.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.7.attention.self.query.weight', 'embed_pooler.model.encoder.layer.7.attention.self.query.bias', 'embed_pooler.model.encoder.layer.7.attention.self.key.weight', 'embed_pooler.model.encoder.layer.7.attention.self.key.bias', 'embed_pooler.model.encoder.layer.7.attention.self.value.weight', 'embed_pooler.model.encoder.layer.7.attention.self.value.bias', 'embed_pooler.model.encoder.layer.7.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.7.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.7.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.7.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.7.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.7.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.7.output.dense.weight', 'embed_pooler.model.encoder.layer.7.output.dense.bias', 'embed_pooler.model.encoder.layer.7.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.7.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.8.attention.self.query.weight', 'embed_pooler.model.encoder.layer.8.attention.self.query.bias', 'embed_pooler.model.encoder.layer.8.attention.self.key.weight', 'embed_pooler.model.encoder.layer.8.attention.self.key.bias', 'embed_pooler.model.encoder.layer.8.attention.self.value.weight', 'embed_pooler.model.encoder.layer.8.attention.self.value.bias', 'embed_pooler.model.encoder.layer.8.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.8.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.8.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.8.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.8.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.8.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.8.output.dense.weight', 'embed_pooler.model.encoder.layer.8.output.dense.bias', 'embed_pooler.model.encoder.layer.8.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.8.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.9.attention.self.query.weight', 'embed_pooler.model.encoder.layer.9.attention.self.query.bias', 'embed_pooler.model.encoder.layer.9.attention.self.key.weight', 'embed_pooler.model.encoder.layer.9.attention.self.key.bias', 'embed_pooler.model.encoder.layer.9.attention.self.value.weight', 'embed_pooler.model.encoder.layer.9.attention.self.value.bias', 'embed_pooler.model.encoder.layer.9.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.9.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.9.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.9.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.9.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.9.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.9.output.dense.weight', 'embed_pooler.model.encoder.layer.9.output.dense.bias', 'embed_pooler.model.encoder.layer.9.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.9.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.10.attention.self.query.weight', 'embed_pooler.model.encoder.layer.10.attention.self.query.bias', 'embed_pooler.model.encoder.layer.10.attention.self.key.weight', 'embed_pooler.model.encoder.layer.10.attention.self.key.bias', 'embed_pooler.model.encoder.layer.10.attention.self.value.weight', 'embed_pooler.model.encoder.layer.10.attention.self.value.bias', 'embed_pooler.model.encoder.layer.10.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.10.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.10.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.10.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.10.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.10.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.10.output.dense.weight', 'embed_pooler.model.encoder.layer.10.output.dense.bias', 'embed_pooler.model.encoder.layer.10.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.10.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.11.attention.self.query.weight', 'embed_pooler.model.encoder.layer.11.attention.self.query.bias', 'embed_pooler.model.encoder.layer.11.attention.self.key.weight', 'embed_pooler.model.encoder.layer.11.attention.self.key.bias', 'embed_pooler.model.encoder.layer.11.attention.self.value.weight', 'embed_pooler.model.encoder.layer.11.attention.self.value.bias', 'embed_pooler.model.encoder.layer.11.attention.output.dense.weight', 'embed_pooler.model.encoder.layer.11.attention.output.dense.bias', 'embed_pooler.model.encoder.layer.11.attention.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.11.attention.output.LayerNorm.bias', 'embed_pooler.model.encoder.layer.11.intermediate.dense.weight', 'embed_pooler.model.encoder.layer.11.intermediate.dense.bias', 'embed_pooler.model.encoder.layer.11.output.dense.weight', 'embed_pooler.model.encoder.layer.11.output.dense.bias', 'embed_pooler.model.encoder.layer.11.output.LayerNorm.weight', 'embed_pooler.model.encoder.layer.11.output.LayerNorm.bias', 'embed_pooler.model.pooler.dense.weight', 'embed_pooler.model.pooler.dense.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(model.state_dict(), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd32a3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "new_model.save_pretrained(\"r1_compressor_v4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
